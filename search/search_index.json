{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PyhDToolkit \u267b\ufe0f An all-in-one package for Python work in my PhD \u267b\ufe0f Link to documentation . License Copyright \u00a9 2019 Felix Soubelet. MIT License","title":"Home"},{"location":"#license","text":"Copyright \u00a9 2019 Felix Soubelet. MIT License","title":"License"},{"location":"docs/About_PyhDToolkit/","text":"About PyhDToolkit Purpose This package is an all-in-one collection of baseline utilities I use in my PhD work. Most of the codes here have their use in my day-to-day work, but not necessarily in our team's softwares. Functionality For now, PyhDToolkit provides some of the following features: A cpymadtools module with tools to integrate with cpymad , a Python bindings library for the MAD-X code; including generators, matching routines, plotting utilities etc. A maths module to incorporate useful methods used in analysis. An optics module for particle accelerator physics related calculations and analysis. A plotting module for my favorite defaults and helpers. A tfstools module similar to cpymadtools , with functionality revolving around handling tfs files and plotting their contents. A utils module for various Python and UNIX utilities. Roadmap In addition to developping current modules, more will be added to better incorporate with the workhorse softwares of the OMC team, notably tfs-pandas and omc3 . Foreseen development includes: Expansion of the optics module to include most simple calculations on beam properties. Expansion of the cpymadtools with utilities as their needs arise in my studies. A sixtracklibtools module for utility functions surrounding the use of sixtracklib , eventually.","title":"About"},{"location":"docs/About_PyhDToolkit/#about-pyhdtoolkit","text":"","title":"About PyhDToolkit"},{"location":"docs/About_PyhDToolkit/#purpose","text":"This package is an all-in-one collection of baseline utilities I use in my PhD work. Most of the codes here have their use in my day-to-day work, but not necessarily in our team's softwares.","title":"Purpose"},{"location":"docs/About_PyhDToolkit/#functionality","text":"For now, PyhDToolkit provides some of the following features: A cpymadtools module with tools to integrate with cpymad , a Python bindings library for the MAD-X code; including generators, matching routines, plotting utilities etc. A maths module to incorporate useful methods used in analysis. An optics module for particle accelerator physics related calculations and analysis. A plotting module for my favorite defaults and helpers. A tfstools module similar to cpymadtools , with functionality revolving around handling tfs files and plotting their contents. A utils module for various Python and UNIX utilities.","title":"Functionality"},{"location":"docs/About_PyhDToolkit/#roadmap","text":"In addition to developping current modules, more will be added to better incorporate with the workhorse softwares of the OMC team, notably tfs-pandas and omc3 . Foreseen development includes: Expansion of the optics module to include most simple calculations on beam properties. Expansion of the cpymadtools with utilities as their needs arise in my studies. A sixtracklibtools module for utility functions surrounding the use of sixtracklib , eventually.","title":"Roadmap"},{"location":"docs/Getting_Started/","text":"Getting Started Installation This code is compatible with Python 3.7+ . There are two possible methods for using this package: either as a Python package with pip , or as a Docker image. With pip You can now install this simply in a virtual environment with: > pip install pyhdtoolkit Installation in a virtual environment Don't know what a virtual environment is or how to set it up? Here is a good primer on virtual environments by RealPython. How about a development environment? Sure thing. This repository uses Poetry as a packaging and build tool. To set yourself up, get a local copy through VCS and run: poetry install This repository follows the Google docstring format, uses Black as a code formatter with a default enforced line length of 100 characters, and Pylint as a linter. You can format the code with make format and lint it (which will format first) with make lint . Testing builds are ensured after each commit through Github Actions. You can run tests locally with the predefined make tests , or through poetry run pytest <options> for customized options. How can I easily reproduce your research done with this? This repository comes with an environment.yml file to reproduce my work conda environment, feel free to use it. If you checked out from version control, you can install this environment and add it to your ipython kernel by running make condaenv . You can also make use of a fully-fetched one through Docker as explained below. With Docker Docker provides an easy way to get access to a fully-fledged environment identical to the one I use, for reproducibility of my results. You can directly pull a pre-built image from Dockerhub (with tag latest being an automated build) with: > docker pull fsoubelet/simenv You can then run a server from within the container and bind a local directory to work on. Assuming you pulled the provided image from Dockerhub, run a jupyterlab server on port 8888 with the command: > docker run --rm -p 8888 :8888 -e JUPYTER_ENABLE_LAB = yes -v <host_dir_to_mount>:/home/jovyan/work fsoubelet/simenv Any jupyter notebook or Python files in the mounted directory can then be used / ran with an environment identical to mine.","title":"Getting Started"},{"location":"docs/Getting_Started/#getting-started","text":"","title":"Getting Started"},{"location":"docs/Getting_Started/#installation","text":"This code is compatible with Python 3.7+ . There are two possible methods for using this package: either as a Python package with pip , or as a Docker image.","title":"Installation"},{"location":"docs/Getting_Started/#with-pip","text":"You can now install this simply in a virtual environment with: > pip install pyhdtoolkit Installation in a virtual environment Don't know what a virtual environment is or how to set it up? Here is a good primer on virtual environments by RealPython. How about a development environment? Sure thing. This repository uses Poetry as a packaging and build tool. To set yourself up, get a local copy through VCS and run: poetry install This repository follows the Google docstring format, uses Black as a code formatter with a default enforced line length of 100 characters, and Pylint as a linter. You can format the code with make format and lint it (which will format first) with make lint . Testing builds are ensured after each commit through Github Actions. You can run tests locally with the predefined make tests , or through poetry run pytest <options> for customized options. How can I easily reproduce your research done with this? This repository comes with an environment.yml file to reproduce my work conda environment, feel free to use it. If you checked out from version control, you can install this environment and add it to your ipython kernel by running make condaenv . You can also make use of a fully-fetched one through Docker as explained below.","title":"With pip"},{"location":"docs/Getting_Started/#with-docker","text":"Docker provides an easy way to get access to a fully-fledged environment identical to the one I use, for reproducibility of my results. You can directly pull a pre-built image from Dockerhub (with tag latest being an automated build) with: > docker pull fsoubelet/simenv You can then run a server from within the container and bind a local directory to work on. Assuming you pulled the provided image from Dockerhub, run a jupyterlab server on port 8888 with the command: > docker run --rm -p 8888 :8888 -e JUPYTER_ENABLE_LAB = yes -v <host_dir_to_mount>:/home/jovyan/work fsoubelet/simenv Any jupyter notebook or Python files in the mounted directory can then be used / ran with an environment identical to mine.","title":"With Docker"},{"location":"reference/pyhdtoolkit/","text":"Module pyhdtoolkit pyhdtoolkit Library ~ ~ ~ ~ ~ ~ ~ pyhdtoolkit is a utility library, written in Python, for my PhD needs. Mainly particle accelerator physics studies and plotting. View Source \"\"\" pyhdtoolkit Library ~~~~~~~~~~~~~~~~~~~ pyhdtoolkit is a utility library, written in Python, for my PhD needs. Mainly particle accelerator physics studies and plotting. :copyright: (c) 2019-2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" # Set default logging handler to avoid \"No handler found\" warnings. __title__ = \"pyhdtoolkit\" __description__ = \"An all-in-one toolkit package to easy my Python work in my PhD.\" __url__ = \"https://github.com/fsoubelet/PyhDToolkit\" __version__ = \"0.8.4\" __author__ = \"Felix Soubelet\" __author_email__ = \"felix.soubelet@cern.ch\" __license__ = \"MIT\" Sub-modules pyhdtoolkit.cpymadtools pyhdtoolkit.maths pyhdtoolkit.optics pyhdtoolkit.plotting pyhdtoolkit.tfstools pyhdtoolkit.utils","title":"Index"},{"location":"reference/pyhdtoolkit/#module-pyhdtoolkit","text":"pyhdtoolkit Library ~ ~ ~ ~ ~ ~ ~ pyhdtoolkit is a utility library, written in Python, for my PhD needs. Mainly particle accelerator physics studies and plotting. View Source \"\"\" pyhdtoolkit Library ~~~~~~~~~~~~~~~~~~~ pyhdtoolkit is a utility library, written in Python, for my PhD needs. Mainly particle accelerator physics studies and plotting. :copyright: (c) 2019-2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" # Set default logging handler to avoid \"No handler found\" warnings. __title__ = \"pyhdtoolkit\" __description__ = \"An all-in-one toolkit package to easy my Python work in my PhD.\" __url__ = \"https://github.com/fsoubelet/PyhDToolkit\" __version__ = \"0.8.4\" __author__ = \"Felix Soubelet\" __author_email__ = \"felix.soubelet@cern.ch\" __license__ = \"MIT\"","title":"Module pyhdtoolkit"},{"location":"reference/pyhdtoolkit/#sub-modules","text":"pyhdtoolkit.cpymadtools pyhdtoolkit.maths pyhdtoolkit.optics pyhdtoolkit.plotting pyhdtoolkit.tfstools pyhdtoolkit.utils","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/cpymadtools/","text":"Module pyhdtoolkit.cpymadtools cpymadtools package ~ ~ ~ ~ ~ ~ ~ cpymadtools is a collection of utilities that integrate within my workflow with the cpymad library. View Source \"\"\" cpymadtools package ~~~~~~~~~~~~~~~~~~~ cpymadtools is a collection of utilities that integrate within my workflow with the `cpymad` library. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .errors import switch_magnetic_errors from .generators import LatticeGenerator from .latwiss import plot_latwiss , plot_machine_survey from .matching import get_closest_tune_approach , get_lhc_tune_and_chroma_knobs , match_tunes_and_chromaticities from .orbit import get_current_orbit_setup , lhc_orbit_variables , setup_lhc_orbit from .parameters import beam_parameters from .plotters import AperturePlotter , DynamicAperturePlotter , PhaseSpacePlotter , TuneDiagramPlotter from .ptc import get_amplitude_detuning , get_rdts from .special import ( apply_lhc_colinearity_knob , apply_lhc_coupling_knob , apply_lhc_rigidity_waist_shift_knob , deactivate_lhc_arc_sextupoles , get_ips_twiss , get_ir_twiss , install_ac_dipole , make_lhc_beams , make_lhc_thin , make_sixtrack_output , power_landau_octupoles , ) from .track import track_single_particle from .twiss import get_pattern_twiss Sub-modules pyhdtoolkit.cpymadtools.constants pyhdtoolkit.cpymadtools.errors pyhdtoolkit.cpymadtools.generators pyhdtoolkit.cpymadtools.latwiss pyhdtoolkit.cpymadtools.matching pyhdtoolkit.cpymadtools.orbit pyhdtoolkit.cpymadtools.parameters pyhdtoolkit.cpymadtools.plotters pyhdtoolkit.cpymadtools.ptc pyhdtoolkit.cpymadtools.special pyhdtoolkit.cpymadtools.track pyhdtoolkit.cpymadtools.twiss","title":"Index"},{"location":"reference/pyhdtoolkit/cpymadtools/#module-pyhdtoolkitcpymadtools","text":"cpymadtools package ~ ~ ~ ~ ~ ~ ~ cpymadtools is a collection of utilities that integrate within my workflow with the cpymad library. View Source \"\"\" cpymadtools package ~~~~~~~~~~~~~~~~~~~ cpymadtools is a collection of utilities that integrate within my workflow with the `cpymad` library. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .errors import switch_magnetic_errors from .generators import LatticeGenerator from .latwiss import plot_latwiss , plot_machine_survey from .matching import get_closest_tune_approach , get_lhc_tune_and_chroma_knobs , match_tunes_and_chromaticities from .orbit import get_current_orbit_setup , lhc_orbit_variables , setup_lhc_orbit from .parameters import beam_parameters from .plotters import AperturePlotter , DynamicAperturePlotter , PhaseSpacePlotter , TuneDiagramPlotter from .ptc import get_amplitude_detuning , get_rdts from .special import ( apply_lhc_colinearity_knob , apply_lhc_coupling_knob , apply_lhc_rigidity_waist_shift_knob , deactivate_lhc_arc_sextupoles , get_ips_twiss , get_ir_twiss , install_ac_dipole , make_lhc_beams , make_lhc_thin , make_sixtrack_output , power_landau_octupoles , ) from .track import track_single_particle from .twiss import get_pattern_twiss","title":"Module pyhdtoolkit.cpymadtools"},{"location":"reference/pyhdtoolkit/cpymadtools/#sub-modules","text":"pyhdtoolkit.cpymadtools.constants pyhdtoolkit.cpymadtools.errors pyhdtoolkit.cpymadtools.generators pyhdtoolkit.cpymadtools.latwiss pyhdtoolkit.cpymadtools.matching pyhdtoolkit.cpymadtools.orbit pyhdtoolkit.cpymadtools.parameters pyhdtoolkit.cpymadtools.plotters pyhdtoolkit.cpymadtools.ptc pyhdtoolkit.cpymadtools.special pyhdtoolkit.cpymadtools.track pyhdtoolkit.cpymadtools.twiss","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/cpymadtools/constants/","text":"Module pyhdtoolkit.cpymadtools.constants Module cpymadtools.constants Created on 2020.02.02 View Source \"\"\" Module cpymadtools.constants ---------------------------- Created on 2020.02.02 :author: Felix Soubelet (felix.soubelet@cern.ch) Specific constants to be used in cpymadtools functions, to help with consistency. \"\"\" DEFAULT_TWISS_COLUMNS = [ \"name\" , \"s\" , \"x\" , \"y\" , \"px\" , \"py\" , \"betx\" , \"bety\" , \"alfx\" , \"alfy\" , \"dx\" , \"dy\" , \"mux\" , \"muy\" , \"r11\" , \"r12\" , \"r21\" , \"r22\" , \"beta11\" , \"beta12\" , \"beta21\" , \"beta22\" , ] LHC_CROSSING_SCHEMES = { \"flat\" : {}, \"lhc_inj\" : { \"on_x1\" : - 170 , \"on_sep1\" : - 2 , \"on_x2\" : 170 , \"on_sep2\" : 3.5 , \"on_x5\" : 170 , \"on_sep5\" : 2 , \"on_x8\" : - 170 , \"on_sep8\" : - 3.5 , \"phi_IR1\" : 90 , \"phi_IR5\" : 0 , }, \"lhc_top\" : { \"on_x1\" : - 160 , \"on_sep1\" : - 0.55 , \"on_x2\" : 200 , \"on_sep2\" : 1.4 , \"on_x5\" : 160 , \"on_sep5\" : 0.55 , \"on_oh5\" : - 1.8 , \"on_x8\" : - 250 , \"on_sep8\" : - 1 , \"phi_IR1\" : 90 , \"phi_IR5\" : 0 , }, \"hllhc_inj\" : { \"on_x1\" : 295 , \"on_sep1\" : - 2 , \"on_x2\" : 170 , \"on_sep2\" : 3.5 , \"on_x5\" : 295 , \"on_sep5\" : 2 , \"on_x8\" : - 170 , \"on_sep8\" : - 3.5 , # phis should be set by optics }, \"hllhc_top\" : { \"on_x1\" : 250 , \"on_sep1\" : - 0.75 , # 0.55 \"on_x2\" : 170 , \"on_sep2\" : 1 , # 1.4 \"on_x5\" : 250 , \"on_sep5\" : 0.75 , # 0.55 # 'on_oh5': -1.8, \"on_x8\" : - 200 , # - 250 \"on_sep8\" : - 1 , \"on_crab1\" : - 190 , \"on_crab5\" : - 190 , # phis should be set by optics }, } # All values are defined as multiples of 0.3 / Energy CORRECTOR_LIMITS = { \"HLLHC\" : dict ( # MQSX1 = mvars [ 'kmax_MQSXF'], MQSX1 = 0.600 / 0.050 , # 0.6 T . m @ 50 mm in IR1&IR5 MQSX2 = 1.360 / 0.017 , # 1.36 T @ 17 mm in IR2&IR8 # MCSX1 = mvars [ 'kmax_MCSXF'], MCSX1 = 0.050 * 2 / ( 0.050 ** 2 ), # 0.050 Tm @ 50 mm in IR1&IR5 MCSX2 = 0.028 * 2 / ( 0.017 ** 2 ), # 0.028 T @ 17 mm in IR2&IR8 # MCSSX1 = mvars [ 'kmax_MCSSXF'], MCSSX1 = 0.050 * 2 / ( 0.050 ** 2 ), # 0.050 Tm @ 50 mm in IR1&IR5 MCSSX2 = 0.11 * 2 / ( 0.017 ** 2 ), # 0.11 T @ 17 mm in IR2&IR8 # MCOX1 = mvars [ 'kmax_MCOXF'], MCOX1 = 0.030 * 6 / ( 0.050 ** 3 ), # 0.030 Tm @ 50 mm in IR1&IR5 MCOX2 = 0.045 * 6 / ( 0.017 ** 3 ), # 0.045 T @ 17 mm in IR2&IR8 # MCOSX1 = mvars [ 'kmax_MCOSXF'], MCOSX1 = 0.030 * 6 / ( 0.050 ** 3 ), # 0.030 Tm @ 50 mm in IR1&IR5 MCOSX2 = 0.048 * 6 / ( 0.017 ** 3 ), # 0.048 T @ 17 mm in IR2&IR8 # MCDX1 = mvars [ 'kmax_MCDXF'], MCDX1 = 0.030 * 24 / ( 0.050 ** 4 ), # 0.030 Tm @ 50 mm in IR1&IR5 # MCDSX1 = mvars [ 'kmax_MCDSXF'], MCDSX1 = 0.030 * 24 / ( 0.050 ** 4 ), # 0.030 Tm @ 50 mm in IR1&IR5 # MCTX1 = mvars [ 'kmax_MCTXF'], MCTX1 = 0.07 * 120 / ( 0.050 ** 5 ), # 0.070 Tm @ 50 mm in IR1&IR5 MCTX2 = 0.01 * 120 / ( 0.017 ** 5 ), # 0.010 Tm @ 17 mm in IR1&IR5 # MCTSX1 = mvars [ 'kmax_MCTSXF'], MCTSX1 = 0.07 * 120 / ( 0.050 ** 5 ), # 0.070 Tm @ 50 mm in IR1&IR5 MQT = 120 , # 120 T / m MQS = 120 , # 120 T / m MS = 1.280 * 2 / ( 0.017 ** 2 ), # 1.28 T @ 17 mm MSS = 1.280 * 2 / ( 0.017 ** 2 ), # 1.28 T @ 17 mm MCS = 0.471 * 2 / ( 0.017 ** 2 ), # 0.471 T @ 17 mm MCO = 0.040 * 6 / ( 0.017 ** 3 ), # 0.04 T @ 17 mm MCD = 0.100 * 24 / ( 0.017 ** 4 ), # 0.1 T @ 17 mm MO = 0.29 * 6 / ( 0.017 ** 3 ), # 0.29 T @ 17 mm ) } FD_FAMILIES = { \"MO\" , \"MS\" , \"MQT\" } # Magnets that have F and D families TWO_FAMILIES = { \"MS\" } # Magnets that have 1 and 2 families SPECIAL_FAMILIES = { \"MQS\" } # Magnets in every second arc Variables CORRECTOR_LIMITS DEFAULT_TWISS_COLUMNS FD_FAMILIES LHC_CROSSING_SCHEMES SPECIAL_FAMILIES TWO_FAMILIES","title":"Constants"},{"location":"reference/pyhdtoolkit/cpymadtools/constants/#module-pyhdtoolkitcpymadtoolsconstants","text":"Module cpymadtools.constants Created on 2020.02.02 View Source \"\"\" Module cpymadtools.constants ---------------------------- Created on 2020.02.02 :author: Felix Soubelet (felix.soubelet@cern.ch) Specific constants to be used in cpymadtools functions, to help with consistency. \"\"\" DEFAULT_TWISS_COLUMNS = [ \"name\" , \"s\" , \"x\" , \"y\" , \"px\" , \"py\" , \"betx\" , \"bety\" , \"alfx\" , \"alfy\" , \"dx\" , \"dy\" , \"mux\" , \"muy\" , \"r11\" , \"r12\" , \"r21\" , \"r22\" , \"beta11\" , \"beta12\" , \"beta21\" , \"beta22\" , ] LHC_CROSSING_SCHEMES = { \"flat\" : {}, \"lhc_inj\" : { \"on_x1\" : - 170 , \"on_sep1\" : - 2 , \"on_x2\" : 170 , \"on_sep2\" : 3.5 , \"on_x5\" : 170 , \"on_sep5\" : 2 , \"on_x8\" : - 170 , \"on_sep8\" : - 3.5 , \"phi_IR1\" : 90 , \"phi_IR5\" : 0 , }, \"lhc_top\" : { \"on_x1\" : - 160 , \"on_sep1\" : - 0.55 , \"on_x2\" : 200 , \"on_sep2\" : 1.4 , \"on_x5\" : 160 , \"on_sep5\" : 0.55 , \"on_oh5\" : - 1.8 , \"on_x8\" : - 250 , \"on_sep8\" : - 1 , \"phi_IR1\" : 90 , \"phi_IR5\" : 0 , }, \"hllhc_inj\" : { \"on_x1\" : 295 , \"on_sep1\" : - 2 , \"on_x2\" : 170 , \"on_sep2\" : 3.5 , \"on_x5\" : 295 , \"on_sep5\" : 2 , \"on_x8\" : - 170 , \"on_sep8\" : - 3.5 , # phis should be set by optics }, \"hllhc_top\" : { \"on_x1\" : 250 , \"on_sep1\" : - 0.75 , # 0.55 \"on_x2\" : 170 , \"on_sep2\" : 1 , # 1.4 \"on_x5\" : 250 , \"on_sep5\" : 0.75 , # 0.55 # 'on_oh5': -1.8, \"on_x8\" : - 200 , # - 250 \"on_sep8\" : - 1 , \"on_crab1\" : - 190 , \"on_crab5\" : - 190 , # phis should be set by optics }, } # All values are defined as multiples of 0.3 / Energy CORRECTOR_LIMITS = { \"HLLHC\" : dict ( # MQSX1 = mvars [ 'kmax_MQSXF'], MQSX1 = 0.600 / 0.050 , # 0.6 T . m @ 50 mm in IR1&IR5 MQSX2 = 1.360 / 0.017 , # 1.36 T @ 17 mm in IR2&IR8 # MCSX1 = mvars [ 'kmax_MCSXF'], MCSX1 = 0.050 * 2 / ( 0.050 ** 2 ), # 0.050 Tm @ 50 mm in IR1&IR5 MCSX2 = 0.028 * 2 / ( 0.017 ** 2 ), # 0.028 T @ 17 mm in IR2&IR8 # MCSSX1 = mvars [ 'kmax_MCSSXF'], MCSSX1 = 0.050 * 2 / ( 0.050 ** 2 ), # 0.050 Tm @ 50 mm in IR1&IR5 MCSSX2 = 0.11 * 2 / ( 0.017 ** 2 ), # 0.11 T @ 17 mm in IR2&IR8 # MCOX1 = mvars [ 'kmax_MCOXF'], MCOX1 = 0.030 * 6 / ( 0.050 ** 3 ), # 0.030 Tm @ 50 mm in IR1&IR5 MCOX2 = 0.045 * 6 / ( 0.017 ** 3 ), # 0.045 T @ 17 mm in IR2&IR8 # MCOSX1 = mvars [ 'kmax_MCOSXF'], MCOSX1 = 0.030 * 6 / ( 0.050 ** 3 ), # 0.030 Tm @ 50 mm in IR1&IR5 MCOSX2 = 0.048 * 6 / ( 0.017 ** 3 ), # 0.048 T @ 17 mm in IR2&IR8 # MCDX1 = mvars [ 'kmax_MCDXF'], MCDX1 = 0.030 * 24 / ( 0.050 ** 4 ), # 0.030 Tm @ 50 mm in IR1&IR5 # MCDSX1 = mvars [ 'kmax_MCDSXF'], MCDSX1 = 0.030 * 24 / ( 0.050 ** 4 ), # 0.030 Tm @ 50 mm in IR1&IR5 # MCTX1 = mvars [ 'kmax_MCTXF'], MCTX1 = 0.07 * 120 / ( 0.050 ** 5 ), # 0.070 Tm @ 50 mm in IR1&IR5 MCTX2 = 0.01 * 120 / ( 0.017 ** 5 ), # 0.010 Tm @ 17 mm in IR1&IR5 # MCTSX1 = mvars [ 'kmax_MCTSXF'], MCTSX1 = 0.07 * 120 / ( 0.050 ** 5 ), # 0.070 Tm @ 50 mm in IR1&IR5 MQT = 120 , # 120 T / m MQS = 120 , # 120 T / m MS = 1.280 * 2 / ( 0.017 ** 2 ), # 1.28 T @ 17 mm MSS = 1.280 * 2 / ( 0.017 ** 2 ), # 1.28 T @ 17 mm MCS = 0.471 * 2 / ( 0.017 ** 2 ), # 0.471 T @ 17 mm MCO = 0.040 * 6 / ( 0.017 ** 3 ), # 0.04 T @ 17 mm MCD = 0.100 * 24 / ( 0.017 ** 4 ), # 0.1 T @ 17 mm MO = 0.29 * 6 / ( 0.017 ** 3 ), # 0.29 T @ 17 mm ) } FD_FAMILIES = { \"MO\" , \"MS\" , \"MQT\" } # Magnets that have F and D families TWO_FAMILIES = { \"MS\" } # Magnets that have 1 and 2 families SPECIAL_FAMILIES = { \"MQS\" } # Magnets in every second arc","title":"Module pyhdtoolkit.cpymadtools.constants"},{"location":"reference/pyhdtoolkit/cpymadtools/constants/#variables","text":"CORRECTOR_LIMITS DEFAULT_TWISS_COLUMNS FD_FAMILIES LHC_CROSSING_SCHEMES SPECIAL_FAMILIES TWO_FAMILIES","title":"Variables"},{"location":"reference/pyhdtoolkit/cpymadtools/errors/","text":"Module pyhdtoolkit.cpymadtools.errors Module cpymadtools.errors Created on 2020.02.03 View Source \"\"\" Module cpymadtools.errors ------------------------- Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to perform MAD-X errors setups and manipulatioins with a cpymad.madx.Madx object, mainly for LHC and HLLHC machines. \"\"\" from cpymad.madx import Madx from loguru import logger # ----- Utlites ----- # def switch_magnetic_errors ( madx : Madx , ** kwargs ) -> None : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Applies magnetic field orders. This will only work for LHC and HLLHC machines. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. Keyword Args: default: sets global default to this value. Defaults to `False`. AB#: sets the default for all of that order, the order being the # number. A# or B#: sets the default for systematic and random of this id. A#s, B#r etc.: sets the specific value. In all kwargs, the order # should be in the range (1...15), where 1 == dipolar field. \"\"\" logger . debug ( \"Setting magnetic errors\" ) global_default = kwargs . get ( \"default\" , False ) for order in range ( 1 , 16 ): logger . trace ( f \"Setting up for order { order } \" ) order_default = kwargs . get ( f \"AB { order : d } \" , global_default ) for ab in \"AB\" : ab_default = kwargs . get ( f \" { ab }{ order : d } \" , order_default ) for sr in \"sr\" : name = f \" { ab }{ order : d }{ sr } \" error_value = int ( kwargs . get ( name , ab_default )) logger . trace ( f \"Setting global for 'ON_ { name } ' to { error_value } \" ) madx . globals [ f \"ON_ { name } \" ] = error_value Functions switch_magnetic_errors def switch_magnetic_errors ( madx : cpymad . madx . Madx , ** kwargs ) -> None INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Applies magnetic field orders. This will only work for LHC and HLLHC machines. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. Keyword Args: None default None sets global default to this value. Defaults to False . False AB# None sets the default for all of that order, the order being the # number. None A# or B# None sets the default for systematic and random of this id. None A#s, B#r etc. None sets the specific value. In all kwargs, the order # should be in the range (1...15), where 1 == dipolar field. None View Source def switch_magnetic_errors ( madx : Madx , ** kwargs ) -> None : \" \"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Applies magnetic field orders. This will only work for LHC and HLLHC machines. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. Keyword Args: default: sets global default to this value. Defaults to `False`. AB#: sets the default for all of that order, the order being the # number. A# or B#: sets the default for systematic and random of this id. A#s, B#r etc.: sets the specific value. In all kwargs, the order # should be in the range (1...15), where 1 == dipolar field. \"\" \" logger . debug ( \"Setting magnetic errors\" ) global_default = kwargs . get ( \"default\" , False ) for order in range ( 1 , 16 ) : logger . trace ( f \"Setting up for order {order}\" ) order_default = kwargs . get ( f \"AB{order:d}\" , global_default ) for ab in \"AB\" : ab_default = kwargs . get ( f \"{ab}{order:d}\" , order_default ) for sr in \"sr\" : name = f \"{ab}{order:d}{sr}\" error_value = int ( kwargs . get ( name , ab_default )) logger . trace ( f \"Setting global for 'ON_{name}' to {error_value}\" ) madx . globals [ f \"ON_{name}\" ] = error_value","title":"Errors"},{"location":"reference/pyhdtoolkit/cpymadtools/errors/#module-pyhdtoolkitcpymadtoolserrors","text":"Module cpymadtools.errors Created on 2020.02.03 View Source \"\"\" Module cpymadtools.errors ------------------------- Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to perform MAD-X errors setups and manipulatioins with a cpymad.madx.Madx object, mainly for LHC and HLLHC machines. \"\"\" from cpymad.madx import Madx from loguru import logger # ----- Utlites ----- # def switch_magnetic_errors ( madx : Madx , ** kwargs ) -> None : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Applies magnetic field orders. This will only work for LHC and HLLHC machines. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. Keyword Args: default: sets global default to this value. Defaults to `False`. AB#: sets the default for all of that order, the order being the # number. A# or B#: sets the default for systematic and random of this id. A#s, B#r etc.: sets the specific value. In all kwargs, the order # should be in the range (1...15), where 1 == dipolar field. \"\"\" logger . debug ( \"Setting magnetic errors\" ) global_default = kwargs . get ( \"default\" , False ) for order in range ( 1 , 16 ): logger . trace ( f \"Setting up for order { order } \" ) order_default = kwargs . get ( f \"AB { order : d } \" , global_default ) for ab in \"AB\" : ab_default = kwargs . get ( f \" { ab }{ order : d } \" , order_default ) for sr in \"sr\" : name = f \" { ab }{ order : d }{ sr } \" error_value = int ( kwargs . get ( name , ab_default )) logger . trace ( f \"Setting global for 'ON_ { name } ' to { error_value } \" ) madx . globals [ f \"ON_ { name } \" ] = error_value","title":"Module pyhdtoolkit.cpymadtools.errors"},{"location":"reference/pyhdtoolkit/cpymadtools/errors/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/cpymadtools/errors/#switch_magnetic_errors","text":"def switch_magnetic_errors ( madx : cpymad . madx . Madx , ** kwargs ) -> None INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Applies magnetic field orders. This will only work for LHC and HLLHC machines. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. Keyword Args: None default None sets global default to this value. Defaults to False . False AB# None sets the default for all of that order, the order being the # number. None A# or B# None sets the default for systematic and random of this id. None A#s, B#r etc. None sets the specific value. In all kwargs, the order # should be in the range (1...15), where 1 == dipolar field. None View Source def switch_magnetic_errors ( madx : Madx , ** kwargs ) -> None : \" \"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Applies magnetic field orders. This will only work for LHC and HLLHC machines. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. Keyword Args: default: sets global default to this value. Defaults to `False`. AB#: sets the default for all of that order, the order being the # number. A# or B#: sets the default for systematic and random of this id. A#s, B#r etc.: sets the specific value. In all kwargs, the order # should be in the range (1...15), where 1 == dipolar field. \"\" \" logger . debug ( \"Setting magnetic errors\" ) global_default = kwargs . get ( \"default\" , False ) for order in range ( 1 , 16 ) : logger . trace ( f \"Setting up for order {order}\" ) order_default = kwargs . get ( f \"AB{order:d}\" , global_default ) for ab in \"AB\" : ab_default = kwargs . get ( f \"{ab}{order:d}\" , order_default ) for sr in \"sr\" : name = f \"{ab}{order:d}{sr}\" error_value = int ( kwargs . get ( name , ab_default )) logger . trace ( f \"Setting global for 'ON_{name}' to {error_value}\" ) madx . globals [ f \"ON_{name}\" ] = error_value","title":"switch_magnetic_errors"},{"location":"reference/pyhdtoolkit/cpymadtools/generators/","text":"Module pyhdtoolkit.cpymadtools.generators Module cpymadtools.generators Created on 2019.06.15 View Source \"\"\" Module cpymadtools.generators ----------------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions for generating different lattices for cpymad.madx.Madx input. \"\"\" # ----- Utlites ----- # class LatticeGenerator : \"\"\" A simple class to handle said functions. \"\"\" @staticmethod def generate_base_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_onesext_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, ks1, 0}; mod: multipole, knl:={0, 0, ks2, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_oneoct_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, 0, koct}; mod: multipole, knl:={0, 0, 0, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_tripleterrors_study_reference () -> str : \"\"\" Generate generic script for reference Twiss, to use in a `cpymad.madx.Madx` object. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 twiss; \"\"\" @staticmethod def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str : \"\"\" Generate generic script for tf_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. tf_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For field errors ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma Rr = 0.05; ! Radius for field errors (??) ON_B2R = 1; ! Activate field errors B2r = {tf_error}; ! Set field errors magnitude -> Units of B2 error (will be in 1E-4) exec, SetEfcomp_Q; ! Assign field errors !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\" @staticmethod def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str : \"\"\" Generate generic script for ms_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. ms_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet MSErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For longitudinal missalignments ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma ealign, ds := {ms_error} * 1E-3 * TGAUSS(GCUTR); ! Gaussian missalignments in meters !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\" Classes LatticeGenerator class LatticeGenerator ( / , * args , ** kwargs ) View Source class LatticeGenerator : \"\"\" A simple class to handle said functions. \"\"\" @staticmethod def generate_base_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_onesext_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, ks1, 0}; mod: multipole, knl:={0, 0, ks2, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_oneoct_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, 0, koct}; mod: multipole, knl:={0, 0, 0, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_tripleterrors_study_reference () -> str : \"\"\" Generate generic script for reference Twiss, to use in a `cpymad.madx.Madx` object. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 twiss; \"\"\" @staticmethod def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str : \"\"\" Generate generic script for tf_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. tf_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For field errors ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma Rr = 0.05; ! Radius for field errors (??) ON_B2R = 1; ! Activate field errors B2r = {tf_error}; ! Set field errors magnitude -> Units of B2 error (will be in 1E-4) exec, SetEfcomp_Q; ! Assign field errors !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\" @staticmethod def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str : \"\"\" Generate generic script for ms_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. ms_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet MSErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For longitudinal missalignments ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma ealign, ds := {ms_error} * 1E-3 * TGAUSS(GCUTR); ! Gaussian missalignments in meters !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\" Static methods generate_base_cas_lattice def generate_base_cas_lattice ( ) -> str Simple function to help unclutter the notebook. Returns: Type Description None A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_base_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" generate_oneoct_cas_lattice def generate_oneoct_cas_lattice ( ) -> str Simple function to help unclutter the notebook. Returns: Type Description None A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_oneoct_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, 0, koct}; mod: multipole, knl:={0, 0, 0, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" generate_onesext_cas_lattice def generate_onesext_cas_lattice ( ) -> str Simple function to help unclutter the notebook. Returns: Type Description None A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_onesext_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, ks1, 0}; mod: multipole, knl:={0, 0, ks2, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" generate_tripleterrors_study_mserror_job def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str Generate generic script for ms_error Twiss, to use in a cpymad.madx.Madx object. Parameters: Name Type Description Default rand_seed str the random seed to provide MAD for the errors distributions. None ms_error str the misalignment error value (along the s axis). None Returns: Type Description None A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str : \"\"\" Generate generic script for ms_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. ms_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet MSErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For longitudinal missalignments ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma ealign, ds := {ms_error} * 1E-3 * TGAUSS(GCUTR); ! Gaussian missalignments in meters !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\" generate_tripleterrors_study_reference def generate_tripleterrors_study_reference ( ) -> str Generate generic script for reference Twiss, to use in a cpymad.madx.Madx object. Returns: Type Description None A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_tripleterrors_study_reference () -> str : \"\"\" Generate generic script for reference Twiss, to use in a `cpymad.madx.Madx` object. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 twiss; \"\"\" generate_tripleterrors_study_tferror_job def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str Generate generic script for tf_error Twiss, to use in a cpymad.madx.Madx object. Parameters: Name Type Description Default rand_seed str the random seed to provide MAD for the errors distributions. None tf_error str the misalignment error value (along the s axis). None Returns: Type Description None A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str : \"\"\" Generate generic script for tf_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. tf_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For field errors ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma Rr = 0.05; ! Radius for field errors (??) ON_B2R = 1; ! Activate field errors B2r = {tf_error}; ! Set field errors magnitude -> Units of B2 error (will be in 1E-4) exec, SetEfcomp_Q; ! Assign field errors !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\"","title":"Generators"},{"location":"reference/pyhdtoolkit/cpymadtools/generators/#module-pyhdtoolkitcpymadtoolsgenerators","text":"Module cpymadtools.generators Created on 2019.06.15 View Source \"\"\" Module cpymadtools.generators ----------------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions for generating different lattices for cpymad.madx.Madx input. \"\"\" # ----- Utlites ----- # class LatticeGenerator : \"\"\" A simple class to handle said functions. \"\"\" @staticmethod def generate_base_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_onesext_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, ks1, 0}; mod: multipole, knl:={0, 0, ks2, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_oneoct_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, 0, koct}; mod: multipole, knl:={0, 0, 0, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_tripleterrors_study_reference () -> str : \"\"\" Generate generic script for reference Twiss, to use in a `cpymad.madx.Madx` object. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 twiss; \"\"\" @staticmethod def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str : \"\"\" Generate generic script for tf_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. tf_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For field errors ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma Rr = 0.05; ! Radius for field errors (??) ON_B2R = 1; ! Activate field errors B2r = {tf_error}; ! Set field errors magnitude -> Units of B2 error (will be in 1E-4) exec, SetEfcomp_Q; ! Assign field errors !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\" @staticmethod def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str : \"\"\" Generate generic script for ms_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. ms_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet MSErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For longitudinal missalignments ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma ealign, ds := {ms_error} * 1E-3 * TGAUSS(GCUTR); ! Gaussian missalignments in meters !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\"","title":"Module pyhdtoolkit.cpymadtools.generators"},{"location":"reference/pyhdtoolkit/cpymadtools/generators/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/cpymadtools/generators/#latticegenerator","text":"class LatticeGenerator ( / , * args , ** kwargs ) View Source class LatticeGenerator : \"\"\" A simple class to handle said functions. \"\"\" @staticmethod def generate_base_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_onesext_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, ks1, 0}; mod: multipole, knl:={0, 0, ks2, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_oneoct_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, 0, koct}; mod: multipole, knl:={0, 0, 0, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_tripleterrors_study_reference () -> str : \"\"\" Generate generic script for reference Twiss, to use in a `cpymad.madx.Madx` object. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 twiss; \"\"\" @staticmethod def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str : \"\"\" Generate generic script for tf_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. tf_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For field errors ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma Rr = 0.05; ! Radius for field errors (??) ON_B2R = 1; ! Activate field errors B2r = {tf_error}; ! Set field errors magnitude -> Units of B2 error (will be in 1E-4) exec, SetEfcomp_Q; ! Assign field errors !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\" @staticmethod def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str : \"\"\" Generate generic script for ms_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. ms_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet MSErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For longitudinal missalignments ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma ealign, ds := {ms_error} * 1E-3 * TGAUSS(GCUTR); ! Gaussian missalignments in meters !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\"","title":"LatticeGenerator"},{"location":"reference/pyhdtoolkit/cpymadtools/generators/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/cpymadtools/generators/#generate_base_cas_lattice","text":"def generate_base_cas_lattice ( ) -> str Simple function to help unclutter the notebook. Returns: Type Description None A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_base_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\"","title":"generate_base_cas_lattice"},{"location":"reference/pyhdtoolkit/cpymadtools/generators/#generate_oneoct_cas_lattice","text":"def generate_oneoct_cas_lattice ( ) -> str Simple function to help unclutter the notebook. Returns: Type Description None A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_oneoct_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, 0, koct}; mod: multipole, knl:={0, 0, 0, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\"","title":"generate_oneoct_cas_lattice"},{"location":"reference/pyhdtoolkit/cpymadtools/generators/#generate_onesext_cas_lattice","text":"def generate_onesext_cas_lattice ( ) -> str Simple function to help unclutter the notebook. Returns: Type Description None A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_onesext_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, ks1, 0}; mod: multipole, knl:={0, 0, ks2, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\"","title":"generate_onesext_cas_lattice"},{"location":"reference/pyhdtoolkit/cpymadtools/generators/#generate_tripleterrors_study_mserror_job","text":"def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str Generate generic script for ms_error Twiss, to use in a cpymad.madx.Madx object. Parameters: Name Type Description Default rand_seed str the random seed to provide MAD for the errors distributions. None ms_error str the misalignment error value (along the s axis). None Returns: Type Description None A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str : \"\"\" Generate generic script for ms_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. ms_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet MSErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For longitudinal missalignments ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma ealign, ds := {ms_error} * 1E-3 * TGAUSS(GCUTR); ! Gaussian missalignments in meters !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\"","title":"generate_tripleterrors_study_mserror_job"},{"location":"reference/pyhdtoolkit/cpymadtools/generators/#generate_tripleterrors_study_reference","text":"def generate_tripleterrors_study_reference ( ) -> str Generate generic script for reference Twiss, to use in a cpymad.madx.Madx object. Returns: Type Description None A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_tripleterrors_study_reference () -> str : \"\"\" Generate generic script for reference Twiss, to use in a `cpymad.madx.Madx` object. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 twiss; \"\"\"","title":"generate_tripleterrors_study_reference"},{"location":"reference/pyhdtoolkit/cpymadtools/generators/#generate_tripleterrors_study_tferror_job","text":"def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str Generate generic script for tf_error Twiss, to use in a cpymad.madx.Madx object. Parameters: Name Type Description Default rand_seed str the random seed to provide MAD for the errors distributions. None tf_error str the misalignment error value (along the s axis). None Returns: Type Description None A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str : \"\"\" Generate generic script for tf_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. tf_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For field errors ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma Rr = 0.05; ! Radius for field errors (??) ON_B2R = 1; ! Activate field errors B2r = {tf_error}; ! Set field errors magnitude -> Units of B2 error (will be in 1E-4) exec, SetEfcomp_Q; ! Assign field errors !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\"","title":"generate_tripleterrors_study_tferror_job"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/","text":"Module pyhdtoolkit.cpymadtools.latwiss Module cpymadtools.latwiss Created on 2019.06.15 View Source \"\"\" Module cpymadtools.latwiss -------------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions to elegantly plot the Twiss parameters output of a cpymad.madx.Madx instance after it has ran, or machine survey. \"\"\" from typing import Dict , Tuple import matplotlib.axes import matplotlib.patches as patches import matplotlib.pyplot as plt import pandas as pd from cpymad.madx import Madx from loguru import logger from pyhdtoolkit.utils.defaults import PLOT_PARAMS plt . rcParams . update ( PLOT_PARAMS ) # ----- Plotters ----- # def plot_latwiss ( madx : Madx , title : str , figsize : Tuple [ int , int ] = ( 18 , 11 ), savefig : str = None , xoffset : float = 0 , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_bpms : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ), k2l_lim : Tuple [ float , float ] = None , ** kwargs , ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is very heavily refactored code, inspired by code from Guido Sterbini. WARNING: This WILL FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xoffset (float): An offset applied to the S coordinate before plotting. This is useful is you want to center a plot around a specific point or element, which would then become located at s = 0. Beware this offset is applied before applying the `xlimits`. Offset defaults to 0 (no change). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_bpms (bool): if True, additional patches will be plotted on the layout subplot to represent Beam Position Monitors. BPMs are plotted in dark grey. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). k2l_lim (Tuple[float, float]): if given, sextupole patches will be plotted on the layout subplot of the figure, and the provided values act as vertical axis limits for the k2l values used for the height of sextupole patches. Keyword Args: Any keyword argument to be transmitted to `_plot_machine_layout`, later on to `plot_lattice_series` and then `matplotlib.patches.Rectangle`, such as lw etc. WARNING: Currently the function tries to plot legends for the different layout patches. The position of the different legends has been hardcoded in corners and might require users to tweak the axis limits (through `k0l_lim`, `k1l_lim` and `k2l_lim`) to ensure legend labels and plotted elements don't overlap. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint: disable=too-many-arguments # Restrict the span of twiss_df to avoid plotting all elements then cropping when xlimits is given logger . info ( \"Plotting optics functions and machine layout\" ) logger . debug ( \"Getting Twiss dataframe from cpymad\" ) twiss_df = madx . table . twiss . dframe () . copy () twiss_df . s = twiss_df . s - xoffset twiss_df = twiss_df [ twiss_df . s . between ( xlimits [ 0 ], xlimits [ 1 ])] if xlimits else twiss_df # Create a subplot for the lattice patches (takes a third of figure) figure = plt . figure ( figsize = figsize ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) _plot_machine_layout ( madx , quadrupole_patches_axis = quadrupole_patches_axis , title = title , xoffset = xoffset , xlimits = xlimits , plot_dipoles = plot_dipoles , plot_quadrupoles = plot_quadrupoles , plot_bpms = plot_bpms , k0l_lim = k0l_lim , k1l_lim = k1l_lim , k2l_lim = k2l_lim , ** kwargs , ) # Plotting beta functions on remaining two thirds of the figure logger . debug ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = \"$ \\\\ beta_x$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = \"$ \\\\ beta_y$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( \"$ \\\\ beta$-functions [m]\" ) betatron_axis . set_xlabel ( \"s [m]\" ) logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = \"$D_x$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = \"$D_y$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersions [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as { savefig } \" ) plt . savefig ( savefig ) return figure def plot_machine_survey ( madx : Madx , title : str = \"Machine Layout\" , figsize : Tuple [ int , int ] = ( 16 , 11 ), savefig : str = None , show_elements : bool = False , high_orders : bool = False , ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing the machine geometry in 2D. Original code is from Guido Sterbini. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. show_elements (bool): if True, will try to plot by differentiating elements. Experimental, defaults to False. high_orders (bool): if True, plot sextupoles and octupoles when show_elements is True, otherwise only up to quadrupoles. Defaults to False. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" logger . debug ( \"Getting machine survey from cpymad\" ) madx . command . survey () survey = madx . table . survey . dframe () figure = plt . figure ( figsize = figsize ) if show_elements : logger . debug ( \"Plotting survey with elements differentiation\" ) element_dfs = _make_survey_groups ( survey ) plt . scatter ( element_dfs [ \"dipoles\" ] . z , element_dfs [ \"dipoles\" ] . x , marker = \".\" , c = element_dfs [ \"dipoles\" ] . s , cmap = \"copper\" , label = \"Dipoles\" , ) plt . scatter ( element_dfs [ \"quad_foc\" ] . z , element_dfs [ \"quad_foc\" ] . x , marker = \"o\" , color = \"blue\" , label = \"QF\" , ) plt . scatter ( element_dfs [ \"quad_defoc\" ] . z , element_dfs [ \"quad_defoc\" ] . x , marker = \"o\" , color = \"red\" , label = \"QD\" , ) if high_orders : logger . debug ( \"Plotting high order magnetic elements (up to octupoles)\" ) plt . scatter ( element_dfs [ \"sextupoles\" ] . z , element_dfs [ \"sextupoles\" ] . x , marker = \".\" , color = \"m\" , label = \"MS\" , ) plt . scatter ( element_dfs [ \"octupoles\" ] . z , element_dfs [ \"octupoles\" ] . x , marker = \".\" , color = \"cyan\" , label = \"MO\" , ) plt . legend ( loc = 2 ) else : logger . debug ( \"Plotting survey without elements differentiation\" ) plt . scatter ( survey . z , survey . x , c = survey . s ) plt . axis ( \"equal\" ) plt . colorbar () . set_label ( \"s [m]\" ) plt . xlabel ( \"z [m]\" ) plt . ylabel ( \"x [m]\" ) plt . title ( title ) if savefig : logger . info ( f \"Saving machine survey plot as { savefig } \" ) plt . savefig ( savefig , format = \"pdf\" , dpi = 500 ) return figure # ----- Utility plotters ----- # def _plot_lattice_series ( ax : matplotlib . axes . Axes , series : pd . DataFrame , height : float = 1.0 , v_offset : float = 0.0 , color : str = \"r\" , alpha : float = 0.5 , ** kwargs , ) -> None : \"\"\" Plots the layout of your machine as a patch of rectangles for different element types. Original code from Guido Sterbini. Args: ax (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. series (pd.DataFrame): a dataframe with your elements' data. height (float): value to reach for the patch on the y axis. v_offset (float): vertical offset for the patch. color (str): color kwarg to transmit to pyplot. alpha (float): alpha kwarg to transmit to pyplot. Keyword Args: Any kwarg that can be given to matplotlib.patches.Rectangle(), for instance `lw` for the edge line width. \"\"\" ax . add_patch ( patches . Rectangle ( ( series . s - series . l , v_offset - height / 2.0 ), # anchor point series . l , # width height , # height color = color , alpha = alpha , ** kwargs , ) ) def _plot_machine_layout ( madx : Madx , quadrupole_patches_axis : matplotlib . axes . Axes , title : str , xoffset : float = 0 , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_bpms : bool = False , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ), k2l_lim : Tuple [ float , float ] = None , ** kwargs , ) -> None : \"\"\" Provided with an active Cpymad class after having ran a script, will plot the lattice layout and the on a given axis. This is the function that takes care of the machine layout in `plot_latwiss`, and is in theory a private function, though if you know what you are doing you may use it individually. WARNING: This WILL FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. quadrupole_patches_axis (matplotlib.axes.Axes): the axis on which to plot. Will also create the appropriate new axes with `twinx()` to plot the element orders asked for. title (str): title of your plot. xoffset (float): An offset applied to the S coordinate before plotting. This is useful is you want to center a plot around a specific point or element, which would then become located at s = 0. Beware this offset is applied before applying the `xlimits`. Offset defaults to 0 (no change). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_bpms (bool): if True, additional patches will be plotted on the layout subplot to represent Beam Position Monitors. BPMs are plotted in dark grey. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). k2l_lim (Tuple[float, float]): if given, sextupole patches will be plotted on the layout subplot of the figure, and the provided values act as vertical axis limits for the k2l values used for the height of sextupole patches. Keyword Args: Any keyword argument to be transmitted to `_plot_lattice_series`, and later on to `matplotlib.patches.Rectangle`, such as lw etc. WARNING: Currently the function tries to plot legends for the different layout patches. The position of the different legends has been hardcoded in corners and might require users to tweak the axis limits (through `k0l_lim`, `k1l_lim` and `k2l_lim`) to ensure legend labels and plotted elements don't overlap. \"\"\" # pylint: disable=too-many-arguments # Restrict the span of twiss_df to avoid plotting all elements then cropping when xlimits is given logger . trace ( \"Getting Twiss dataframe from cpymad\" ) twiss_df = madx . table . twiss . dframe () . copy () twiss_df . s = twiss_df . s - xoffset twiss_df = twiss_df [ twiss_df . s . between ( xlimits [ 0 ], xlimits [ 1 ])] if xlimits else twiss_df logger . debug ( \"Plotting machine layout\" ) logger . trace ( f \"Plotting from axis ' { quadrupole_patches_axis } '\" ) quadrupole_patches_axis . set_ylabel ( \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) quadrupole_patches_axis . set_xlim ( xlimits ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # 0-level line dipole_patches_axis = quadrupole_patches_axis . twinx () dipole_patches_axis . set_ylabel ( \"$ \\\\ theta$=K0L [rad]\" , color = \"royalblue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"royalblue\" ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) # All elements can be defined as a 'multipole', but dipoles can also be defined as 'rbend' or 'sbend', # quadrupoles as 'quadrupoles' and sextupoles as 'sextupoles'. Function does not handle higher orders. logger . debug ( \"Extracting element-specific dataframes\" ) dipoles_df = twiss_df [ ( twiss_df . keyword . isin ([ \"multipole\" , \"rbend\" , \"sbend\" ])) & ( twiss_df . name . str . contains ( \"B\" , case = False )) ] quadrupoles_df = twiss_df [ ( twiss_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( twiss_df . name . str . contains ( \"Q\" , case = False )) ] sextupoles_df = twiss_df [ ( twiss_df . keyword . isin ([ \"multipole\" , \"sextupole\" ])) & ( twiss_df . name . str . contains ( \"S\" , case = False )) ] bpms_df = twiss_df [( twiss_df . keyword . isin ([ \"monitor\" ])) & ( twiss_df . name . str . contains ( \"BPM\" , case = False ))] if plot_dipoles : # beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' logger . debug ( \"Plotting dipole patches\" ) plotted_elements = 0 # will help us not declare a label for legend at every patch for dipole_name , dipole in dipoles_df . iterrows (): # by default twiss.dframe() has names as index if dipole . k0l != 0 or dipole . angle != 0 : logger . trace ( f \"Plotting dipole element ' { dipole_name } '\" ) _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l if dipole . k0l != 0 else dipole . angle , v_offset = dipole . k0l / 2 if dipole . k0l != 0 else dipole . angle / 2 , color = \"royalblue\" , label = \"MB\" if plotted_elements == 0 else None , ** kwargs , ) plotted_elements += 1 dipole_patches_axis . legend ( loc = 1 , fontsize = 16 ) if plot_quadrupoles : logger . debug ( \"Plotting quadrupole patches\" ) plotted_elements = 0 for quadrupole_name , quadrupole in quadrupoles_df . iterrows (): logger . trace ( f \"Plotting quadrupole element ' { quadrupole_name } '\" ) _plot_lattice_series ( quadrupole_patches_axis , quadrupole , height = quadrupole . k1l , v_offset = quadrupole . k1l / 2 , color = \"r\" , label = \"MQ\" if plotted_elements == 0 else None , ** kwargs , ) plotted_elements += 1 quadrupole_patches_axis . legend ( loc = 2 , fontsize = 16 ) if k2l_lim : logger . debug ( \"Plotting sextupole patches\" ) sextupoles_patches_axis = quadrupole_patches_axis . twinx () sextupoles_patches_axis . set_ylabel ( \"K2L [m$^{-2}$]\" , color = \"darkgoldenrod\" ) sextupoles_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"darkgoldenrod\" ) sextupoles_patches_axis . spines [ \"right\" ] . set_position (( \"axes\" , 1.1 )) sextupoles_patches_axis . set_ylim ( k2l_lim ) plotted_elements = 0 for sextupole_name , sextupole in sextupoles_df . iterrows (): logger . trace ( f \"Plotting sextupole element ' { sextupole_name } '\" ) _plot_lattice_series ( sextupoles_patches_axis , sextupole , height = sextupole . k2l , v_offset = sextupole . k2l / 2 , color = \"goldenrod\" , label = \"MS\" if plotted_elements == 0 else None , ** kwargs , ) plotted_elements += 1 sextupoles_patches_axis . legend ( loc = 3 , fontsize = 16 ) if plot_bpms : logger . debug ( \"Plotting BPM patches\" ) bpm_patches_axis = quadrupole_patches_axis . twinx () bpm_patches_axis . set_axis_off () # hide yticks, labels etc bpm_patches_axis . set_ylim ( - 1.6 , 1.6 ) plotted_elements = 0 for bpm_name , bpm in bpms_df . iterrows (): logger . trace ( f \"Plotting BPM element ' { bpm_name } '\" ) _plot_lattice_series ( bpm_patches_axis , bpm , height = 2 , v_offset = 0 , color = \"dimgrey\" , label = \"BPM\" if plotted_elements == 0 else None , ** kwargs , ) plotted_elements += 1 bpm_patches_axis . legend ( loc = 4 , fontsize = 16 ) # ----- Helpers ----- # def _make_survey_groups ( survey_df : pd . DataFrame ) -> Dict [ str , pd . DataFrame ]: \"\"\" Gets a survey dataframe and returns different sub-dataframes corresponding to different magnetic elements. Args: survey_df (pd.DataFrame): machine survey dataframe obtained from your Madx instance, with <instance>.table.survey.dframe(). Returns: A dictionary containing a dataframe for dipoles, focusing quadrupoles, defocusing quadrupoles, sextupoles and octupoles. The keys are self-explanatory. \"\"\" logger . debug ( \"Getting different element groups dframes from MAD-X survey\" ) return { \"dipoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sbend\" , \"rbend\" ])) & ( survey_df . name . str . contains ( \"B\" , case = False )) ], \"quad_foc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"F\" , case = False )) ], \"quad_defoc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"D\" , case = False )) ], \"sextupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sextupole\" ])) & ( survey_df . name . str . contains ( \"S\" , case = False )) ], \"octupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"octupole\" ])) & ( survey_df . name . str . contains ( \"O\" , case = False )) ], } Variables PLOT_PARAMS Functions plot_latwiss def plot_latwiss ( madx : cpymad . madx . Madx , title : str , figsize : Tuple [ int , int ] = ( 18 , 11 ), savefig : str = None , xoffset : float = 0 , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_bpms : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ), k2l_lim : Tuple [ float , float ] = None , ** kwargs ) -> matplotlib . figure . Figure Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is very heavily refactored code, inspired by code from Guido Sterbini. WARNING: This WILL FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xoffset (float): An offset applied to the S coordinate before plotting. This is useful is you want to center a plot around a specific point or element, which would then become located at s = 0. Beware this offset is applied before applying the xlimits . Offset defaults to 0 (no change). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_bpms (bool): if True, additional patches will be plotted on the layout subplot to represent Beam Position Monitors. BPMs are plotted in dark grey. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). k2l_lim (Tuple[float, float]): if given, sextupole patches will be plotted on the layout subplot of the figure, and the provided values act as vertical axis limits for the k2l values used for the height of sextupole patches. Keyword Args: Any keyword argument to be transmitted to _plot_machine_layout , later on to plot_lattice_series and then matplotlib.patches.Rectangle , such as lw etc. WARNING: Currently the function tries to plot legends for the different layout patches. The position of the different legends has been hardcoded in corners and might require users to tweak the axis limits (through k0l_lim , k1l_lim and k2l_lim ) to ensure legend labels and plotted elements don't overlap. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source def plot_latwiss ( madx : Madx , title : str , figsize : Tuple [ int , int ] = ( 18 , 11 ), savefig : str = None , xoffset : float = 0 , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_bpms : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ), k2l_lim : Tuple [ float , float ] = None , ** kwargs , ) -> matplotlib . figure . Figure : \" \"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is very heavily refactored code, inspired by code from Guido Sterbini. WARNING: This WILL FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xoffset (float): An offset applied to the S coordinate before plotting. This is useful is you want to center a plot around a specific point or element, which would then become located at s = 0. Beware this offset is applied before applying the `xlimits`. Offset defaults to 0 (no change). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_bpms (bool): if True, additional patches will be plotted on the layout subplot to represent Beam Position Monitors. BPMs are plotted in dark grey. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). k2l_lim (Tuple[float, float]): if given, sextupole patches will be plotted on the layout subplot of the figure, and the provided values act as vertical axis limits for the k2l values used for the height of sextupole patches. Keyword Args: Any keyword argument to be transmitted to `_plot_machine_layout`, later on to `plot_lattice_series` and then `matplotlib.patches.Rectangle`, such as lw etc. WARNING: Currently the function tries to plot legends for the different layout patches. The position of the different legends has been hardcoded in corners and might require users to tweak the axis limits (through `k0l_lim`, `k1l_lim` and `k2l_lim`) to ensure legend labels and plotted elements don't overlap. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\" \" # pylint: disable=too-many-arguments # Restrict the span of twiss_df to avoid plotting all elements then cropping when xlimits is given logger . info ( \"Plotting optics functions and machine layout\" ) logger . debug ( \"Getting Twiss dataframe from cpymad\" ) twiss_df = madx . table . twiss . dframe (). copy () twiss_df . s = twiss_df . s - xoffset twiss_df = twiss_df [ twiss_df . s . between ( xlimits [ 0 ] , xlimits [ 1 ] ) ] if xlimits else twiss_df # Create a subplot for the lattice patches (takes a third of figure) figure = plt . figure ( figsize = figsize ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) _plot_machine_layout ( madx , quadrupole_patches_axis = quadrupole_patches_axis , title = title , xoffset = xoffset , xlimits = xlimits , plot_dipoles = plot_dipoles , plot_quadrupoles = plot_quadrupoles , plot_bpms = plot_bpms , k0l_lim = k0l_lim , k1l_lim = k1l_lim , k2l_lim = k2l_lim , ** kwargs , ) # Plotting beta functions on remaining two thirds of the figure logger . debug ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = \"$ \\\\ beta_x$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = \"$ \\\\ beta_y$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set _ylabel ( \"$ \\\\ beta$-functions [m]\" ) betatron_axis . set _xlabel ( \"s [m]\" ) logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = \"$D_x$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = \"$D_y$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set _ylabel ( \"Dispersions [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set _ylim ( beta_ylim ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set _ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig ) return figure plot_machine_survey def plot_machine_survey ( madx : cpymad . madx . Madx , title : str = 'Machine Layout' , figsize : Tuple [ int , int ] = ( 16 , 11 ), savefig : str = None , show_elements : bool = False , high_orders : bool = False ) -> matplotlib . figure . Figure Provided with an active Cpymad class after having ran a script, will create a plot representing the machine geometry in 2D. Original code is from Guido Sterbini. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None title str title of your plot. None figsize Tuple[int, int] size of the figure, defaults to (16, 10). None savefig str will save the figure if this is not None, using the string value passed. None show_elements bool if True, will try to plot by differentiating elements. Experimental, defaults to False. None high_orders bool if True, plot sextupoles and octupoles when show_elements is True, otherwise only up to quadrupoles. Defaults to False. None Returns: Type Description None The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source def plot_machine_survey ( madx : Madx , title : str = \"Machine Layout\" , figsize : Tuple [ int, int ] = ( 16 , 11 ), savefig : str = None , show_elements : bool = False , high_orders : bool = False , ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing the machine geometry in 2D. Original code is from Guido Sterbini. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. show_elements (bool): if True, will try to plot by differentiating elements. Experimental, defaults to False. high_orders (bool): if True, plot sextupoles and octupoles when show_elements is True, otherwise only up to quadrupoles. Defaults to False. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" logger . debug ( \"Getting machine survey from cpymad\" ) madx . command . survey () survey = madx . table . survey . dframe () figure = plt . figure ( figsize = figsize ) if show_elements : logger . debug ( \"Plotting survey with elements differentiation\" ) element_dfs = _make_survey_groups ( survey ) plt . scatter ( element_dfs [ \"dipoles\" ] . z , element_dfs [ \"dipoles\" ] . x , marker = \".\" , c = element_dfs [ \"dipoles\" ] . s , cmap = \"copper\" , label = \"Dipoles\" , ) plt . scatter ( element_dfs [ \"quad_foc\" ] . z , element_dfs [ \"quad_foc\" ] . x , marker = \"o\" , color = \"blue\" , label = \"QF\" , ) plt . scatter ( element_dfs [ \"quad_defoc\" ] . z , element_dfs [ \"quad_defoc\" ] . x , marker = \"o\" , color = \"red\" , label = \"QD\" , ) if high_orders : logger . debug ( \"Plotting high order magnetic elements (up to octupoles)\" ) plt . scatter ( element_dfs [ \"sextupoles\" ] . z , element_dfs [ \"sextupoles\" ] . x , marker = \".\" , color = \"m\" , label = \"MS\" , ) plt . scatter ( element_dfs [ \"octupoles\" ] . z , element_dfs [ \"octupoles\" ] . x , marker = \".\" , color = \"cyan\" , label = \"MO\" , ) plt . legend ( loc = 2 ) else : logger . debug ( \"Plotting survey without elements differentiation\" ) plt . scatter ( survey . z , survey . x , c = survey . s ) plt . axis ( \"equal\" ) plt . colorbar (). set_label ( \"s [m]\" ) plt . xlabel ( \"z [m]\" ) plt . ylabel ( \"x [m]\" ) plt . title ( title ) if savefig : logger . info ( f \"Saving machine survey plot as {savefig}\" ) plt . savefig ( savefig , format = \"pdf\" , dpi = 500 ) return figure","title":"Latwiss"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/#module-pyhdtoolkitcpymadtoolslatwiss","text":"Module cpymadtools.latwiss Created on 2019.06.15 View Source \"\"\" Module cpymadtools.latwiss -------------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions to elegantly plot the Twiss parameters output of a cpymad.madx.Madx instance after it has ran, or machine survey. \"\"\" from typing import Dict , Tuple import matplotlib.axes import matplotlib.patches as patches import matplotlib.pyplot as plt import pandas as pd from cpymad.madx import Madx from loguru import logger from pyhdtoolkit.utils.defaults import PLOT_PARAMS plt . rcParams . update ( PLOT_PARAMS ) # ----- Plotters ----- # def plot_latwiss ( madx : Madx , title : str , figsize : Tuple [ int , int ] = ( 18 , 11 ), savefig : str = None , xoffset : float = 0 , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_bpms : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ), k2l_lim : Tuple [ float , float ] = None , ** kwargs , ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is very heavily refactored code, inspired by code from Guido Sterbini. WARNING: This WILL FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xoffset (float): An offset applied to the S coordinate before plotting. This is useful is you want to center a plot around a specific point or element, which would then become located at s = 0. Beware this offset is applied before applying the `xlimits`. Offset defaults to 0 (no change). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_bpms (bool): if True, additional patches will be plotted on the layout subplot to represent Beam Position Monitors. BPMs are plotted in dark grey. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). k2l_lim (Tuple[float, float]): if given, sextupole patches will be plotted on the layout subplot of the figure, and the provided values act as vertical axis limits for the k2l values used for the height of sextupole patches. Keyword Args: Any keyword argument to be transmitted to `_plot_machine_layout`, later on to `plot_lattice_series` and then `matplotlib.patches.Rectangle`, such as lw etc. WARNING: Currently the function tries to plot legends for the different layout patches. The position of the different legends has been hardcoded in corners and might require users to tweak the axis limits (through `k0l_lim`, `k1l_lim` and `k2l_lim`) to ensure legend labels and plotted elements don't overlap. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint: disable=too-many-arguments # Restrict the span of twiss_df to avoid plotting all elements then cropping when xlimits is given logger . info ( \"Plotting optics functions and machine layout\" ) logger . debug ( \"Getting Twiss dataframe from cpymad\" ) twiss_df = madx . table . twiss . dframe () . copy () twiss_df . s = twiss_df . s - xoffset twiss_df = twiss_df [ twiss_df . s . between ( xlimits [ 0 ], xlimits [ 1 ])] if xlimits else twiss_df # Create a subplot for the lattice patches (takes a third of figure) figure = plt . figure ( figsize = figsize ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) _plot_machine_layout ( madx , quadrupole_patches_axis = quadrupole_patches_axis , title = title , xoffset = xoffset , xlimits = xlimits , plot_dipoles = plot_dipoles , plot_quadrupoles = plot_quadrupoles , plot_bpms = plot_bpms , k0l_lim = k0l_lim , k1l_lim = k1l_lim , k2l_lim = k2l_lim , ** kwargs , ) # Plotting beta functions on remaining two thirds of the figure logger . debug ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = \"$ \\\\ beta_x$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = \"$ \\\\ beta_y$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( \"$ \\\\ beta$-functions [m]\" ) betatron_axis . set_xlabel ( \"s [m]\" ) logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = \"$D_x$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = \"$D_y$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersions [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as { savefig } \" ) plt . savefig ( savefig ) return figure def plot_machine_survey ( madx : Madx , title : str = \"Machine Layout\" , figsize : Tuple [ int , int ] = ( 16 , 11 ), savefig : str = None , show_elements : bool = False , high_orders : bool = False , ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing the machine geometry in 2D. Original code is from Guido Sterbini. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. show_elements (bool): if True, will try to plot by differentiating elements. Experimental, defaults to False. high_orders (bool): if True, plot sextupoles and octupoles when show_elements is True, otherwise only up to quadrupoles. Defaults to False. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" logger . debug ( \"Getting machine survey from cpymad\" ) madx . command . survey () survey = madx . table . survey . dframe () figure = plt . figure ( figsize = figsize ) if show_elements : logger . debug ( \"Plotting survey with elements differentiation\" ) element_dfs = _make_survey_groups ( survey ) plt . scatter ( element_dfs [ \"dipoles\" ] . z , element_dfs [ \"dipoles\" ] . x , marker = \".\" , c = element_dfs [ \"dipoles\" ] . s , cmap = \"copper\" , label = \"Dipoles\" , ) plt . scatter ( element_dfs [ \"quad_foc\" ] . z , element_dfs [ \"quad_foc\" ] . x , marker = \"o\" , color = \"blue\" , label = \"QF\" , ) plt . scatter ( element_dfs [ \"quad_defoc\" ] . z , element_dfs [ \"quad_defoc\" ] . x , marker = \"o\" , color = \"red\" , label = \"QD\" , ) if high_orders : logger . debug ( \"Plotting high order magnetic elements (up to octupoles)\" ) plt . scatter ( element_dfs [ \"sextupoles\" ] . z , element_dfs [ \"sextupoles\" ] . x , marker = \".\" , color = \"m\" , label = \"MS\" , ) plt . scatter ( element_dfs [ \"octupoles\" ] . z , element_dfs [ \"octupoles\" ] . x , marker = \".\" , color = \"cyan\" , label = \"MO\" , ) plt . legend ( loc = 2 ) else : logger . debug ( \"Plotting survey without elements differentiation\" ) plt . scatter ( survey . z , survey . x , c = survey . s ) plt . axis ( \"equal\" ) plt . colorbar () . set_label ( \"s [m]\" ) plt . xlabel ( \"z [m]\" ) plt . ylabel ( \"x [m]\" ) plt . title ( title ) if savefig : logger . info ( f \"Saving machine survey plot as { savefig } \" ) plt . savefig ( savefig , format = \"pdf\" , dpi = 500 ) return figure # ----- Utility plotters ----- # def _plot_lattice_series ( ax : matplotlib . axes . Axes , series : pd . DataFrame , height : float = 1.0 , v_offset : float = 0.0 , color : str = \"r\" , alpha : float = 0.5 , ** kwargs , ) -> None : \"\"\" Plots the layout of your machine as a patch of rectangles for different element types. Original code from Guido Sterbini. Args: ax (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. series (pd.DataFrame): a dataframe with your elements' data. height (float): value to reach for the patch on the y axis. v_offset (float): vertical offset for the patch. color (str): color kwarg to transmit to pyplot. alpha (float): alpha kwarg to transmit to pyplot. Keyword Args: Any kwarg that can be given to matplotlib.patches.Rectangle(), for instance `lw` for the edge line width. \"\"\" ax . add_patch ( patches . Rectangle ( ( series . s - series . l , v_offset - height / 2.0 ), # anchor point series . l , # width height , # height color = color , alpha = alpha , ** kwargs , ) ) def _plot_machine_layout ( madx : Madx , quadrupole_patches_axis : matplotlib . axes . Axes , title : str , xoffset : float = 0 , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_bpms : bool = False , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ), k2l_lim : Tuple [ float , float ] = None , ** kwargs , ) -> None : \"\"\" Provided with an active Cpymad class after having ran a script, will plot the lattice layout and the on a given axis. This is the function that takes care of the machine layout in `plot_latwiss`, and is in theory a private function, though if you know what you are doing you may use it individually. WARNING: This WILL FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. quadrupole_patches_axis (matplotlib.axes.Axes): the axis on which to plot. Will also create the appropriate new axes with `twinx()` to plot the element orders asked for. title (str): title of your plot. xoffset (float): An offset applied to the S coordinate before plotting. This is useful is you want to center a plot around a specific point or element, which would then become located at s = 0. Beware this offset is applied before applying the `xlimits`. Offset defaults to 0 (no change). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_bpms (bool): if True, additional patches will be plotted on the layout subplot to represent Beam Position Monitors. BPMs are plotted in dark grey. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). k2l_lim (Tuple[float, float]): if given, sextupole patches will be plotted on the layout subplot of the figure, and the provided values act as vertical axis limits for the k2l values used for the height of sextupole patches. Keyword Args: Any keyword argument to be transmitted to `_plot_lattice_series`, and later on to `matplotlib.patches.Rectangle`, such as lw etc. WARNING: Currently the function tries to plot legends for the different layout patches. The position of the different legends has been hardcoded in corners and might require users to tweak the axis limits (through `k0l_lim`, `k1l_lim` and `k2l_lim`) to ensure legend labels and plotted elements don't overlap. \"\"\" # pylint: disable=too-many-arguments # Restrict the span of twiss_df to avoid plotting all elements then cropping when xlimits is given logger . trace ( \"Getting Twiss dataframe from cpymad\" ) twiss_df = madx . table . twiss . dframe () . copy () twiss_df . s = twiss_df . s - xoffset twiss_df = twiss_df [ twiss_df . s . between ( xlimits [ 0 ], xlimits [ 1 ])] if xlimits else twiss_df logger . debug ( \"Plotting machine layout\" ) logger . trace ( f \"Plotting from axis ' { quadrupole_patches_axis } '\" ) quadrupole_patches_axis . set_ylabel ( \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) quadrupole_patches_axis . set_xlim ( xlimits ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # 0-level line dipole_patches_axis = quadrupole_patches_axis . twinx () dipole_patches_axis . set_ylabel ( \"$ \\\\ theta$=K0L [rad]\" , color = \"royalblue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"royalblue\" ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) # All elements can be defined as a 'multipole', but dipoles can also be defined as 'rbend' or 'sbend', # quadrupoles as 'quadrupoles' and sextupoles as 'sextupoles'. Function does not handle higher orders. logger . debug ( \"Extracting element-specific dataframes\" ) dipoles_df = twiss_df [ ( twiss_df . keyword . isin ([ \"multipole\" , \"rbend\" , \"sbend\" ])) & ( twiss_df . name . str . contains ( \"B\" , case = False )) ] quadrupoles_df = twiss_df [ ( twiss_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( twiss_df . name . str . contains ( \"Q\" , case = False )) ] sextupoles_df = twiss_df [ ( twiss_df . keyword . isin ([ \"multipole\" , \"sextupole\" ])) & ( twiss_df . name . str . contains ( \"S\" , case = False )) ] bpms_df = twiss_df [( twiss_df . keyword . isin ([ \"monitor\" ])) & ( twiss_df . name . str . contains ( \"BPM\" , case = False ))] if plot_dipoles : # beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' logger . debug ( \"Plotting dipole patches\" ) plotted_elements = 0 # will help us not declare a label for legend at every patch for dipole_name , dipole in dipoles_df . iterrows (): # by default twiss.dframe() has names as index if dipole . k0l != 0 or dipole . angle != 0 : logger . trace ( f \"Plotting dipole element ' { dipole_name } '\" ) _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l if dipole . k0l != 0 else dipole . angle , v_offset = dipole . k0l / 2 if dipole . k0l != 0 else dipole . angle / 2 , color = \"royalblue\" , label = \"MB\" if plotted_elements == 0 else None , ** kwargs , ) plotted_elements += 1 dipole_patches_axis . legend ( loc = 1 , fontsize = 16 ) if plot_quadrupoles : logger . debug ( \"Plotting quadrupole patches\" ) plotted_elements = 0 for quadrupole_name , quadrupole in quadrupoles_df . iterrows (): logger . trace ( f \"Plotting quadrupole element ' { quadrupole_name } '\" ) _plot_lattice_series ( quadrupole_patches_axis , quadrupole , height = quadrupole . k1l , v_offset = quadrupole . k1l / 2 , color = \"r\" , label = \"MQ\" if plotted_elements == 0 else None , ** kwargs , ) plotted_elements += 1 quadrupole_patches_axis . legend ( loc = 2 , fontsize = 16 ) if k2l_lim : logger . debug ( \"Plotting sextupole patches\" ) sextupoles_patches_axis = quadrupole_patches_axis . twinx () sextupoles_patches_axis . set_ylabel ( \"K2L [m$^{-2}$]\" , color = \"darkgoldenrod\" ) sextupoles_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"darkgoldenrod\" ) sextupoles_patches_axis . spines [ \"right\" ] . set_position (( \"axes\" , 1.1 )) sextupoles_patches_axis . set_ylim ( k2l_lim ) plotted_elements = 0 for sextupole_name , sextupole in sextupoles_df . iterrows (): logger . trace ( f \"Plotting sextupole element ' { sextupole_name } '\" ) _plot_lattice_series ( sextupoles_patches_axis , sextupole , height = sextupole . k2l , v_offset = sextupole . k2l / 2 , color = \"goldenrod\" , label = \"MS\" if plotted_elements == 0 else None , ** kwargs , ) plotted_elements += 1 sextupoles_patches_axis . legend ( loc = 3 , fontsize = 16 ) if plot_bpms : logger . debug ( \"Plotting BPM patches\" ) bpm_patches_axis = quadrupole_patches_axis . twinx () bpm_patches_axis . set_axis_off () # hide yticks, labels etc bpm_patches_axis . set_ylim ( - 1.6 , 1.6 ) plotted_elements = 0 for bpm_name , bpm in bpms_df . iterrows (): logger . trace ( f \"Plotting BPM element ' { bpm_name } '\" ) _plot_lattice_series ( bpm_patches_axis , bpm , height = 2 , v_offset = 0 , color = \"dimgrey\" , label = \"BPM\" if plotted_elements == 0 else None , ** kwargs , ) plotted_elements += 1 bpm_patches_axis . legend ( loc = 4 , fontsize = 16 ) # ----- Helpers ----- # def _make_survey_groups ( survey_df : pd . DataFrame ) -> Dict [ str , pd . DataFrame ]: \"\"\" Gets a survey dataframe and returns different sub-dataframes corresponding to different magnetic elements. Args: survey_df (pd.DataFrame): machine survey dataframe obtained from your Madx instance, with <instance>.table.survey.dframe(). Returns: A dictionary containing a dataframe for dipoles, focusing quadrupoles, defocusing quadrupoles, sextupoles and octupoles. The keys are self-explanatory. \"\"\" logger . debug ( \"Getting different element groups dframes from MAD-X survey\" ) return { \"dipoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sbend\" , \"rbend\" ])) & ( survey_df . name . str . contains ( \"B\" , case = False )) ], \"quad_foc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"F\" , case = False )) ], \"quad_defoc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"D\" , case = False )) ], \"sextupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sextupole\" ])) & ( survey_df . name . str . contains ( \"S\" , case = False )) ], \"octupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"octupole\" ])) & ( survey_df . name . str . contains ( \"O\" , case = False )) ], }","title":"Module pyhdtoolkit.cpymadtools.latwiss"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/#variables","text":"PLOT_PARAMS","title":"Variables"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/#plot_latwiss","text":"def plot_latwiss ( madx : cpymad . madx . Madx , title : str , figsize : Tuple [ int , int ] = ( 18 , 11 ), savefig : str = None , xoffset : float = 0 , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_bpms : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ), k2l_lim : Tuple [ float , float ] = None , ** kwargs ) -> matplotlib . figure . Figure Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is very heavily refactored code, inspired by code from Guido Sterbini. WARNING: This WILL FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xoffset (float): An offset applied to the S coordinate before plotting. This is useful is you want to center a plot around a specific point or element, which would then become located at s = 0. Beware this offset is applied before applying the xlimits . Offset defaults to 0 (no change). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_bpms (bool): if True, additional patches will be plotted on the layout subplot to represent Beam Position Monitors. BPMs are plotted in dark grey. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). k2l_lim (Tuple[float, float]): if given, sextupole patches will be plotted on the layout subplot of the figure, and the provided values act as vertical axis limits for the k2l values used for the height of sextupole patches. Keyword Args: Any keyword argument to be transmitted to _plot_machine_layout , later on to plot_lattice_series and then matplotlib.patches.Rectangle , such as lw etc. WARNING: Currently the function tries to plot legends for the different layout patches. The position of the different legends has been hardcoded in corners and might require users to tweak the axis limits (through k0l_lim , k1l_lim and k2l_lim ) to ensure legend labels and plotted elements don't overlap. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source def plot_latwiss ( madx : Madx , title : str , figsize : Tuple [ int , int ] = ( 18 , 11 ), savefig : str = None , xoffset : float = 0 , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_bpms : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ), k2l_lim : Tuple [ float , float ] = None , ** kwargs , ) -> matplotlib . figure . Figure : \" \"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is very heavily refactored code, inspired by code from Guido Sterbini. WARNING: This WILL FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xoffset (float): An offset applied to the S coordinate before plotting. This is useful is you want to center a plot around a specific point or element, which would then become located at s = 0. Beware this offset is applied before applying the `xlimits`. Offset defaults to 0 (no change). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_bpms (bool): if True, additional patches will be plotted on the layout subplot to represent Beam Position Monitors. BPMs are plotted in dark grey. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). k2l_lim (Tuple[float, float]): if given, sextupole patches will be plotted on the layout subplot of the figure, and the provided values act as vertical axis limits for the k2l values used for the height of sextupole patches. Keyword Args: Any keyword argument to be transmitted to `_plot_machine_layout`, later on to `plot_lattice_series` and then `matplotlib.patches.Rectangle`, such as lw etc. WARNING: Currently the function tries to plot legends for the different layout patches. The position of the different legends has been hardcoded in corners and might require users to tweak the axis limits (through `k0l_lim`, `k1l_lim` and `k2l_lim`) to ensure legend labels and plotted elements don't overlap. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\" \" # pylint: disable=too-many-arguments # Restrict the span of twiss_df to avoid plotting all elements then cropping when xlimits is given logger . info ( \"Plotting optics functions and machine layout\" ) logger . debug ( \"Getting Twiss dataframe from cpymad\" ) twiss_df = madx . table . twiss . dframe (). copy () twiss_df . s = twiss_df . s - xoffset twiss_df = twiss_df [ twiss_df . s . between ( xlimits [ 0 ] , xlimits [ 1 ] ) ] if xlimits else twiss_df # Create a subplot for the lattice patches (takes a third of figure) figure = plt . figure ( figsize = figsize ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) _plot_machine_layout ( madx , quadrupole_patches_axis = quadrupole_patches_axis , title = title , xoffset = xoffset , xlimits = xlimits , plot_dipoles = plot_dipoles , plot_quadrupoles = plot_quadrupoles , plot_bpms = plot_bpms , k0l_lim = k0l_lim , k1l_lim = k1l_lim , k2l_lim = k2l_lim , ** kwargs , ) # Plotting beta functions on remaining two thirds of the figure logger . debug ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = \"$ \\\\ beta_x$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = \"$ \\\\ beta_y$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set _ylabel ( \"$ \\\\ beta$-functions [m]\" ) betatron_axis . set _xlabel ( \"s [m]\" ) logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = \"$D_x$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = \"$D_y$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set _ylabel ( \"Dispersions [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set _ylim ( beta_ylim ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set _ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig ) return figure","title":"plot_latwiss"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/#plot_machine_survey","text":"def plot_machine_survey ( madx : cpymad . madx . Madx , title : str = 'Machine Layout' , figsize : Tuple [ int , int ] = ( 16 , 11 ), savefig : str = None , show_elements : bool = False , high_orders : bool = False ) -> matplotlib . figure . Figure Provided with an active Cpymad class after having ran a script, will create a plot representing the machine geometry in 2D. Original code is from Guido Sterbini. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None title str title of your plot. None figsize Tuple[int, int] size of the figure, defaults to (16, 10). None savefig str will save the figure if this is not None, using the string value passed. None show_elements bool if True, will try to plot by differentiating elements. Experimental, defaults to False. None high_orders bool if True, plot sextupoles and octupoles when show_elements is True, otherwise only up to quadrupoles. Defaults to False. None Returns: Type Description None The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source def plot_machine_survey ( madx : Madx , title : str = \"Machine Layout\" , figsize : Tuple [ int, int ] = ( 16 , 11 ), savefig : str = None , show_elements : bool = False , high_orders : bool = False , ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing the machine geometry in 2D. Original code is from Guido Sterbini. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. show_elements (bool): if True, will try to plot by differentiating elements. Experimental, defaults to False. high_orders (bool): if True, plot sextupoles and octupoles when show_elements is True, otherwise only up to quadrupoles. Defaults to False. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" logger . debug ( \"Getting machine survey from cpymad\" ) madx . command . survey () survey = madx . table . survey . dframe () figure = plt . figure ( figsize = figsize ) if show_elements : logger . debug ( \"Plotting survey with elements differentiation\" ) element_dfs = _make_survey_groups ( survey ) plt . scatter ( element_dfs [ \"dipoles\" ] . z , element_dfs [ \"dipoles\" ] . x , marker = \".\" , c = element_dfs [ \"dipoles\" ] . s , cmap = \"copper\" , label = \"Dipoles\" , ) plt . scatter ( element_dfs [ \"quad_foc\" ] . z , element_dfs [ \"quad_foc\" ] . x , marker = \"o\" , color = \"blue\" , label = \"QF\" , ) plt . scatter ( element_dfs [ \"quad_defoc\" ] . z , element_dfs [ \"quad_defoc\" ] . x , marker = \"o\" , color = \"red\" , label = \"QD\" , ) if high_orders : logger . debug ( \"Plotting high order magnetic elements (up to octupoles)\" ) plt . scatter ( element_dfs [ \"sextupoles\" ] . z , element_dfs [ \"sextupoles\" ] . x , marker = \".\" , color = \"m\" , label = \"MS\" , ) plt . scatter ( element_dfs [ \"octupoles\" ] . z , element_dfs [ \"octupoles\" ] . x , marker = \".\" , color = \"cyan\" , label = \"MO\" , ) plt . legend ( loc = 2 ) else : logger . debug ( \"Plotting survey without elements differentiation\" ) plt . scatter ( survey . z , survey . x , c = survey . s ) plt . axis ( \"equal\" ) plt . colorbar (). set_label ( \"s [m]\" ) plt . xlabel ( \"z [m]\" ) plt . ylabel ( \"x [m]\" ) plt . title ( title ) if savefig : logger . info ( f \"Saving machine survey plot as {savefig}\" ) plt . savefig ( savefig , format = \"pdf\" , dpi = 500 ) return figure","title":"plot_machine_survey"},{"location":"reference/pyhdtoolkit/cpymadtools/matching/","text":"Module pyhdtoolkit.cpymadtools.matching Module cpymadtools.matching Created on 2020.02.03 View Source \"\"\" Module cpymadtools.matching --------------------------- Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to perform MAD-X matchings with a cpymad.madx.Madx object. \"\"\" from typing import Dict , Sequence , Tuple from cpymad.madx import Madx from loguru import logger # ----- Utlites ----- # def get_lhc_tune_and_chroma_knobs ( accelerator : str , beam : int = 1 , telescopic_squeeze : bool = False ) -> Tuple [ str , str , str , str ]: \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get names of knobs needed to match tunes and chromaticities as a tuple of strings. Args: accelerator (str): Accelerator either 'LHC' (dQ[xy], dQp[xy] knobs) or 'HLLHC' (kqt[fd], ks[fd] knobs). beam (int): Beam to use, for the knob names. telescopic_squeeze (bool): if set to True, returns the knobs for Telescopic Squeeze configuration. Defaults to False. Returns: Tuple of strings with knobs for `(qx, qy, dqx, dqy)`. \"\"\" beam = 2 if beam == 4 else beam suffix = \"_sq\" if telescopic_squeeze else \"\" if accelerator . upper () not in ( \"LHC\" , \"HLLHC\" ): logger . error ( \"Invalid accelerator name, only 'LHC' and 'HLLHC' implemented\" ) raise NotImplementedError ( f \"Accelerator ' { accelerator } ' not implemented.\" ) return { \"LHC\" : ( f \"dQx.b { beam }{ suffix } \" , f \"dQy.b { beam }{ suffix } \" , f \"dQpx.b { beam }{ suffix } \" , f \"dQpy.b { beam }{ suffix } \" , ), \"HLLHC\" : ( f \"kqtf.b { beam }{ suffix } \" , f \"kqtd.b { beam }{ suffix } \" , f \"ksf.b { beam }{ suffix } \" , f \"ksd.b { beam }{ suffix } \" , ), }[ accelerator . upper ()] def match_tunes_and_chromaticities ( madx : Madx , accelerator : str = None , sequence : str = None , q1_target : float = None , q2_target : float = None , dq1_target : float = None , dq2_target : float = None , varied_knobs : Sequence [ str ] = None , telescopic_squeeze : bool = False , step : float = 1e-7 , calls : int = 100 , tolerance : float = 1e-21 , ) -> None : \"\"\" Provided with an active `cpymad` class after having ran a script, will run an additional matching command to reach the provided values for tunes and chromaticities. Tune matching is always performed. If chromaticity target values are given, then a matching is done for them, followed by an additionnal matching for both tunes and chromaticities. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. accelerator (str): name of the accelerator, used to determmine knobs if 'variables' not given. Automatic determination will only work for LHC and HLLHC. sequence (str): name of the sequence you want to activate for the tune matching. q1_target (float): horizontal tune to match to. q2_target (float): vertical tune to match to. dq1_target (float): horizontal chromaticity to match to. dq2_target (float): vertical chromaticity to match to. varied_knobs (Sequence[str]): the variables names to 'vary' in the MADX routine. An input could be [\"kqf\", \"ksd\", \"kqf\", \"kqd\"] as they are common names used for quadrupole and sextupole strengths (foc / defoc) in most examples. telescopic_squeeze (bool): LHC specific. If set to True, uses the (HL)LHC knobs for Telescopic Squeeze configuration. Defaults to False, but will default to True in a later release. step (float): step size to use when varying knobs. calls (int): max number of varying calls to perform. tolerance (float): tolerance for successfull matching. \"\"\" if accelerator and not varied_knobs : logger . trace ( f \"Getting knobs from default { accelerator . upper () } values\" ) varied_knobs = get_lhc_tune_and_chroma_knobs ( accelerator = accelerator , beam = int ( sequence [ - 1 ]), telescopic_squeeze = telescopic_squeeze ) def match ( * args , ** kwargs ): \"\"\"Create matching commands for kwarg targets, varying the given args.\"\"\" logger . debug ( f \"Executing matching commands, using sequence ' { sequence } '\" ) madx . command . match ( chrom = True ) logger . trace ( f \"Targets are given as { kwargs } \" ) madx . command . global_ ( sequence = sequence , ** kwargs ) for variable_name in args : logger . trace ( f \"Creating vary command for knob ' { variable_name } '\" ) madx . command . vary ( name = variable_name , step = step ) madx . command . lmdif ( calls = calls , tolerance = tolerance ) madx . command . endmatch () logger . trace ( \"Performing routine TWISS\" ) madx . twiss () # prevents errors if the user forget to do so before querying tables if q1_target and q2_target and dq1_target and dq2_target : logger . info ( f \"Doing combined matching to Qx= { q1_target } , Qy= { q2_target } , \" f \"dqx= { dq1_target } , dqy= { dq2_target } for sequence ' { sequence } '\" ) logger . trace ( f \"Vary knobs sent are { varied_knobs } \" ) match ( * varied_knobs , q1 = q1_target , q2 = q2_target , dq1 = dq1_target , dq2 = dq2_target ) elif q1_target and q2_target : logger . info ( f \"Matching tunes to Qx= { q1_target } , Qy= { q2_target } for sequence ' { sequence } '\" ) logger . trace ( f \"Vary knobs sent are { varied_knobs [: 2 ] } \" ) match ( * varied_knobs [: 2 ], q1 = q1_target , q2 = q2_target ) # first two in varied_knobs are tune knobs def get_closest_tune_approach ( madx : Madx , accelerator : str = None , sequence : str = None , varied_knobs : Sequence [ str ] = None , telescopic_squeeze : bool = False , explicit_targets : Tuple [ float , float ] = None , step : float = 1e-7 , calls : float = 100 , tolerance : float = 1e-21 , ) -> float : \"\"\" Provided with an active `cpymad` class after having ran a script, tries to match the tunes to their mid-fractional tunes. The difference between this mid-tune and the actual matched tune is the closest tune approach. NOTA BENE: This assumes your lattice has previously been matched to desired tunes and chromaticities, as it will determine the appropriate targets from the Madx instance's internal tables. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. accelerator (str): name of the accelerator, used to determmine knobs if 'variables' not given. Automatic determination will only work for LHC and HLLHC. sequence (str): name of the sequence you want to activate for the tune matching. varied_knobs (Sequence[str]): the variables names to 'vary' in the MADX routine. An input could be [\"kqf\", \"ksd\", \"kqf\", \"kqd\"] as they are common names used for quadrupole and sextupole strengths (foc / defoc) in most examples. telescopic_squeeze (bool): LHC specific. If set to True, uses the (HL)LHC knobs for Telescopic Squeeze configuration. Defaults to False. explicit_targets (Tuple[float, float]): if given, will be used as matching targets for Qx, Qy. Otherwise, the target is determined as the middle of the current fractional tunes. Defaults to None. step (float): step size to use when varying knobs. calls (int): max number of varying calls to perform. tolerance (float): tolerance for successfull matching. Returns: The closest tune approach, in absolute value. \"\"\" if accelerator and not varied_knobs : logger . trace ( f \"Getting knobs from default { accelerator . upper () } values\" ) varied_knobs = get_lhc_tune_and_chroma_knobs ( accelerator = accelerator , beam = int ( sequence [ - 1 ]), telescopic_squeeze = telescopic_squeeze ) logger . debug ( \"Saving knob values to restore after closest tune approach\" ) saved_knobs : Dict [ str , float ] = { knob : madx . globals [ knob ] for knob in varied_knobs } logger . trace ( f \"Saved knobs are { saved_knobs } \" ) if explicit_targets : qx_target , qy_target = explicit_targets q1 , q2 = qx_target , qy_target # the integer part is used later on else : logger . trace ( \"Retrieving tunes and chromaticities from internal tables\" ) q1 , q2 = madx . table . summ . q1 [ 0 ], madx . table . summ . q2 [ 0 ] dq1 , dq2 = madx . table . summ . dq1 [ 0 ], madx . table . summ . dq2 [ 0 ] logger . trace ( f \"Retrieved values are q1 = { q1 } , q2 = { q2 } , dq1 = { dq1 } , dq2 = { dq2 } \" ) logger . trace ( \"Determining target tunes for closest approach\" ) middle_of_fractional_tunes = ( _fractional_tune ( q1 ) + _fractional_tune ( q2 )) / 2 qx_target = int ( q1 ) + middle_of_fractional_tunes qy_target = int ( q2 ) + middle_of_fractional_tunes logger . debug ( f \"Targeting tunes Qx = { qx_target } | Qy = { qy_target } \" ) logger . info ( \"Performing closest tune approach routine, matching should fail at DeltaQ = dqmin\" ) match_tunes_and_chromaticities ( madx , accelerator , sequence , qx_target , qy_target , # dq1, # remove? # dq2, # remove? varied_knobs = varied_knobs , step = step , calls = calls , tolerance = tolerance , ) logger . debug ( \"Retrieving tune separation from internal tables\" ) dqmin = madx . table . summ . q1 [ 0 ] - madx . table . summ . q2 [ 0 ] - ( int ( q1 ) - int ( q2 )) logger . info ( \"Restoring saved knobs\" ) for knob , knob_value in saved_knobs . items (): madx . globals [ knob ] = knob_value madx . twiss () return abs ( dqmin ) # ----- Helpers ----- # def _fractional_tune ( tune : float ) -> float : \"\"\" Return only the fractional part of a tune value. Args: tune (float): tune value. Returns: The fractional part. \"\"\" return tune - int ( tune ) # ok since int truncates to lower integer Functions get_closest_tune_approach def get_closest_tune_approach ( madx : cpymad . madx . Madx , accelerator : str = None , sequence : str = None , varied_knobs : Sequence [ str ] = None , telescopic_squeeze : bool = False , explicit_targets : Tuple [ float , float ] = None , step : float = 1e-07 , calls : float = 100 , tolerance : float = 1e-21 ) -> float Provided with an active cpymad class after having ran a script, tries to match the tunes to their mid-fractional tunes. The difference between this mid-tune and the actual matched tune is the closest tune approach. NOTA BENE: This assumes your lattice has previously been matched to desired tunes and chromaticities, as it will determine the appropriate targets from the Madx instance's internal tables. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None accelerator str name of the accelerator, used to determmine knobs if 'variables' not given. Automatic determination will only work for LHC and HLLHC. None sequence str name of the sequence you want to activate for the tune matching. None varied_knobs Sequence[str] the variables names to 'vary' in the MADX routine. An input could be [\"kqf\", \"ksd\", \"kqf\", \"kqd\"] as they are common names used for quadrupole and sextupole strengths (foc / defoc) in most examples. None telescopic_squeeze bool LHC specific. If set to True, uses the (HL)LHC knobs for Telescopic Squeeze configuration. Defaults to False. None explicit_targets Tuple[float, float] if given, will be used as matching targets for Qx, Qy. Otherwise, the target is determined as the middle of the current fractional tunes. Defaults to None. None step float step size to use when varying knobs. None calls int max number of varying calls to perform. None tolerance float tolerance for successfull matching. None Returns: Type Description None The closest tune approach, in absolute value. View Source def get_closest_tune_approach ( madx : Madx , accelerator : str = None , sequence : str = None , varied_knobs : Sequence [ str ] = None , telescopic_squeeze : bool = False , explicit_targets : Tuple [ float, float ] = None , step : float = 1e-7 , calls : float = 100 , tolerance : float = 1e-21 , ) -> float : \"\"\" Provided with an active `cpymad` class after having ran a script, tries to match the tunes to their mid-fractional tunes. The difference between this mid-tune and the actual matched tune is the closest tune approach. NOTA BENE: This assumes your lattice has previously been matched to desired tunes and chromaticities, as it will determine the appropriate targets from the Madx instance's internal tables. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. accelerator (str): name of the accelerator, used to determmine knobs if 'variables' not given. Automatic determination will only work for LHC and HLLHC. sequence (str): name of the sequence you want to activate for the tune matching. varied_knobs (Sequence[str]): the variables names to 'vary' in the MADX routine. An input could be [\" kqf \", \" ksd \", \" kqf \", \" kqd \"] as they are common names used for quadrupole and sextupole strengths (foc / defoc) in most examples. telescopic_squeeze (bool): LHC specific. If set to True, uses the (HL)LHC knobs for Telescopic Squeeze configuration. Defaults to False. explicit_targets (Tuple[float, float]): if given, will be used as matching targets for Qx, Qy. Otherwise, the target is determined as the middle of the current fractional tunes. Defaults to None. step (float): step size to use when varying knobs. calls (int): max number of varying calls to perform. tolerance (float): tolerance for successfull matching. Returns: The closest tune approach, in absolute value. \"\"\" if accelerator and not varied_knobs : logger . trace ( f \"Getting knobs from default {accelerator.upper()} values\" ) varied_knobs = get_lhc_tune_and_chroma_knobs ( accelerator = accelerator , beam = int ( sequence [ -1 ] ), telescopic_squeeze = telescopic_squeeze ) logger . debug ( \"Saving knob values to restore after closest tune approach\" ) saved_knobs : Dict [ str, float ] = { knob : madx . globals [ knob ] for knob in varied_knobs } logger . trace ( f \"Saved knobs are {saved_knobs}\" ) if explicit_targets : qx_target , qy_target = explicit_targets q1 , q2 = qx_target , qy_target # the integer part is used later on else : logger . trace ( \"Retrieving tunes and chromaticities from internal tables\" ) q1 , q2 = madx . table . summ . q1 [ 0 ] , madx . table . summ . q2 [ 0 ] dq1 , dq2 = madx . table . summ . dq1 [ 0 ] , madx . table . summ . dq2 [ 0 ] logger . trace ( f \"Retrieved values are q1 = {q1}, q2 = {q2}, dq1 = {dq1}, dq2 = {dq2}\" ) logger . trace ( \"Determining target tunes for closest approach\" ) middle_of_fractional_tunes = ( _fractional_tune ( q1 ) + _fractional_tune ( q2 )) / 2 qx_target = int ( q1 ) + middle_of_fractional_tunes qy_target = int ( q2 ) + middle_of_fractional_tunes logger . debug ( f \"Targeting tunes Qx = {qx_target} | Qy = {qy_target}\" ) logger . info ( \"Performing closest tune approach routine, matching should fail at DeltaQ = dqmin\" ) match_tunes_and_chromaticities ( madx , accelerator , sequence , qx_target , qy_target , # dq1 , # remove ? # dq2 , # remove ? varied_knobs = varied_knobs , step = step , calls = calls , tolerance = tolerance , ) logger . debug ( \"Retrieving tune separation from internal tables\" ) dqmin = madx . table . summ . q1 [ 0 ] - madx . table . summ . q2 [ 0 ] - ( int ( q1 ) - int ( q2 )) logger . info ( \"Restoring saved knobs\" ) for knob , knob_value in saved_knobs . items () : madx . globals [ knob ] = knob_value madx . twiss () return abs ( dqmin ) get_lhc_tune_and_chroma_knobs def get_lhc_tune_and_chroma_knobs ( accelerator : str , beam : int = 1 , telescopic_squeeze : bool = False ) -> Tuple [ str , str , str , str ] INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get names of knobs needed to match tunes and chromaticities as a tuple of strings. Parameters: Name Type Description Default accelerator str Accelerator either 'LHC' (dQ[xy], dQp[xy] knobs) or 'HLLHC' (kqt[fd], ks[fd] knobs). None beam int Beam to use, for the knob names. None telescopic_squeeze bool if set to True, returns the knobs for Telescopic Squeeze configuration. Defaults to False. None Returns: Type Description None Tuple of strings with knobs for (qx, qy, dqx, dqy) . View Source def get_lhc_tune_and_chroma_knobs ( accelerator : str , beam : int = 1 , telescopic_squeeze : bool = False ) -> Tuple [ str, str, str, str ] : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get names of knobs needed to match tunes and chromaticities as a tuple of strings. Args: accelerator (str): Accelerator either 'LHC' (dQ[xy], dQp[xy] knobs) or 'HLLHC' (kqt[fd], ks[fd] knobs). beam (int): Beam to use, for the knob names. telescopic_squeeze (bool): if set to True, returns the knobs for Telescopic Squeeze configuration. Defaults to False. Returns: Tuple of strings with knobs for `(qx, qy, dqx, dqy)`. \"\"\" beam = 2 if beam == 4 else beam suffix = \"_sq\" if telescopic_squeeze else \"\" if accelerator . upper () not in ( \"LHC\" , \"HLLHC\" ) : logger . error ( \"Invalid accelerator name, only 'LHC' and 'HLLHC' implemented\" ) raise NotImplementedError ( f \"Accelerator '{accelerator}' not implemented.\" ) return { \"LHC\" : ( f \"dQx.b{beam}{suffix}\" , f \"dQy.b{beam}{suffix}\" , f \"dQpx.b{beam}{suffix}\" , f \"dQpy.b{beam}{suffix}\" , ), \"HLLHC\" : ( f \"kqtf.b{beam}{suffix}\" , f \"kqtd.b{beam}{suffix}\" , f \"ksf.b{beam}{suffix}\" , f \"ksd.b{beam}{suffix}\" , ), } [ accelerator.upper() ] match_tunes_and_chromaticities def match_tunes_and_chromaticities ( madx : cpymad . madx . Madx , accelerator : str = None , sequence : str = None , q1_target : float = None , q2_target : float = None , dq1_target : float = None , dq2_target : float = None , varied_knobs : Sequence [ str ] = None , telescopic_squeeze : bool = False , step : float = 1e-07 , calls : int = 100 , tolerance : float = 1e-21 ) -> None Provided with an active cpymad class after having ran a script, will run an additional matching command to reach the provided values for tunes and chromaticities. Tune matching is always performed. If chromaticity target values are given, then a matching is done for them, followed by an additionnal matching for both tunes and chromaticities. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None accelerator str name of the accelerator, used to determmine knobs if 'variables' not given. Automatic determination will only work for LHC and HLLHC. None sequence str name of the sequence you want to activate for the tune matching. None q1_target float horizontal tune to match to. None q2_target float vertical tune to match to. None dq1_target float horizontal chromaticity to match to. None dq2_target float vertical chromaticity to match to. None varied_knobs Sequence[str] the variables names to 'vary' in the MADX routine. An input could be [\"kqf\", \"ksd\", \"kqf\", \"kqd\"] as they are common names used for quadrupole and sextupole strengths (foc / defoc) in most examples. None telescopic_squeeze bool LHC specific. If set to True, uses the (HL)LHC knobs for Telescopic Squeeze configuration. Defaults to False, but will default to True in a later release. None step float step size to use when varying knobs. None calls int max number of varying calls to perform. None tolerance float tolerance for successfull matching. None View Source def match_tunes_and_chromaticities ( madx : Madx , accelerator : str = None , sequence : str = None , q1_target : float = None , q2_target : float = None , dq1_target : float = None , dq2_target : float = None , varied_knobs : Sequence [ str ] = None , telescopic_squeeze : bool = False , step : float = 1e-7 , calls : int = 100 , tolerance : float = 1e-21 , ) -> None : \"\"\" Provided with an active `cpymad` class after having ran a script, will run an additional matching command to reach the provided values for tunes and chromaticities. Tune matching is always performed. If chromaticity target values are given, then a matching is done for them, followed by an additionnal matching for both tunes and chromaticities. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. accelerator (str): name of the accelerator, used to determmine knobs if 'variables' not given. Automatic determination will only work for LHC and HLLHC. sequence (str): name of the sequence you want to activate for the tune matching. q1_target (float): horizontal tune to match to. q2_target (float): vertical tune to match to. dq1_target (float): horizontal chromaticity to match to. dq2_target (float): vertical chromaticity to match to. varied_knobs (Sequence[str]): the variables names to 'vary' in the MADX routine. An input could be [\" kqf \", \" ksd \", \" kqf \", \" kqd \"] as they are common names used for quadrupole and sextupole strengths (foc / defoc) in most examples. telescopic_squeeze (bool): LHC specific. If set to True, uses the (HL)LHC knobs for Telescopic Squeeze configuration. Defaults to False, but will default to True in a later release. step (float): step size to use when varying knobs. calls (int): max number of varying calls to perform. tolerance (float): tolerance for successfull matching. \"\"\" if accelerator and not varied_knobs : logger . trace ( f \"Getting knobs from default {accelerator.upper()} values\" ) varied_knobs = get_lhc_tune_and_chroma_knobs ( accelerator = accelerator , beam = int ( sequence [ -1 ] ), telescopic_squeeze = telescopic_squeeze ) def match ( * args , ** kwargs ) : \"\"\"Create matching commands for kwarg targets, varying the given args.\"\"\" logger . debug ( f \"Executing matching commands, using sequence '{sequence}'\" ) madx . command . match ( chrom = True ) logger . trace ( f \"Targets are given as {kwargs}\" ) madx . command . global_ ( sequence = sequence , ** kwargs ) for variable_name in args : logger . trace ( f \"Creating vary command for knob '{variable_name}'\" ) madx . command . vary ( name = variable_name , step = step ) madx . command . lmdif ( calls = calls , tolerance = tolerance ) madx . command . endmatch () logger . trace ( \"Performing routine TWISS\" ) madx . twiss () # prevents errors if the user forget to do so before querying tables if q1_target and q2_target and dq1_target and dq2_target : logger . info ( f \"Doing combined matching to Qx={q1_target}, Qy={q2_target}, \" f \"dqx={dq1_target}, dqy={dq2_target} for sequence '{sequence}'\" ) logger . trace ( f \"Vary knobs sent are {varied_knobs}\" ) match ( * varied_knobs , q1 = q1_target , q2 = q2_target , dq1 = dq1_target , dq2 = dq2_target ) elif q1_target and q2_target : logger . info ( f \"Matching tunes to Qx={q1_target}, Qy={q2_target} for sequence '{sequence}'\" ) logger . trace ( f \"Vary knobs sent are {varied_knobs[:2]}\" ) match ( * varied_knobs [ :2 ] , q1 = q1_target , q2 = q2_target ) # first two in varied_knobs are tune knobs","title":"Matching"},{"location":"reference/pyhdtoolkit/cpymadtools/matching/#module-pyhdtoolkitcpymadtoolsmatching","text":"Module cpymadtools.matching Created on 2020.02.03 View Source \"\"\" Module cpymadtools.matching --------------------------- Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to perform MAD-X matchings with a cpymad.madx.Madx object. \"\"\" from typing import Dict , Sequence , Tuple from cpymad.madx import Madx from loguru import logger # ----- Utlites ----- # def get_lhc_tune_and_chroma_knobs ( accelerator : str , beam : int = 1 , telescopic_squeeze : bool = False ) -> Tuple [ str , str , str , str ]: \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get names of knobs needed to match tunes and chromaticities as a tuple of strings. Args: accelerator (str): Accelerator either 'LHC' (dQ[xy], dQp[xy] knobs) or 'HLLHC' (kqt[fd], ks[fd] knobs). beam (int): Beam to use, for the knob names. telescopic_squeeze (bool): if set to True, returns the knobs for Telescopic Squeeze configuration. Defaults to False. Returns: Tuple of strings with knobs for `(qx, qy, dqx, dqy)`. \"\"\" beam = 2 if beam == 4 else beam suffix = \"_sq\" if telescopic_squeeze else \"\" if accelerator . upper () not in ( \"LHC\" , \"HLLHC\" ): logger . error ( \"Invalid accelerator name, only 'LHC' and 'HLLHC' implemented\" ) raise NotImplementedError ( f \"Accelerator ' { accelerator } ' not implemented.\" ) return { \"LHC\" : ( f \"dQx.b { beam }{ suffix } \" , f \"dQy.b { beam }{ suffix } \" , f \"dQpx.b { beam }{ suffix } \" , f \"dQpy.b { beam }{ suffix } \" , ), \"HLLHC\" : ( f \"kqtf.b { beam }{ suffix } \" , f \"kqtd.b { beam }{ suffix } \" , f \"ksf.b { beam }{ suffix } \" , f \"ksd.b { beam }{ suffix } \" , ), }[ accelerator . upper ()] def match_tunes_and_chromaticities ( madx : Madx , accelerator : str = None , sequence : str = None , q1_target : float = None , q2_target : float = None , dq1_target : float = None , dq2_target : float = None , varied_knobs : Sequence [ str ] = None , telescopic_squeeze : bool = False , step : float = 1e-7 , calls : int = 100 , tolerance : float = 1e-21 , ) -> None : \"\"\" Provided with an active `cpymad` class after having ran a script, will run an additional matching command to reach the provided values for tunes and chromaticities. Tune matching is always performed. If chromaticity target values are given, then a matching is done for them, followed by an additionnal matching for both tunes and chromaticities. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. accelerator (str): name of the accelerator, used to determmine knobs if 'variables' not given. Automatic determination will only work for LHC and HLLHC. sequence (str): name of the sequence you want to activate for the tune matching. q1_target (float): horizontal tune to match to. q2_target (float): vertical tune to match to. dq1_target (float): horizontal chromaticity to match to. dq2_target (float): vertical chromaticity to match to. varied_knobs (Sequence[str]): the variables names to 'vary' in the MADX routine. An input could be [\"kqf\", \"ksd\", \"kqf\", \"kqd\"] as they are common names used for quadrupole and sextupole strengths (foc / defoc) in most examples. telescopic_squeeze (bool): LHC specific. If set to True, uses the (HL)LHC knobs for Telescopic Squeeze configuration. Defaults to False, but will default to True in a later release. step (float): step size to use when varying knobs. calls (int): max number of varying calls to perform. tolerance (float): tolerance for successfull matching. \"\"\" if accelerator and not varied_knobs : logger . trace ( f \"Getting knobs from default { accelerator . upper () } values\" ) varied_knobs = get_lhc_tune_and_chroma_knobs ( accelerator = accelerator , beam = int ( sequence [ - 1 ]), telescopic_squeeze = telescopic_squeeze ) def match ( * args , ** kwargs ): \"\"\"Create matching commands for kwarg targets, varying the given args.\"\"\" logger . debug ( f \"Executing matching commands, using sequence ' { sequence } '\" ) madx . command . match ( chrom = True ) logger . trace ( f \"Targets are given as { kwargs } \" ) madx . command . global_ ( sequence = sequence , ** kwargs ) for variable_name in args : logger . trace ( f \"Creating vary command for knob ' { variable_name } '\" ) madx . command . vary ( name = variable_name , step = step ) madx . command . lmdif ( calls = calls , tolerance = tolerance ) madx . command . endmatch () logger . trace ( \"Performing routine TWISS\" ) madx . twiss () # prevents errors if the user forget to do so before querying tables if q1_target and q2_target and dq1_target and dq2_target : logger . info ( f \"Doing combined matching to Qx= { q1_target } , Qy= { q2_target } , \" f \"dqx= { dq1_target } , dqy= { dq2_target } for sequence ' { sequence } '\" ) logger . trace ( f \"Vary knobs sent are { varied_knobs } \" ) match ( * varied_knobs , q1 = q1_target , q2 = q2_target , dq1 = dq1_target , dq2 = dq2_target ) elif q1_target and q2_target : logger . info ( f \"Matching tunes to Qx= { q1_target } , Qy= { q2_target } for sequence ' { sequence } '\" ) logger . trace ( f \"Vary knobs sent are { varied_knobs [: 2 ] } \" ) match ( * varied_knobs [: 2 ], q1 = q1_target , q2 = q2_target ) # first two in varied_knobs are tune knobs def get_closest_tune_approach ( madx : Madx , accelerator : str = None , sequence : str = None , varied_knobs : Sequence [ str ] = None , telescopic_squeeze : bool = False , explicit_targets : Tuple [ float , float ] = None , step : float = 1e-7 , calls : float = 100 , tolerance : float = 1e-21 , ) -> float : \"\"\" Provided with an active `cpymad` class after having ran a script, tries to match the tunes to their mid-fractional tunes. The difference between this mid-tune and the actual matched tune is the closest tune approach. NOTA BENE: This assumes your lattice has previously been matched to desired tunes and chromaticities, as it will determine the appropriate targets from the Madx instance's internal tables. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. accelerator (str): name of the accelerator, used to determmine knobs if 'variables' not given. Automatic determination will only work for LHC and HLLHC. sequence (str): name of the sequence you want to activate for the tune matching. varied_knobs (Sequence[str]): the variables names to 'vary' in the MADX routine. An input could be [\"kqf\", \"ksd\", \"kqf\", \"kqd\"] as they are common names used for quadrupole and sextupole strengths (foc / defoc) in most examples. telescopic_squeeze (bool): LHC specific. If set to True, uses the (HL)LHC knobs for Telescopic Squeeze configuration. Defaults to False. explicit_targets (Tuple[float, float]): if given, will be used as matching targets for Qx, Qy. Otherwise, the target is determined as the middle of the current fractional tunes. Defaults to None. step (float): step size to use when varying knobs. calls (int): max number of varying calls to perform. tolerance (float): tolerance for successfull matching. Returns: The closest tune approach, in absolute value. \"\"\" if accelerator and not varied_knobs : logger . trace ( f \"Getting knobs from default { accelerator . upper () } values\" ) varied_knobs = get_lhc_tune_and_chroma_knobs ( accelerator = accelerator , beam = int ( sequence [ - 1 ]), telescopic_squeeze = telescopic_squeeze ) logger . debug ( \"Saving knob values to restore after closest tune approach\" ) saved_knobs : Dict [ str , float ] = { knob : madx . globals [ knob ] for knob in varied_knobs } logger . trace ( f \"Saved knobs are { saved_knobs } \" ) if explicit_targets : qx_target , qy_target = explicit_targets q1 , q2 = qx_target , qy_target # the integer part is used later on else : logger . trace ( \"Retrieving tunes and chromaticities from internal tables\" ) q1 , q2 = madx . table . summ . q1 [ 0 ], madx . table . summ . q2 [ 0 ] dq1 , dq2 = madx . table . summ . dq1 [ 0 ], madx . table . summ . dq2 [ 0 ] logger . trace ( f \"Retrieved values are q1 = { q1 } , q2 = { q2 } , dq1 = { dq1 } , dq2 = { dq2 } \" ) logger . trace ( \"Determining target tunes for closest approach\" ) middle_of_fractional_tunes = ( _fractional_tune ( q1 ) + _fractional_tune ( q2 )) / 2 qx_target = int ( q1 ) + middle_of_fractional_tunes qy_target = int ( q2 ) + middle_of_fractional_tunes logger . debug ( f \"Targeting tunes Qx = { qx_target } | Qy = { qy_target } \" ) logger . info ( \"Performing closest tune approach routine, matching should fail at DeltaQ = dqmin\" ) match_tunes_and_chromaticities ( madx , accelerator , sequence , qx_target , qy_target , # dq1, # remove? # dq2, # remove? varied_knobs = varied_knobs , step = step , calls = calls , tolerance = tolerance , ) logger . debug ( \"Retrieving tune separation from internal tables\" ) dqmin = madx . table . summ . q1 [ 0 ] - madx . table . summ . q2 [ 0 ] - ( int ( q1 ) - int ( q2 )) logger . info ( \"Restoring saved knobs\" ) for knob , knob_value in saved_knobs . items (): madx . globals [ knob ] = knob_value madx . twiss () return abs ( dqmin ) # ----- Helpers ----- # def _fractional_tune ( tune : float ) -> float : \"\"\" Return only the fractional part of a tune value. Args: tune (float): tune value. Returns: The fractional part. \"\"\" return tune - int ( tune ) # ok since int truncates to lower integer","title":"Module pyhdtoolkit.cpymadtools.matching"},{"location":"reference/pyhdtoolkit/cpymadtools/matching/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/cpymadtools/matching/#get_closest_tune_approach","text":"def get_closest_tune_approach ( madx : cpymad . madx . Madx , accelerator : str = None , sequence : str = None , varied_knobs : Sequence [ str ] = None , telescopic_squeeze : bool = False , explicit_targets : Tuple [ float , float ] = None , step : float = 1e-07 , calls : float = 100 , tolerance : float = 1e-21 ) -> float Provided with an active cpymad class after having ran a script, tries to match the tunes to their mid-fractional tunes. The difference between this mid-tune and the actual matched tune is the closest tune approach. NOTA BENE: This assumes your lattice has previously been matched to desired tunes and chromaticities, as it will determine the appropriate targets from the Madx instance's internal tables. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None accelerator str name of the accelerator, used to determmine knobs if 'variables' not given. Automatic determination will only work for LHC and HLLHC. None sequence str name of the sequence you want to activate for the tune matching. None varied_knobs Sequence[str] the variables names to 'vary' in the MADX routine. An input could be [\"kqf\", \"ksd\", \"kqf\", \"kqd\"] as they are common names used for quadrupole and sextupole strengths (foc / defoc) in most examples. None telescopic_squeeze bool LHC specific. If set to True, uses the (HL)LHC knobs for Telescopic Squeeze configuration. Defaults to False. None explicit_targets Tuple[float, float] if given, will be used as matching targets for Qx, Qy. Otherwise, the target is determined as the middle of the current fractional tunes. Defaults to None. None step float step size to use when varying knobs. None calls int max number of varying calls to perform. None tolerance float tolerance for successfull matching. None Returns: Type Description None The closest tune approach, in absolute value. View Source def get_closest_tune_approach ( madx : Madx , accelerator : str = None , sequence : str = None , varied_knobs : Sequence [ str ] = None , telescopic_squeeze : bool = False , explicit_targets : Tuple [ float, float ] = None , step : float = 1e-7 , calls : float = 100 , tolerance : float = 1e-21 , ) -> float : \"\"\" Provided with an active `cpymad` class after having ran a script, tries to match the tunes to their mid-fractional tunes. The difference between this mid-tune and the actual matched tune is the closest tune approach. NOTA BENE: This assumes your lattice has previously been matched to desired tunes and chromaticities, as it will determine the appropriate targets from the Madx instance's internal tables. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. accelerator (str): name of the accelerator, used to determmine knobs if 'variables' not given. Automatic determination will only work for LHC and HLLHC. sequence (str): name of the sequence you want to activate for the tune matching. varied_knobs (Sequence[str]): the variables names to 'vary' in the MADX routine. An input could be [\" kqf \", \" ksd \", \" kqf \", \" kqd \"] as they are common names used for quadrupole and sextupole strengths (foc / defoc) in most examples. telescopic_squeeze (bool): LHC specific. If set to True, uses the (HL)LHC knobs for Telescopic Squeeze configuration. Defaults to False. explicit_targets (Tuple[float, float]): if given, will be used as matching targets for Qx, Qy. Otherwise, the target is determined as the middle of the current fractional tunes. Defaults to None. step (float): step size to use when varying knobs. calls (int): max number of varying calls to perform. tolerance (float): tolerance for successfull matching. Returns: The closest tune approach, in absolute value. \"\"\" if accelerator and not varied_knobs : logger . trace ( f \"Getting knobs from default {accelerator.upper()} values\" ) varied_knobs = get_lhc_tune_and_chroma_knobs ( accelerator = accelerator , beam = int ( sequence [ -1 ] ), telescopic_squeeze = telescopic_squeeze ) logger . debug ( \"Saving knob values to restore after closest tune approach\" ) saved_knobs : Dict [ str, float ] = { knob : madx . globals [ knob ] for knob in varied_knobs } logger . trace ( f \"Saved knobs are {saved_knobs}\" ) if explicit_targets : qx_target , qy_target = explicit_targets q1 , q2 = qx_target , qy_target # the integer part is used later on else : logger . trace ( \"Retrieving tunes and chromaticities from internal tables\" ) q1 , q2 = madx . table . summ . q1 [ 0 ] , madx . table . summ . q2 [ 0 ] dq1 , dq2 = madx . table . summ . dq1 [ 0 ] , madx . table . summ . dq2 [ 0 ] logger . trace ( f \"Retrieved values are q1 = {q1}, q2 = {q2}, dq1 = {dq1}, dq2 = {dq2}\" ) logger . trace ( \"Determining target tunes for closest approach\" ) middle_of_fractional_tunes = ( _fractional_tune ( q1 ) + _fractional_tune ( q2 )) / 2 qx_target = int ( q1 ) + middle_of_fractional_tunes qy_target = int ( q2 ) + middle_of_fractional_tunes logger . debug ( f \"Targeting tunes Qx = {qx_target} | Qy = {qy_target}\" ) logger . info ( \"Performing closest tune approach routine, matching should fail at DeltaQ = dqmin\" ) match_tunes_and_chromaticities ( madx , accelerator , sequence , qx_target , qy_target , # dq1 , # remove ? # dq2 , # remove ? varied_knobs = varied_knobs , step = step , calls = calls , tolerance = tolerance , ) logger . debug ( \"Retrieving tune separation from internal tables\" ) dqmin = madx . table . summ . q1 [ 0 ] - madx . table . summ . q2 [ 0 ] - ( int ( q1 ) - int ( q2 )) logger . info ( \"Restoring saved knobs\" ) for knob , knob_value in saved_knobs . items () : madx . globals [ knob ] = knob_value madx . twiss () return abs ( dqmin )","title":"get_closest_tune_approach"},{"location":"reference/pyhdtoolkit/cpymadtools/matching/#get_lhc_tune_and_chroma_knobs","text":"def get_lhc_tune_and_chroma_knobs ( accelerator : str , beam : int = 1 , telescopic_squeeze : bool = False ) -> Tuple [ str , str , str , str ] INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get names of knobs needed to match tunes and chromaticities as a tuple of strings. Parameters: Name Type Description Default accelerator str Accelerator either 'LHC' (dQ[xy], dQp[xy] knobs) or 'HLLHC' (kqt[fd], ks[fd] knobs). None beam int Beam to use, for the knob names. None telescopic_squeeze bool if set to True, returns the knobs for Telescopic Squeeze configuration. Defaults to False. None Returns: Type Description None Tuple of strings with knobs for (qx, qy, dqx, dqy) . View Source def get_lhc_tune_and_chroma_knobs ( accelerator : str , beam : int = 1 , telescopic_squeeze : bool = False ) -> Tuple [ str, str, str, str ] : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get names of knobs needed to match tunes and chromaticities as a tuple of strings. Args: accelerator (str): Accelerator either 'LHC' (dQ[xy], dQp[xy] knobs) or 'HLLHC' (kqt[fd], ks[fd] knobs). beam (int): Beam to use, for the knob names. telescopic_squeeze (bool): if set to True, returns the knobs for Telescopic Squeeze configuration. Defaults to False. Returns: Tuple of strings with knobs for `(qx, qy, dqx, dqy)`. \"\"\" beam = 2 if beam == 4 else beam suffix = \"_sq\" if telescopic_squeeze else \"\" if accelerator . upper () not in ( \"LHC\" , \"HLLHC\" ) : logger . error ( \"Invalid accelerator name, only 'LHC' and 'HLLHC' implemented\" ) raise NotImplementedError ( f \"Accelerator '{accelerator}' not implemented.\" ) return { \"LHC\" : ( f \"dQx.b{beam}{suffix}\" , f \"dQy.b{beam}{suffix}\" , f \"dQpx.b{beam}{suffix}\" , f \"dQpy.b{beam}{suffix}\" , ), \"HLLHC\" : ( f \"kqtf.b{beam}{suffix}\" , f \"kqtd.b{beam}{suffix}\" , f \"ksf.b{beam}{suffix}\" , f \"ksd.b{beam}{suffix}\" , ), } [ accelerator.upper() ]","title":"get_lhc_tune_and_chroma_knobs"},{"location":"reference/pyhdtoolkit/cpymadtools/matching/#match_tunes_and_chromaticities","text":"def match_tunes_and_chromaticities ( madx : cpymad . madx . Madx , accelerator : str = None , sequence : str = None , q1_target : float = None , q2_target : float = None , dq1_target : float = None , dq2_target : float = None , varied_knobs : Sequence [ str ] = None , telescopic_squeeze : bool = False , step : float = 1e-07 , calls : int = 100 , tolerance : float = 1e-21 ) -> None Provided with an active cpymad class after having ran a script, will run an additional matching command to reach the provided values for tunes and chromaticities. Tune matching is always performed. If chromaticity target values are given, then a matching is done for them, followed by an additionnal matching for both tunes and chromaticities. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None accelerator str name of the accelerator, used to determmine knobs if 'variables' not given. Automatic determination will only work for LHC and HLLHC. None sequence str name of the sequence you want to activate for the tune matching. None q1_target float horizontal tune to match to. None q2_target float vertical tune to match to. None dq1_target float horizontal chromaticity to match to. None dq2_target float vertical chromaticity to match to. None varied_knobs Sequence[str] the variables names to 'vary' in the MADX routine. An input could be [\"kqf\", \"ksd\", \"kqf\", \"kqd\"] as they are common names used for quadrupole and sextupole strengths (foc / defoc) in most examples. None telescopic_squeeze bool LHC specific. If set to True, uses the (HL)LHC knobs for Telescopic Squeeze configuration. Defaults to False, but will default to True in a later release. None step float step size to use when varying knobs. None calls int max number of varying calls to perform. None tolerance float tolerance for successfull matching. None View Source def match_tunes_and_chromaticities ( madx : Madx , accelerator : str = None , sequence : str = None , q1_target : float = None , q2_target : float = None , dq1_target : float = None , dq2_target : float = None , varied_knobs : Sequence [ str ] = None , telescopic_squeeze : bool = False , step : float = 1e-7 , calls : int = 100 , tolerance : float = 1e-21 , ) -> None : \"\"\" Provided with an active `cpymad` class after having ran a script, will run an additional matching command to reach the provided values for tunes and chromaticities. Tune matching is always performed. If chromaticity target values are given, then a matching is done for them, followed by an additionnal matching for both tunes and chromaticities. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. accelerator (str): name of the accelerator, used to determmine knobs if 'variables' not given. Automatic determination will only work for LHC and HLLHC. sequence (str): name of the sequence you want to activate for the tune matching. q1_target (float): horizontal tune to match to. q2_target (float): vertical tune to match to. dq1_target (float): horizontal chromaticity to match to. dq2_target (float): vertical chromaticity to match to. varied_knobs (Sequence[str]): the variables names to 'vary' in the MADX routine. An input could be [\" kqf \", \" ksd \", \" kqf \", \" kqd \"] as they are common names used for quadrupole and sextupole strengths (foc / defoc) in most examples. telescopic_squeeze (bool): LHC specific. If set to True, uses the (HL)LHC knobs for Telescopic Squeeze configuration. Defaults to False, but will default to True in a later release. step (float): step size to use when varying knobs. calls (int): max number of varying calls to perform. tolerance (float): tolerance for successfull matching. \"\"\" if accelerator and not varied_knobs : logger . trace ( f \"Getting knobs from default {accelerator.upper()} values\" ) varied_knobs = get_lhc_tune_and_chroma_knobs ( accelerator = accelerator , beam = int ( sequence [ -1 ] ), telescopic_squeeze = telescopic_squeeze ) def match ( * args , ** kwargs ) : \"\"\"Create matching commands for kwarg targets, varying the given args.\"\"\" logger . debug ( f \"Executing matching commands, using sequence '{sequence}'\" ) madx . command . match ( chrom = True ) logger . trace ( f \"Targets are given as {kwargs}\" ) madx . command . global_ ( sequence = sequence , ** kwargs ) for variable_name in args : logger . trace ( f \"Creating vary command for knob '{variable_name}'\" ) madx . command . vary ( name = variable_name , step = step ) madx . command . lmdif ( calls = calls , tolerance = tolerance ) madx . command . endmatch () logger . trace ( \"Performing routine TWISS\" ) madx . twiss () # prevents errors if the user forget to do so before querying tables if q1_target and q2_target and dq1_target and dq2_target : logger . info ( f \"Doing combined matching to Qx={q1_target}, Qy={q2_target}, \" f \"dqx={dq1_target}, dqy={dq2_target} for sequence '{sequence}'\" ) logger . trace ( f \"Vary knobs sent are {varied_knobs}\" ) match ( * varied_knobs , q1 = q1_target , q2 = q2_target , dq1 = dq1_target , dq2 = dq2_target ) elif q1_target and q2_target : logger . info ( f \"Matching tunes to Qx={q1_target}, Qy={q2_target} for sequence '{sequence}'\" ) logger . trace ( f \"Vary knobs sent are {varied_knobs[:2]}\" ) match ( * varied_knobs [ :2 ] , q1 = q1_target , q2 = q2_target ) # first two in varied_knobs are tune knobs","title":"match_tunes_and_chromaticities"},{"location":"reference/pyhdtoolkit/cpymadtools/orbit/","text":"Module pyhdtoolkit.cpymadtools.orbit Module cpymadtools.orbit Created on 2020.02.03 View Source \"\"\" Module cpymadtools.orbit ------------------------ Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to perform MAD-X orbit setup with a cpymad.madx.Madx object, mainly for LHC and HLLHC machines. \"\"\" from typing import Dict , List , Tuple from cpymad.madx import Madx from loguru import logger from pyhdtoolkit.cpymadtools.constants import LHC_CROSSING_SCHEMES # ----- Utilities ----- # def lhc_orbit_variables () -> Tuple [ List [ str ], Dict [ str , str ]]: \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get the variable names used for orbit setup in the (HL)LHC. Returns: A tuple with a list of all orbit variables, and a dict of additional variables, that in the default configurations have the same value as another variable. \"\"\" logger . trace ( \"Returning (HL)LHC orbit variables\" ) on_variables = ( \"crab1\" , \"crab5\" , # exists only in HL-LHC \"x1\" , \"sep1\" , \"o1\" , \"oh1\" , \"ov1\" , \"x2\" , \"sep2\" , \"o2\" , \"oe2\" , \"a2\" , \"oh2\" , \"ov2\" , \"x5\" , \"sep5\" , \"o5\" , \"oh5\" , \"ov5\" , \"phi_IR5\" , \"x8\" , \"sep8\" , \"o8\" , \"a8\" , \"sep8h\" , \"x8v\" , \"oh8\" , \"ov8\" , \"alice\" , \"sol_alice\" , \"lhcb\" , \"sol_atlas\" , \"sol_cms\" , ) variables = [ f \"on_ { var } \" for var in on_variables ] + [ f \"phi_IR { ir : d } \" for ir in ( 1 , 2 , 5 , 8 )] special = { \"on_ssep1\" : \"on_sep1\" , \"on_xx1\" : \"on_x1\" , \"on_ssep5\" : \"on_sep5\" , \"on_xx5\" : \"on_x5\" , } return variables , special def setup_lhc_orbit ( madx : Madx , scheme : str = \"flat\" , ** kwargs ) -> Dict [ str , float ]: \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Automated orbit setup for (hl)lhc runs, for some default schemes. Assumed that at least sequence and optics files have been called. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. scheme (str): the default scheme to apply, as defined in `LHC_CROSSING_SCHEMES`. Accepted values are keys of `LHC_CROSSING_SCHEMES`. Defaults to 'flat' (every orbit variable to 0). Keyword Args: All standard crossing scheme variables (on_x1, phi_IR1, etc). Values given here override the values in the default scheme configurations. Returns: A dictionary of all orbit variables set, and their values as set in the MAD-X globals. \"\"\" if scheme not in LHC_CROSSING_SCHEMES . keys (): logger . error ( f \"Invalid scheme parameter, should be one of { LHC_CROSSING_SCHEMES . keys () } \" ) raise ValueError ( \"Invalid scheme parameter given\" ) logger . debug ( \"Getting orbit variables\" ) variables , special = lhc_orbit_variables () scheme_dict = LHC_CROSSING_SCHEMES [ scheme ] final_scheme = {} for orbit_variable in variables : variable_value = kwargs . get ( orbit_variable , scheme_dict . get ( orbit_variable , 0 )) logger . trace ( f \"Setting orbit variable ' { orbit_variable } ' to { variable_value } \" ) # Sets value in MAD-X globals & returned dict, taken from scheme dict or kwargs if provided madx . globals [ orbit_variable ] = final_scheme [ orbit_variable ] = variable_value for special_variable , copy_from in special . items (): special_variable_value = kwargs . get ( special_variable , madx . globals [ copy_from ]) logger . trace ( f \"Setting special orbit variable ' { special_variable } ' to { special_variable_value } \" ) # Sets value in MAD-X globals & returned dict, taken from a given global or kwargs if provided madx . globals [ special_variable ] = final_scheme [ special_variable ] = special_variable_value return final_scheme def get_current_orbit_setup ( madx : Madx ) -> Dict [ str , float ]: \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get the current values for the (HL)LHC orbit variales. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. Returns: A dictionary of all orbit variables set, and their values as set in the MAD-X globals. \"\"\" logger . debug ( \"Extracting orbit variables from global table\" ) variables , specials = lhc_orbit_variables () return { orbit_variable : madx . globals [ orbit_variable ] for orbit_variable in variables + list ( specials . keys ()) } Variables LHC_CROSSING_SCHEMES Functions get_current_orbit_setup def get_current_orbit_setup ( madx : cpymad . madx . Madx ) -> Dict [ str , float ] INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get the current values for the (HL)LHC orbit variales. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None Returns: Type Description None A dictionary of all orbit variables set, and their values as set in the MAD-X globals. View Source def get_current_orbit_setup ( madx : Madx ) -> Dict [ str, float ] : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get the current values for the (HL)LHC orbit variales. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. Returns: A dictionary of all orbit variables set, and their values as set in the MAD-X globals. \"\"\" logger . debug ( \"Extracting orbit variables from global table\" ) variables , specials = lhc_orbit_variables () return { orbit_variable : madx . globals [ orbit_variable ] for orbit_variable in variables + list ( specials . keys ()) } lhc_orbit_variables def lhc_orbit_variables ( ) -> Tuple [ List [ str ], Dict [ str , str ]] INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get the variable names used for orbit setup in the (HL)LHC. Returns: Type Description None A tuple with a list of all orbit variables, and a dict of additional variables, that in the default configurations have the same value as another variable. View Source def lhc_orbit_variables () -> Tuple [ List[str ] , Dict [ str, str ] ]: \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get the variable names used for orbit setup in the (HL)LHC. Returns: A tuple with a list of all orbit variables, and a dict of additional variables, that in the default configurations have the same value as another variable. \"\"\" logger . trace ( \"Returning (HL)LHC orbit variables\" ) on_variables = ( \"crab1\" , \"crab5\" , # exists only in HL - LHC \"x1\" , \"sep1\" , \"o1\" , \"oh1\" , \"ov1\" , \"x2\" , \"sep2\" , \"o2\" , \"oe2\" , \"a2\" , \"oh2\" , \"ov2\" , \"x5\" , \"sep5\" , \"o5\" , \"oh5\" , \"ov5\" , \"phi_IR5\" , \"x8\" , \"sep8\" , \"o8\" , \"a8\" , \"sep8h\" , \"x8v\" , \"oh8\" , \"ov8\" , \"alice\" , \"sol_alice\" , \"lhcb\" , \"sol_atlas\" , \"sol_cms\" , ) variables = [ f\"on_{var}\" for var in on_variables ] + [ f\"phi_IR{ir:d}\" for ir in (1, 2, 5, 8) ] special = { \"on_ssep1\" : \"on_sep1\" , \"on_xx1\" : \"on_x1\" , \"on_ssep5\" : \"on_sep5\" , \"on_xx5\" : \"on_x5\" , } return variables , special setup_lhc_orbit def setup_lhc_orbit ( madx : cpymad . madx . Madx , scheme : str = 'flat' , ** kwargs ) -> Dict [ str , float ] INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Automated orbit setup for (hl)lhc runs, for some default schemes. Assumed that at least sequence and optics files have been called. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. scheme (str): the default scheme to apply, as defined in LHC_CROSSING_SCHEMES . Accepted values are keys of LHC_CROSSING_SCHEMES . Defaults to 'flat' (every orbit variable to 0). Keyword Args: All standard crossing scheme variables (on_x1, phi_IR1, etc). Values given here override the values in the default scheme configurations. Returns: A dictionary of all orbit variables set, and their values as set in the MAD-X globals. View Source def setup_lhc_orbit ( madx : Madx , scheme : str = \"flat\" , ** kwargs ) -> Dict [ str, float ] : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Automated orbit setup for (hl)lhc runs, for some default schemes. Assumed that at least sequence and optics files have been called. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. scheme (str): the default scheme to apply, as defined in `LHC_CROSSING_SCHEMES`. Accepted values are keys of `LHC_CROSSING_SCHEMES`. Defaults to 'flat' (every orbit variable to 0). Keyword Args: All standard crossing scheme variables (on_x1, phi_IR1, etc). Values given here override the values in the default scheme configurations. Returns: A dictionary of all orbit variables set, and their values as set in the MAD-X globals. \"\"\" if scheme not in LHC_CROSSING_SCHEMES . keys () : logger . error ( f \"Invalid scheme parameter, should be one of {LHC_CROSSING_SCHEMES.keys()}\" ) raise ValueError ( \"Invalid scheme parameter given\" ) logger . debug ( \"Getting orbit variables\" ) variables , special = lhc_orbit_variables () scheme_dict = LHC_CROSSING_SCHEMES [ scheme ] final_scheme = {} for orbit_variable in variables : variable_value = kwargs . get ( orbit_variable , scheme_dict . get ( orbit_variable , 0 )) logger . trace ( f \"Setting orbit variable '{orbit_variable}' to {variable_value}\" ) # Sets value in MAD - X globals & returned dict , taken from scheme dict or kwargs if provided madx . globals [ orbit_variable ] = final_scheme [ orbit_variable ] = variable_value for special_variable , copy_from in special . items () : special_variable_value = kwargs . get ( special_variable , madx . globals [ copy_from ] ) logger . trace ( f \"Setting special orbit variable '{special_variable}' to {special_variable_value}\" ) # Sets value in MAD - X globals & returned dict , taken from a given global or kwargs if provided madx . globals [ special_variable ] = final_scheme [ special_variable ] = special_variable_value return final_scheme","title":"Orbit"},{"location":"reference/pyhdtoolkit/cpymadtools/orbit/#module-pyhdtoolkitcpymadtoolsorbit","text":"Module cpymadtools.orbit Created on 2020.02.03 View Source \"\"\" Module cpymadtools.orbit ------------------------ Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to perform MAD-X orbit setup with a cpymad.madx.Madx object, mainly for LHC and HLLHC machines. \"\"\" from typing import Dict , List , Tuple from cpymad.madx import Madx from loguru import logger from pyhdtoolkit.cpymadtools.constants import LHC_CROSSING_SCHEMES # ----- Utilities ----- # def lhc_orbit_variables () -> Tuple [ List [ str ], Dict [ str , str ]]: \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get the variable names used for orbit setup in the (HL)LHC. Returns: A tuple with a list of all orbit variables, and a dict of additional variables, that in the default configurations have the same value as another variable. \"\"\" logger . trace ( \"Returning (HL)LHC orbit variables\" ) on_variables = ( \"crab1\" , \"crab5\" , # exists only in HL-LHC \"x1\" , \"sep1\" , \"o1\" , \"oh1\" , \"ov1\" , \"x2\" , \"sep2\" , \"o2\" , \"oe2\" , \"a2\" , \"oh2\" , \"ov2\" , \"x5\" , \"sep5\" , \"o5\" , \"oh5\" , \"ov5\" , \"phi_IR5\" , \"x8\" , \"sep8\" , \"o8\" , \"a8\" , \"sep8h\" , \"x8v\" , \"oh8\" , \"ov8\" , \"alice\" , \"sol_alice\" , \"lhcb\" , \"sol_atlas\" , \"sol_cms\" , ) variables = [ f \"on_ { var } \" for var in on_variables ] + [ f \"phi_IR { ir : d } \" for ir in ( 1 , 2 , 5 , 8 )] special = { \"on_ssep1\" : \"on_sep1\" , \"on_xx1\" : \"on_x1\" , \"on_ssep5\" : \"on_sep5\" , \"on_xx5\" : \"on_x5\" , } return variables , special def setup_lhc_orbit ( madx : Madx , scheme : str = \"flat\" , ** kwargs ) -> Dict [ str , float ]: \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Automated orbit setup for (hl)lhc runs, for some default schemes. Assumed that at least sequence and optics files have been called. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. scheme (str): the default scheme to apply, as defined in `LHC_CROSSING_SCHEMES`. Accepted values are keys of `LHC_CROSSING_SCHEMES`. Defaults to 'flat' (every orbit variable to 0). Keyword Args: All standard crossing scheme variables (on_x1, phi_IR1, etc). Values given here override the values in the default scheme configurations. Returns: A dictionary of all orbit variables set, and their values as set in the MAD-X globals. \"\"\" if scheme not in LHC_CROSSING_SCHEMES . keys (): logger . error ( f \"Invalid scheme parameter, should be one of { LHC_CROSSING_SCHEMES . keys () } \" ) raise ValueError ( \"Invalid scheme parameter given\" ) logger . debug ( \"Getting orbit variables\" ) variables , special = lhc_orbit_variables () scheme_dict = LHC_CROSSING_SCHEMES [ scheme ] final_scheme = {} for orbit_variable in variables : variable_value = kwargs . get ( orbit_variable , scheme_dict . get ( orbit_variable , 0 )) logger . trace ( f \"Setting orbit variable ' { orbit_variable } ' to { variable_value } \" ) # Sets value in MAD-X globals & returned dict, taken from scheme dict or kwargs if provided madx . globals [ orbit_variable ] = final_scheme [ orbit_variable ] = variable_value for special_variable , copy_from in special . items (): special_variable_value = kwargs . get ( special_variable , madx . globals [ copy_from ]) logger . trace ( f \"Setting special orbit variable ' { special_variable } ' to { special_variable_value } \" ) # Sets value in MAD-X globals & returned dict, taken from a given global or kwargs if provided madx . globals [ special_variable ] = final_scheme [ special_variable ] = special_variable_value return final_scheme def get_current_orbit_setup ( madx : Madx ) -> Dict [ str , float ]: \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get the current values for the (HL)LHC orbit variales. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. Returns: A dictionary of all orbit variables set, and their values as set in the MAD-X globals. \"\"\" logger . debug ( \"Extracting orbit variables from global table\" ) variables , specials = lhc_orbit_variables () return { orbit_variable : madx . globals [ orbit_variable ] for orbit_variable in variables + list ( specials . keys ()) }","title":"Module pyhdtoolkit.cpymadtools.orbit"},{"location":"reference/pyhdtoolkit/cpymadtools/orbit/#variables","text":"LHC_CROSSING_SCHEMES","title":"Variables"},{"location":"reference/pyhdtoolkit/cpymadtools/orbit/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/cpymadtools/orbit/#get_current_orbit_setup","text":"def get_current_orbit_setup ( madx : cpymad . madx . Madx ) -> Dict [ str , float ] INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get the current values for the (HL)LHC orbit variales. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None Returns: Type Description None A dictionary of all orbit variables set, and their values as set in the MAD-X globals. View Source def get_current_orbit_setup ( madx : Madx ) -> Dict [ str, float ] : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get the current values for the (HL)LHC orbit variales. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. Returns: A dictionary of all orbit variables set, and their values as set in the MAD-X globals. \"\"\" logger . debug ( \"Extracting orbit variables from global table\" ) variables , specials = lhc_orbit_variables () return { orbit_variable : madx . globals [ orbit_variable ] for orbit_variable in variables + list ( specials . keys ()) }","title":"get_current_orbit_setup"},{"location":"reference/pyhdtoolkit/cpymadtools/orbit/#lhc_orbit_variables","text":"def lhc_orbit_variables ( ) -> Tuple [ List [ str ], Dict [ str , str ]] INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get the variable names used for orbit setup in the (HL)LHC. Returns: Type Description None A tuple with a list of all orbit variables, and a dict of additional variables, that in the default configurations have the same value as another variable. View Source def lhc_orbit_variables () -> Tuple [ List[str ] , Dict [ str, str ] ]: \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Get the variable names used for orbit setup in the (HL)LHC. Returns: A tuple with a list of all orbit variables, and a dict of additional variables, that in the default configurations have the same value as another variable. \"\"\" logger . trace ( \"Returning (HL)LHC orbit variables\" ) on_variables = ( \"crab1\" , \"crab5\" , # exists only in HL - LHC \"x1\" , \"sep1\" , \"o1\" , \"oh1\" , \"ov1\" , \"x2\" , \"sep2\" , \"o2\" , \"oe2\" , \"a2\" , \"oh2\" , \"ov2\" , \"x5\" , \"sep5\" , \"o5\" , \"oh5\" , \"ov5\" , \"phi_IR5\" , \"x8\" , \"sep8\" , \"o8\" , \"a8\" , \"sep8h\" , \"x8v\" , \"oh8\" , \"ov8\" , \"alice\" , \"sol_alice\" , \"lhcb\" , \"sol_atlas\" , \"sol_cms\" , ) variables = [ f\"on_{var}\" for var in on_variables ] + [ f\"phi_IR{ir:d}\" for ir in (1, 2, 5, 8) ] special = { \"on_ssep1\" : \"on_sep1\" , \"on_xx1\" : \"on_x1\" , \"on_ssep5\" : \"on_sep5\" , \"on_xx5\" : \"on_x5\" , } return variables , special","title":"lhc_orbit_variables"},{"location":"reference/pyhdtoolkit/cpymadtools/orbit/#setup_lhc_orbit","text":"def setup_lhc_orbit ( madx : cpymad . madx . Madx , scheme : str = 'flat' , ** kwargs ) -> Dict [ str , float ] INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Automated orbit setup for (hl)lhc runs, for some default schemes. Assumed that at least sequence and optics files have been called. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. scheme (str): the default scheme to apply, as defined in LHC_CROSSING_SCHEMES . Accepted values are keys of LHC_CROSSING_SCHEMES . Defaults to 'flat' (every orbit variable to 0). Keyword Args: All standard crossing scheme variables (on_x1, phi_IR1, etc). Values given here override the values in the default scheme configurations. Returns: A dictionary of all orbit variables set, and their values as set in the MAD-X globals. View Source def setup_lhc_orbit ( madx : Madx , scheme : str = \"flat\" , ** kwargs ) -> Dict [ str, float ] : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Automated orbit setup for (hl)lhc runs, for some default schemes. Assumed that at least sequence and optics files have been called. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. scheme (str): the default scheme to apply, as defined in `LHC_CROSSING_SCHEMES`. Accepted values are keys of `LHC_CROSSING_SCHEMES`. Defaults to 'flat' (every orbit variable to 0). Keyword Args: All standard crossing scheme variables (on_x1, phi_IR1, etc). Values given here override the values in the default scheme configurations. Returns: A dictionary of all orbit variables set, and their values as set in the MAD-X globals. \"\"\" if scheme not in LHC_CROSSING_SCHEMES . keys () : logger . error ( f \"Invalid scheme parameter, should be one of {LHC_CROSSING_SCHEMES.keys()}\" ) raise ValueError ( \"Invalid scheme parameter given\" ) logger . debug ( \"Getting orbit variables\" ) variables , special = lhc_orbit_variables () scheme_dict = LHC_CROSSING_SCHEMES [ scheme ] final_scheme = {} for orbit_variable in variables : variable_value = kwargs . get ( orbit_variable , scheme_dict . get ( orbit_variable , 0 )) logger . trace ( f \"Setting orbit variable '{orbit_variable}' to {variable_value}\" ) # Sets value in MAD - X globals & returned dict , taken from scheme dict or kwargs if provided madx . globals [ orbit_variable ] = final_scheme [ orbit_variable ] = variable_value for special_variable , copy_from in special . items () : special_variable_value = kwargs . get ( special_variable , madx . globals [ copy_from ] ) logger . trace ( f \"Setting special orbit variable '{special_variable}' to {special_variable_value}\" ) # Sets value in MAD - X globals & returned dict , taken from a given global or kwargs if provided madx . globals [ special_variable ] = final_scheme [ special_variable ] = special_variable_value return final_scheme","title":"setup_lhc_orbit"},{"location":"reference/pyhdtoolkit/cpymadtools/parameters/","text":"Module pyhdtoolkit.cpymadtools.parameters Module cpymadtools.parameters Created on 2020.02.03 View Source \"\"\" Module cpymadtools.parameters ----------------------------- Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to compute different beam and machine parameters. \"\"\" from typing import Dict import numpy as np from loguru import logger # ----- Utilities ----- # def beam_parameters ( pc_gev : float , en_x_m : float , en_y_m : float , deltap_p : float , verbose : bool = False , ) -> Dict [ str , float ]: \"\"\"Calculate beam parameters from provided values. Args: pc_gev (float): particle momentum. en_x_m (float): horizontal emittance, in meters. en_y_m (float): vertical emittance, in meters. deltap_p (float): momentum deviation. verbose (bool): bolean, whether to print out a summary of parameters or not. Returns: A dictionnary with the calculated values. \"\"\" e0_gev = 0.9382720813 e_tot_gev = np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) gamma_r = e_tot_gev / e0_gev beta_r = pc_gev / np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) parameters : Dict [ str , float ] = { \"pc_GeV\" : pc_gev , # Particle momentum [GeV] \"B_rho_Tm\" : 3.3356 * pc_gev , # Beam rigidity [T/m] \"E_0_GeV\" : e0_gev , # Rest mass energy [GeV] \"E_tot_GeV\" : e_tot_gev , # Total beam energy [GeV] \"E_kin_GeV\" : e_tot_gev - e0_gev , # Kinectic beam energy [GeV] \"gamma_r\" : gamma_r , # Relativistic gamma \"beta_r\" : beta_r , # Relativistic beta \"en_x_m\" : en_x_m , # Horizontal emittance [m] \"en_y_m\" : en_y_m , # Vertical emittance [m] \"eg_x_m\" : en_x_m / gamma_r / beta_r , # Horizontal geometrical emittance \"eg_y_m\" : en_y_m / gamma_r / beta_r , # Vertical geometrical emittance \"deltap_p\" : deltap_p , # Momentum deviation } if verbose : logger . trace ( \"Outputing computed parameter values\" ) print ( f \"\"\"Particle type: proton Beam momentum = { parameters [ \"pc_GeV\" ] : 2.3f } GeV/c Normalized x-emittance = { parameters [ \"en_x_m\" ] * 1e6 : 2.3f } mm mrad Normalized y-emittance = { parameters [ \"en_y_m\" ] * 1e6 : 2.3f } mm mrad Momentum deviation deltap/p = { parameters [ \"deltap_p\" ] } -> Beam total energy = { parameters [ \"E_tot_GeV\" ] : 2.3f } GeV -> Beam kinetic energy = { parameters [ \"E_kin_GeV\" ] : 2.3f } GeV -> Beam rigidity = { parameters [ \"B_rho_Tm\" ] : 2.3f } Tm -> Relativistic beta = { parameters [ \"beta_r\" ] : 2.5f } -> Relativistic gamma = { parameters [ \"gamma_r\" ] : 2.3f } -> Geometrical x emittance = { parameters [ \"eg_x_m\" ] * 1e6 : 2.3f } mm mrad -> Geometrical y emittance = { parameters [ \"eg_y_m\" ] * 1e6 : 2.3f } mm mrad \"\"\" ) return parameters Functions beam_parameters def beam_parameters ( pc_gev : float , en_x_m : float , en_y_m : float , deltap_p : float , verbose : bool = False ) -> Dict [ str , float ] Calculate beam parameters from provided values. Parameters: Name Type Description Default pc_gev float particle momentum. None en_x_m float horizontal emittance, in meters. None en_y_m float vertical emittance, in meters. None deltap_p float momentum deviation. None verbose bool bolean, whether to print out a summary of parameters or not. None Returns: Type Description None A dictionnary with the calculated values. View Source def beam_parameters ( pc_gev : float , en_x_m : float , en_y_m : float , deltap_p : float , verbose : bool = False , ) -> Dict [ str, float ] : \"\"\"Calculate beam parameters from provided values. Args: pc_gev (float): particle momentum. en_x_m (float): horizontal emittance, in meters. en_y_m (float): vertical emittance, in meters. deltap_p (float): momentum deviation. verbose (bool): bolean, whether to print out a summary of parameters or not. Returns: A dictionnary with the calculated values. \"\"\" e0_gev = 0.9382720813 e_tot_gev = np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) gamma_r = e_tot_gev / e0_gev beta_r = pc_gev / np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) parameters : Dict [ str, float ] = { \"pc_GeV\" : pc_gev , # Particle momentum [ GeV ] \"B_rho_Tm\" : 3.3356 * pc_gev , # Beam rigidity [ T/m ] \"E_0_GeV\" : e0_gev , # Rest mass energy [ GeV ] \"E_tot_GeV\" : e_tot_gev , # Total beam energy [ GeV ] \"E_kin_GeV\" : e_tot_gev - e0_gev , # Kinectic beam energy [ GeV ] \"gamma_r\" : gamma_r , # Relativistic gamma \"beta_r\" : beta_r , # Relativistic beta \"en_x_m\" : en_x_m , # Horizontal emittance [ m ] \"en_y_m\" : en_y_m , # Vertical emittance [ m ] \"eg_x_m\" : en_x_m / gamma_r / beta_r , # Horizontal geometrical emittance \"eg_y_m\" : en_y_m / gamma_r / beta_r , # Vertical geometrical emittance \"deltap_p\" : deltap_p , # Momentum deviation } if verbose : logger . trace ( \"Outputing computed parameter values\" ) print ( f \"\"\"Particle type: proton Beam momentum = {parameters[\" pc_GeV \"]:2.3f} GeV/c Normalized x-emittance = {parameters[\" en_x_m \"] * 1e6:2.3f} mm mrad Normalized y-emittance = {parameters[\" en_y_m \"] * 1e6:2.3f} mm mrad Momentum deviation deltap/p = {parameters[\" deltap_p \"]} -> Beam total energy = {parameters[\" E_tot_GeV \"]:2.3f} GeV -> Beam kinetic energy = {parameters[\" E_kin_GeV \"]:2.3f} GeV -> Beam rigidity = {parameters[\" B_rho_Tm \"]:2.3f} Tm -> Relativistic beta = {parameters[\" beta_r \"]:2.5f} -> Relativistic gamma = {parameters[\" gamma_r \"]:2.3f} -> Geometrical x emittance = {parameters[\" eg_x_m \"] * 1e6:2.3f} mm mrad -> Geometrical y emittance = {parameters[\" eg_y_m \"] * 1e6:2.3f} mm mrad \"\"\" ) return parameters","title":"Parameters"},{"location":"reference/pyhdtoolkit/cpymadtools/parameters/#module-pyhdtoolkitcpymadtoolsparameters","text":"Module cpymadtools.parameters Created on 2020.02.03 View Source \"\"\" Module cpymadtools.parameters ----------------------------- Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to compute different beam and machine parameters. \"\"\" from typing import Dict import numpy as np from loguru import logger # ----- Utilities ----- # def beam_parameters ( pc_gev : float , en_x_m : float , en_y_m : float , deltap_p : float , verbose : bool = False , ) -> Dict [ str , float ]: \"\"\"Calculate beam parameters from provided values. Args: pc_gev (float): particle momentum. en_x_m (float): horizontal emittance, in meters. en_y_m (float): vertical emittance, in meters. deltap_p (float): momentum deviation. verbose (bool): bolean, whether to print out a summary of parameters or not. Returns: A dictionnary with the calculated values. \"\"\" e0_gev = 0.9382720813 e_tot_gev = np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) gamma_r = e_tot_gev / e0_gev beta_r = pc_gev / np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) parameters : Dict [ str , float ] = { \"pc_GeV\" : pc_gev , # Particle momentum [GeV] \"B_rho_Tm\" : 3.3356 * pc_gev , # Beam rigidity [T/m] \"E_0_GeV\" : e0_gev , # Rest mass energy [GeV] \"E_tot_GeV\" : e_tot_gev , # Total beam energy [GeV] \"E_kin_GeV\" : e_tot_gev - e0_gev , # Kinectic beam energy [GeV] \"gamma_r\" : gamma_r , # Relativistic gamma \"beta_r\" : beta_r , # Relativistic beta \"en_x_m\" : en_x_m , # Horizontal emittance [m] \"en_y_m\" : en_y_m , # Vertical emittance [m] \"eg_x_m\" : en_x_m / gamma_r / beta_r , # Horizontal geometrical emittance \"eg_y_m\" : en_y_m / gamma_r / beta_r , # Vertical geometrical emittance \"deltap_p\" : deltap_p , # Momentum deviation } if verbose : logger . trace ( \"Outputing computed parameter values\" ) print ( f \"\"\"Particle type: proton Beam momentum = { parameters [ \"pc_GeV\" ] : 2.3f } GeV/c Normalized x-emittance = { parameters [ \"en_x_m\" ] * 1e6 : 2.3f } mm mrad Normalized y-emittance = { parameters [ \"en_y_m\" ] * 1e6 : 2.3f } mm mrad Momentum deviation deltap/p = { parameters [ \"deltap_p\" ] } -> Beam total energy = { parameters [ \"E_tot_GeV\" ] : 2.3f } GeV -> Beam kinetic energy = { parameters [ \"E_kin_GeV\" ] : 2.3f } GeV -> Beam rigidity = { parameters [ \"B_rho_Tm\" ] : 2.3f } Tm -> Relativistic beta = { parameters [ \"beta_r\" ] : 2.5f } -> Relativistic gamma = { parameters [ \"gamma_r\" ] : 2.3f } -> Geometrical x emittance = { parameters [ \"eg_x_m\" ] * 1e6 : 2.3f } mm mrad -> Geometrical y emittance = { parameters [ \"eg_y_m\" ] * 1e6 : 2.3f } mm mrad \"\"\" ) return parameters","title":"Module pyhdtoolkit.cpymadtools.parameters"},{"location":"reference/pyhdtoolkit/cpymadtools/parameters/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/cpymadtools/parameters/#beam_parameters","text":"def beam_parameters ( pc_gev : float , en_x_m : float , en_y_m : float , deltap_p : float , verbose : bool = False ) -> Dict [ str , float ] Calculate beam parameters from provided values. Parameters: Name Type Description Default pc_gev float particle momentum. None en_x_m float horizontal emittance, in meters. None en_y_m float vertical emittance, in meters. None deltap_p float momentum deviation. None verbose bool bolean, whether to print out a summary of parameters or not. None Returns: Type Description None A dictionnary with the calculated values. View Source def beam_parameters ( pc_gev : float , en_x_m : float , en_y_m : float , deltap_p : float , verbose : bool = False , ) -> Dict [ str, float ] : \"\"\"Calculate beam parameters from provided values. Args: pc_gev (float): particle momentum. en_x_m (float): horizontal emittance, in meters. en_y_m (float): vertical emittance, in meters. deltap_p (float): momentum deviation. verbose (bool): bolean, whether to print out a summary of parameters or not. Returns: A dictionnary with the calculated values. \"\"\" e0_gev = 0.9382720813 e_tot_gev = np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) gamma_r = e_tot_gev / e0_gev beta_r = pc_gev / np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) parameters : Dict [ str, float ] = { \"pc_GeV\" : pc_gev , # Particle momentum [ GeV ] \"B_rho_Tm\" : 3.3356 * pc_gev , # Beam rigidity [ T/m ] \"E_0_GeV\" : e0_gev , # Rest mass energy [ GeV ] \"E_tot_GeV\" : e_tot_gev , # Total beam energy [ GeV ] \"E_kin_GeV\" : e_tot_gev - e0_gev , # Kinectic beam energy [ GeV ] \"gamma_r\" : gamma_r , # Relativistic gamma \"beta_r\" : beta_r , # Relativistic beta \"en_x_m\" : en_x_m , # Horizontal emittance [ m ] \"en_y_m\" : en_y_m , # Vertical emittance [ m ] \"eg_x_m\" : en_x_m / gamma_r / beta_r , # Horizontal geometrical emittance \"eg_y_m\" : en_y_m / gamma_r / beta_r , # Vertical geometrical emittance \"deltap_p\" : deltap_p , # Momentum deviation } if verbose : logger . trace ( \"Outputing computed parameter values\" ) print ( f \"\"\"Particle type: proton Beam momentum = {parameters[\" pc_GeV \"]:2.3f} GeV/c Normalized x-emittance = {parameters[\" en_x_m \"] * 1e6:2.3f} mm mrad Normalized y-emittance = {parameters[\" en_y_m \"] * 1e6:2.3f} mm mrad Momentum deviation deltap/p = {parameters[\" deltap_p \"]} -> Beam total energy = {parameters[\" E_tot_GeV \"]:2.3f} GeV -> Beam kinetic energy = {parameters[\" E_kin_GeV \"]:2.3f} GeV -> Beam rigidity = {parameters[\" B_rho_Tm \"]:2.3f} Tm -> Relativistic beta = {parameters[\" beta_r \"]:2.5f} -> Relativistic gamma = {parameters[\" gamma_r \"]:2.3f} -> Geometrical x emittance = {parameters[\" eg_x_m \"] * 1e6:2.3f} mm mrad -> Geometrical y emittance = {parameters[\" eg_y_m \"] * 1e6:2.3f} mm mrad \"\"\" ) return parameters","title":"beam_parameters"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/","text":"Module pyhdtoolkit.cpymadtools.plotters Module cpymadtools.plotters Created on 2019.12.08 View Source \"\"\" Module cpymadtools.plotters --------------------------- Created on 2019.12.08 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions to plot different output results from a cpymad.madx.Madx object's simulation results. \"\"\" from pathlib import Path from typing import Dict , Tuple import matplotlib import matplotlib.pyplot as plt import numpy as np import pandas as pd from cpymad.madx import Madx from loguru import logger from matplotlib import colors as mcolors from pyhdtoolkit.optics.twiss import courant_snyder_transform from pyhdtoolkit.utils.defaults import PLOT_PARAMS plt . rcParams . update ( PLOT_PARAMS ) COLORS_DICT = dict ( mcolors . BASE_COLORS , ** mcolors . CSS4_COLORS ) BY_HSV = sorted ( ( tuple ( mcolors . rgb_to_hsv ( mcolors . to_rgba ( color )[: 3 ])), name ) for name , color in COLORS_DICT . items () ) SORTED_COLORS = [ name for hsv , name in BY_HSV ] class AperturePlotter : \"\"\" A class to plot the physical aperture of your machine. \"\"\" @staticmethod def plot_aperture ( madx : Madx , beam_params : Dict [ str , float ], figsize : Tuple [ int , int ] = ( 13 , 20 ), xlimits : Tuple [ float , float ] = None , hplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. beam_params (Dict[str, float]): a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. figsize (str): size of the figure, defaults to (15, 15). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. hplane_ylim (Tuple[float, float]): the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). vplane_ylim (Tuple[float, float]): the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint: disable=too-many-arguments # We need to interpolate in order to get high resolution along the s direction logger . debug ( \"Running interpolation in cpymad\" ) madx . input ( \"\"\" select, flag=interpolate, class=drift, slice=4, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=8, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; select, flag=interpolate, class=rbend, slice=10, range=#s/#e; twiss; \"\"\" ) logger . debug ( \"Getting Twiss dframe from cpymad\" ) twiss_hr : pd . DataFrame = madx . table . twiss . dframe () twiss_hr [ \"betatronic_envelope_x\" ] = np . sqrt ( twiss_hr . betx . values * beam_params [ \"eg_y_m\" ]) twiss_hr [ \"betatronic_envelope_y\" ] = np . sqrt ( twiss_hr . bety . values * beam_params [ \"eg_y_m\" ]) twiss_hr [ \"dispersive_envelope_x\" ] = twiss_hr . dx . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"dispersive_envelope_y\" ] = twiss_hr . dy . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"envelope_x\" ] = np . sqrt ( twiss_hr . betatronic_envelope_x . values ** 2 + ( twiss_hr . dx . values * beam_params [ \"deltap_p\" ]) ** 2 ) twiss_hr [ \"envelope_y\" ] = np . sqrt ( twiss_hr . betatronic_envelope_y . values ** 2 + ( twiss_hr . dy . values * beam_params [ \"deltap_p\" ]) ** 2 ) machine = twiss_hr [ twiss_hr . apertype == \"ellipse\" ] figure = plt . figure ( figsize = figsize ) logger . debug ( \"Plotting the horizontal aperture\" ) axis1 = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) axis1 . plot ( twiss_hr . s , twiss_hr . envelope_x , color = \"b\" ) axis1 . plot ( twiss_hr . s , - twiss_hr . envelope_x , color = \"b\" ) axis1 . fill_between ( twiss_hr . s , twiss_hr . envelope_x , - twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_x , - 3 * twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( machine . s , machine . aper_1 , machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . fill_between ( machine . s , - machine . aper_1 , - machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . plot ( machine . s , machine . aper_1 , \"k.-\" ) axis1 . plot ( machine . s , - machine . aper_1 , \"k.-\" ) axis1 . set_xlim ( xlimits ) axis1 . set_ylim ( hplane_ylim ) axis1 . set_ylabel ( \"x [m]\" ) axis1 . set_xlabel ( \"s [m]\" ) axis1 . set_title ( f \"Horizontal aperture at { beam_params [ 'pc_GeV' ] } GeV/c\" ) logger . debug ( \"Plotting the vertical aperture\" ) axis2 = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis2 . plot ( twiss_hr . s , twiss_hr . envelope_y , color = \"r\" ) axis2 . plot ( twiss_hr . s , - twiss_hr . envelope_y , color = \"r\" ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( machine . s , machine . aper_2 , machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . fill_between ( machine . s , - machine . aper_2 , - machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . plot ( machine . s , machine . aper_2 , \"k.-\" ) axis2 . plot ( machine . s , - machine . aper_2 , \"k.-\" ) axis2 . set_ylim ( vplane_ylim ) axis2 . set_ylabel ( \"y [m]\" ) axis2 . set_xlabel ( \"s [m]\" ) axis2 . set_title ( f \"Vertical aperture at { beam_params [ 'pc_GeV' ] } GeV/c\" ) logger . debug ( \"Plotting the stay-clear envelope\" ) axis3 = plt . subplot2grid (( 3 , 3 ), ( 2 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis3 . plot ( machine . s , machine . aper_1 / machine . envelope_x , \".-b\" , label = \"Horizontal plane\" ) axis3 . plot ( machine . s , machine . aper_2 / machine . envelope_y , \".-r\" , label = \"Vertical plane\" ) axis3 . set_xlim ( xlimits ) axis3 . set_ylabel ( \"n1\" ) axis3 . set_xlabel ( \"s [m]\" ) axis3 . legend ( loc = \"best\" ) axis3 . set_title ( f \"Stay-clear envelope at { beam_params [ 'pc_GeV' ] } GeV/c\" ) if savefig : logger . info ( f \"Saving aperture plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure class DynamicAperturePlotter : \"\"\" A class to plot the dynamic aperture of your machine. \"\"\" @staticmethod def plot_dynamic_aperture ( vx_coords : np . ndarray , vy_coords : np . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure : \"\"\" Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Args: vx_coords (np.ndarray): numpy array of horizontal coordinates over turns. vy_coords (np.ndarray): numpy array of vertical coordinates over turns. n_particles (int): number of particles simulated. savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" figure = plt . figure ( figsize = ( 12 , 7 )) turn_lost = [] x_in_lost = [] for particle in range ( n_particles ): nb = len ( vx_coords [ particle ]) - max ( np . isnan ( vx_coords [ particle ]) . sum (), np . isnan ( vy_coords [ particle ]) . sum () ) turn_lost . append ( nb ) x_in_lost . append ( vx_coords [ particle ][ 0 ] ** 2 + vy_coords [ particle ][ 0 ] ** 2 ) turn_lost = np . array ( turn_lost ) x_in_lost = np . array ( x_in_lost ) plt . scatter ( turn_lost , x_in_lost * 1000 , linewidths = 0.7 , c = \"darkblue\" , marker = \".\" ) plt . title ( \"Amplitudes lost over turns\" , fontsize = 20 ) plt . xlabel ( \"Number of Turns Survived\" , fontsize = 17 ) plt . ylabel ( \"Initial amplitude [mm]\" , fontsize = 17 ) if savefig : logger . info ( f \"Saving dynamic aperture plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure class PhaseSpacePlotter : \"\"\" A class to plot Courant-Snyder coordinates phase space. \"\"\" @staticmethod def plot_courant_snyder_phase_space ( madx : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ): logger . error ( f \"Plane should be either Horizontal or Vertical but ' { plane } ' was given\" ) raise ValueError ( \"Invalid plane value\" ) figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) # Getting the P matrix to compute Courant-Snyder coordinates logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = madx . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . alfy [ 0 ] beta = madx . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . bety [ 0 ] logger . debug ( f \"Plotting Courant-Snyder phase space for the { plane . lower () } plane\" ) for index , _ in enumerate ( u_coordinates ): logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle { index } \" ) u = np . array ([ u_coordinates [ index ], pu_coordinates [ index ]]) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0 , :] * 1e3 , u_bar [ 1 , :] * 1e3 , s = 0.1 , c = \"k\" ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$ \\\\ bar {x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$ \\\\ bar {y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving Courant-Snyder phase space plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure @staticmethod def plot_courant_snyder_phase_space_colored ( madx : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156th color. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ): logger . error ( f \"Plane should be either Horizontal or Vertical but ' { plane } ' was given\" ) raise ValueError ( \"Invalid plane value\" ) # Getting a sufficiently long array of colors to use colors = int ( np . floor ( len ( u_coordinates ) / 100 )) * SORTED_COLORS while len ( colors ) > len ( u_coordinates ): colors . pop () figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = madx . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . alfy [ 0 ] beta = madx . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . bety [ 0 ] logger . debug ( f \"Plotting colored normalised phase space for the { plane . lower () } plane\" ) for index , _ in enumerate ( u_coordinates ): logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle { index } \" ) u = np . array ([ u_coordinates [ index ], pu_coordinates [ index ]]) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0 , :] * 1e3 , u_bar [ 1 , :] * 1e3 , s = 0.1 , c = colors [ index ]) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$ \\\\ bar {x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$ \\\\ bar {y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving colored Courant-Snyder phase space plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure class TuneDiagramPlotter : \"\"\" A class to plot a blank tune diagram with Farey sequences, as well as your working points. \"\"\" @staticmethod def farey_sequence ( order : int ) -> list : \"\"\" Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Args: order (int): the order up to which we want to calculate the sequence. Returns: The sequence as a list. \"\"\" seq = [[ 0 , 1 ]] a , b , c , d = 0 , 1 , 1 , order while c <= order : k = int (( order + b ) / d ) a , b , c , d = c , d , k * c - a , k * d - b seq . append ([ a , b ]) return seq @staticmethod def plot_blank_tune_diagram () -> matplotlib . figure . Figure : \"\"\" Plotting the tune diagram up to the 6th order. Original code from Rogelio Tom\u00e1s. Returns: The figure on which resonance lines from farey sequences are drawn. \"\"\" logger . debug ( \"Plotting resonance lines from Farey sequence, up to 5th order\" ) figure = plt . figure ( figsize = ( 13 , 13 )) plt . ylim (( 0 , 1 )) plt . xlim (( 0 , 1 )) x = np . linspace ( 0 , 1 , 1000 ) for i in range ( 1 , 6 ): farey_sequences = TuneDiagramPlotter . farey_sequence ( i ) for f in farey_sequences : h , k = f # Node h/k on the axes for sequence in farey_sequences : p , q = sequence a = float ( k * p ) # Resonance linea Qx + b*Qy = clinkedtop / q if a > 0 : b = float ( q - k * p ) c = float ( p * h ) plt . plot ( x , c / a - x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( x , c / a + x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , 1 - x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , 1 - x , \"b\" , alpha = 0.1 ) if q == k and p == 1 : # FN elements below 1/k break plt . title ( \"Tune Diagram\" , fontsize = 20 ) plt . axis ( \"square\" ) plt . xlim ([ 0 , 1 ]) plt . ylim ([ 0 , 1 ]) plt . xlabel ( \"$Q_ {x} }$\" , fontsize = 17 ) plt . ylabel ( \"$Q_ {y} $\" , fontsize = 17 ) return figure @staticmethod def plot_tune_diagram ( madx : Madx , v_qx : np . ndarray = np . array ([ 0 ]), vxgood : np . ndarray = np . array ([ False ]), v_qy : np . ndarray = np . array ([ 0 ]), vygood : np . ndarray = np . array ([ False ]), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plots the evolution of particles' tunes on a Tune Diagram. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. v_qx (np.ndarray): horizontal tune value as a numpy array. vxgood (np.ndarray): ?? v_qy (np.ndarray): vertical tune value as a numpy array. vygood (np.ndarray): ?? savefig: will save the figure if this is not None, using the string value passed. Returns: The figure on which the diagram is drawn. \"\"\" figure = TuneDiagramPlotter . plot_blank_tune_diagram () logger . debug ( \"Getting Tunes from cpymad\" ) new_q1 : float = madx . table . summ . dframe () . q1 [ 0 ] new_q2 : float = madx . table . summ . dframe () . q2 [ 0 ] if vxgood . any () and vygood . any (): plt . plot ( v_qx [ vxgood * vygood ], v_qy [ vxgood * vygood ], \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif vxgood . any () and ~ vygood . any (): tp = np . ones ( len ( vxgood )) * ( new_q2 - np . floor ( new_q2 )) plt . plot ( v_qx [ vxgood ], tp [ vxgood ], \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif ~ vxgood . any () and vygood . any (): tp = np . ones ( len ( vygood )) * ( new_q1 - np . floor ( new_q1 )) plt . plot ( tp [ vygood ], v_qy [ vygood ], \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) if savefig : logger . info ( f \"Saving Tune diagram plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure Variables BY_HSV COLORS_DICT PLOT_PARAMS SORTED_COLORS Classes AperturePlotter class AperturePlotter ( / , * args , ** kwargs ) View Source class AperturePlotter : \"\"\" A class to plot the physical aperture of your machine. \"\"\" @staticmethod def plot_aperture ( madx : Madx , beam_params : Dict [ str, float ] , figsize : Tuple [ int, int ] = ( 13 , 20 ), xlimits : Tuple [ float, float ] = None , hplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. beam_params (Dict[str, float]): a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. figsize (str): size of the figure, defaults to (15, 15). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. hplane_ylim (Tuple[float, float]): the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). vplane_ylim (Tuple[float, float]): the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments # We need to interpolate in order to get high resolution along the s direction logger . debug ( \"Running interpolation in cpymad\" ) madx . input ( \"\"\" select, flag=interpolate, class=drift, slice=4, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=8, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; select, flag=interpolate, class=rbend, slice=10, range=#s/#e; twiss; \"\"\" ) logger . debug ( \"Getting Twiss dframe from cpymad\" ) twiss_hr : pd . DataFrame = madx . table . twiss . dframe () twiss_hr [ \"betatronic_envelope_x\" ] = np . sqrt ( twiss_hr . betx . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"betatronic_envelope_y\" ] = np . sqrt ( twiss_hr . bety . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"dispersive_envelope_x\" ] = twiss_hr . dx . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"dispersive_envelope_y\" ] = twiss_hr . dy . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"envelope_x\" ] = np . sqrt ( twiss_hr . betatronic_envelope_x . values ** 2 + ( twiss_hr . dx . values * beam_params [ \"deltap_p\" ] ) ** 2 ) twiss_hr [ \"envelope_y\" ] = np . sqrt ( twiss_hr . betatronic_envelope_y . values ** 2 + ( twiss_hr . dy . values * beam_params [ \"deltap_p\" ] ) ** 2 ) machine = twiss_hr [ twiss_hr.apertype == \"ellipse\" ] figure = plt . figure ( figsize = figsize ) logger . debug ( \"Plotting the horizontal aperture\" ) axis1 = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) axis1 . plot ( twiss_hr . s , twiss_hr . envelope_x , color = \"b\" ) axis1 . plot ( twiss_hr . s , - twiss_hr . envelope_x , color = \"b\" ) axis1 . fill_between ( twiss_hr . s , twiss_hr . envelope_x , - twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_x , - 3 * twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( machine . s , machine . aper_1 , machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . fill_between ( machine . s , - machine . aper_1 , - machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . plot ( machine . s , machine . aper_1 , \"k.-\" ) axis1 . plot ( machine . s , - machine . aper_1 , \"k.-\" ) axis1 . set_xlim ( xlimits ) axis1 . set_ylim ( hplane_ylim ) axis1 . set_ylabel ( \"x [m]\" ) axis1 . set_xlabel ( \"s [m]\" ) axis1 . set_title ( f \"Horizontal aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the vertical aperture\" ) axis2 = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis2 . plot ( twiss_hr . s , twiss_hr . envelope_y , color = \"r\" ) axis2 . plot ( twiss_hr . s , - twiss_hr . envelope_y , color = \"r\" ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( machine . s , machine . aper_2 , machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . fill_between ( machine . s , - machine . aper_2 , - machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . plot ( machine . s , machine . aper_2 , \"k.-\" ) axis2 . plot ( machine . s , - machine . aper_2 , \"k.-\" ) axis2 . set_ylim ( vplane_ylim ) axis2 . set_ylabel ( \"y [m]\" ) axis2 . set_xlabel ( \"s [m]\" ) axis2 . set_title ( f \"Vertical aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the stay-clear envelope\" ) axis3 = plt . subplot2grid (( 3 , 3 ), ( 2 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis3 . plot ( machine . s , machine . aper_1 / machine . envelope_x , \".-b\" , label = \"Horizontal plane\" ) axis3 . plot ( machine . s , machine . aper_2 / machine . envelope_y , \".-r\" , label = \"Vertical plane\" ) axis3 . set_xlim ( xlimits ) axis3 . set_ylabel ( \"n1\" ) axis3 . set_xlabel ( \"s [m]\" ) axis3 . legend ( loc = \"best\" ) axis3 . set_title ( f \"Stay-clear envelope at {beam_params['pc_GeV']} GeV/c\" ) if savefig : logger . info ( f \"Saving aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure Static methods plot_aperture def plot_aperture ( madx : cpymad . madx . Madx , beam_params : Dict [ str , float ], figsize : Tuple [ int , int ] = ( 13 , 20 ), xlimits : Tuple [ float , float ] = None , hplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), savefig : str = None ) -> matplotlib . figure . Figure Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None beam_params Dict[str, float] a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. None figsize str size of the figure, defaults to (15, 15). None xlimits Tuple[float, float] will implement xlim (for the s coordinate) if this is not None, using the tuple passed. None hplane_ylim Tuple[float, float] the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). None vplane_ylim Tuple[float, float] the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). None savefig str will save the figure if this is not None, using the string value passed. None Returns: Type Description None The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_aperture ( madx : Madx , beam_params : Dict [ str, float ] , figsize : Tuple [ int, int ] = ( 13 , 20 ), xlimits : Tuple [ float, float ] = None , hplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. beam_params (Dict[str, float]): a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. figsize (str): size of the figure, defaults to (15, 15). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. hplane_ylim (Tuple[float, float]): the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). vplane_ylim (Tuple[float, float]): the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments # We need to interpolate in order to get high resolution along the s direction logger . debug ( \"Running interpolation in cpymad\" ) madx . input ( \"\"\" select, flag=interpolate, class=drift, slice=4, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=8, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; select, flag=interpolate, class=rbend, slice=10, range=#s/#e; twiss; \"\"\" ) logger . debug ( \"Getting Twiss dframe from cpymad\" ) twiss_hr : pd . DataFrame = madx . table . twiss . dframe () twiss_hr [ \"betatronic_envelope_x\" ] = np . sqrt ( twiss_hr . betx . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"betatronic_envelope_y\" ] = np . sqrt ( twiss_hr . bety . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"dispersive_envelope_x\" ] = twiss_hr . dx . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"dispersive_envelope_y\" ] = twiss_hr . dy . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"envelope_x\" ] = np . sqrt ( twiss_hr . betatronic_envelope_x . values ** 2 + ( twiss_hr . dx . values * beam_params [ \"deltap_p\" ] ) ** 2 ) twiss_hr [ \"envelope_y\" ] = np . sqrt ( twiss_hr . betatronic_envelope_y . values ** 2 + ( twiss_hr . dy . values * beam_params [ \"deltap_p\" ] ) ** 2 ) machine = twiss_hr [ twiss_hr.apertype == \"ellipse\" ] figure = plt . figure ( figsize = figsize ) logger . debug ( \"Plotting the horizontal aperture\" ) axis1 = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) axis1 . plot ( twiss_hr . s , twiss_hr . envelope_x , color = \"b\" ) axis1 . plot ( twiss_hr . s , - twiss_hr . envelope_x , color = \"b\" ) axis1 . fill_between ( twiss_hr . s , twiss_hr . envelope_x , - twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_x , - 3 * twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( machine . s , machine . aper_1 , machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . fill_between ( machine . s , - machine . aper_1 , - machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . plot ( machine . s , machine . aper_1 , \"k.-\" ) axis1 . plot ( machine . s , - machine . aper_1 , \"k.-\" ) axis1 . set_xlim ( xlimits ) axis1 . set_ylim ( hplane_ylim ) axis1 . set_ylabel ( \"x [m]\" ) axis1 . set_xlabel ( \"s [m]\" ) axis1 . set_title ( f \"Horizontal aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the vertical aperture\" ) axis2 = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis2 . plot ( twiss_hr . s , twiss_hr . envelope_y , color = \"r\" ) axis2 . plot ( twiss_hr . s , - twiss_hr . envelope_y , color = \"r\" ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( machine . s , machine . aper_2 , machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . fill_between ( machine . s , - machine . aper_2 , - machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . plot ( machine . s , machine . aper_2 , \"k.-\" ) axis2 . plot ( machine . s , - machine . aper_2 , \"k.-\" ) axis2 . set_ylim ( vplane_ylim ) axis2 . set_ylabel ( \"y [m]\" ) axis2 . set_xlabel ( \"s [m]\" ) axis2 . set_title ( f \"Vertical aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the stay-clear envelope\" ) axis3 = plt . subplot2grid (( 3 , 3 ), ( 2 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis3 . plot ( machine . s , machine . aper_1 / machine . envelope_x , \".-b\" , label = \"Horizontal plane\" ) axis3 . plot ( machine . s , machine . aper_2 / machine . envelope_y , \".-r\" , label = \"Vertical plane\" ) axis3 . set_xlim ( xlimits ) axis3 . set_ylabel ( \"n1\" ) axis3 . set_xlabel ( \"s [m]\" ) axis3 . legend ( loc = \"best\" ) axis3 . set_title ( f \"Stay-clear envelope at {beam_params['pc_GeV']} GeV/c\" ) if savefig : logger . info ( f \"Saving aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure DynamicAperturePlotter class DynamicAperturePlotter ( / , * args , ** kwargs ) View Source class DynamicAperturePlotter : \"\"\" A class to plot the dynamic aperture of your machine. \"\"\" @staticmethod def plot_dynamic_aperture ( vx_coords : np . ndarray , vy_coords : np . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure : \"\"\" Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Args: vx_coords (np.ndarray): numpy array of horizontal coordinates over turns. vy_coords (np.ndarray): numpy array of vertical coordinates over turns. n_particles (int): number of particles simulated. savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" figure = plt . figure ( figsize = ( 12 , 7 )) turn_lost = [] x_in_lost = [] for particle in range ( n_particles ) : nb = len ( vx_coords [ particle ] ) - max ( np . isnan ( vx_coords [ particle ] ). sum (), np . isnan ( vy_coords [ particle ] ). sum () ) turn_lost . append ( nb ) x_in_lost . append ( vx_coords [ particle ][ 0 ] ** 2 + vy_coords [ particle ][ 0 ] ** 2 ) turn_lost = np . array ( turn_lost ) x_in_lost = np . array ( x_in_lost ) plt . scatter ( turn_lost , x_in_lost * 1000 , linewidths = 0.7 , c = \"darkblue\" , marker = \".\" ) plt . title ( \"Amplitudes lost over turns\" , fontsize = 20 ) plt . xlabel ( \"Number of Turns Survived\" , fontsize = 17 ) plt . ylabel ( \"Initial amplitude [mm]\" , fontsize = 17 ) if savefig : logger . info ( f \"Saving dynamic aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure Static methods plot_dynamic_aperture def plot_dynamic_aperture ( vx_coords : numpy . ndarray , vy_coords : numpy . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Parameters: Name Type Description Default vx_coords np.ndarray numpy array of horizontal coordinates over turns. None vy_coords np.ndarray numpy array of vertical coordinates over turns. None n_particles int number of particles simulated. None savefig str will save the figure if this is not None, using the string value passed. None Returns: Type Description None The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_dynamic_aperture ( vx_coords : np . ndarray , vy_coords : np . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure : \"\"\" Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Args: vx_coords (np.ndarray): numpy array of horizontal coordinates over turns. vy_coords (np.ndarray): numpy array of vertical coordinates over turns. n_particles (int): number of particles simulated. savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" figure = plt . figure ( figsize = ( 12 , 7 )) turn_lost = [] x_in_lost = [] for particle in range ( n_particles ) : nb = len ( vx_coords [ particle ] ) - max ( np . isnan ( vx_coords [ particle ] ). sum (), np . isnan ( vy_coords [ particle ] ). sum () ) turn_lost . append ( nb ) x_in_lost . append ( vx_coords [ particle ][ 0 ] ** 2 + vy_coords [ particle ][ 0 ] ** 2 ) turn_lost = np . array ( turn_lost ) x_in_lost = np . array ( x_in_lost ) plt . scatter ( turn_lost , x_in_lost * 1000 , linewidths = 0.7 , c = \"darkblue\" , marker = \".\" ) plt . title ( \"Amplitudes lost over turns\" , fontsize = 20 ) plt . xlabel ( \"Number of Turns Survived\" , fontsize = 17 ) plt . ylabel ( \"Initial amplitude [mm]\" , fontsize = 17 ) if savefig : logger . info ( f \"Saving dynamic aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure PhaseSpacePlotter class PhaseSpacePlotter ( / , * args , ** kwargs ) View Source class PhaseSpacePlotter : \"\"\" A class to plot Courant-Snyder coordinates phase space. \"\"\" @staticmethod def plot_courant_snyder_phase_space ( madx : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) # Getting the P matrix to compute Courant - Snyder coordinates logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = madx . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . alfy [ 0 ] beta = madx . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . bety [ 0 ] logger . debug ( f \"Plotting Courant-Snyder phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = \"k\" ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure @staticmethod def plot_courant_snyder_phase_space_colored ( madx : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156th color. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) # Getting a sufficiently long array of colors to use colors = int ( np . floor ( len ( u_coordinates ) / 100 )) * SORTED_COLORS while len ( colors ) > len ( u_coordinates ) : colors . pop () figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = madx . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . alfy [ 0 ] beta = madx . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . bety [ 0 ] logger . debug ( f \"Plotting colored normalised phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = colors [ index ] ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving colored Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure Static methods plot_courant_snyder_phase_space def plot_courant_snyder_phase_space ( madx : cpymad . madx . Madx , u_coordinates : numpy . ndarray , pu_coordinates : numpy . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = 'Horizontal' ) -> matplotlib . figure . Figure Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None u_coordinates np.ndarray numpy array of particles's coordinates for the given plane. None pu_coordinates np.ndarray numpy array of particles's momentum coordinates for the given plane. None savefig str will save the figure if this is not None, using the string value passed. None size Tuple[int, int] the wanted matplotlib figure size. Defaults to (16, 8). (16, 8) plane str the physical plane to plot. Defaults to 'Horizontal'. 'Horizontal' Returns: Type Description None The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_courant_snyder_phase_space ( madx : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) # Getting the P matrix to compute Courant - Snyder coordinates logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = madx . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . alfy [ 0 ] beta = madx . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . bety [ 0 ] logger . debug ( f \"Plotting Courant-Snyder phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = \"k\" ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure plot_courant_snyder_phase_space_colored def plot_courant_snyder_phase_space_colored ( madx : cpymad . madx . Madx , u_coordinates : numpy . ndarray , pu_coordinates : numpy . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = 'Horizontal' ) -> matplotlib . figure . Figure Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156 th color. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None u_coordinates np.ndarray numpy array of particles's coordinates for the given plane. None pu_coordinates np.ndarray numpy array of particles's momentum coordinates for the given plane. None savefig str will save the figure if this is not None, using the string value passed. None size Tuple[int, int] the wanted matplotlib figure size. Defaults to (16, 8). (16, 8) plane str the physical plane to plot. Defaults to 'Horizontal'. 'Horizontal' Returns: Type Description None The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_courant_snyder_phase_space_colored ( madx : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156th color. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) # Getting a sufficiently long array of colors to use colors = int ( np . floor ( len ( u_coordinates ) / 100 )) * SORTED_COLORS while len ( colors ) > len ( u_coordinates ) : colors . pop () figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = madx . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . alfy [ 0 ] beta = madx . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . bety [ 0 ] logger . debug ( f \"Plotting colored normalised phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = colors [ index ] ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving colored Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure TuneDiagramPlotter class TuneDiagramPlotter ( / , * args , ** kwargs ) View Source class TuneDiagramPlotter : \"\"\" A class to plot a blank tune diagram with Farey sequences, as well as your working points. \"\"\" @staticmethod def farey_sequence ( order : int ) -> list : \"\"\" Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Args: order (int): the order up to which we want to calculate the sequence. Returns: The sequence as a list. \"\"\" seq = [ [0, 1 ] ] a , b , c , d = 0 , 1 , 1 , order while c <= order : k = int (( order + b ) / d ) a , b , c , d = c , d , k * c - a , k * d - b seq . append ( [ a, b ] ) return seq @staticmethod def plot_blank_tune_diagram () -> matplotlib . figure . Figure : \"\"\" Plotting the tune diagram up to the 6th order. Original code from Rogelio Tom\u00e1s. Returns: The figure on which resonance lines from farey sequences are drawn. \"\"\" logger . debug ( \"Plotting resonance lines from Farey sequence, up to 5th order\" ) figure = plt . figure ( figsize = ( 13 , 13 )) plt . ylim (( 0 , 1 )) plt . xlim (( 0 , 1 )) x = np . linspace ( 0 , 1 , 1000 ) for i in range ( 1 , 6 ) : farey_sequences = TuneDiagramPlotter . farey_sequence ( i ) for f in farey_sequences : h , k = f # Node h / k on the axes for sequence in farey_sequences : p , q = sequence a = float ( k * p ) # Resonance linea Qx + b * Qy = clinkedtop / q if a > 0 : b = float ( q - k * p ) c = float ( p * h ) plt . plot ( x , c / a - x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( x , c / a + x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , 1 - x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , 1 - x , \"b\" , alpha = 0.1 ) if q == k and p == 1 : # FN elements below 1 / k break plt . title ( \"Tune Diagram\" , fontsize = 20 ) plt . axis ( \"square\" ) plt . xlim ( [ 0, 1 ] ) plt . ylim ( [ 0, 1 ] ) plt . xlabel ( \"$Q_{x}}$\" , fontsize = 17 ) plt . ylabel ( \"$Q_{y}$\" , fontsize = 17 ) return figure @staticmethod def plot_tune_diagram ( madx : Madx , v_qx : np . ndarray = np . array ( [ 0 ] ), vxgood : np . ndarray = np . array ( [ False ] ), v_qy : np . ndarray = np . array ( [ 0 ] ), vygood : np . ndarray = np . array ( [ False ] ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plots the evolution of particles' tunes on a Tune Diagram. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. v_qx (np.ndarray): horizontal tune value as a numpy array. vxgood (np.ndarray): ?? v_qy (np.ndarray): vertical tune value as a numpy array. vygood (np.ndarray): ?? savefig: will save the figure if this is not None, using the string value passed. Returns: The figure on which the diagram is drawn. \"\"\" figure = TuneDiagramPlotter . plot_blank_tune_diagram () logger . debug ( \"Getting Tunes from cpymad\" ) new_q1 : float = madx . table . summ . dframe (). q1 [ 0 ] new_q2 : float = madx . table . summ . dframe (). q2 [ 0 ] if vxgood . any () and vygood . any () : plt . plot ( v_qx [ vxgood * vygood ] , v_qy [ vxgood * vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif vxgood . any () and ~ vygood . any () : tp = np . ones ( len ( vxgood )) * ( new_q2 - np . floor ( new_q2 )) plt . plot ( v_qx [ vxgood ] , tp [ vxgood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif ~ vxgood . any () and vygood . any () : tp = np . ones ( len ( vygood )) * ( new_q1 - np . floor ( new_q1 )) plt . plot ( tp [ vygood ] , v_qy [ vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) if savefig : logger . info ( f \"Saving Tune diagram plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure Static methods farey_sequence def farey_sequence ( order : int ) -> list Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Parameters: Name Type Description Default order int the order up to which we want to calculate the sequence. None Returns: Type Description None The sequence as a list. View Source @staticmethod def farey_sequence ( order : int ) -> list : \"\"\" Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Args: order (int): the order up to which we want to calculate the sequence. Returns: The sequence as a list. \"\"\" seq = [ [0, 1 ] ] a , b , c , d = 0 , 1 , 1 , order while c <= order : k = int (( order + b ) / d ) a , b , c , d = c , d , k * c - a , k * d - b seq . append ( [ a, b ] ) return seq plot_blank_tune_diagram def plot_blank_tune_diagram ( ) -> matplotlib . figure . Figure Plotting the tune diagram up to the 6 th order. Original code from Rogelio Tom\u00e1s. Returns: Type Description None The figure on which resonance lines from farey sequences are drawn. View Source @staticmethod def plot_blank_tune_diagram () -> matplotlib . figure . Figure : \"\"\" Plotting the tune diagram up to the 6th order. Original code from Rogelio Tom\u00e1s. Returns: The figure on which resonance lines from farey sequences are drawn. \"\"\" logger . debug ( \"Plotting resonance lines from Farey sequence, up to 5th order\" ) figure = plt . figure ( figsize = ( 13 , 13 )) plt . ylim (( 0 , 1 )) plt . xlim (( 0 , 1 )) x = np . linspace ( 0 , 1 , 1000 ) for i in range ( 1 , 6 ) : farey_sequences = TuneDiagramPlotter . farey_sequence ( i ) for f in farey_sequences : h , k = f # Node h / k on the axes for sequence in farey_sequences : p , q = sequence a = float ( k * p ) # Resonance linea Qx + b * Qy = clinkedtop / q if a > 0 : b = float ( q - k * p ) c = float ( p * h ) plt . plot ( x , c / a - x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( x , c / a + x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , 1 - x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , 1 - x , \"b\" , alpha = 0.1 ) if q == k and p == 1 : # FN elements below 1 / k break plt . title ( \"Tune Diagram\" , fontsize = 20 ) plt . axis ( \"square\" ) plt . xlim ( [ 0, 1 ] ) plt . ylim ( [ 0, 1 ] ) plt . xlabel ( \"$Q_{x}}$\" , fontsize = 17 ) plt . ylabel ( \"$Q_{y}$\" , fontsize = 17 ) return figure plot_tune_diagram def plot_tune_diagram ( madx : cpymad . madx . Madx , v_qx : numpy . ndarray = array ([ 0 ]), vxgood : numpy . ndarray = array ([ False ]), v_qy : numpy . ndarray = array ([ 0 ]), vygood : numpy . ndarray = array ([ False ]), savefig : str = None ) -> matplotlib . figure . Figure Plots the evolution of particles' tunes on a Tune Diagram. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None v_qx np.ndarray horizontal tune value as a numpy array. None vxgood np.ndarray ?? None v_qy np.ndarray vertical tune value as a numpy array. None vygood np.ndarray ?? None savefig None will save the figure if this is not None, using the string value passed. None Returns: Type Description None The figure on which the diagram is drawn. View Source @staticmethod def plot_tune_diagram ( madx : Madx , v_qx : np . ndarray = np . array ( [ 0 ] ), vxgood : np . ndarray = np . array ( [ False ] ), v_qy : np . ndarray = np . array ( [ 0 ] ), vygood : np . ndarray = np . array ( [ False ] ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plots the evolution of particles' tunes on a Tune Diagram. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. v_qx (np.ndarray): horizontal tune value as a numpy array. vxgood (np.ndarray): ?? v_qy (np.ndarray): vertical tune value as a numpy array. vygood (np.ndarray): ?? savefig: will save the figure if this is not None, using the string value passed. Returns: The figure on which the diagram is drawn. \"\"\" figure = TuneDiagramPlotter . plot_blank_tune_diagram () logger . debug ( \"Getting Tunes from cpymad\" ) new_q1 : float = madx . table . summ . dframe (). q1 [ 0 ] new_q2 : float = madx . table . summ . dframe (). q2 [ 0 ] if vxgood . any () and vygood . any () : plt . plot ( v_qx [ vxgood * vygood ] , v_qy [ vxgood * vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif vxgood . any () and ~ vygood . any () : tp = np . ones ( len ( vxgood )) * ( new_q2 - np . floor ( new_q2 )) plt . plot ( v_qx [ vxgood ] , tp [ vxgood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif ~ vxgood . any () and vygood . any () : tp = np . ones ( len ( vygood )) * ( new_q1 - np . floor ( new_q1 )) plt . plot ( tp [ vygood ] , v_qy [ vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) if savefig : logger . info ( f \"Saving Tune diagram plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure","title":"Plotters"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#module-pyhdtoolkitcpymadtoolsplotters","text":"Module cpymadtools.plotters Created on 2019.12.08 View Source \"\"\" Module cpymadtools.plotters --------------------------- Created on 2019.12.08 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions to plot different output results from a cpymad.madx.Madx object's simulation results. \"\"\" from pathlib import Path from typing import Dict , Tuple import matplotlib import matplotlib.pyplot as plt import numpy as np import pandas as pd from cpymad.madx import Madx from loguru import logger from matplotlib import colors as mcolors from pyhdtoolkit.optics.twiss import courant_snyder_transform from pyhdtoolkit.utils.defaults import PLOT_PARAMS plt . rcParams . update ( PLOT_PARAMS ) COLORS_DICT = dict ( mcolors . BASE_COLORS , ** mcolors . CSS4_COLORS ) BY_HSV = sorted ( ( tuple ( mcolors . rgb_to_hsv ( mcolors . to_rgba ( color )[: 3 ])), name ) for name , color in COLORS_DICT . items () ) SORTED_COLORS = [ name for hsv , name in BY_HSV ] class AperturePlotter : \"\"\" A class to plot the physical aperture of your machine. \"\"\" @staticmethod def plot_aperture ( madx : Madx , beam_params : Dict [ str , float ], figsize : Tuple [ int , int ] = ( 13 , 20 ), xlimits : Tuple [ float , float ] = None , hplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. beam_params (Dict[str, float]): a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. figsize (str): size of the figure, defaults to (15, 15). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. hplane_ylim (Tuple[float, float]): the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). vplane_ylim (Tuple[float, float]): the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint: disable=too-many-arguments # We need to interpolate in order to get high resolution along the s direction logger . debug ( \"Running interpolation in cpymad\" ) madx . input ( \"\"\" select, flag=interpolate, class=drift, slice=4, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=8, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; select, flag=interpolate, class=rbend, slice=10, range=#s/#e; twiss; \"\"\" ) logger . debug ( \"Getting Twiss dframe from cpymad\" ) twiss_hr : pd . DataFrame = madx . table . twiss . dframe () twiss_hr [ \"betatronic_envelope_x\" ] = np . sqrt ( twiss_hr . betx . values * beam_params [ \"eg_y_m\" ]) twiss_hr [ \"betatronic_envelope_y\" ] = np . sqrt ( twiss_hr . bety . values * beam_params [ \"eg_y_m\" ]) twiss_hr [ \"dispersive_envelope_x\" ] = twiss_hr . dx . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"dispersive_envelope_y\" ] = twiss_hr . dy . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"envelope_x\" ] = np . sqrt ( twiss_hr . betatronic_envelope_x . values ** 2 + ( twiss_hr . dx . values * beam_params [ \"deltap_p\" ]) ** 2 ) twiss_hr [ \"envelope_y\" ] = np . sqrt ( twiss_hr . betatronic_envelope_y . values ** 2 + ( twiss_hr . dy . values * beam_params [ \"deltap_p\" ]) ** 2 ) machine = twiss_hr [ twiss_hr . apertype == \"ellipse\" ] figure = plt . figure ( figsize = figsize ) logger . debug ( \"Plotting the horizontal aperture\" ) axis1 = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) axis1 . plot ( twiss_hr . s , twiss_hr . envelope_x , color = \"b\" ) axis1 . plot ( twiss_hr . s , - twiss_hr . envelope_x , color = \"b\" ) axis1 . fill_between ( twiss_hr . s , twiss_hr . envelope_x , - twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_x , - 3 * twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( machine . s , machine . aper_1 , machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . fill_between ( machine . s , - machine . aper_1 , - machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . plot ( machine . s , machine . aper_1 , \"k.-\" ) axis1 . plot ( machine . s , - machine . aper_1 , \"k.-\" ) axis1 . set_xlim ( xlimits ) axis1 . set_ylim ( hplane_ylim ) axis1 . set_ylabel ( \"x [m]\" ) axis1 . set_xlabel ( \"s [m]\" ) axis1 . set_title ( f \"Horizontal aperture at { beam_params [ 'pc_GeV' ] } GeV/c\" ) logger . debug ( \"Plotting the vertical aperture\" ) axis2 = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis2 . plot ( twiss_hr . s , twiss_hr . envelope_y , color = \"r\" ) axis2 . plot ( twiss_hr . s , - twiss_hr . envelope_y , color = \"r\" ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( machine . s , machine . aper_2 , machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . fill_between ( machine . s , - machine . aper_2 , - machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . plot ( machine . s , machine . aper_2 , \"k.-\" ) axis2 . plot ( machine . s , - machine . aper_2 , \"k.-\" ) axis2 . set_ylim ( vplane_ylim ) axis2 . set_ylabel ( \"y [m]\" ) axis2 . set_xlabel ( \"s [m]\" ) axis2 . set_title ( f \"Vertical aperture at { beam_params [ 'pc_GeV' ] } GeV/c\" ) logger . debug ( \"Plotting the stay-clear envelope\" ) axis3 = plt . subplot2grid (( 3 , 3 ), ( 2 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis3 . plot ( machine . s , machine . aper_1 / machine . envelope_x , \".-b\" , label = \"Horizontal plane\" ) axis3 . plot ( machine . s , machine . aper_2 / machine . envelope_y , \".-r\" , label = \"Vertical plane\" ) axis3 . set_xlim ( xlimits ) axis3 . set_ylabel ( \"n1\" ) axis3 . set_xlabel ( \"s [m]\" ) axis3 . legend ( loc = \"best\" ) axis3 . set_title ( f \"Stay-clear envelope at { beam_params [ 'pc_GeV' ] } GeV/c\" ) if savefig : logger . info ( f \"Saving aperture plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure class DynamicAperturePlotter : \"\"\" A class to plot the dynamic aperture of your machine. \"\"\" @staticmethod def plot_dynamic_aperture ( vx_coords : np . ndarray , vy_coords : np . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure : \"\"\" Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Args: vx_coords (np.ndarray): numpy array of horizontal coordinates over turns. vy_coords (np.ndarray): numpy array of vertical coordinates over turns. n_particles (int): number of particles simulated. savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" figure = plt . figure ( figsize = ( 12 , 7 )) turn_lost = [] x_in_lost = [] for particle in range ( n_particles ): nb = len ( vx_coords [ particle ]) - max ( np . isnan ( vx_coords [ particle ]) . sum (), np . isnan ( vy_coords [ particle ]) . sum () ) turn_lost . append ( nb ) x_in_lost . append ( vx_coords [ particle ][ 0 ] ** 2 + vy_coords [ particle ][ 0 ] ** 2 ) turn_lost = np . array ( turn_lost ) x_in_lost = np . array ( x_in_lost ) plt . scatter ( turn_lost , x_in_lost * 1000 , linewidths = 0.7 , c = \"darkblue\" , marker = \".\" ) plt . title ( \"Amplitudes lost over turns\" , fontsize = 20 ) plt . xlabel ( \"Number of Turns Survived\" , fontsize = 17 ) plt . ylabel ( \"Initial amplitude [mm]\" , fontsize = 17 ) if savefig : logger . info ( f \"Saving dynamic aperture plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure class PhaseSpacePlotter : \"\"\" A class to plot Courant-Snyder coordinates phase space. \"\"\" @staticmethod def plot_courant_snyder_phase_space ( madx : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ): logger . error ( f \"Plane should be either Horizontal or Vertical but ' { plane } ' was given\" ) raise ValueError ( \"Invalid plane value\" ) figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) # Getting the P matrix to compute Courant-Snyder coordinates logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = madx . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . alfy [ 0 ] beta = madx . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . bety [ 0 ] logger . debug ( f \"Plotting Courant-Snyder phase space for the { plane . lower () } plane\" ) for index , _ in enumerate ( u_coordinates ): logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle { index } \" ) u = np . array ([ u_coordinates [ index ], pu_coordinates [ index ]]) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0 , :] * 1e3 , u_bar [ 1 , :] * 1e3 , s = 0.1 , c = \"k\" ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$ \\\\ bar {x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$ \\\\ bar {y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving Courant-Snyder phase space plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure @staticmethod def plot_courant_snyder_phase_space_colored ( madx : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156th color. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ): logger . error ( f \"Plane should be either Horizontal or Vertical but ' { plane } ' was given\" ) raise ValueError ( \"Invalid plane value\" ) # Getting a sufficiently long array of colors to use colors = int ( np . floor ( len ( u_coordinates ) / 100 )) * SORTED_COLORS while len ( colors ) > len ( u_coordinates ): colors . pop () figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = madx . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . alfy [ 0 ] beta = madx . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . bety [ 0 ] logger . debug ( f \"Plotting colored normalised phase space for the { plane . lower () } plane\" ) for index , _ in enumerate ( u_coordinates ): logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle { index } \" ) u = np . array ([ u_coordinates [ index ], pu_coordinates [ index ]]) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0 , :] * 1e3 , u_bar [ 1 , :] * 1e3 , s = 0.1 , c = colors [ index ]) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$ \\\\ bar {x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$ \\\\ bar {y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving colored Courant-Snyder phase space plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure class TuneDiagramPlotter : \"\"\" A class to plot a blank tune diagram with Farey sequences, as well as your working points. \"\"\" @staticmethod def farey_sequence ( order : int ) -> list : \"\"\" Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Args: order (int): the order up to which we want to calculate the sequence. Returns: The sequence as a list. \"\"\" seq = [[ 0 , 1 ]] a , b , c , d = 0 , 1 , 1 , order while c <= order : k = int (( order + b ) / d ) a , b , c , d = c , d , k * c - a , k * d - b seq . append ([ a , b ]) return seq @staticmethod def plot_blank_tune_diagram () -> matplotlib . figure . Figure : \"\"\" Plotting the tune diagram up to the 6th order. Original code from Rogelio Tom\u00e1s. Returns: The figure on which resonance lines from farey sequences are drawn. \"\"\" logger . debug ( \"Plotting resonance lines from Farey sequence, up to 5th order\" ) figure = plt . figure ( figsize = ( 13 , 13 )) plt . ylim (( 0 , 1 )) plt . xlim (( 0 , 1 )) x = np . linspace ( 0 , 1 , 1000 ) for i in range ( 1 , 6 ): farey_sequences = TuneDiagramPlotter . farey_sequence ( i ) for f in farey_sequences : h , k = f # Node h/k on the axes for sequence in farey_sequences : p , q = sequence a = float ( k * p ) # Resonance linea Qx + b*Qy = clinkedtop / q if a > 0 : b = float ( q - k * p ) c = float ( p * h ) plt . plot ( x , c / a - x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( x , c / a + x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , 1 - x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , 1 - x , \"b\" , alpha = 0.1 ) if q == k and p == 1 : # FN elements below 1/k break plt . title ( \"Tune Diagram\" , fontsize = 20 ) plt . axis ( \"square\" ) plt . xlim ([ 0 , 1 ]) plt . ylim ([ 0 , 1 ]) plt . xlabel ( \"$Q_ {x} }$\" , fontsize = 17 ) plt . ylabel ( \"$Q_ {y} $\" , fontsize = 17 ) return figure @staticmethod def plot_tune_diagram ( madx : Madx , v_qx : np . ndarray = np . array ([ 0 ]), vxgood : np . ndarray = np . array ([ False ]), v_qy : np . ndarray = np . array ([ 0 ]), vygood : np . ndarray = np . array ([ False ]), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plots the evolution of particles' tunes on a Tune Diagram. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. v_qx (np.ndarray): horizontal tune value as a numpy array. vxgood (np.ndarray): ?? v_qy (np.ndarray): vertical tune value as a numpy array. vygood (np.ndarray): ?? savefig: will save the figure if this is not None, using the string value passed. Returns: The figure on which the diagram is drawn. \"\"\" figure = TuneDiagramPlotter . plot_blank_tune_diagram () logger . debug ( \"Getting Tunes from cpymad\" ) new_q1 : float = madx . table . summ . dframe () . q1 [ 0 ] new_q2 : float = madx . table . summ . dframe () . q2 [ 0 ] if vxgood . any () and vygood . any (): plt . plot ( v_qx [ vxgood * vygood ], v_qy [ vxgood * vygood ], \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif vxgood . any () and ~ vygood . any (): tp = np . ones ( len ( vxgood )) * ( new_q2 - np . floor ( new_q2 )) plt . plot ( v_qx [ vxgood ], tp [ vxgood ], \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif ~ vxgood . any () and vygood . any (): tp = np . ones ( len ( vygood )) * ( new_q1 - np . floor ( new_q1 )) plt . plot ( tp [ vygood ], v_qy [ vygood ], \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) if savefig : logger . info ( f \"Saving Tune diagram plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure","title":"Module pyhdtoolkit.cpymadtools.plotters"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#variables","text":"BY_HSV COLORS_DICT PLOT_PARAMS SORTED_COLORS","title":"Variables"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#apertureplotter","text":"class AperturePlotter ( / , * args , ** kwargs ) View Source class AperturePlotter : \"\"\" A class to plot the physical aperture of your machine. \"\"\" @staticmethod def plot_aperture ( madx : Madx , beam_params : Dict [ str, float ] , figsize : Tuple [ int, int ] = ( 13 , 20 ), xlimits : Tuple [ float, float ] = None , hplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. beam_params (Dict[str, float]): a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. figsize (str): size of the figure, defaults to (15, 15). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. hplane_ylim (Tuple[float, float]): the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). vplane_ylim (Tuple[float, float]): the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments # We need to interpolate in order to get high resolution along the s direction logger . debug ( \"Running interpolation in cpymad\" ) madx . input ( \"\"\" select, flag=interpolate, class=drift, slice=4, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=8, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; select, flag=interpolate, class=rbend, slice=10, range=#s/#e; twiss; \"\"\" ) logger . debug ( \"Getting Twiss dframe from cpymad\" ) twiss_hr : pd . DataFrame = madx . table . twiss . dframe () twiss_hr [ \"betatronic_envelope_x\" ] = np . sqrt ( twiss_hr . betx . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"betatronic_envelope_y\" ] = np . sqrt ( twiss_hr . bety . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"dispersive_envelope_x\" ] = twiss_hr . dx . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"dispersive_envelope_y\" ] = twiss_hr . dy . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"envelope_x\" ] = np . sqrt ( twiss_hr . betatronic_envelope_x . values ** 2 + ( twiss_hr . dx . values * beam_params [ \"deltap_p\" ] ) ** 2 ) twiss_hr [ \"envelope_y\" ] = np . sqrt ( twiss_hr . betatronic_envelope_y . values ** 2 + ( twiss_hr . dy . values * beam_params [ \"deltap_p\" ] ) ** 2 ) machine = twiss_hr [ twiss_hr.apertype == \"ellipse\" ] figure = plt . figure ( figsize = figsize ) logger . debug ( \"Plotting the horizontal aperture\" ) axis1 = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) axis1 . plot ( twiss_hr . s , twiss_hr . envelope_x , color = \"b\" ) axis1 . plot ( twiss_hr . s , - twiss_hr . envelope_x , color = \"b\" ) axis1 . fill_between ( twiss_hr . s , twiss_hr . envelope_x , - twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_x , - 3 * twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( machine . s , machine . aper_1 , machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . fill_between ( machine . s , - machine . aper_1 , - machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . plot ( machine . s , machine . aper_1 , \"k.-\" ) axis1 . plot ( machine . s , - machine . aper_1 , \"k.-\" ) axis1 . set_xlim ( xlimits ) axis1 . set_ylim ( hplane_ylim ) axis1 . set_ylabel ( \"x [m]\" ) axis1 . set_xlabel ( \"s [m]\" ) axis1 . set_title ( f \"Horizontal aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the vertical aperture\" ) axis2 = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis2 . plot ( twiss_hr . s , twiss_hr . envelope_y , color = \"r\" ) axis2 . plot ( twiss_hr . s , - twiss_hr . envelope_y , color = \"r\" ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( machine . s , machine . aper_2 , machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . fill_between ( machine . s , - machine . aper_2 , - machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . plot ( machine . s , machine . aper_2 , \"k.-\" ) axis2 . plot ( machine . s , - machine . aper_2 , \"k.-\" ) axis2 . set_ylim ( vplane_ylim ) axis2 . set_ylabel ( \"y [m]\" ) axis2 . set_xlabel ( \"s [m]\" ) axis2 . set_title ( f \"Vertical aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the stay-clear envelope\" ) axis3 = plt . subplot2grid (( 3 , 3 ), ( 2 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis3 . plot ( machine . s , machine . aper_1 / machine . envelope_x , \".-b\" , label = \"Horizontal plane\" ) axis3 . plot ( machine . s , machine . aper_2 / machine . envelope_y , \".-r\" , label = \"Vertical plane\" ) axis3 . set_xlim ( xlimits ) axis3 . set_ylabel ( \"n1\" ) axis3 . set_xlabel ( \"s [m]\" ) axis3 . legend ( loc = \"best\" ) axis3 . set_title ( f \"Stay-clear envelope at {beam_params['pc_GeV']} GeV/c\" ) if savefig : logger . info ( f \"Saving aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure","title":"AperturePlotter"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#plot_aperture","text":"def plot_aperture ( madx : cpymad . madx . Madx , beam_params : Dict [ str , float ], figsize : Tuple [ int , int ] = ( 13 , 20 ), xlimits : Tuple [ float , float ] = None , hplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), savefig : str = None ) -> matplotlib . figure . Figure Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None beam_params Dict[str, float] a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. None figsize str size of the figure, defaults to (15, 15). None xlimits Tuple[float, float] will implement xlim (for the s coordinate) if this is not None, using the tuple passed. None hplane_ylim Tuple[float, float] the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). None vplane_ylim Tuple[float, float] the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). None savefig str will save the figure if this is not None, using the string value passed. None Returns: Type Description None The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_aperture ( madx : Madx , beam_params : Dict [ str, float ] , figsize : Tuple [ int, int ] = ( 13 , 20 ), xlimits : Tuple [ float, float ] = None , hplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. beam_params (Dict[str, float]): a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. figsize (str): size of the figure, defaults to (15, 15). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. hplane_ylim (Tuple[float, float]): the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). vplane_ylim (Tuple[float, float]): the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments # We need to interpolate in order to get high resolution along the s direction logger . debug ( \"Running interpolation in cpymad\" ) madx . input ( \"\"\" select, flag=interpolate, class=drift, slice=4, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=8, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; select, flag=interpolate, class=rbend, slice=10, range=#s/#e; twiss; \"\"\" ) logger . debug ( \"Getting Twiss dframe from cpymad\" ) twiss_hr : pd . DataFrame = madx . table . twiss . dframe () twiss_hr [ \"betatronic_envelope_x\" ] = np . sqrt ( twiss_hr . betx . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"betatronic_envelope_y\" ] = np . sqrt ( twiss_hr . bety . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"dispersive_envelope_x\" ] = twiss_hr . dx . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"dispersive_envelope_y\" ] = twiss_hr . dy . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"envelope_x\" ] = np . sqrt ( twiss_hr . betatronic_envelope_x . values ** 2 + ( twiss_hr . dx . values * beam_params [ \"deltap_p\" ] ) ** 2 ) twiss_hr [ \"envelope_y\" ] = np . sqrt ( twiss_hr . betatronic_envelope_y . values ** 2 + ( twiss_hr . dy . values * beam_params [ \"deltap_p\" ] ) ** 2 ) machine = twiss_hr [ twiss_hr.apertype == \"ellipse\" ] figure = plt . figure ( figsize = figsize ) logger . debug ( \"Plotting the horizontal aperture\" ) axis1 = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) axis1 . plot ( twiss_hr . s , twiss_hr . envelope_x , color = \"b\" ) axis1 . plot ( twiss_hr . s , - twiss_hr . envelope_x , color = \"b\" ) axis1 . fill_between ( twiss_hr . s , twiss_hr . envelope_x , - twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_x , - 3 * twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( machine . s , machine . aper_1 , machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . fill_between ( machine . s , - machine . aper_1 , - machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . plot ( machine . s , machine . aper_1 , \"k.-\" ) axis1 . plot ( machine . s , - machine . aper_1 , \"k.-\" ) axis1 . set_xlim ( xlimits ) axis1 . set_ylim ( hplane_ylim ) axis1 . set_ylabel ( \"x [m]\" ) axis1 . set_xlabel ( \"s [m]\" ) axis1 . set_title ( f \"Horizontal aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the vertical aperture\" ) axis2 = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis2 . plot ( twiss_hr . s , twiss_hr . envelope_y , color = \"r\" ) axis2 . plot ( twiss_hr . s , - twiss_hr . envelope_y , color = \"r\" ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( machine . s , machine . aper_2 , machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . fill_between ( machine . s , - machine . aper_2 , - machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . plot ( machine . s , machine . aper_2 , \"k.-\" ) axis2 . plot ( machine . s , - machine . aper_2 , \"k.-\" ) axis2 . set_ylim ( vplane_ylim ) axis2 . set_ylabel ( \"y [m]\" ) axis2 . set_xlabel ( \"s [m]\" ) axis2 . set_title ( f \"Vertical aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the stay-clear envelope\" ) axis3 = plt . subplot2grid (( 3 , 3 ), ( 2 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis3 . plot ( machine . s , machine . aper_1 / machine . envelope_x , \".-b\" , label = \"Horizontal plane\" ) axis3 . plot ( machine . s , machine . aper_2 / machine . envelope_y , \".-r\" , label = \"Vertical plane\" ) axis3 . set_xlim ( xlimits ) axis3 . set_ylabel ( \"n1\" ) axis3 . set_xlabel ( \"s [m]\" ) axis3 . legend ( loc = \"best\" ) axis3 . set_title ( f \"Stay-clear envelope at {beam_params['pc_GeV']} GeV/c\" ) if savefig : logger . info ( f \"Saving aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure","title":"plot_aperture"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#dynamicapertureplotter","text":"class DynamicAperturePlotter ( / , * args , ** kwargs ) View Source class DynamicAperturePlotter : \"\"\" A class to plot the dynamic aperture of your machine. \"\"\" @staticmethod def plot_dynamic_aperture ( vx_coords : np . ndarray , vy_coords : np . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure : \"\"\" Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Args: vx_coords (np.ndarray): numpy array of horizontal coordinates over turns. vy_coords (np.ndarray): numpy array of vertical coordinates over turns. n_particles (int): number of particles simulated. savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" figure = plt . figure ( figsize = ( 12 , 7 )) turn_lost = [] x_in_lost = [] for particle in range ( n_particles ) : nb = len ( vx_coords [ particle ] ) - max ( np . isnan ( vx_coords [ particle ] ). sum (), np . isnan ( vy_coords [ particle ] ). sum () ) turn_lost . append ( nb ) x_in_lost . append ( vx_coords [ particle ][ 0 ] ** 2 + vy_coords [ particle ][ 0 ] ** 2 ) turn_lost = np . array ( turn_lost ) x_in_lost = np . array ( x_in_lost ) plt . scatter ( turn_lost , x_in_lost * 1000 , linewidths = 0.7 , c = \"darkblue\" , marker = \".\" ) plt . title ( \"Amplitudes lost over turns\" , fontsize = 20 ) plt . xlabel ( \"Number of Turns Survived\" , fontsize = 17 ) plt . ylabel ( \"Initial amplitude [mm]\" , fontsize = 17 ) if savefig : logger . info ( f \"Saving dynamic aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure","title":"DynamicAperturePlotter"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#plot_dynamic_aperture","text":"def plot_dynamic_aperture ( vx_coords : numpy . ndarray , vy_coords : numpy . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Parameters: Name Type Description Default vx_coords np.ndarray numpy array of horizontal coordinates over turns. None vy_coords np.ndarray numpy array of vertical coordinates over turns. None n_particles int number of particles simulated. None savefig str will save the figure if this is not None, using the string value passed. None Returns: Type Description None The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_dynamic_aperture ( vx_coords : np . ndarray , vy_coords : np . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure : \"\"\" Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Args: vx_coords (np.ndarray): numpy array of horizontal coordinates over turns. vy_coords (np.ndarray): numpy array of vertical coordinates over turns. n_particles (int): number of particles simulated. savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" figure = plt . figure ( figsize = ( 12 , 7 )) turn_lost = [] x_in_lost = [] for particle in range ( n_particles ) : nb = len ( vx_coords [ particle ] ) - max ( np . isnan ( vx_coords [ particle ] ). sum (), np . isnan ( vy_coords [ particle ] ). sum () ) turn_lost . append ( nb ) x_in_lost . append ( vx_coords [ particle ][ 0 ] ** 2 + vy_coords [ particle ][ 0 ] ** 2 ) turn_lost = np . array ( turn_lost ) x_in_lost = np . array ( x_in_lost ) plt . scatter ( turn_lost , x_in_lost * 1000 , linewidths = 0.7 , c = \"darkblue\" , marker = \".\" ) plt . title ( \"Amplitudes lost over turns\" , fontsize = 20 ) plt . xlabel ( \"Number of Turns Survived\" , fontsize = 17 ) plt . ylabel ( \"Initial amplitude [mm]\" , fontsize = 17 ) if savefig : logger . info ( f \"Saving dynamic aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure","title":"plot_dynamic_aperture"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#phasespaceplotter","text":"class PhaseSpacePlotter ( / , * args , ** kwargs ) View Source class PhaseSpacePlotter : \"\"\" A class to plot Courant-Snyder coordinates phase space. \"\"\" @staticmethod def plot_courant_snyder_phase_space ( madx : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) # Getting the P matrix to compute Courant - Snyder coordinates logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = madx . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . alfy [ 0 ] beta = madx . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . bety [ 0 ] logger . debug ( f \"Plotting Courant-Snyder phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = \"k\" ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure @staticmethod def plot_courant_snyder_phase_space_colored ( madx : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156th color. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) # Getting a sufficiently long array of colors to use colors = int ( np . floor ( len ( u_coordinates ) / 100 )) * SORTED_COLORS while len ( colors ) > len ( u_coordinates ) : colors . pop () figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = madx . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . alfy [ 0 ] beta = madx . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . bety [ 0 ] logger . debug ( f \"Plotting colored normalised phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = colors [ index ] ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving colored Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure","title":"PhaseSpacePlotter"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#static-methods_2","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#plot_courant_snyder_phase_space","text":"def plot_courant_snyder_phase_space ( madx : cpymad . madx . Madx , u_coordinates : numpy . ndarray , pu_coordinates : numpy . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = 'Horizontal' ) -> matplotlib . figure . Figure Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None u_coordinates np.ndarray numpy array of particles's coordinates for the given plane. None pu_coordinates np.ndarray numpy array of particles's momentum coordinates for the given plane. None savefig str will save the figure if this is not None, using the string value passed. None size Tuple[int, int] the wanted matplotlib figure size. Defaults to (16, 8). (16, 8) plane str the physical plane to plot. Defaults to 'Horizontal'. 'Horizontal' Returns: Type Description None The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_courant_snyder_phase_space ( madx : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) # Getting the P matrix to compute Courant - Snyder coordinates logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = madx . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . alfy [ 0 ] beta = madx . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . bety [ 0 ] logger . debug ( f \"Plotting Courant-Snyder phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = \"k\" ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure","title":"plot_courant_snyder_phase_space"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#plot_courant_snyder_phase_space_colored","text":"def plot_courant_snyder_phase_space_colored ( madx : cpymad . madx . Madx , u_coordinates : numpy . ndarray , pu_coordinates : numpy . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = 'Horizontal' ) -> matplotlib . figure . Figure Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156 th color. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None u_coordinates np.ndarray numpy array of particles's coordinates for the given plane. None pu_coordinates np.ndarray numpy array of particles's momentum coordinates for the given plane. None savefig str will save the figure if this is not None, using the string value passed. None size Tuple[int, int] the wanted matplotlib figure size. Defaults to (16, 8). (16, 8) plane str the physical plane to plot. Defaults to 'Horizontal'. 'Horizontal' Returns: Type Description None The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_courant_snyder_phase_space_colored ( madx : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156th color. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) # Getting a sufficiently long array of colors to use colors = int ( np . floor ( len ( u_coordinates ) / 100 )) * SORTED_COLORS while len ( colors ) > len ( u_coordinates ) : colors . pop () figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = madx . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . alfy [ 0 ] beta = madx . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else madx . table . twiss . bety [ 0 ] logger . debug ( f \"Plotting colored normalised phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = colors [ index ] ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving colored Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure","title":"plot_courant_snyder_phase_space_colored"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#tunediagramplotter","text":"class TuneDiagramPlotter ( / , * args , ** kwargs ) View Source class TuneDiagramPlotter : \"\"\" A class to plot a blank tune diagram with Farey sequences, as well as your working points. \"\"\" @staticmethod def farey_sequence ( order : int ) -> list : \"\"\" Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Args: order (int): the order up to which we want to calculate the sequence. Returns: The sequence as a list. \"\"\" seq = [ [0, 1 ] ] a , b , c , d = 0 , 1 , 1 , order while c <= order : k = int (( order + b ) / d ) a , b , c , d = c , d , k * c - a , k * d - b seq . append ( [ a, b ] ) return seq @staticmethod def plot_blank_tune_diagram () -> matplotlib . figure . Figure : \"\"\" Plotting the tune diagram up to the 6th order. Original code from Rogelio Tom\u00e1s. Returns: The figure on which resonance lines from farey sequences are drawn. \"\"\" logger . debug ( \"Plotting resonance lines from Farey sequence, up to 5th order\" ) figure = plt . figure ( figsize = ( 13 , 13 )) plt . ylim (( 0 , 1 )) plt . xlim (( 0 , 1 )) x = np . linspace ( 0 , 1 , 1000 ) for i in range ( 1 , 6 ) : farey_sequences = TuneDiagramPlotter . farey_sequence ( i ) for f in farey_sequences : h , k = f # Node h / k on the axes for sequence in farey_sequences : p , q = sequence a = float ( k * p ) # Resonance linea Qx + b * Qy = clinkedtop / q if a > 0 : b = float ( q - k * p ) c = float ( p * h ) plt . plot ( x , c / a - x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( x , c / a + x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , 1 - x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , 1 - x , \"b\" , alpha = 0.1 ) if q == k and p == 1 : # FN elements below 1 / k break plt . title ( \"Tune Diagram\" , fontsize = 20 ) plt . axis ( \"square\" ) plt . xlim ( [ 0, 1 ] ) plt . ylim ( [ 0, 1 ] ) plt . xlabel ( \"$Q_{x}}$\" , fontsize = 17 ) plt . ylabel ( \"$Q_{y}$\" , fontsize = 17 ) return figure @staticmethod def plot_tune_diagram ( madx : Madx , v_qx : np . ndarray = np . array ( [ 0 ] ), vxgood : np . ndarray = np . array ( [ False ] ), v_qy : np . ndarray = np . array ( [ 0 ] ), vygood : np . ndarray = np . array ( [ False ] ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plots the evolution of particles' tunes on a Tune Diagram. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. v_qx (np.ndarray): horizontal tune value as a numpy array. vxgood (np.ndarray): ?? v_qy (np.ndarray): vertical tune value as a numpy array. vygood (np.ndarray): ?? savefig: will save the figure if this is not None, using the string value passed. Returns: The figure on which the diagram is drawn. \"\"\" figure = TuneDiagramPlotter . plot_blank_tune_diagram () logger . debug ( \"Getting Tunes from cpymad\" ) new_q1 : float = madx . table . summ . dframe (). q1 [ 0 ] new_q2 : float = madx . table . summ . dframe (). q2 [ 0 ] if vxgood . any () and vygood . any () : plt . plot ( v_qx [ vxgood * vygood ] , v_qy [ vxgood * vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif vxgood . any () and ~ vygood . any () : tp = np . ones ( len ( vxgood )) * ( new_q2 - np . floor ( new_q2 )) plt . plot ( v_qx [ vxgood ] , tp [ vxgood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif ~ vxgood . any () and vygood . any () : tp = np . ones ( len ( vygood )) * ( new_q1 - np . floor ( new_q1 )) plt . plot ( tp [ vygood ] , v_qy [ vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) if savefig : logger . info ( f \"Saving Tune diagram plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure","title":"TuneDiagramPlotter"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#static-methods_3","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#farey_sequence","text":"def farey_sequence ( order : int ) -> list Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Parameters: Name Type Description Default order int the order up to which we want to calculate the sequence. None Returns: Type Description None The sequence as a list. View Source @staticmethod def farey_sequence ( order : int ) -> list : \"\"\" Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Args: order (int): the order up to which we want to calculate the sequence. Returns: The sequence as a list. \"\"\" seq = [ [0, 1 ] ] a , b , c , d = 0 , 1 , 1 , order while c <= order : k = int (( order + b ) / d ) a , b , c , d = c , d , k * c - a , k * d - b seq . append ( [ a, b ] ) return seq","title":"farey_sequence"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#plot_blank_tune_diagram","text":"def plot_blank_tune_diagram ( ) -> matplotlib . figure . Figure Plotting the tune diagram up to the 6 th order. Original code from Rogelio Tom\u00e1s. Returns: Type Description None The figure on which resonance lines from farey sequences are drawn. View Source @staticmethod def plot_blank_tune_diagram () -> matplotlib . figure . Figure : \"\"\" Plotting the tune diagram up to the 6th order. Original code from Rogelio Tom\u00e1s. Returns: The figure on which resonance lines from farey sequences are drawn. \"\"\" logger . debug ( \"Plotting resonance lines from Farey sequence, up to 5th order\" ) figure = plt . figure ( figsize = ( 13 , 13 )) plt . ylim (( 0 , 1 )) plt . xlim (( 0 , 1 )) x = np . linspace ( 0 , 1 , 1000 ) for i in range ( 1 , 6 ) : farey_sequences = TuneDiagramPlotter . farey_sequence ( i ) for f in farey_sequences : h , k = f # Node h / k on the axes for sequence in farey_sequences : p , q = sequence a = float ( k * p ) # Resonance linea Qx + b * Qy = clinkedtop / q if a > 0 : b = float ( q - k * p ) c = float ( p * h ) plt . plot ( x , c / a - x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( x , c / a + x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , 1 - x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , 1 - x , \"b\" , alpha = 0.1 ) if q == k and p == 1 : # FN elements below 1 / k break plt . title ( \"Tune Diagram\" , fontsize = 20 ) plt . axis ( \"square\" ) plt . xlim ( [ 0, 1 ] ) plt . ylim ( [ 0, 1 ] ) plt . xlabel ( \"$Q_{x}}$\" , fontsize = 17 ) plt . ylabel ( \"$Q_{y}$\" , fontsize = 17 ) return figure","title":"plot_blank_tune_diagram"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#plot_tune_diagram","text":"def plot_tune_diagram ( madx : cpymad . madx . Madx , v_qx : numpy . ndarray = array ([ 0 ]), vxgood : numpy . ndarray = array ([ False ]), v_qy : numpy . ndarray = array ([ 0 ]), vygood : numpy . ndarray = array ([ False ]), savefig : str = None ) -> matplotlib . figure . Figure Plots the evolution of particles' tunes on a Tune Diagram. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None v_qx np.ndarray horizontal tune value as a numpy array. None vxgood np.ndarray ?? None v_qy np.ndarray vertical tune value as a numpy array. None vygood np.ndarray ?? None savefig None will save the figure if this is not None, using the string value passed. None Returns: Type Description None The figure on which the diagram is drawn. View Source @staticmethod def plot_tune_diagram ( madx : Madx , v_qx : np . ndarray = np . array ( [ 0 ] ), vxgood : np . ndarray = np . array ( [ False ] ), v_qy : np . ndarray = np . array ( [ 0 ] ), vygood : np . ndarray = np . array ( [ False ] ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plots the evolution of particles' tunes on a Tune Diagram. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. v_qx (np.ndarray): horizontal tune value as a numpy array. vxgood (np.ndarray): ?? v_qy (np.ndarray): vertical tune value as a numpy array. vygood (np.ndarray): ?? savefig: will save the figure if this is not None, using the string value passed. Returns: The figure on which the diagram is drawn. \"\"\" figure = TuneDiagramPlotter . plot_blank_tune_diagram () logger . debug ( \"Getting Tunes from cpymad\" ) new_q1 : float = madx . table . summ . dframe (). q1 [ 0 ] new_q2 : float = madx . table . summ . dframe (). q2 [ 0 ] if vxgood . any () and vygood . any () : plt . plot ( v_qx [ vxgood * vygood ] , v_qy [ vxgood * vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif vxgood . any () and ~ vygood . any () : tp = np . ones ( len ( vxgood )) * ( new_q2 - np . floor ( new_q2 )) plt . plot ( v_qx [ vxgood ] , tp [ vxgood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif ~ vxgood . any () and vygood . any () : tp = np . ones ( len ( vygood )) * ( new_q1 - np . floor ( new_q1 )) plt . plot ( tp [ vygood ] , v_qy [ vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) if savefig : logger . info ( f \"Saving Tune diagram plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"pdf\" , dpi = 500 ) return figure","title":"plot_tune_diagram"},{"location":"reference/pyhdtoolkit/cpymadtools/ptc/","text":"Module pyhdtoolkit.cpymadtools.ptc Module cpymadtools.ptc Created on 2020.02.03 View Source \"\"\" Module cpymadtools.ptc ---------------------- Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to harness MAD-X PTC functionality with a cpymad.madx.Madx object. \"\"\" from pathlib import Path from typing import Union import tfs from cpymad.madx import Madx from loguru import logger # ----- Utilities ----- # def get_amplitude_detuning ( madx : Madx , order : int = 2 , file : Union [ Path , str ] = None ) -> tfs . TfsDataFrame : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Calculate amplitude detuning via PTC_NORMAL. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. order (int): maximum derivative order (only 0, 1 or 2 implemented in PTC). Defaults to `2`. file (Union[Path, str]): path to output file. Default `None` Returns: A TfsDataframe with results. \"\"\" if order >= 3 : logger . error ( f \"Maximum amplitude detuning order in PTC is 2, but { order : d } was requested\" ) raise NotImplementedError ( \"PTC amplitude detuning is not implemented for order > 2\" ) logger . info ( \"Entering PTC to calculate amplitude detuning\" ) madx . ptc_create_universe () # layout I got with mask (jdilly) # model=3 (Sixtrack code model: Delta-Matrix-Kick-Matrix) # method=4 (integration order), nst=3 (integration steps), exact=True (exact Hamiltonian) logger . trace ( \"Creating PTC layout\" ) madx . ptc_create_layout ( model = 3 , method = 4 , nst = 3 , exact = True ) # alternative layout: model=3, method=6, nst=3 # resplit=True (adaptive splitting of magnets), thin=0.0005 (splitting of quads), # xbend=0.0005 (splitting of dipoles) # madx.ptc_create_layout(model=3, method=6, nst=3, resplit=True, thin=0.0005, xbend=0.0005) logger . trace ( \"Incorporating MAD-X alignment errors\" ) madx . ptc_align () # use madx alignment errors # madx.ptc_setswitch(fringe=True) # include fringe effects logger . trace ( \"Selecting tune orders\" ) madx . select_ptc_normal ( q1 = \"0\" , q2 = \"0\" ) for ii in range ( 1 , order + 1 ): # These are d^iQ/ddp^i madx . select_ptc_normal ( dq1 = f \" { ii : d } \" , dq2 = f \" { ii : d } \" ) # ANH = anharmonicities (ex, ey, deltap), works only with parameters as full strings # could be done nicer with permutations ... logger . trace ( \"Selecting anharmonicities\" ) if order >= 1 : # madx.select_ptc_normal('anhx=0, 0, 1') # dQx/ddp # madx.select_ptc_normal('anhy=0, 0, 1') # dQy/ddp madx . select_ptc_normal ( \"anhx=1, 0, 0\" ) # dQx/dex madx . select_ptc_normal ( \"anhx=0, 1, 0\" ) # dQx/dey madx . select_ptc_normal ( \"anhy=1, 0, 0\" ) # dQy/dex madx . select_ptc_normal ( \"anhy=0, 1, 0\" ) # dQy/dey if order >= 2 : # madx.select_ptc_normal('anhx=0, 0, 2') # d^2Qx/ddp^2 # madx.select_ptc_normal('anhy=0, 0, 2') # d^2Qy/ddp^2 madx . select_ptc_normal ( \"anhx=2, 0, 0\" ) # d^2Qx/dex^2 madx . select_ptc_normal ( \"anhx=1, 1, 0\" ) # d^2Qx/dexdey madx . select_ptc_normal ( \"anhx=0, 2, 0\" ) # d^2Qx/dey^2 madx . select_ptc_normal ( \"anhy=2, 0, 0\" ) # d^2Qy/dex^2 madx . select_ptc_normal ( \"anhy=1, 1, 0\" ) # d^2Qy/dexdey madx . select_ptc_normal ( \"anhy=0, 2, 0\" ) # d^2Qy/dey^2 # icase = phase-space dimensionality, no = order of map logger . debug ( \"Executing PTC Normal\" ) madx . ptc_normal ( closed_orbit = True , normal = True , icase = 5 , no = 5 ) madx . ptc_end () logger . debug ( \"Extracting results to TfsDataFrame\" ) dframe = tfs . TfsDataFrame ( madx . table . normal_results . dframe ()) dframe . columns = dframe . columns . str . upper () dframe . NAME = dframe . NAME . str . upper () dframe . index = range ( len ( dframe . NAME )) # table has a weird index if file : logger . debug ( f \"Exporting results to disk at ' { Path ( file ) . absolute () } '\" ) tfs . write ( file , dframe ) return dframe def get_rdts ( madx : Madx , order : int = 4 , file : Union [ Path , str ] = None ) -> tfs . TfsDataFrame : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Calculate the RDTs via PTC_TWISS. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. order (int): maximum derivative order (only 0, 1 or 2 implemented in PTC). Defaults to `2`. file (Union[Path, str]): path to output file. Default `None` Returns: A TfsDataframe with results. \"\"\" logger . info ( f \"Entering PTC to calculate RDTs up to order { order } \" ) madx . ptc_create_universe () logger . trace ( \"Creating PTC layout\" ) madx . ptc_create_layout ( model = 3 , method = 4 , nst = 3 , exact = True ) # madx.ptc_create_layout(model=3, method=6, nst=1) # from Michi logger . trace ( \"Incorporating MAD-X alignment errors\" ) madx . ptc_align () # use madx alignment errors # madx.ptc_setswitch(fringe=True) # include fringe effects logger . debug ( \"Executing PTC Twiss\" ) madx . ptc_twiss ( icase = 6 , no = order , normal = True , trackrdts = True ) madx . ptc_end () logger . debug ( \"Extracting results to TfsDataFrame\" ) dframe = tfs . TfsDataFrame ( madx . table . twissrdt . dframe ()) dframe . columns = dframe . columns . str . upper () dframe . NAME = dframe . NAME . str . upper () if file : logger . debug ( f \"Exporting results to disk at ' { Path ( file ) . absolute () } '\" ) tfs . write ( file , dframe ) return dframe Functions get_amplitude_detuning def get_amplitude_detuning ( madx : cpymad . madx . Madx , order : int = 2 , file : Union [ pathlib . Path , str ] = None ) -> tfs . handler . TfsDataFrame INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Calculate amplitude detuning via PTC_NORMAL. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None order int maximum derivative order (only 0, 1 or 2 implemented in PTC). Defaults to 2 . 2 file Union[Path, str] path to output file. Default None None Returns: Type Description None A TfsDataframe with results. View Source def get_amplitude_detuning ( madx : Madx , order : int = 2 , file : Union [ Path , str ] = None ) -> tfs . TfsDataFrame : \" \"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Calculate amplitude detuning via PTC_NORMAL. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. order (int): maximum derivative order (only 0, 1 or 2 implemented in PTC). Defaults to `2`. file (Union[Path, str]): path to output file. Default `None` Returns: A TfsDataframe with results. \"\" \" if order >= 3 : logger . error ( f \"Maximum amplitude detuning order in PTC is 2, but {order:d} was requested\" ) raise NotImplementedError ( \"PTC amplitude detuning is not implemented for order > 2\" ) logger . info ( \"Entering PTC to calculate amplitude detuning\" ) madx . ptc_create_universe () # layout I got with mask (jdilly) # model=3 (Sixtrack code model: Delta-Matrix-Kick-Matrix) # method=4 (integration order), nst=3 (integration steps), exact=True (exact Hamiltonian) logger . trace ( \"Creating PTC layout\" ) madx . ptc_create_layout ( model = 3 , method = 4 , nst = 3 , exact = True ) # alternative layout: model=3, method=6, nst=3 # resplit=True (adaptive splitting of magnets), thin=0.0005 (splitting of quads), # xbend=0.0005 (splitting of dipoles) # madx.ptc_create_layout(model=3, method=6, nst=3, resplit=True, thin=0.0005, xbend=0.0005) logger . trace ( \"Incorporating MAD-X alignment errors\" ) madx . ptc_align () # use madx alignment errors # madx.ptc_setswitch(fringe=True) # include fringe effects logger . trace ( \"Selecting tune orders\" ) madx . select_ptc_normal ( q1 = \"0\" , q2 = \"0\" ) for ii in range ( 1 , order + 1 ) : # These are d^iQ/ddp^i madx . select_ptc_normal ( dq1 = f \"{ii:d}\" , dq2 = f \"{ii:d}\" ) # ANH = anharmonicities (ex, ey, deltap), works only with parameters as full strings # could be done nicer with permutations ... logger . trace ( \"Selecting anharmonicities\" ) if order >= 1 : # madx.select_ptc_normal('anhx=0, 0, 1') # dQx/ddp # madx.select_ptc_normal('anhy=0, 0, 1') # dQy/ddp madx . select_ptc_normal ( \"anhx=1, 0, 0\" ) # dQx/dex madx . select_ptc_normal ( \"anhx=0, 1, 0\" ) # dQx/dey madx . select_ptc_normal ( \"anhy=1, 0, 0\" ) # dQy/dex madx . select_ptc_normal ( \"anhy=0, 1, 0\" ) # dQy/dey if order >= 2 : # madx.select_ptc_normal('anhx=0, 0, 2') # d^2Qx/ddp^2 # madx.select_ptc_normal('anhy=0, 0, 2') # d^2Qy/ddp^2 madx . select_ptc_normal ( \"anhx=2, 0, 0\" ) # d^2Qx/dex^2 madx . select_ptc_normal ( \"anhx=1, 1, 0\" ) # d^2Qx/dexdey madx . select_ptc_normal ( \"anhx=0, 2, 0\" ) # d^2Qx/dey^2 madx . select_ptc_normal ( \"anhy=2, 0, 0\" ) # d^2Qy/dex^2 madx . select_ptc_normal ( \"anhy=1, 1, 0\" ) # d^2Qy/dexdey madx . select_ptc_normal ( \"anhy=0, 2, 0\" ) # d^2Qy/dey^2 # icase = phase-space dimensionality, no = order of map logger . debug ( \"Executing PTC Normal\" ) madx . ptc_normal ( closed_orbit = True , normal = True , icase = 5 , no = 5 ) madx . ptc_end () logger . debug ( \"Extracting results to TfsDataFrame\" ) dframe = tfs . TfsDataFrame ( madx . table . normal_results . dframe ()) dframe . columns = dframe . columns . str . upper () dframe . NAME = dframe . NAME . str . upper () dframe . index = range ( len ( dframe . NAME )) # table has a weird index if file : logger . debug ( f \"Exporting results to disk at '{Path(file).absolute()}'\" ) tfs . write ( file , dframe ) return dframe get_rdts def get_rdts ( madx : cpymad . madx . Madx , order : int = 4 , file : Union [ pathlib . Path , str ] = None ) -> tfs . handler . TfsDataFrame INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Calculate the RDTs via PTC_TWISS. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None order int maximum derivative order (only 0, 1 or 2 implemented in PTC). Defaults to 2 . 2 file Union[Path, str] path to output file. Default None None Returns: Type Description None A TfsDataframe with results. View Source def get_rdts ( madx : Madx , order : int = 4 , file : Union [ Path , str ] = None ) -> tfs . TfsDataFrame : \" \"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Calculate the RDTs via PTC_TWISS. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. order (int): maximum derivative order (only 0, 1 or 2 implemented in PTC). Defaults to `2`. file (Union[Path, str]): path to output file. Default `None` Returns: A TfsDataframe with results. \"\" \" logger . info ( f \"Entering PTC to calculate RDTs up to order {order}\" ) madx . ptc_create_universe () logger . trace ( \"Creating PTC layout\" ) madx . ptc_create_layout ( model = 3 , method = 4 , nst = 3 , exact = True ) # madx.ptc_create_layout(model=3, method=6, nst=1) # from Michi logger . trace ( \"Incorporating MAD-X alignment errors\" ) madx . ptc_align () # use madx alignment errors # madx.ptc_setswitch(fringe=True) # include fringe effects logger . debug ( \"Executing PTC Twiss\" ) madx . ptc_twiss ( icase = 6 , no = order , normal = True , trackrdts = True ) madx . ptc_end () logger . debug ( \"Extracting results to TfsDataFrame\" ) dframe = tfs . TfsDataFrame ( madx . table . twissrdt . dframe ()) dframe . columns = dframe . columns . str . upper () dframe . NAME = dframe . NAME . str . upper () if file : logger . debug ( f \"Exporting results to disk at '{Path(file).absolute()}'\" ) tfs . write ( file , dframe ) return dframe","title":"Ptc"},{"location":"reference/pyhdtoolkit/cpymadtools/ptc/#module-pyhdtoolkitcpymadtoolsptc","text":"Module cpymadtools.ptc Created on 2020.02.03 View Source \"\"\" Module cpymadtools.ptc ---------------------- Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to harness MAD-X PTC functionality with a cpymad.madx.Madx object. \"\"\" from pathlib import Path from typing import Union import tfs from cpymad.madx import Madx from loguru import logger # ----- Utilities ----- # def get_amplitude_detuning ( madx : Madx , order : int = 2 , file : Union [ Path , str ] = None ) -> tfs . TfsDataFrame : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Calculate amplitude detuning via PTC_NORMAL. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. order (int): maximum derivative order (only 0, 1 or 2 implemented in PTC). Defaults to `2`. file (Union[Path, str]): path to output file. Default `None` Returns: A TfsDataframe with results. \"\"\" if order >= 3 : logger . error ( f \"Maximum amplitude detuning order in PTC is 2, but { order : d } was requested\" ) raise NotImplementedError ( \"PTC amplitude detuning is not implemented for order > 2\" ) logger . info ( \"Entering PTC to calculate amplitude detuning\" ) madx . ptc_create_universe () # layout I got with mask (jdilly) # model=3 (Sixtrack code model: Delta-Matrix-Kick-Matrix) # method=4 (integration order), nst=3 (integration steps), exact=True (exact Hamiltonian) logger . trace ( \"Creating PTC layout\" ) madx . ptc_create_layout ( model = 3 , method = 4 , nst = 3 , exact = True ) # alternative layout: model=3, method=6, nst=3 # resplit=True (adaptive splitting of magnets), thin=0.0005 (splitting of quads), # xbend=0.0005 (splitting of dipoles) # madx.ptc_create_layout(model=3, method=6, nst=3, resplit=True, thin=0.0005, xbend=0.0005) logger . trace ( \"Incorporating MAD-X alignment errors\" ) madx . ptc_align () # use madx alignment errors # madx.ptc_setswitch(fringe=True) # include fringe effects logger . trace ( \"Selecting tune orders\" ) madx . select_ptc_normal ( q1 = \"0\" , q2 = \"0\" ) for ii in range ( 1 , order + 1 ): # These are d^iQ/ddp^i madx . select_ptc_normal ( dq1 = f \" { ii : d } \" , dq2 = f \" { ii : d } \" ) # ANH = anharmonicities (ex, ey, deltap), works only with parameters as full strings # could be done nicer with permutations ... logger . trace ( \"Selecting anharmonicities\" ) if order >= 1 : # madx.select_ptc_normal('anhx=0, 0, 1') # dQx/ddp # madx.select_ptc_normal('anhy=0, 0, 1') # dQy/ddp madx . select_ptc_normal ( \"anhx=1, 0, 0\" ) # dQx/dex madx . select_ptc_normal ( \"anhx=0, 1, 0\" ) # dQx/dey madx . select_ptc_normal ( \"anhy=1, 0, 0\" ) # dQy/dex madx . select_ptc_normal ( \"anhy=0, 1, 0\" ) # dQy/dey if order >= 2 : # madx.select_ptc_normal('anhx=0, 0, 2') # d^2Qx/ddp^2 # madx.select_ptc_normal('anhy=0, 0, 2') # d^2Qy/ddp^2 madx . select_ptc_normal ( \"anhx=2, 0, 0\" ) # d^2Qx/dex^2 madx . select_ptc_normal ( \"anhx=1, 1, 0\" ) # d^2Qx/dexdey madx . select_ptc_normal ( \"anhx=0, 2, 0\" ) # d^2Qx/dey^2 madx . select_ptc_normal ( \"anhy=2, 0, 0\" ) # d^2Qy/dex^2 madx . select_ptc_normal ( \"anhy=1, 1, 0\" ) # d^2Qy/dexdey madx . select_ptc_normal ( \"anhy=0, 2, 0\" ) # d^2Qy/dey^2 # icase = phase-space dimensionality, no = order of map logger . debug ( \"Executing PTC Normal\" ) madx . ptc_normal ( closed_orbit = True , normal = True , icase = 5 , no = 5 ) madx . ptc_end () logger . debug ( \"Extracting results to TfsDataFrame\" ) dframe = tfs . TfsDataFrame ( madx . table . normal_results . dframe ()) dframe . columns = dframe . columns . str . upper () dframe . NAME = dframe . NAME . str . upper () dframe . index = range ( len ( dframe . NAME )) # table has a weird index if file : logger . debug ( f \"Exporting results to disk at ' { Path ( file ) . absolute () } '\" ) tfs . write ( file , dframe ) return dframe def get_rdts ( madx : Madx , order : int = 4 , file : Union [ Path , str ] = None ) -> tfs . TfsDataFrame : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Calculate the RDTs via PTC_TWISS. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. order (int): maximum derivative order (only 0, 1 or 2 implemented in PTC). Defaults to `2`. file (Union[Path, str]): path to output file. Default `None` Returns: A TfsDataframe with results. \"\"\" logger . info ( f \"Entering PTC to calculate RDTs up to order { order } \" ) madx . ptc_create_universe () logger . trace ( \"Creating PTC layout\" ) madx . ptc_create_layout ( model = 3 , method = 4 , nst = 3 , exact = True ) # madx.ptc_create_layout(model=3, method=6, nst=1) # from Michi logger . trace ( \"Incorporating MAD-X alignment errors\" ) madx . ptc_align () # use madx alignment errors # madx.ptc_setswitch(fringe=True) # include fringe effects logger . debug ( \"Executing PTC Twiss\" ) madx . ptc_twiss ( icase = 6 , no = order , normal = True , trackrdts = True ) madx . ptc_end () logger . debug ( \"Extracting results to TfsDataFrame\" ) dframe = tfs . TfsDataFrame ( madx . table . twissrdt . dframe ()) dframe . columns = dframe . columns . str . upper () dframe . NAME = dframe . NAME . str . upper () if file : logger . debug ( f \"Exporting results to disk at ' { Path ( file ) . absolute () } '\" ) tfs . write ( file , dframe ) return dframe","title":"Module pyhdtoolkit.cpymadtools.ptc"},{"location":"reference/pyhdtoolkit/cpymadtools/ptc/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/cpymadtools/ptc/#get_amplitude_detuning","text":"def get_amplitude_detuning ( madx : cpymad . madx . Madx , order : int = 2 , file : Union [ pathlib . Path , str ] = None ) -> tfs . handler . TfsDataFrame INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Calculate amplitude detuning via PTC_NORMAL. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None order int maximum derivative order (only 0, 1 or 2 implemented in PTC). Defaults to 2 . 2 file Union[Path, str] path to output file. Default None None Returns: Type Description None A TfsDataframe with results. View Source def get_amplitude_detuning ( madx : Madx , order : int = 2 , file : Union [ Path , str ] = None ) -> tfs . TfsDataFrame : \" \"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Calculate amplitude detuning via PTC_NORMAL. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. order (int): maximum derivative order (only 0, 1 or 2 implemented in PTC). Defaults to `2`. file (Union[Path, str]): path to output file. Default `None` Returns: A TfsDataframe with results. \"\" \" if order >= 3 : logger . error ( f \"Maximum amplitude detuning order in PTC is 2, but {order:d} was requested\" ) raise NotImplementedError ( \"PTC amplitude detuning is not implemented for order > 2\" ) logger . info ( \"Entering PTC to calculate amplitude detuning\" ) madx . ptc_create_universe () # layout I got with mask (jdilly) # model=3 (Sixtrack code model: Delta-Matrix-Kick-Matrix) # method=4 (integration order), nst=3 (integration steps), exact=True (exact Hamiltonian) logger . trace ( \"Creating PTC layout\" ) madx . ptc_create_layout ( model = 3 , method = 4 , nst = 3 , exact = True ) # alternative layout: model=3, method=6, nst=3 # resplit=True (adaptive splitting of magnets), thin=0.0005 (splitting of quads), # xbend=0.0005 (splitting of dipoles) # madx.ptc_create_layout(model=3, method=6, nst=3, resplit=True, thin=0.0005, xbend=0.0005) logger . trace ( \"Incorporating MAD-X alignment errors\" ) madx . ptc_align () # use madx alignment errors # madx.ptc_setswitch(fringe=True) # include fringe effects logger . trace ( \"Selecting tune orders\" ) madx . select_ptc_normal ( q1 = \"0\" , q2 = \"0\" ) for ii in range ( 1 , order + 1 ) : # These are d^iQ/ddp^i madx . select_ptc_normal ( dq1 = f \"{ii:d}\" , dq2 = f \"{ii:d}\" ) # ANH = anharmonicities (ex, ey, deltap), works only with parameters as full strings # could be done nicer with permutations ... logger . trace ( \"Selecting anharmonicities\" ) if order >= 1 : # madx.select_ptc_normal('anhx=0, 0, 1') # dQx/ddp # madx.select_ptc_normal('anhy=0, 0, 1') # dQy/ddp madx . select_ptc_normal ( \"anhx=1, 0, 0\" ) # dQx/dex madx . select_ptc_normal ( \"anhx=0, 1, 0\" ) # dQx/dey madx . select_ptc_normal ( \"anhy=1, 0, 0\" ) # dQy/dex madx . select_ptc_normal ( \"anhy=0, 1, 0\" ) # dQy/dey if order >= 2 : # madx.select_ptc_normal('anhx=0, 0, 2') # d^2Qx/ddp^2 # madx.select_ptc_normal('anhy=0, 0, 2') # d^2Qy/ddp^2 madx . select_ptc_normal ( \"anhx=2, 0, 0\" ) # d^2Qx/dex^2 madx . select_ptc_normal ( \"anhx=1, 1, 0\" ) # d^2Qx/dexdey madx . select_ptc_normal ( \"anhx=0, 2, 0\" ) # d^2Qx/dey^2 madx . select_ptc_normal ( \"anhy=2, 0, 0\" ) # d^2Qy/dex^2 madx . select_ptc_normal ( \"anhy=1, 1, 0\" ) # d^2Qy/dexdey madx . select_ptc_normal ( \"anhy=0, 2, 0\" ) # d^2Qy/dey^2 # icase = phase-space dimensionality, no = order of map logger . debug ( \"Executing PTC Normal\" ) madx . ptc_normal ( closed_orbit = True , normal = True , icase = 5 , no = 5 ) madx . ptc_end () logger . debug ( \"Extracting results to TfsDataFrame\" ) dframe = tfs . TfsDataFrame ( madx . table . normal_results . dframe ()) dframe . columns = dframe . columns . str . upper () dframe . NAME = dframe . NAME . str . upper () dframe . index = range ( len ( dframe . NAME )) # table has a weird index if file : logger . debug ( f \"Exporting results to disk at '{Path(file).absolute()}'\" ) tfs . write ( file , dframe ) return dframe","title":"get_amplitude_detuning"},{"location":"reference/pyhdtoolkit/cpymadtools/ptc/#get_rdts","text":"def get_rdts ( madx : cpymad . madx . Madx , order : int = 4 , file : Union [ pathlib . Path , str ] = None ) -> tfs . handler . TfsDataFrame INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Calculate the RDTs via PTC_TWISS. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None order int maximum derivative order (only 0, 1 or 2 implemented in PTC). Defaults to 2 . 2 file Union[Path, str] path to output file. Default None None Returns: Type Description None A TfsDataframe with results. View Source def get_rdts ( madx : Madx , order : int = 4 , file : Union [ Path , str ] = None ) -> tfs . TfsDataFrame : \" \"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Calculate the RDTs via PTC_TWISS. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. order (int): maximum derivative order (only 0, 1 or 2 implemented in PTC). Defaults to `2`. file (Union[Path, str]): path to output file. Default `None` Returns: A TfsDataframe with results. \"\" \" logger . info ( f \"Entering PTC to calculate RDTs up to order {order}\" ) madx . ptc_create_universe () logger . trace ( \"Creating PTC layout\" ) madx . ptc_create_layout ( model = 3 , method = 4 , nst = 3 , exact = True ) # madx.ptc_create_layout(model=3, method=6, nst=1) # from Michi logger . trace ( \"Incorporating MAD-X alignment errors\" ) madx . ptc_align () # use madx alignment errors # madx.ptc_setswitch(fringe=True) # include fringe effects logger . debug ( \"Executing PTC Twiss\" ) madx . ptc_twiss ( icase = 6 , no = order , normal = True , trackrdts = True ) madx . ptc_end () logger . debug ( \"Extracting results to TfsDataFrame\" ) dframe = tfs . TfsDataFrame ( madx . table . twissrdt . dframe ()) dframe . columns = dframe . columns . str . upper () dframe . NAME = dframe . NAME . str . upper () if file : logger . debug ( f \"Exporting results to disk at '{Path(file).absolute()}'\" ) tfs . write ( file , dframe ) return dframe","title":"get_rdts"},{"location":"reference/pyhdtoolkit/cpymadtools/special/","text":"Module pyhdtoolkit.cpymadtools.special Module cpymadtools.special Created on 2020.02.03 View Source \"\"\" Module cpymadtools.special -------------------------- Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to perform MAD-X actions with a cpymad.madx.Madx object, that are very specific to LHC and HLLHC use cases. \"\"\" from typing import List , Sequence , Tuple import numpy as np import tfs from cpymad.madx import Madx from loguru import logger from pyhdtoolkit.cpymadtools.constants import DEFAULT_TWISS_COLUMNS from pyhdtoolkit.cpymadtools.twiss import get_pattern_twiss # ----- Setup Utlites ----- # def make_lhc_beams ( madx : Madx , energy : float = 6500 , emittance : float = 3.75e-6 , ** kwargs ) -> None : \"\"\" Define beams with default configuratons for `LHCB1` and `LHCB2` sequences. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. energy (float): beam energy in GeV. Defaults to 6500. emittance (float): emittance in meters, which will be used to calculate geometric emittance, then fed to the BEAM command. Keyword Args: Any keyword argument that can be given to the MAD-X BEAM command. \"\"\" logger . info ( \"Making default beams for 'lhcb1' and 'lhbc2' sequences\" ) madx . globals [ \"NRJ\" ] = energy madx . globals [ \"brho\" ] = energy * 1e9 / madx . globals . clight geometric_emit = madx . globals [ \"geometric_emit\" ] = emittance / ( energy / 0.938 ) for beam in ( 1 , 2 ): logger . trace ( f \"Defining beam for sequence 'lhcb { beam : d } '\" ) madx . command . beam ( sequence = f \"lhcb { beam : d } \" , particle = \"proton\" , bv = 1 if beam == 1 else - 1 , energy = energy , npart = 1.0e10 , ex = geometric_emit , ey = geometric_emit , ** kwargs , ) def power_landau_octupoles ( madx : Madx , mo_current : float , beam : int , defective_arc : bool = False ) -> None : \"\"\" Power the Landau octupoles in the (HL)LHC. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. mo_current (float): MO powering in Amps. beam (int): beam to use. defective_arc: If set to `True`, the KOD in Arc 56 are powered for less Imax. \"\"\" try : brho = madx . globals . nrj * 1e9 / madx . globals . clight # clight is MAD-X constant except AttributeError as madx_error : logger . error ( \"The global MAD-X variable 'NRJ' should have been set in the optics files but is not defined.\" ) raise EnvironmentError ( \"No 'NRJ' variable found in scripts\" ) from madx_error logger . info ( f \"Powering Landau Octupoles, beam { beam } @ { madx . globals . nrj } GeV with { mo_current } A.\" ) strength = mo_current / madx . globals . Imax_MO * madx . globals . Kmax_MO / brho beam = 2 if beam == 4 else beam for arc in _all_lhc_arcs ( beam ): for fd in \"FD\" : octupole = f \"KO { fd } . { arc } \" logger . trace ( f \"Powering element ' { octupole } ' at { strength } Amps\" ) madx . globals [ octupole ] = strength if defective_arc and ( beam == 1 ): madx . globals [ \"KOD.A56B1\" ] = strength * 4.65 / 6 # defective MO group def deactivate_lhc_arc_sextupoles ( madx : Madx , beam : int ) -> None : \"\"\" Deactivate all arc sextupoles in the (HL)LHC. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. beam (int): beam to use. \"\"\" # KSF1 and KSD2 - Strong sextupoles of sectors 81/12/45/56 # KSF2 and KSD1 - Weak sextupoles of sectors 81/12/45/56 # Rest: Weak sextupoles in sectors 78/23/34/67 logger . info ( f \"Deactivating all arc sextupoles for beam { beam } .\" ) beam = 2 if beam == 4 else beam for arc in _all_lhc_arcs ( beam ): for fd in \"FD\" : for i in ( 1 , 2 ): sextupole = f \"KS { fd }{ i : d } . { arc } \" logger . trace ( f \"De-powering element ' { sextupole } '\" ) madx . globals [ sextupole ] = 0.0 def apply_lhc_colinearity_knob ( madx : Madx , colinearity_knob_value : float = 0 , ir : int = None ) -> None : \"\"\" Applies the LHC colinearity knob. If you don't know what this is, you should not be using this function. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. colinearity_knob_value (float): Units of the colinearity knob to apply. Defaults to 0 so users don't mess up local coupling by mistake. This should be a positive integer, normally between 1 and 10. ir (int): The Interaction Region to apply the knob to, should be one of [1, 2, 5, 8]. Classically 1 or 5. \"\"\" logger . info ( f \"Applying Colinearity knob with a unit setting of { colinearity_knob_value } \" ) logger . warning ( \"You should re-match tunes & chromaticities after this\" ) knob_variables = ( f \"KQSX3.R { ir : d } \" , f \"KQSX3.L { ir : d } \" ) # MQSX IP coupling correctors right_knob , left_knob = knob_variables madx . globals [ right_knob ] = colinearity_knob_value * 1e-4 logger . trace ( f \"Set ' { right_knob } ' to { madx . globals [ right_knob ] } \" ) madx . globals [ left_knob ] = - 1 * colinearity_knob_value * 1e-4 logger . trace ( f \"Set ' { left_knob } ' to { madx . globals [ left_knob ] } \" ) def apply_lhc_rigidity_waist_shift_knob ( madx : Madx , rigidty_waist_shift_value : float = 0 , ir : int = None , side : str = \"left\" ) -> None : \"\"\" Applies the LHC rigidity waist shift knob, moving the waist left or right of IP. If you don't know what this is, you should not be using this function. Warning: Applying the shift will modify your tunes and most likely flip them, making a subsequent matching impossible if your lattice has coupling. To avoid this, match to tunes split further apart before applying the waist shift knob, and then match to the desired working point. For instance for the LHC, match to (62.27, 60.36) before applying, and only then match to (62.31, 60.32). Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. rigidty_waist_shift_value (float): Units of the rigidity waist shift knob (positive values only). ir (int): The Interaction Region to apply the knob to, should be one of [1, 2, 5, 8]. Classically 1 or 5. side (str): Which side of the IP to move the waist to, determines a sign in the calculation. Defaults to 'left', which means s_waist < s_ip (and setting it to 'right' would move the waist to s_waist > s_ip). \"\"\" logger . info ( f \"Applying Rigidity Waist Shift knob with a unit setting of { rigidty_waist_shift_value } \" ) logger . warning ( \"You should re-match tunes & chromaticities after this\" ) knob_variables = ( f \"kqx.r { ir : d } \" , f \"kqx.l { ir : d } \" ) # Closest IP triplet right_knob , left_knob = knob_variables current_right_knob = madx . globals [ right_knob ] current_left_knob = madx . globals [ left_knob ] if side == \"left\" : madx . globals [ right_knob ] = ( 1 - rigidty_waist_shift_value * 0.005 ) * current_right_knob madx . globals [ left_knob ] = ( 1 + rigidty_waist_shift_value * 0.005 ) * current_left_knob elif side == \"right\" : madx . globals [ right_knob ] = ( 1 + rigidty_waist_shift_value * 0.005 ) * current_right_knob madx . globals [ left_knob ] = ( 1 - rigidty_waist_shift_value * 0.005 ) * current_left_knob else : logger . error ( f \"Given side ' { side } ' invalid, only 'left' and 'right' are accepted values.\" ) raise ValueError ( \"Invalid value for parameter 'side'.\" ) logger . trace ( f \"Set ' { right_knob } ' to { madx . globals [ right_knob ] } \" ) logger . trace ( f \"Set ' { left_knob } ' to { madx . globals [ left_knob ] } \" ) def apply_lhc_coupling_knob ( madx : Madx , coupling_knob : float = 0 , beam : int = 1 , telescopic_squeeze : bool = False ) -> None : \"\"\" Applies the LHC coupling knob to reach the desired C- value. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. coupling_knob (float): Desired value for the Cminus, typically a few units of 1E-3. Defaults to 0 so users don't mess up coupling by mistake beam (int): beam to apply the knob to, defaults to beam 1. telescopic_squeeze (bool): if set to True, uses the knobs for Telescopic Squeeze configuration. Defaults to False. \"\"\" logger . info ( \"Applying coupling knob\" ) logger . warning ( \"You should re-match tunes & chromaticities after this\" ) suffix = \"_sq\" if telescopic_squeeze else \"\" knob_name = f \"CMRS.b { beam : d }{ suffix } \" logger . trace ( f \"Knob ' { knob_name } ' is { madx . globals [ knob_name ] } before implementation\" ) madx . globals [ knob_name ] = coupling_knob logger . trace ( f \"Set ' { knob_name } ' to { madx . globals [ knob_name ] } \" ) def make_sixtrack_output ( madx : Madx , energy : int ) -> None : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Prepare output for sixtrack run. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. energy (float): beam energy in GeV. \"\"\" logger . info ( \"Preparing outputs for SixTrack\" ) logger . debug ( \"Powering RF cavities\" ) madx . globals [ \"VRF400\" ] = 8 if energy < 5000 else 16 # is 6 at injection for protons iirc? madx . globals [ \"LAGRF400.B1\" ] = 0.5 # cavity phase difference in units of 2pi madx . globals [ \"LAGRF400.B2\" ] = 0.0 logger . debug ( \"Executing TWISS and SIXTRACK commands\" ) madx . twiss () # used by sixtrack madx . sixtrack ( cavall = True , radius = 0.017 ) # this value is only ok for HL(LHC) magnet radius def install_ac_dipole ( madx : Madx , deltaqx : float , deltaqy : float , sigma_x : float , sigma_y : float , geometric_emit : float = None , start_turn : int = 100 , ramp_turns : int = 2000 , top_turns : int = 6600 , ) -> None : \"\"\" Installs an AC dipole for BEAM 1 ONLY. This function assumes that you have already defined lhcb1, made a beam for it (BEAM command or `make_lhc_beams` function) and matched to your desired working point. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. deltaqx (float): the deltaQx (horizontal tune excitation) used by the AC dipole. deltaqy (float): the deltaQy (vertical tune excitation) used by the AC dipole. sigma_x (float): the horizontal amplitude to drive the beam to, in bunch sigma. sigma_y (float): the vertical amplitude to drive the beam to, in bunch sigma. geometric_emit (float): the geometric emittance that was used when defining the beam. If not provided, it is assumed that 'geometric_emit' is a defined global in MAD-X, and the value will be directly queried from the internal tables. start_turn (int): the turn at which to start ramping up the AC dipole. Defaults to 100. ramp_turns (int): the number of turns to use for the ramp-up and the ramp-down of the AC dipole. This number is important in order to preserve the adiabaticity of the cycle. Defaults to 2000 as in the LHC. top_turns (int): the number of turns to drive the beam for. Defaults to 6600 as in the LHC. \"\"\" if top_turns > 6600 : logger . warning ( f \"Configuring the AC Dipole for { top_turns } of driving is fine for MAD-X but is \" \"higher than what the device can do in the (HL)LHC! Beware.\" ) ramp1 , ramp2 = start_turn , start_turn + ramp_turns ramp3 = ramp2 + top_turns ramp4 = ramp3 + ramp_turns logger . debug ( \"Retrieving tunes from internal tables\" ) q1 , q2 = madx . table . summ . q1 [ 0 ], madx . table . summ . q2 [ 0 ] logger . trace ( f \"Retrieved values are q1 = { q1 } , q2 = { q2 } \" ) q1_dipole , q2_dipole = q1 + deltaqx , q2 + deltaqy if not geometric_emit : logger . debug ( \"No value provided for the geometric emittance used when creating the beam, the value will be \" \"queried from MAD-X's global 'geometric_emit'\" ) geometric_emit = madx . globals [ \"geometric_emit\" ] logger . info ( f \"Installing AC Dipole to drive the tunes to Qx_D = { q1_dipole } | Qy_D = { q2_dipole } \" ) madx . input ( f \"MKACH.6L4.B1: hacdipole, l=0, freq:= { q1_dipole } , lag=0, volt:=voltx, ramp1= { ramp1 } , \" f \"ramp2= { ramp2 } , ramp3= { ramp3 } , ramp4= { ramp4 } ;\" ) madx . input ( f \"MKACV.6L4.B1: vacdipole, l=0, freq:= { q2_dipole } , lag=0, volt:=volty, ramp1= { ramp1 } , \" f \"ramp2= { ramp2 } , ramp3= { ramp3 } , ramp4= { ramp4 } ;\" ) madx . command . seqedit ( sequence = \"lhcb1\" ) madx . command . flatten () madx . command . install ( element = \"MKACH.6L4.B1\" , at = \"0.0\" , from_ = \"MKQA.6L4.B1\" ) madx . command . install ( element = \"MKACV.6L4.B1\" , at = \"0.0\" , from_ = \"MKQA.6L4.B1\" ) madx . command . endedit () logger . trace ( \"Querying BETX and BETY at AC Dipole location\" ) madx . input ( \"betax_acd = table(twiss, MKQA.6L4.B1, betx);\" ) madx . input ( \"betay_acd = table(twiss, MKQA.6L4.B1, bety);\" ) betax_acd = madx . globals [ \"betax_acd\" ] betay_acd = madx . globals [ \"betay_acd\" ] brho = madx . sequence . lhcb1 . beam . brho voltx = sigma_x * np . sqrt ( geometric_emit ) * brho * np . abs ( deltaqx ) * 4 * np . pi / np . sqrt ( betax_acd ) volty = sigma_y * np . sqrt ( geometric_emit ) * brho * np . abs ( deltaqy ) * 4 * np . pi / np . sqrt ( betay_acd ) madx . globals [ \"voltx\" ] = voltx madx . globals [ \"volty\" ] = volty # ----- Miscellaneous Utilities ----- # def make_lhc_thin ( madx : Madx , sequence : str , slicefactor : int = 1 , ** kwargs ) -> None : \"\"\" Makethin for the LHC sequence as previously done in MAD-X macros. This will use the `teapot` style and will enforce `makedipedge`. Args: madx (Madx): an instantiated cpymad.madx.Madx object. sequence (str): the sequence to use for the MAKETHIN command. slicefactor (int): the slice factor to apply in makethin. Defaults to 1. Keyword Args: The keyword arguments for the MAD-X MAKETHN commands, namely `style` (will default to `teapot`) and the `makedipedge` flag (will default to True). \"\"\" logger . info ( f \"Slicing sequence ' { sequence } '\" ) madx . select ( flag = \"makethin\" , clear = True ) four_slices_patterns = [ r \"mbx\\.\" , r \"mbrb\\.\" , r \"mbrc\\.\" , r \"mbrs\\.\" ] four_slicefactor_patterns = [ r \"mqwa\\.\" , r \"mqwb\\.\" , r \"mqy\\.\" , r \"mqm\\.\" , r \"mqmc\\.\" , r \"mqml\\.\" , r \"mqtlh\\.\" , r \"mqtli\\.\" , r \"mqt\\.\" , ] logger . trace ( \"Defining slices for general MB and MQ elements\" ) madx . select ( flag = \"makethin\" , class_ = \"MB\" , slice = 2 ) madx . select ( flag = \"makethin\" , class_ = \"MQ\" , slice = 2 * slicefactor ) logger . trace ( \"Defining slices for triplets\" ) madx . select ( flag = \"makethin\" , class_ = \"mqxa\" , slice = 16 * slicefactor ) madx . select ( flag = \"makethin\" , class_ = \"mqxb\" , slice = 16 * slicefactor ) logger . trace ( \"Defining slices for various specifc mb elements\" ) for pattern in four_slices_patterns : madx . select ( flag = \"makethin\" , pattern = pattern , slice = 4 ) logger . trace ( \"Defining slices for varous specifc mq elements\" ) for pattern in four_slicefactor_patterns : madx . select ( flag = \"makethin\" , pattern = pattern , slice = 4 * slicefactor ) madx . use ( sequence = sequence ) style = kwargs . get ( \"style\" , \"teapot\" ) makedipedge = kwargs . get ( \"makedipedge\" , True ) madx . command . makethin ( sequence = sequence , style = style , makedipedge = makedipedge ) def re_cycle_sequence ( madx : Madx , sequence : str = \"lhcb1\" , start : str = \"IP3\" ) -> None : \"\"\" Re-cycle the provided sequence from a different starting point. Args: madx (Madx): an instantiated cpymad.madx.Madx object. sequence (str): the sequence to re cycle. start (str): element to start the new cycle from. \"\"\" logger . debug ( f \"Re-cycling sequence ' { sequence } ' from { start } \" ) madx . command . seqedit ( sequence = sequence ) madx . command . flatten () madx . command . cycle ( start = start ) madx . command . endedit () # ----- Twiss Utilities ----- # def get_ips_twiss ( madx : Madx , columns : Sequence [ str ] = DEFAULT_TWISS_COLUMNS , ** kwargs ) -> tfs . TfsDataFrame : \"\"\" Quickly get the `TWISS` table for certain variables at IP locations only. The `SUMM` table will be included as the TfsDataFrame's header dictionary. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as `chrom`, `ripken`, `centre` or starting coordinates with `betax`, 'betay` etc. Returns: A TfsDataFrame of the twiss output. \"\"\" logger . info ( \"Getting Twiss at IPs\" ) return get_pattern_twiss ( madx = madx , patterns = [ \"IP\" ], columns = columns , ** kwargs ) def get_ir_twiss ( madx : Madx , ir : int , columns : Sequence [ str ] = DEFAULT_TWISS_COLUMNS , ** kwargs ) -> tfs . TfsDataFrame : \"\"\" Quickly get the `TWISS` table for certain variables for one IR, meaning at the IP and Q1 to Q3 both left and right of the IP. The `SUMM` table will be included as the TfsDataFrame's header dictionary. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. ir (int): which interaction region to get the TWISS for. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as `chrom`, `ripken`, `centre` or starting coordinates with `betax`, 'betay` etc. Returns: A TfsDataFrame of the twiss output. \"\"\" logger . info ( f \"Getting Twiss for IR { ir : d } \" ) return get_pattern_twiss ( madx = madx , patterns = [ f \"IP { ir : d } \" , f \"MQXA.[12345][RL] { ir : d } \" , f \"MQXB.[AB][12345][RL] { ir : d } \" , f \"MQXF[AB].[AB][12345][RL] { ir : d } \" , # this is for HLLHC ], columns = columns , ** kwargs , ) # ----- Helpers ----- # def _all_lhc_arcs ( beam : int ) -> List [ str ]: \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Names of all LHC arcs for a given beam. Args: beam (int): beam to get names for. Returns: The list of names. \"\"\" return [ f \"A { i + 1 }{ ( i + 1 ) % 8 + 1 } B { beam : d } \" for i in range ( 8 )] def _get_k_strings ( start : int = 0 , stop : int = 8 , orientation : str = \"both\" ) -> List [ str ]: \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Returns the list of K-strings for various magnets and orders (K1L, K2SL etc strings). Args: start (int): the starting order, defaults to 0. stop (int): the order to go up to, defaults to 8. orientation (str): magnet orientation, can be 'straight', 'skew' or 'both'. Defaults to 'both'. Returns: The list of names as strings. \"\"\" if orientation not in ( \"straight\" , \"skew\" , \"both\" ,): logger . error ( f \"Orientation ' { orientation } ' is not accepted, should be one of 'straight', 'skew', 'both'.\" ) raise ValueError ( \"Invalid 'orientation' parameter\" ) if orientation == \"straight\" : orientation = ( \"\" ,) elif orientation == \"skew\" : orientation = ( \"S\" ,) else : # both orientation = ( \"\" , \"S\" ) return [ f \"K { i : d }{ s : s } L\" for i in range ( start , stop ) for s in orientation ] Variables DEFAULT_TWISS_COLUMNS Functions apply_lhc_colinearity_knob def apply_lhc_colinearity_knob ( madx : cpymad . madx . Madx , colinearity_knob_value : float = 0 , ir : int = None ) -> None Applies the LHC colinearity knob. If you don't know what this is, you should not be using this function. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None colinearity_knob_value float Units of the colinearity knob to apply. Defaults to 0 so users don't mess up local coupling by mistake. This should be a positive integer, normally between 1 and 10. None ir int The Interaction Region to apply the knob to, should be one of [1, 2, 5, 8]. Classically 1 or 5. None View Source def apply_lhc_colinearity_knob ( madx : Madx , colinearity_knob_value : float = 0 , ir : int = None ) -> None : \"\"\" Applies the LHC colinearity knob. If you don't know what this is, you should not be using this function. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. colinearity_knob_value (float): Units of the colinearity knob to apply. Defaults to 0 so users don't mess up local coupling by mistake. This should be a positive integer, normally between 1 and 10. ir (int): The Interaction Region to apply the knob to, should be one of [1, 2, 5, 8]. Classically 1 or 5. \"\"\" logger . info ( f \"Applying Colinearity knob with a unit setting of {colinearity_knob_value}\" ) logger . warning ( \"You should re-match tunes & chromaticities after this\" ) knob_variables = ( f \"KQSX3.R{ir:d}\" , f \"KQSX3.L{ir:d}\" ) # MQSX IP coupling correctors right_knob , left_knob = knob_variables madx . globals [ right_knob ] = colinearity_knob_value * 1e-4 logger . trace ( f \"Set '{right_knob}' to {madx.globals[right_knob]}\" ) madx . globals [ left_knob ] = - 1 * colinearity_knob_value * 1e-4 logger . trace ( f \"Set '{left_knob}' to {madx.globals[left_knob]}\" ) apply_lhc_coupling_knob def apply_lhc_coupling_knob ( madx : cpymad . madx . Madx , coupling_knob : float = 0 , beam : int = 1 , telescopic_squeeze : bool = False ) -> None Applies the LHC coupling knob to reach the desired C- value. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. coupling_knob (float): Desired value for the Cminus, typically a few units of 1E-3. Defaults to 0 so users don't mess up coupling by mistake beam (int): beam to apply the knob to, defaults to beam 1. telescopic_squeeze (bool): if set to True, uses the knobs for Telescopic Squeeze configuration. Defaults to False. View Source def apply_lhc_coupling_knob ( madx : Madx , coupling_knob : float = 0 , beam : int = 1 , telescopic_squeeze : bool = False ) -> None : \"\"\" Applies the LHC coupling knob to reach the desired C- value. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. coupling_knob (float): Desired value for the Cminus, typically a few units of 1E-3. Defaults to 0 so users don't mess up coupling by mistake beam (int): beam to apply the knob to, defaults to beam 1. telescopic_squeeze (bool): if set to True, uses the knobs for Telescopic Squeeze configuration. Defaults to False. \"\"\" logger . info ( \"Applying coupling knob\" ) logger . warning ( \"You should re-match tunes & chromaticities after this\" ) suffix = \"_sq\" if telescopic_squeeze else \"\" knob_name = f \"CMRS.b{beam:d}{suffix}\" logger . trace ( f \"Knob '{knob_name}' is {madx.globals[knob_name]} before implementation\" ) madx . globals [ knob_name ] = coupling_knob logger . trace ( f \"Set '{knob_name}' to {madx.globals[knob_name]}\" ) apply_lhc_rigidity_waist_shift_knob def apply_lhc_rigidity_waist_shift_knob ( madx : cpymad . madx . Madx , rigidty_waist_shift_value : float = 0 , ir : int = None , side : str = 'left' ) -> None Applies the LHC rigidity waist shift knob, moving the waist left or right of IP. If you don't know what this is, you should not be using this function. Warning: Applying the shift will modify your tunes and most likely flip them, making a subsequent matching impossible if your lattice has coupling. To avoid this, match to tunes split further apart before applying the waist shift knob, and then match to the desired working point. For instance for the LHC, match to (62.27, 60.36) before applying, and only then match to (62.31, 60.32). Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None rigidty_waist_shift_value float Units of the rigidity waist shift knob (positive values only). None ir int The Interaction Region to apply the knob to, should be one of [1, 2, 5, 8]. Classically 1 or 5. None side str Which side of the IP to move the waist to, determines a sign in the calculation. Defaults to 'left', which means s_waist < s_ip (and setting it to 'right' would move the waist to s_waist > s_ip). None View Source def apply_lhc_rigidity_waist_shift_knob ( madx : Madx , rigidty_waist_shift_value : float = 0 , ir : int = None , side : str = \"left\" ) -> None : \"\"\" Applies the LHC rigidity waist shift knob, moving the waist left or right of IP. If you don't know what this is, you should not be using this function. Warning: Applying the shift will modify your tunes and most likely flip them, making a subsequent matching impossible if your lattice has coupling. To avoid this, match to tunes split further apart before applying the waist shift knob, and then match to the desired working point. For instance for the LHC, match to (62.27, 60.36) before applying, and only then match to (62.31, 60.32). Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. rigidty_waist_shift_value (float): Units of the rigidity waist shift knob (positive values only). ir (int): The Interaction Region to apply the knob to, should be one of [1, 2, 5, 8]. Classically 1 or 5. side (str): Which side of the IP to move the waist to, determines a sign in the calculation. Defaults to 'left', which means s_waist < s_ip (and setting it to 'right' would move the waist to s_waist > s_ip). \"\"\" logger . info ( f \"Applying Rigidity Waist Shift knob with a unit setting of {rigidty_waist_shift_value}\" ) logger . warning ( \"You should re-match tunes & chromaticities after this\" ) knob_variables = ( f \"kqx.r{ir:d}\" , f \"kqx.l{ir:d}\" ) # Closest IP triplet right_knob , left_knob = knob_variables current_right_knob = madx . globals [ right_knob ] current_left_knob = madx . globals [ left_knob ] if side == \"left\" : madx . globals [ right_knob ] = ( 1 - rigidty_waist_shift_value * 0.005 ) * current_right_knob madx . globals [ left_knob ] = ( 1 + rigidty_waist_shift_value * 0.005 ) * current_left_knob elif side == \"right\" : madx . globals [ right_knob ] = ( 1 + rigidty_waist_shift_value * 0.005 ) * current_right_knob madx . globals [ left_knob ] = ( 1 - rigidty_waist_shift_value * 0.005 ) * current_left_knob else : logger . error ( f \"Given side '{side}' invalid, only 'left' and 'right' are accepted values.\" ) raise ValueError ( \"Invalid value for parameter 'side'.\" ) logger . trace ( f \"Set '{right_knob}' to {madx.globals[right_knob]}\" ) logger . trace ( f \"Set '{left_knob}' to {madx.globals[left_knob]}\" ) deactivate_lhc_arc_sextupoles def deactivate_lhc_arc_sextupoles ( madx : cpymad . madx . Madx , beam : int ) -> None Deactivate all arc sextupoles in the (HL)LHC. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None beam int beam to use. None View Source def deactivate_lhc_arc_sextupoles ( madx : Madx , beam : int ) -> None : \"\"\" Deactivate all arc sextupoles in the (HL)LHC. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. beam (int): beam to use. \"\"\" # KSF1 and KSD2 - Strong sextupoles of sectors 81 / 12 / 45 / 56 # KSF2 and KSD1 - Weak sextupoles of sectors 81 / 12 / 45 / 56 # Rest : Weak sextupoles in sectors 78 / 23 / 34 / 67 logger . info ( f \"Deactivating all arc sextupoles for beam {beam}.\" ) beam = 2 if beam == 4 else beam for arc in _all_lhc_arcs ( beam ) : for fd in \"FD\" : for i in ( 1 , 2 ) : sextupole = f \"KS{fd}{i:d}.{arc}\" logger . trace ( f \"De-powering element '{sextupole}'\" ) madx . globals [ sextupole ] = 0.0 get_ips_twiss def get_ips_twiss ( madx : cpymad . madx . Madx , columns : Sequence [ str ] = [ 'name' , 's' , 'x' , 'y' , 'px' , 'py' , 'betx' , 'bety' , 'alfx' , 'alfy' , 'dx' , 'dy' , 'mux' , 'muy' , 'r11' , 'r12' , 'r21' , 'r22' , 'beta11' , 'beta12' , 'beta21' , 'beta22' ], ** kwargs ) -> tfs . handler . TfsDataFrame Quickly get the TWISS table for certain variables at IP locations only. The SUMM table will be included as the TfsDataFrame's header dictionary. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as chrom , ripken , centre or starting coordinates with betax , 'betay` etc. Returns: A TfsDataFrame of the twiss output. View Source def get_ips_twiss ( madx : Madx , columns : Sequence [ str ] = DEFAULT_TWISS_COLUMNS , ** kwargs ) -> tfs . TfsDataFrame : \" \"\" Quickly get the `TWISS` table for certain variables at IP locations only. The `SUMM` table will be included as the TfsDataFrame's header dictionary. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as `chrom`, `ripken`, `centre` or starting coordinates with `betax`, 'betay` etc. Returns: A TfsDataFrame of the twiss output. \"\" \" logger . info ( \"Getting Twiss at IPs\" ) return get_pattern_twiss ( madx = madx , patterns = [ \"IP\" ] , columns = columns , ** kwargs ) get_ir_twiss def get_ir_twiss ( madx : cpymad . madx . Madx , ir : int , columns : Sequence [ str ] = [ 'name' , 's' , 'x' , 'y' , 'px' , 'py' , 'betx' , 'bety' , 'alfx' , 'alfy' , 'dx' , 'dy' , 'mux' , 'muy' , 'r11' , 'r12' , 'r21' , 'r22' , 'beta11' , 'beta12' , 'beta21' , 'beta22' ], ** kwargs ) -> tfs . handler . TfsDataFrame Quickly get the TWISS table for certain variables for one IR, meaning at the IP and Q1 to Q3 both left and right of the IP. The SUMM table will be included as the TfsDataFrame's header dictionary. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. ir (int): which interaction region to get the TWISS for. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as chrom , ripken , centre or starting coordinates with betax , 'betay` etc. Returns: A TfsDataFrame of the twiss output. View Source def get_ir_twiss ( madx : Madx , ir : int , columns : Sequence [ str ] = DEFAULT_TWISS_COLUMNS , ** kwargs ) -> tfs . TfsDataFrame : \"\"\" Quickly get the `TWISS` table for certain variables for one IR, meaning at the IP and Q1 to Q3 both left and right of the IP. The `SUMM` table will be included as the TfsDataFrame's header dictionary. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. ir (int): which interaction region to get the TWISS for. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as `chrom`, `ripken`, `centre` or starting coordinates with `betax`, 'betay` etc. Returns: A TfsDataFrame of the twiss output. \"\"\" logger . info ( f \"Getting Twiss for IR {ir:d}\" ) return get_pattern_twiss ( madx = madx , patterns = [ f \"IP{ir:d}\" , f \"MQXA.[12345][RL]{ir:d}\" , f \"MQXB.[AB][12345][RL]{ir:d}\" , f \"MQXF[AB].[AB][12345][RL]{ir:d}\" , # this is for HLLHC ], columns = columns , ** kwargs , ) install_ac_dipole def install_ac_dipole ( madx : cpymad . madx . Madx , deltaqx : float , deltaqy : float , sigma_x : float , sigma_y : float , geometric_emit : float = None , start_turn : int = 100 , ramp_turns : int = 2000 , top_turns : int = 6600 ) -> None Installs an AC dipole for BEAM 1 ONLY. This function assumes that you have already defined lhcb1, made a beam for it (BEAM command or make_lhc_beams function) and matched to your desired working point. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None deltaqx float the deltaQx (horizontal tune excitation) used by the AC dipole. None deltaqy float the deltaQy (vertical tune excitation) used by the AC dipole. None sigma_x float the horizontal amplitude to drive the beam to, in bunch sigma. None sigma_y float the vertical amplitude to drive the beam to, in bunch sigma. None geometric_emit float the geometric emittance that was used when defining the beam. If not provided, it is assumed that 'geometric_emit' is a defined global in MAD-X, and the value will be directly queried from the internal tables. None start_turn int the turn at which to start ramping up the AC dipole. Defaults to 100. 100 ramp_turns int the number of turns to use for the ramp-up and the ramp-down of the AC dipole. This number is important in order to preserve the adiabaticity of the cycle. Defaults to 2000 as in the LHC. None top_turns int the number of turns to drive the beam for. Defaults to 6600 as in the LHC. 6600 as in the LHC View Source def install_ac_dipole ( madx : Madx , deltaqx : float , deltaqy : float , sigma_x : float , sigma_y : float , geometric_emit : float = None , start_turn : int = 100 , ramp_turns : int = 2000 , top_turns : int = 6600 , ) -> None : \" \"\" Installs an AC dipole for BEAM 1 ONLY. This function assumes that you have already defined lhcb1, made a beam for it (BEAM command or `make_lhc_beams` function) and matched to your desired working point. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. deltaqx (float): the deltaQx (horizontal tune excitation) used by the AC dipole. deltaqy (float): the deltaQy (vertical tune excitation) used by the AC dipole. sigma_x (float): the horizontal amplitude to drive the beam to, in bunch sigma. sigma_y (float): the vertical amplitude to drive the beam to, in bunch sigma. geometric_emit (float): the geometric emittance that was used when defining the beam. If not provided, it is assumed that 'geometric_emit' is a defined global in MAD-X, and the value will be directly queried from the internal tables. start_turn (int): the turn at which to start ramping up the AC dipole. Defaults to 100. ramp_turns (int): the number of turns to use for the ramp-up and the ramp-down of the AC dipole. This number is important in order to preserve the adiabaticity of the cycle. Defaults to 2000 as in the LHC. top_turns (int): the number of turns to drive the beam for. Defaults to 6600 as in the LHC. \"\" \" if top_turns > 6600 : logger . warning ( f \"Configuring the AC Dipole for {top_turns} of driving is fine for MAD-X but is \" \"higher than what the device can do in the (HL)LHC! Beware.\" ) ramp1 , ramp2 = start_turn , start_turn + ramp_turns ramp3 = ramp2 + top_turns ramp4 = ramp3 + ramp_turns logger . debug ( \"Retrieving tunes from internal tables\" ) q1 , q2 = madx . table . summ . q1 [ 0 ] , madx . table . summ . q2 [ 0 ] logger . trace ( f \"Retrieved values are q1 = {q1}, q2 = {q2}\" ) q1_dipole , q2_dipole = q1 + deltaqx , q2 + deltaqy if not geometric_emit : logger . debug ( \"No value provided for the geometric emittance used when creating the beam, the value will be \" \"queried from MAD-X's global 'geometric_emit'\" ) geometric_emit = madx . globals [ \"geometric_emit\" ] logger . info ( f \"Installing AC Dipole to drive the tunes to Qx_D = {q1_dipole} | Qy_D = {q2_dipole}\" ) madx . input ( f \"MKACH.6L4.B1: hacdipole, l=0, freq:={q1_dipole}, lag=0, volt:=voltx, ramp1={ramp1}, \" f \"ramp2={ramp2}, ramp3={ramp3}, ramp4={ramp4};\" ) madx . input ( f \"MKACV.6L4.B1: vacdipole, l=0, freq:={q2_dipole}, lag=0, volt:=volty, ramp1={ramp1}, \" f \"ramp2={ramp2}, ramp3={ramp3}, ramp4={ramp4};\" ) madx . command . seqedit ( sequence = \"lhcb1\" ) madx . command . flatten () madx . command . install ( element = \"MKACH.6L4.B1\" , at = \"0.0\" , from_ = \"MKQA.6L4.B1\" ) madx . command . install ( element = \"MKACV.6L4.B1\" , at = \"0.0\" , from_ = \"MKQA.6L4.B1\" ) madx . command . endedit () logger . trace ( \"Querying BETX and BETY at AC Dipole location\" ) madx . input ( \"betax_acd = table(twiss, MKQA.6L4.B1, betx);\" ) madx . input ( \"betay_acd = table(twiss, MKQA.6L4.B1, bety);\" ) betax_acd = madx . globals [ \"betax_acd\" ] betay_acd = madx . globals [ \"betay_acd\" ] brho = madx . sequence . lhcb1 . beam . brho voltx = sigma_x * np . sqrt ( geometric_emit ) * brho * np . abs ( deltaqx ) * 4 * np . pi / np . sqrt ( betax_acd ) volty = sigma_y * np . sqrt ( geometric_emit ) * brho * np . abs ( deltaqy ) * 4 * np . pi / np . sqrt ( betay_acd ) madx . globals [ \"voltx\" ] = voltx madx . globals [ \"volty\" ] = volty make_lhc_beams def make_lhc_beams ( madx : cpymad . madx . Madx , energy : float = 6500 , emittance : float = 3.75e-06 , ** kwargs ) -> None Define beams with default configuratons for LHCB1 and LHCB2 sequences. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. energy (float): beam energy in GeV. Defaults to 6500. emittance (float): emittance in meters, which will be used to calculate geometric emittance, then fed to the BEAM command. Keyword Args: Any keyword argument that can be given to the MAD-X BEAM command. View Source def make_lhc_beams ( madx : Madx , energy : float = 6500 , emittance : float = 3.75e-6 , ** kwargs ) -> None : \" \"\" Define beams with default configuratons for `LHCB1` and `LHCB2` sequences. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. energy (float): beam energy in GeV. Defaults to 6500. emittance (float): emittance in meters, which will be used to calculate geometric emittance, then fed to the BEAM command. Keyword Args: Any keyword argument that can be given to the MAD-X BEAM command. \"\" \" logger . info ( \"Making default beams for 'lhcb1' and 'lhbc2' sequences\" ) madx . globals [ \"NRJ\" ] = energy madx . globals [ \"brho\" ] = energy * 1e9 / madx . globals . clight geometric_emit = madx . globals [ \"geometric_emit\" ] = emittance / ( energy / 0.938 ) for beam in ( 1 , 2 ) : logger . trace ( f \"Defining beam for sequence 'lhcb{beam:d}'\" ) madx . command . beam ( sequence = f \"lhcb{beam:d}\" , particle = \"proton\" , bv = 1 if beam == 1 else - 1 , energy = energy , npart = 1.0e10 , ex = geometric_emit , ey = geometric_emit , ** kwargs , ) make_lhc_thin def make_lhc_thin ( madx : cpymad . madx . Madx , sequence : str , slicefactor : int = 1 , ** kwargs ) -> None Makethin for the LHC sequence as previously done in MAD-X macros. This will use the teapot style and will enforce makedipedge . Args: madx (Madx): an instantiated cpymad.madx.Madx object. sequence (str): the sequence to use for the MAKETHIN command. slicefactor (int): the slice factor to apply in makethin. Defaults to 1. Keyword Args: The keyword arguments for the MAD-X MAKETHN commands, namely style (will default to teapot ) and the makedipedge flag (will default to True). View Source def make_lhc_thin ( madx : Madx , sequence : str , slicefactor : int = 1 , ** kwargs ) -> None : \" \"\" Makethin for the LHC sequence as previously done in MAD-X macros. This will use the `teapot` style and will enforce `makedipedge`. Args: madx (Madx): an instantiated cpymad.madx.Madx object. sequence (str): the sequence to use for the MAKETHIN command. slicefactor (int): the slice factor to apply in makethin. Defaults to 1. Keyword Args: The keyword arguments for the MAD-X MAKETHN commands, namely `style` (will default to `teapot`) and the `makedipedge` flag (will default to True). \"\" \" logger . info ( f \"Slicing sequence '{sequence}'\" ) madx . select ( flag = \"makethin\" , clear = True ) four_slices_patterns = [ r \"mbx \\ .\" , r \"mbrb \\ .\" , r \"mbrc \\ .\" , r \"mbrs \\ .\" ] four_slicefactor_patterns = [ r \"mqwa \\ .\" , r \"mqwb \\ .\" , r \"mqy \\ .\" , r \"mqm \\ .\" , r \"mqmc \\ .\" , r \"mqml \\ .\" , r \"mqtlh \\ .\" , r \"mqtli \\ .\" , r \"mqt \\ .\" , ] logger . trace ( \"Defining slices for general MB and MQ elements\" ) madx . select ( flag = \"makethin\" , class_ = \"MB\" , slice = 2 ) madx . select ( flag = \"makethin\" , class_ = \"MQ\" , slice = 2 * slicefactor ) logger . trace ( \"Defining slices for triplets\" ) madx . select ( flag = \"makethin\" , class_ = \"mqxa\" , slice = 16 * slicefactor ) madx . select ( flag = \"makethin\" , class_ = \"mqxb\" , slice = 16 * slicefactor ) logger . trace ( \"Defining slices for various specifc mb elements\" ) for pattern in four_slices_patterns : madx . select ( flag = \"makethin\" , pattern = pattern , slice = 4 ) logger . trace ( \"Defining slices for varous specifc mq elements\" ) for pattern in four_slicefactor_patterns : madx . select ( flag = \"makethin\" , pattern = pattern , slice = 4 * slicefactor ) madx . use ( sequence = sequence ) style = kwargs . get ( \"style\" , \"teapot\" ) makedipedge = kwargs . get ( \"makedipedge\" , True ) madx . command . makethin ( sequence = sequence , style = style , makedipedge = makedipedge ) make_sixtrack_output def make_sixtrack_output ( madx : cpymad . madx . Madx , energy : int ) -> None INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Prepare output for sixtrack run. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None energy float beam energy in GeV. None View Source def make_sixtrack_output ( madx : Madx , energy : int ) -> None : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Prepare output for sixtrack run. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. energy (float): beam energy in GeV. \"\"\" logger . info ( \"Preparing outputs for SixTrack\" ) logger . debug ( \"Powering RF cavities\" ) madx . globals [ \"VRF400\" ] = 8 if energy < 5000 else 16 # is 6 at injection for protons iirc ? madx . globals [ \"LAGRF400.B1\" ] = 0.5 # cavity phase difference in units of 2 pi madx . globals [ \"LAGRF400.B2\" ] = 0.0 logger . debug ( \"Executing TWISS and SIXTRACK commands\" ) madx . twiss () # used by sixtrack madx . sixtrack ( cavall = True , radius = 0.017 ) # this value is only ok for HL ( LHC ) magnet radius power_landau_octupoles def power_landau_octupoles ( madx : cpymad . madx . Madx , mo_current : float , beam : int , defective_arc : bool = False ) -> None Power the Landau octupoles in the (HL)LHC. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None mo_current float MO powering in Amps. None beam int beam to use. None defective_arc None If set to True , the KOD in Arc 56 are powered for less Imax. None View Source def power_landau_octupoles ( madx : Madx , mo_current : float , beam : int , defective_arc : bool = False ) -> None : \"\"\" Power the Landau octupoles in the (HL)LHC. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. mo_current (float): MO powering in Amps. beam (int): beam to use. defective_arc: If set to `True`, the KOD in Arc 56 are powered for less Imax. \"\"\" try : brho = madx . globals . nrj * 1e9 / madx . globals . clight # clight is MAD-X constant except AttributeError as madx_error : logger . error ( \"The global MAD-X variable 'NRJ' should have been set in the optics files but is not defined.\" ) raise EnvironmentError ( \"No 'NRJ' variable found in scripts\" ) from madx_error logger . info ( f \"Powering Landau Octupoles, beam {beam} @ {madx.globals.nrj} GeV with {mo_current} A.\" ) strength = mo_current / madx . globals . Imax_MO * madx . globals . Kmax_MO / brho beam = 2 if beam == 4 else beam for arc in _all_lhc_arcs ( beam ): for fd in \"FD\" : octupole = f \"KO{fd}.{arc}\" logger . trace ( f \"Powering element '{octupole}' at {strength} Amps\" ) madx . globals [ octupole ] = strength if defective_arc and ( beam == 1 ): madx . globals [ \"KOD.A56B1\" ] = strength * 4.65 / 6 # defective MO group re_cycle_sequence def re_cycle_sequence ( madx : cpymad . madx . Madx , sequence : str = 'lhcb1' , start : str = 'IP3' ) -> None Re-cycle the provided sequence from a different starting point. Parameters: Name Type Description Default madx Madx an instantiated cpymad.madx.Madx object. None sequence str the sequence to re cycle. None start str element to start the new cycle from. None View Source def re_cycle_sequence ( madx : Madx , sequence : str = \"lhcb1\" , start : str = \"IP3\" ) -> None : \"\"\" Re-cycle the provided sequence from a different starting point. Args: madx (Madx): an instantiated cpymad.madx.Madx object. sequence (str): the sequence to re cycle. start (str): element to start the new cycle from. \"\"\" logger . debug ( f \"Re-cycling sequence ' { sequence } ' from {start}\" ) madx . command . seqedit ( sequence = sequence ) madx . command . flatten () madx . command . cycle ( start = start ) madx . command . ende dit ()","title":"Special"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#module-pyhdtoolkitcpymadtoolsspecial","text":"Module cpymadtools.special Created on 2020.02.03 View Source \"\"\" Module cpymadtools.special -------------------------- Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to perform MAD-X actions with a cpymad.madx.Madx object, that are very specific to LHC and HLLHC use cases. \"\"\" from typing import List , Sequence , Tuple import numpy as np import tfs from cpymad.madx import Madx from loguru import logger from pyhdtoolkit.cpymadtools.constants import DEFAULT_TWISS_COLUMNS from pyhdtoolkit.cpymadtools.twiss import get_pattern_twiss # ----- Setup Utlites ----- # def make_lhc_beams ( madx : Madx , energy : float = 6500 , emittance : float = 3.75e-6 , ** kwargs ) -> None : \"\"\" Define beams with default configuratons for `LHCB1` and `LHCB2` sequences. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. energy (float): beam energy in GeV. Defaults to 6500. emittance (float): emittance in meters, which will be used to calculate geometric emittance, then fed to the BEAM command. Keyword Args: Any keyword argument that can be given to the MAD-X BEAM command. \"\"\" logger . info ( \"Making default beams for 'lhcb1' and 'lhbc2' sequences\" ) madx . globals [ \"NRJ\" ] = energy madx . globals [ \"brho\" ] = energy * 1e9 / madx . globals . clight geometric_emit = madx . globals [ \"geometric_emit\" ] = emittance / ( energy / 0.938 ) for beam in ( 1 , 2 ): logger . trace ( f \"Defining beam for sequence 'lhcb { beam : d } '\" ) madx . command . beam ( sequence = f \"lhcb { beam : d } \" , particle = \"proton\" , bv = 1 if beam == 1 else - 1 , energy = energy , npart = 1.0e10 , ex = geometric_emit , ey = geometric_emit , ** kwargs , ) def power_landau_octupoles ( madx : Madx , mo_current : float , beam : int , defective_arc : bool = False ) -> None : \"\"\" Power the Landau octupoles in the (HL)LHC. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. mo_current (float): MO powering in Amps. beam (int): beam to use. defective_arc: If set to `True`, the KOD in Arc 56 are powered for less Imax. \"\"\" try : brho = madx . globals . nrj * 1e9 / madx . globals . clight # clight is MAD-X constant except AttributeError as madx_error : logger . error ( \"The global MAD-X variable 'NRJ' should have been set in the optics files but is not defined.\" ) raise EnvironmentError ( \"No 'NRJ' variable found in scripts\" ) from madx_error logger . info ( f \"Powering Landau Octupoles, beam { beam } @ { madx . globals . nrj } GeV with { mo_current } A.\" ) strength = mo_current / madx . globals . Imax_MO * madx . globals . Kmax_MO / brho beam = 2 if beam == 4 else beam for arc in _all_lhc_arcs ( beam ): for fd in \"FD\" : octupole = f \"KO { fd } . { arc } \" logger . trace ( f \"Powering element ' { octupole } ' at { strength } Amps\" ) madx . globals [ octupole ] = strength if defective_arc and ( beam == 1 ): madx . globals [ \"KOD.A56B1\" ] = strength * 4.65 / 6 # defective MO group def deactivate_lhc_arc_sextupoles ( madx : Madx , beam : int ) -> None : \"\"\" Deactivate all arc sextupoles in the (HL)LHC. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. beam (int): beam to use. \"\"\" # KSF1 and KSD2 - Strong sextupoles of sectors 81/12/45/56 # KSF2 and KSD1 - Weak sextupoles of sectors 81/12/45/56 # Rest: Weak sextupoles in sectors 78/23/34/67 logger . info ( f \"Deactivating all arc sextupoles for beam { beam } .\" ) beam = 2 if beam == 4 else beam for arc in _all_lhc_arcs ( beam ): for fd in \"FD\" : for i in ( 1 , 2 ): sextupole = f \"KS { fd }{ i : d } . { arc } \" logger . trace ( f \"De-powering element ' { sextupole } '\" ) madx . globals [ sextupole ] = 0.0 def apply_lhc_colinearity_knob ( madx : Madx , colinearity_knob_value : float = 0 , ir : int = None ) -> None : \"\"\" Applies the LHC colinearity knob. If you don't know what this is, you should not be using this function. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. colinearity_knob_value (float): Units of the colinearity knob to apply. Defaults to 0 so users don't mess up local coupling by mistake. This should be a positive integer, normally between 1 and 10. ir (int): The Interaction Region to apply the knob to, should be one of [1, 2, 5, 8]. Classically 1 or 5. \"\"\" logger . info ( f \"Applying Colinearity knob with a unit setting of { colinearity_knob_value } \" ) logger . warning ( \"You should re-match tunes & chromaticities after this\" ) knob_variables = ( f \"KQSX3.R { ir : d } \" , f \"KQSX3.L { ir : d } \" ) # MQSX IP coupling correctors right_knob , left_knob = knob_variables madx . globals [ right_knob ] = colinearity_knob_value * 1e-4 logger . trace ( f \"Set ' { right_knob } ' to { madx . globals [ right_knob ] } \" ) madx . globals [ left_knob ] = - 1 * colinearity_knob_value * 1e-4 logger . trace ( f \"Set ' { left_knob } ' to { madx . globals [ left_knob ] } \" ) def apply_lhc_rigidity_waist_shift_knob ( madx : Madx , rigidty_waist_shift_value : float = 0 , ir : int = None , side : str = \"left\" ) -> None : \"\"\" Applies the LHC rigidity waist shift knob, moving the waist left or right of IP. If you don't know what this is, you should not be using this function. Warning: Applying the shift will modify your tunes and most likely flip them, making a subsequent matching impossible if your lattice has coupling. To avoid this, match to tunes split further apart before applying the waist shift knob, and then match to the desired working point. For instance for the LHC, match to (62.27, 60.36) before applying, and only then match to (62.31, 60.32). Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. rigidty_waist_shift_value (float): Units of the rigidity waist shift knob (positive values only). ir (int): The Interaction Region to apply the knob to, should be one of [1, 2, 5, 8]. Classically 1 or 5. side (str): Which side of the IP to move the waist to, determines a sign in the calculation. Defaults to 'left', which means s_waist < s_ip (and setting it to 'right' would move the waist to s_waist > s_ip). \"\"\" logger . info ( f \"Applying Rigidity Waist Shift knob with a unit setting of { rigidty_waist_shift_value } \" ) logger . warning ( \"You should re-match tunes & chromaticities after this\" ) knob_variables = ( f \"kqx.r { ir : d } \" , f \"kqx.l { ir : d } \" ) # Closest IP triplet right_knob , left_knob = knob_variables current_right_knob = madx . globals [ right_knob ] current_left_knob = madx . globals [ left_knob ] if side == \"left\" : madx . globals [ right_knob ] = ( 1 - rigidty_waist_shift_value * 0.005 ) * current_right_knob madx . globals [ left_knob ] = ( 1 + rigidty_waist_shift_value * 0.005 ) * current_left_knob elif side == \"right\" : madx . globals [ right_knob ] = ( 1 + rigidty_waist_shift_value * 0.005 ) * current_right_knob madx . globals [ left_knob ] = ( 1 - rigidty_waist_shift_value * 0.005 ) * current_left_knob else : logger . error ( f \"Given side ' { side } ' invalid, only 'left' and 'right' are accepted values.\" ) raise ValueError ( \"Invalid value for parameter 'side'.\" ) logger . trace ( f \"Set ' { right_knob } ' to { madx . globals [ right_knob ] } \" ) logger . trace ( f \"Set ' { left_knob } ' to { madx . globals [ left_knob ] } \" ) def apply_lhc_coupling_knob ( madx : Madx , coupling_knob : float = 0 , beam : int = 1 , telescopic_squeeze : bool = False ) -> None : \"\"\" Applies the LHC coupling knob to reach the desired C- value. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. coupling_knob (float): Desired value for the Cminus, typically a few units of 1E-3. Defaults to 0 so users don't mess up coupling by mistake beam (int): beam to apply the knob to, defaults to beam 1. telescopic_squeeze (bool): if set to True, uses the knobs for Telescopic Squeeze configuration. Defaults to False. \"\"\" logger . info ( \"Applying coupling knob\" ) logger . warning ( \"You should re-match tunes & chromaticities after this\" ) suffix = \"_sq\" if telescopic_squeeze else \"\" knob_name = f \"CMRS.b { beam : d }{ suffix } \" logger . trace ( f \"Knob ' { knob_name } ' is { madx . globals [ knob_name ] } before implementation\" ) madx . globals [ knob_name ] = coupling_knob logger . trace ( f \"Set ' { knob_name } ' to { madx . globals [ knob_name ] } \" ) def make_sixtrack_output ( madx : Madx , energy : int ) -> None : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Prepare output for sixtrack run. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. energy (float): beam energy in GeV. \"\"\" logger . info ( \"Preparing outputs for SixTrack\" ) logger . debug ( \"Powering RF cavities\" ) madx . globals [ \"VRF400\" ] = 8 if energy < 5000 else 16 # is 6 at injection for protons iirc? madx . globals [ \"LAGRF400.B1\" ] = 0.5 # cavity phase difference in units of 2pi madx . globals [ \"LAGRF400.B2\" ] = 0.0 logger . debug ( \"Executing TWISS and SIXTRACK commands\" ) madx . twiss () # used by sixtrack madx . sixtrack ( cavall = True , radius = 0.017 ) # this value is only ok for HL(LHC) magnet radius def install_ac_dipole ( madx : Madx , deltaqx : float , deltaqy : float , sigma_x : float , sigma_y : float , geometric_emit : float = None , start_turn : int = 100 , ramp_turns : int = 2000 , top_turns : int = 6600 , ) -> None : \"\"\" Installs an AC dipole for BEAM 1 ONLY. This function assumes that you have already defined lhcb1, made a beam for it (BEAM command or `make_lhc_beams` function) and matched to your desired working point. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. deltaqx (float): the deltaQx (horizontal tune excitation) used by the AC dipole. deltaqy (float): the deltaQy (vertical tune excitation) used by the AC dipole. sigma_x (float): the horizontal amplitude to drive the beam to, in bunch sigma. sigma_y (float): the vertical amplitude to drive the beam to, in bunch sigma. geometric_emit (float): the geometric emittance that was used when defining the beam. If not provided, it is assumed that 'geometric_emit' is a defined global in MAD-X, and the value will be directly queried from the internal tables. start_turn (int): the turn at which to start ramping up the AC dipole. Defaults to 100. ramp_turns (int): the number of turns to use for the ramp-up and the ramp-down of the AC dipole. This number is important in order to preserve the adiabaticity of the cycle. Defaults to 2000 as in the LHC. top_turns (int): the number of turns to drive the beam for. Defaults to 6600 as in the LHC. \"\"\" if top_turns > 6600 : logger . warning ( f \"Configuring the AC Dipole for { top_turns } of driving is fine for MAD-X but is \" \"higher than what the device can do in the (HL)LHC! Beware.\" ) ramp1 , ramp2 = start_turn , start_turn + ramp_turns ramp3 = ramp2 + top_turns ramp4 = ramp3 + ramp_turns logger . debug ( \"Retrieving tunes from internal tables\" ) q1 , q2 = madx . table . summ . q1 [ 0 ], madx . table . summ . q2 [ 0 ] logger . trace ( f \"Retrieved values are q1 = { q1 } , q2 = { q2 } \" ) q1_dipole , q2_dipole = q1 + deltaqx , q2 + deltaqy if not geometric_emit : logger . debug ( \"No value provided for the geometric emittance used when creating the beam, the value will be \" \"queried from MAD-X's global 'geometric_emit'\" ) geometric_emit = madx . globals [ \"geometric_emit\" ] logger . info ( f \"Installing AC Dipole to drive the tunes to Qx_D = { q1_dipole } | Qy_D = { q2_dipole } \" ) madx . input ( f \"MKACH.6L4.B1: hacdipole, l=0, freq:= { q1_dipole } , lag=0, volt:=voltx, ramp1= { ramp1 } , \" f \"ramp2= { ramp2 } , ramp3= { ramp3 } , ramp4= { ramp4 } ;\" ) madx . input ( f \"MKACV.6L4.B1: vacdipole, l=0, freq:= { q2_dipole } , lag=0, volt:=volty, ramp1= { ramp1 } , \" f \"ramp2= { ramp2 } , ramp3= { ramp3 } , ramp4= { ramp4 } ;\" ) madx . command . seqedit ( sequence = \"lhcb1\" ) madx . command . flatten () madx . command . install ( element = \"MKACH.6L4.B1\" , at = \"0.0\" , from_ = \"MKQA.6L4.B1\" ) madx . command . install ( element = \"MKACV.6L4.B1\" , at = \"0.0\" , from_ = \"MKQA.6L4.B1\" ) madx . command . endedit () logger . trace ( \"Querying BETX and BETY at AC Dipole location\" ) madx . input ( \"betax_acd = table(twiss, MKQA.6L4.B1, betx);\" ) madx . input ( \"betay_acd = table(twiss, MKQA.6L4.B1, bety);\" ) betax_acd = madx . globals [ \"betax_acd\" ] betay_acd = madx . globals [ \"betay_acd\" ] brho = madx . sequence . lhcb1 . beam . brho voltx = sigma_x * np . sqrt ( geometric_emit ) * brho * np . abs ( deltaqx ) * 4 * np . pi / np . sqrt ( betax_acd ) volty = sigma_y * np . sqrt ( geometric_emit ) * brho * np . abs ( deltaqy ) * 4 * np . pi / np . sqrt ( betay_acd ) madx . globals [ \"voltx\" ] = voltx madx . globals [ \"volty\" ] = volty # ----- Miscellaneous Utilities ----- # def make_lhc_thin ( madx : Madx , sequence : str , slicefactor : int = 1 , ** kwargs ) -> None : \"\"\" Makethin for the LHC sequence as previously done in MAD-X macros. This will use the `teapot` style and will enforce `makedipedge`. Args: madx (Madx): an instantiated cpymad.madx.Madx object. sequence (str): the sequence to use for the MAKETHIN command. slicefactor (int): the slice factor to apply in makethin. Defaults to 1. Keyword Args: The keyword arguments for the MAD-X MAKETHN commands, namely `style` (will default to `teapot`) and the `makedipedge` flag (will default to True). \"\"\" logger . info ( f \"Slicing sequence ' { sequence } '\" ) madx . select ( flag = \"makethin\" , clear = True ) four_slices_patterns = [ r \"mbx\\.\" , r \"mbrb\\.\" , r \"mbrc\\.\" , r \"mbrs\\.\" ] four_slicefactor_patterns = [ r \"mqwa\\.\" , r \"mqwb\\.\" , r \"mqy\\.\" , r \"mqm\\.\" , r \"mqmc\\.\" , r \"mqml\\.\" , r \"mqtlh\\.\" , r \"mqtli\\.\" , r \"mqt\\.\" , ] logger . trace ( \"Defining slices for general MB and MQ elements\" ) madx . select ( flag = \"makethin\" , class_ = \"MB\" , slice = 2 ) madx . select ( flag = \"makethin\" , class_ = \"MQ\" , slice = 2 * slicefactor ) logger . trace ( \"Defining slices for triplets\" ) madx . select ( flag = \"makethin\" , class_ = \"mqxa\" , slice = 16 * slicefactor ) madx . select ( flag = \"makethin\" , class_ = \"mqxb\" , slice = 16 * slicefactor ) logger . trace ( \"Defining slices for various specifc mb elements\" ) for pattern in four_slices_patterns : madx . select ( flag = \"makethin\" , pattern = pattern , slice = 4 ) logger . trace ( \"Defining slices for varous specifc mq elements\" ) for pattern in four_slicefactor_patterns : madx . select ( flag = \"makethin\" , pattern = pattern , slice = 4 * slicefactor ) madx . use ( sequence = sequence ) style = kwargs . get ( \"style\" , \"teapot\" ) makedipedge = kwargs . get ( \"makedipedge\" , True ) madx . command . makethin ( sequence = sequence , style = style , makedipedge = makedipedge ) def re_cycle_sequence ( madx : Madx , sequence : str = \"lhcb1\" , start : str = \"IP3\" ) -> None : \"\"\" Re-cycle the provided sequence from a different starting point. Args: madx (Madx): an instantiated cpymad.madx.Madx object. sequence (str): the sequence to re cycle. start (str): element to start the new cycle from. \"\"\" logger . debug ( f \"Re-cycling sequence ' { sequence } ' from { start } \" ) madx . command . seqedit ( sequence = sequence ) madx . command . flatten () madx . command . cycle ( start = start ) madx . command . endedit () # ----- Twiss Utilities ----- # def get_ips_twiss ( madx : Madx , columns : Sequence [ str ] = DEFAULT_TWISS_COLUMNS , ** kwargs ) -> tfs . TfsDataFrame : \"\"\" Quickly get the `TWISS` table for certain variables at IP locations only. The `SUMM` table will be included as the TfsDataFrame's header dictionary. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as `chrom`, `ripken`, `centre` or starting coordinates with `betax`, 'betay` etc. Returns: A TfsDataFrame of the twiss output. \"\"\" logger . info ( \"Getting Twiss at IPs\" ) return get_pattern_twiss ( madx = madx , patterns = [ \"IP\" ], columns = columns , ** kwargs ) def get_ir_twiss ( madx : Madx , ir : int , columns : Sequence [ str ] = DEFAULT_TWISS_COLUMNS , ** kwargs ) -> tfs . TfsDataFrame : \"\"\" Quickly get the `TWISS` table for certain variables for one IR, meaning at the IP and Q1 to Q3 both left and right of the IP. The `SUMM` table will be included as the TfsDataFrame's header dictionary. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. ir (int): which interaction region to get the TWISS for. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as `chrom`, `ripken`, `centre` or starting coordinates with `betax`, 'betay` etc. Returns: A TfsDataFrame of the twiss output. \"\"\" logger . info ( f \"Getting Twiss for IR { ir : d } \" ) return get_pattern_twiss ( madx = madx , patterns = [ f \"IP { ir : d } \" , f \"MQXA.[12345][RL] { ir : d } \" , f \"MQXB.[AB][12345][RL] { ir : d } \" , f \"MQXF[AB].[AB][12345][RL] { ir : d } \" , # this is for HLLHC ], columns = columns , ** kwargs , ) # ----- Helpers ----- # def _all_lhc_arcs ( beam : int ) -> List [ str ]: \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Names of all LHC arcs for a given beam. Args: beam (int): beam to get names for. Returns: The list of names. \"\"\" return [ f \"A { i + 1 }{ ( i + 1 ) % 8 + 1 } B { beam : d } \" for i in range ( 8 )] def _get_k_strings ( start : int = 0 , stop : int = 8 , orientation : str = \"both\" ) -> List [ str ]: \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Returns the list of K-strings for various magnets and orders (K1L, K2SL etc strings). Args: start (int): the starting order, defaults to 0. stop (int): the order to go up to, defaults to 8. orientation (str): magnet orientation, can be 'straight', 'skew' or 'both'. Defaults to 'both'. Returns: The list of names as strings. \"\"\" if orientation not in ( \"straight\" , \"skew\" , \"both\" ,): logger . error ( f \"Orientation ' { orientation } ' is not accepted, should be one of 'straight', 'skew', 'both'.\" ) raise ValueError ( \"Invalid 'orientation' parameter\" ) if orientation == \"straight\" : orientation = ( \"\" ,) elif orientation == \"skew\" : orientation = ( \"S\" ,) else : # both orientation = ( \"\" , \"S\" ) return [ f \"K { i : d }{ s : s } L\" for i in range ( start , stop ) for s in orientation ]","title":"Module pyhdtoolkit.cpymadtools.special"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#variables","text":"DEFAULT_TWISS_COLUMNS","title":"Variables"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#apply_lhc_colinearity_knob","text":"def apply_lhc_colinearity_knob ( madx : cpymad . madx . Madx , colinearity_knob_value : float = 0 , ir : int = None ) -> None Applies the LHC colinearity knob. If you don't know what this is, you should not be using this function. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None colinearity_knob_value float Units of the colinearity knob to apply. Defaults to 0 so users don't mess up local coupling by mistake. This should be a positive integer, normally between 1 and 10. None ir int The Interaction Region to apply the knob to, should be one of [1, 2, 5, 8]. Classically 1 or 5. None View Source def apply_lhc_colinearity_knob ( madx : Madx , colinearity_knob_value : float = 0 , ir : int = None ) -> None : \"\"\" Applies the LHC colinearity knob. If you don't know what this is, you should not be using this function. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. colinearity_knob_value (float): Units of the colinearity knob to apply. Defaults to 0 so users don't mess up local coupling by mistake. This should be a positive integer, normally between 1 and 10. ir (int): The Interaction Region to apply the knob to, should be one of [1, 2, 5, 8]. Classically 1 or 5. \"\"\" logger . info ( f \"Applying Colinearity knob with a unit setting of {colinearity_knob_value}\" ) logger . warning ( \"You should re-match tunes & chromaticities after this\" ) knob_variables = ( f \"KQSX3.R{ir:d}\" , f \"KQSX3.L{ir:d}\" ) # MQSX IP coupling correctors right_knob , left_knob = knob_variables madx . globals [ right_knob ] = colinearity_knob_value * 1e-4 logger . trace ( f \"Set '{right_knob}' to {madx.globals[right_knob]}\" ) madx . globals [ left_knob ] = - 1 * colinearity_knob_value * 1e-4 logger . trace ( f \"Set '{left_knob}' to {madx.globals[left_knob]}\" )","title":"apply_lhc_colinearity_knob"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#apply_lhc_coupling_knob","text":"def apply_lhc_coupling_knob ( madx : cpymad . madx . Madx , coupling_knob : float = 0 , beam : int = 1 , telescopic_squeeze : bool = False ) -> None Applies the LHC coupling knob to reach the desired C- value. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. coupling_knob (float): Desired value for the Cminus, typically a few units of 1E-3. Defaults to 0 so users don't mess up coupling by mistake beam (int): beam to apply the knob to, defaults to beam 1. telescopic_squeeze (bool): if set to True, uses the knobs for Telescopic Squeeze configuration. Defaults to False. View Source def apply_lhc_coupling_knob ( madx : Madx , coupling_knob : float = 0 , beam : int = 1 , telescopic_squeeze : bool = False ) -> None : \"\"\" Applies the LHC coupling knob to reach the desired C- value. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. coupling_knob (float): Desired value for the Cminus, typically a few units of 1E-3. Defaults to 0 so users don't mess up coupling by mistake beam (int): beam to apply the knob to, defaults to beam 1. telescopic_squeeze (bool): if set to True, uses the knobs for Telescopic Squeeze configuration. Defaults to False. \"\"\" logger . info ( \"Applying coupling knob\" ) logger . warning ( \"You should re-match tunes & chromaticities after this\" ) suffix = \"_sq\" if telescopic_squeeze else \"\" knob_name = f \"CMRS.b{beam:d}{suffix}\" logger . trace ( f \"Knob '{knob_name}' is {madx.globals[knob_name]} before implementation\" ) madx . globals [ knob_name ] = coupling_knob logger . trace ( f \"Set '{knob_name}' to {madx.globals[knob_name]}\" )","title":"apply_lhc_coupling_knob"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#apply_lhc_rigidity_waist_shift_knob","text":"def apply_lhc_rigidity_waist_shift_knob ( madx : cpymad . madx . Madx , rigidty_waist_shift_value : float = 0 , ir : int = None , side : str = 'left' ) -> None Applies the LHC rigidity waist shift knob, moving the waist left or right of IP. If you don't know what this is, you should not be using this function. Warning: Applying the shift will modify your tunes and most likely flip them, making a subsequent matching impossible if your lattice has coupling. To avoid this, match to tunes split further apart before applying the waist shift knob, and then match to the desired working point. For instance for the LHC, match to (62.27, 60.36) before applying, and only then match to (62.31, 60.32). Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None rigidty_waist_shift_value float Units of the rigidity waist shift knob (positive values only). None ir int The Interaction Region to apply the knob to, should be one of [1, 2, 5, 8]. Classically 1 or 5. None side str Which side of the IP to move the waist to, determines a sign in the calculation. Defaults to 'left', which means s_waist < s_ip (and setting it to 'right' would move the waist to s_waist > s_ip). None View Source def apply_lhc_rigidity_waist_shift_knob ( madx : Madx , rigidty_waist_shift_value : float = 0 , ir : int = None , side : str = \"left\" ) -> None : \"\"\" Applies the LHC rigidity waist shift knob, moving the waist left or right of IP. If you don't know what this is, you should not be using this function. Warning: Applying the shift will modify your tunes and most likely flip them, making a subsequent matching impossible if your lattice has coupling. To avoid this, match to tunes split further apart before applying the waist shift knob, and then match to the desired working point. For instance for the LHC, match to (62.27, 60.36) before applying, and only then match to (62.31, 60.32). Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. rigidty_waist_shift_value (float): Units of the rigidity waist shift knob (positive values only). ir (int): The Interaction Region to apply the knob to, should be one of [1, 2, 5, 8]. Classically 1 or 5. side (str): Which side of the IP to move the waist to, determines a sign in the calculation. Defaults to 'left', which means s_waist < s_ip (and setting it to 'right' would move the waist to s_waist > s_ip). \"\"\" logger . info ( f \"Applying Rigidity Waist Shift knob with a unit setting of {rigidty_waist_shift_value}\" ) logger . warning ( \"You should re-match tunes & chromaticities after this\" ) knob_variables = ( f \"kqx.r{ir:d}\" , f \"kqx.l{ir:d}\" ) # Closest IP triplet right_knob , left_knob = knob_variables current_right_knob = madx . globals [ right_knob ] current_left_knob = madx . globals [ left_knob ] if side == \"left\" : madx . globals [ right_knob ] = ( 1 - rigidty_waist_shift_value * 0.005 ) * current_right_knob madx . globals [ left_knob ] = ( 1 + rigidty_waist_shift_value * 0.005 ) * current_left_knob elif side == \"right\" : madx . globals [ right_knob ] = ( 1 + rigidty_waist_shift_value * 0.005 ) * current_right_knob madx . globals [ left_knob ] = ( 1 - rigidty_waist_shift_value * 0.005 ) * current_left_knob else : logger . error ( f \"Given side '{side}' invalid, only 'left' and 'right' are accepted values.\" ) raise ValueError ( \"Invalid value for parameter 'side'.\" ) logger . trace ( f \"Set '{right_knob}' to {madx.globals[right_knob]}\" ) logger . trace ( f \"Set '{left_knob}' to {madx.globals[left_knob]}\" )","title":"apply_lhc_rigidity_waist_shift_knob"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#deactivate_lhc_arc_sextupoles","text":"def deactivate_lhc_arc_sextupoles ( madx : cpymad . madx . Madx , beam : int ) -> None Deactivate all arc sextupoles in the (HL)LHC. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None beam int beam to use. None View Source def deactivate_lhc_arc_sextupoles ( madx : Madx , beam : int ) -> None : \"\"\" Deactivate all arc sextupoles in the (HL)LHC. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. beam (int): beam to use. \"\"\" # KSF1 and KSD2 - Strong sextupoles of sectors 81 / 12 / 45 / 56 # KSF2 and KSD1 - Weak sextupoles of sectors 81 / 12 / 45 / 56 # Rest : Weak sextupoles in sectors 78 / 23 / 34 / 67 logger . info ( f \"Deactivating all arc sextupoles for beam {beam}.\" ) beam = 2 if beam == 4 else beam for arc in _all_lhc_arcs ( beam ) : for fd in \"FD\" : for i in ( 1 , 2 ) : sextupole = f \"KS{fd}{i:d}.{arc}\" logger . trace ( f \"De-powering element '{sextupole}'\" ) madx . globals [ sextupole ] = 0.0","title":"deactivate_lhc_arc_sextupoles"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#get_ips_twiss","text":"def get_ips_twiss ( madx : cpymad . madx . Madx , columns : Sequence [ str ] = [ 'name' , 's' , 'x' , 'y' , 'px' , 'py' , 'betx' , 'bety' , 'alfx' , 'alfy' , 'dx' , 'dy' , 'mux' , 'muy' , 'r11' , 'r12' , 'r21' , 'r22' , 'beta11' , 'beta12' , 'beta21' , 'beta22' ], ** kwargs ) -> tfs . handler . TfsDataFrame Quickly get the TWISS table for certain variables at IP locations only. The SUMM table will be included as the TfsDataFrame's header dictionary. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as chrom , ripken , centre or starting coordinates with betax , 'betay` etc. Returns: A TfsDataFrame of the twiss output. View Source def get_ips_twiss ( madx : Madx , columns : Sequence [ str ] = DEFAULT_TWISS_COLUMNS , ** kwargs ) -> tfs . TfsDataFrame : \" \"\" Quickly get the `TWISS` table for certain variables at IP locations only. The `SUMM` table will be included as the TfsDataFrame's header dictionary. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as `chrom`, `ripken`, `centre` or starting coordinates with `betax`, 'betay` etc. Returns: A TfsDataFrame of the twiss output. \"\" \" logger . info ( \"Getting Twiss at IPs\" ) return get_pattern_twiss ( madx = madx , patterns = [ \"IP\" ] , columns = columns , ** kwargs )","title":"get_ips_twiss"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#get_ir_twiss","text":"def get_ir_twiss ( madx : cpymad . madx . Madx , ir : int , columns : Sequence [ str ] = [ 'name' , 's' , 'x' , 'y' , 'px' , 'py' , 'betx' , 'bety' , 'alfx' , 'alfy' , 'dx' , 'dy' , 'mux' , 'muy' , 'r11' , 'r12' , 'r21' , 'r22' , 'beta11' , 'beta12' , 'beta21' , 'beta22' ], ** kwargs ) -> tfs . handler . TfsDataFrame Quickly get the TWISS table for certain variables for one IR, meaning at the IP and Q1 to Q3 both left and right of the IP. The SUMM table will be included as the TfsDataFrame's header dictionary. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. ir (int): which interaction region to get the TWISS for. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as chrom , ripken , centre or starting coordinates with betax , 'betay` etc. Returns: A TfsDataFrame of the twiss output. View Source def get_ir_twiss ( madx : Madx , ir : int , columns : Sequence [ str ] = DEFAULT_TWISS_COLUMNS , ** kwargs ) -> tfs . TfsDataFrame : \"\"\" Quickly get the `TWISS` table for certain variables for one IR, meaning at the IP and Q1 to Q3 both left and right of the IP. The `SUMM` table will be included as the TfsDataFrame's header dictionary. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. ir (int): which interaction region to get the TWISS for. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as `chrom`, `ripken`, `centre` or starting coordinates with `betax`, 'betay` etc. Returns: A TfsDataFrame of the twiss output. \"\"\" logger . info ( f \"Getting Twiss for IR {ir:d}\" ) return get_pattern_twiss ( madx = madx , patterns = [ f \"IP{ir:d}\" , f \"MQXA.[12345][RL]{ir:d}\" , f \"MQXB.[AB][12345][RL]{ir:d}\" , f \"MQXF[AB].[AB][12345][RL]{ir:d}\" , # this is for HLLHC ], columns = columns , ** kwargs , )","title":"get_ir_twiss"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#install_ac_dipole","text":"def install_ac_dipole ( madx : cpymad . madx . Madx , deltaqx : float , deltaqy : float , sigma_x : float , sigma_y : float , geometric_emit : float = None , start_turn : int = 100 , ramp_turns : int = 2000 , top_turns : int = 6600 ) -> None Installs an AC dipole for BEAM 1 ONLY. This function assumes that you have already defined lhcb1, made a beam for it (BEAM command or make_lhc_beams function) and matched to your desired working point. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None deltaqx float the deltaQx (horizontal tune excitation) used by the AC dipole. None deltaqy float the deltaQy (vertical tune excitation) used by the AC dipole. None sigma_x float the horizontal amplitude to drive the beam to, in bunch sigma. None sigma_y float the vertical amplitude to drive the beam to, in bunch sigma. None geometric_emit float the geometric emittance that was used when defining the beam. If not provided, it is assumed that 'geometric_emit' is a defined global in MAD-X, and the value will be directly queried from the internal tables. None start_turn int the turn at which to start ramping up the AC dipole. Defaults to 100. 100 ramp_turns int the number of turns to use for the ramp-up and the ramp-down of the AC dipole. This number is important in order to preserve the adiabaticity of the cycle. Defaults to 2000 as in the LHC. None top_turns int the number of turns to drive the beam for. Defaults to 6600 as in the LHC. 6600 as in the LHC View Source def install_ac_dipole ( madx : Madx , deltaqx : float , deltaqy : float , sigma_x : float , sigma_y : float , geometric_emit : float = None , start_turn : int = 100 , ramp_turns : int = 2000 , top_turns : int = 6600 , ) -> None : \" \"\" Installs an AC dipole for BEAM 1 ONLY. This function assumes that you have already defined lhcb1, made a beam for it (BEAM command or `make_lhc_beams` function) and matched to your desired working point. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. deltaqx (float): the deltaQx (horizontal tune excitation) used by the AC dipole. deltaqy (float): the deltaQy (vertical tune excitation) used by the AC dipole. sigma_x (float): the horizontal amplitude to drive the beam to, in bunch sigma. sigma_y (float): the vertical amplitude to drive the beam to, in bunch sigma. geometric_emit (float): the geometric emittance that was used when defining the beam. If not provided, it is assumed that 'geometric_emit' is a defined global in MAD-X, and the value will be directly queried from the internal tables. start_turn (int): the turn at which to start ramping up the AC dipole. Defaults to 100. ramp_turns (int): the number of turns to use for the ramp-up and the ramp-down of the AC dipole. This number is important in order to preserve the adiabaticity of the cycle. Defaults to 2000 as in the LHC. top_turns (int): the number of turns to drive the beam for. Defaults to 6600 as in the LHC. \"\" \" if top_turns > 6600 : logger . warning ( f \"Configuring the AC Dipole for {top_turns} of driving is fine for MAD-X but is \" \"higher than what the device can do in the (HL)LHC! Beware.\" ) ramp1 , ramp2 = start_turn , start_turn + ramp_turns ramp3 = ramp2 + top_turns ramp4 = ramp3 + ramp_turns logger . debug ( \"Retrieving tunes from internal tables\" ) q1 , q2 = madx . table . summ . q1 [ 0 ] , madx . table . summ . q2 [ 0 ] logger . trace ( f \"Retrieved values are q1 = {q1}, q2 = {q2}\" ) q1_dipole , q2_dipole = q1 + deltaqx , q2 + deltaqy if not geometric_emit : logger . debug ( \"No value provided for the geometric emittance used when creating the beam, the value will be \" \"queried from MAD-X's global 'geometric_emit'\" ) geometric_emit = madx . globals [ \"geometric_emit\" ] logger . info ( f \"Installing AC Dipole to drive the tunes to Qx_D = {q1_dipole} | Qy_D = {q2_dipole}\" ) madx . input ( f \"MKACH.6L4.B1: hacdipole, l=0, freq:={q1_dipole}, lag=0, volt:=voltx, ramp1={ramp1}, \" f \"ramp2={ramp2}, ramp3={ramp3}, ramp4={ramp4};\" ) madx . input ( f \"MKACV.6L4.B1: vacdipole, l=0, freq:={q2_dipole}, lag=0, volt:=volty, ramp1={ramp1}, \" f \"ramp2={ramp2}, ramp3={ramp3}, ramp4={ramp4};\" ) madx . command . seqedit ( sequence = \"lhcb1\" ) madx . command . flatten () madx . command . install ( element = \"MKACH.6L4.B1\" , at = \"0.0\" , from_ = \"MKQA.6L4.B1\" ) madx . command . install ( element = \"MKACV.6L4.B1\" , at = \"0.0\" , from_ = \"MKQA.6L4.B1\" ) madx . command . endedit () logger . trace ( \"Querying BETX and BETY at AC Dipole location\" ) madx . input ( \"betax_acd = table(twiss, MKQA.6L4.B1, betx);\" ) madx . input ( \"betay_acd = table(twiss, MKQA.6L4.B1, bety);\" ) betax_acd = madx . globals [ \"betax_acd\" ] betay_acd = madx . globals [ \"betay_acd\" ] brho = madx . sequence . lhcb1 . beam . brho voltx = sigma_x * np . sqrt ( geometric_emit ) * brho * np . abs ( deltaqx ) * 4 * np . pi / np . sqrt ( betax_acd ) volty = sigma_y * np . sqrt ( geometric_emit ) * brho * np . abs ( deltaqy ) * 4 * np . pi / np . sqrt ( betay_acd ) madx . globals [ \"voltx\" ] = voltx madx . globals [ \"volty\" ] = volty","title":"install_ac_dipole"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#make_lhc_beams","text":"def make_lhc_beams ( madx : cpymad . madx . Madx , energy : float = 6500 , emittance : float = 3.75e-06 , ** kwargs ) -> None Define beams with default configuratons for LHCB1 and LHCB2 sequences. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. energy (float): beam energy in GeV. Defaults to 6500. emittance (float): emittance in meters, which will be used to calculate geometric emittance, then fed to the BEAM command. Keyword Args: Any keyword argument that can be given to the MAD-X BEAM command. View Source def make_lhc_beams ( madx : Madx , energy : float = 6500 , emittance : float = 3.75e-6 , ** kwargs ) -> None : \" \"\" Define beams with default configuratons for `LHCB1` and `LHCB2` sequences. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. energy (float): beam energy in GeV. Defaults to 6500. emittance (float): emittance in meters, which will be used to calculate geometric emittance, then fed to the BEAM command. Keyword Args: Any keyword argument that can be given to the MAD-X BEAM command. \"\" \" logger . info ( \"Making default beams for 'lhcb1' and 'lhbc2' sequences\" ) madx . globals [ \"NRJ\" ] = energy madx . globals [ \"brho\" ] = energy * 1e9 / madx . globals . clight geometric_emit = madx . globals [ \"geometric_emit\" ] = emittance / ( energy / 0.938 ) for beam in ( 1 , 2 ) : logger . trace ( f \"Defining beam for sequence 'lhcb{beam:d}'\" ) madx . command . beam ( sequence = f \"lhcb{beam:d}\" , particle = \"proton\" , bv = 1 if beam == 1 else - 1 , energy = energy , npart = 1.0e10 , ex = geometric_emit , ey = geometric_emit , ** kwargs , )","title":"make_lhc_beams"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#make_lhc_thin","text":"def make_lhc_thin ( madx : cpymad . madx . Madx , sequence : str , slicefactor : int = 1 , ** kwargs ) -> None Makethin for the LHC sequence as previously done in MAD-X macros. This will use the teapot style and will enforce makedipedge . Args: madx (Madx): an instantiated cpymad.madx.Madx object. sequence (str): the sequence to use for the MAKETHIN command. slicefactor (int): the slice factor to apply in makethin. Defaults to 1. Keyword Args: The keyword arguments for the MAD-X MAKETHN commands, namely style (will default to teapot ) and the makedipedge flag (will default to True). View Source def make_lhc_thin ( madx : Madx , sequence : str , slicefactor : int = 1 , ** kwargs ) -> None : \" \"\" Makethin for the LHC sequence as previously done in MAD-X macros. This will use the `teapot` style and will enforce `makedipedge`. Args: madx (Madx): an instantiated cpymad.madx.Madx object. sequence (str): the sequence to use for the MAKETHIN command. slicefactor (int): the slice factor to apply in makethin. Defaults to 1. Keyword Args: The keyword arguments for the MAD-X MAKETHN commands, namely `style` (will default to `teapot`) and the `makedipedge` flag (will default to True). \"\" \" logger . info ( f \"Slicing sequence '{sequence}'\" ) madx . select ( flag = \"makethin\" , clear = True ) four_slices_patterns = [ r \"mbx \\ .\" , r \"mbrb \\ .\" , r \"mbrc \\ .\" , r \"mbrs \\ .\" ] four_slicefactor_patterns = [ r \"mqwa \\ .\" , r \"mqwb \\ .\" , r \"mqy \\ .\" , r \"mqm \\ .\" , r \"mqmc \\ .\" , r \"mqml \\ .\" , r \"mqtlh \\ .\" , r \"mqtli \\ .\" , r \"mqt \\ .\" , ] logger . trace ( \"Defining slices for general MB and MQ elements\" ) madx . select ( flag = \"makethin\" , class_ = \"MB\" , slice = 2 ) madx . select ( flag = \"makethin\" , class_ = \"MQ\" , slice = 2 * slicefactor ) logger . trace ( \"Defining slices for triplets\" ) madx . select ( flag = \"makethin\" , class_ = \"mqxa\" , slice = 16 * slicefactor ) madx . select ( flag = \"makethin\" , class_ = \"mqxb\" , slice = 16 * slicefactor ) logger . trace ( \"Defining slices for various specifc mb elements\" ) for pattern in four_slices_patterns : madx . select ( flag = \"makethin\" , pattern = pattern , slice = 4 ) logger . trace ( \"Defining slices for varous specifc mq elements\" ) for pattern in four_slicefactor_patterns : madx . select ( flag = \"makethin\" , pattern = pattern , slice = 4 * slicefactor ) madx . use ( sequence = sequence ) style = kwargs . get ( \"style\" , \"teapot\" ) makedipedge = kwargs . get ( \"makedipedge\" , True ) madx . command . makethin ( sequence = sequence , style = style , makedipedge = makedipedge )","title":"make_lhc_thin"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#make_sixtrack_output","text":"def make_sixtrack_output ( madx : cpymad . madx . Madx , energy : int ) -> None INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Prepare output for sixtrack run. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None energy float beam energy in GeV. None View Source def make_sixtrack_output ( madx : Madx , energy : int ) -> None : \"\"\" INITIAL IMPLEMENTATION CREDITS GO TO JOSCHUA DILLY (@JoschD). Prepare output for sixtrack run. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. energy (float): beam energy in GeV. \"\"\" logger . info ( \"Preparing outputs for SixTrack\" ) logger . debug ( \"Powering RF cavities\" ) madx . globals [ \"VRF400\" ] = 8 if energy < 5000 else 16 # is 6 at injection for protons iirc ? madx . globals [ \"LAGRF400.B1\" ] = 0.5 # cavity phase difference in units of 2 pi madx . globals [ \"LAGRF400.B2\" ] = 0.0 logger . debug ( \"Executing TWISS and SIXTRACK commands\" ) madx . twiss () # used by sixtrack madx . sixtrack ( cavall = True , radius = 0.017 ) # this value is only ok for HL ( LHC ) magnet radius","title":"make_sixtrack_output"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#power_landau_octupoles","text":"def power_landau_octupoles ( madx : cpymad . madx . Madx , mo_current : float , beam : int , defective_arc : bool = False ) -> None Power the Landau octupoles in the (HL)LHC. Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None mo_current float MO powering in Amps. None beam int beam to use. None defective_arc None If set to True , the KOD in Arc 56 are powered for less Imax. None View Source def power_landau_octupoles ( madx : Madx , mo_current : float , beam : int , defective_arc : bool = False ) -> None : \"\"\" Power the Landau octupoles in the (HL)LHC. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. mo_current (float): MO powering in Amps. beam (int): beam to use. defective_arc: If set to `True`, the KOD in Arc 56 are powered for less Imax. \"\"\" try : brho = madx . globals . nrj * 1e9 / madx . globals . clight # clight is MAD-X constant except AttributeError as madx_error : logger . error ( \"The global MAD-X variable 'NRJ' should have been set in the optics files but is not defined.\" ) raise EnvironmentError ( \"No 'NRJ' variable found in scripts\" ) from madx_error logger . info ( f \"Powering Landau Octupoles, beam {beam} @ {madx.globals.nrj} GeV with {mo_current} A.\" ) strength = mo_current / madx . globals . Imax_MO * madx . globals . Kmax_MO / brho beam = 2 if beam == 4 else beam for arc in _all_lhc_arcs ( beam ): for fd in \"FD\" : octupole = f \"KO{fd}.{arc}\" logger . trace ( f \"Powering element '{octupole}' at {strength} Amps\" ) madx . globals [ octupole ] = strength if defective_arc and ( beam == 1 ): madx . globals [ \"KOD.A56B1\" ] = strength * 4.65 / 6 # defective MO group","title":"power_landau_octupoles"},{"location":"reference/pyhdtoolkit/cpymadtools/special/#re_cycle_sequence","text":"def re_cycle_sequence ( madx : cpymad . madx . Madx , sequence : str = 'lhcb1' , start : str = 'IP3' ) -> None Re-cycle the provided sequence from a different starting point. Parameters: Name Type Description Default madx Madx an instantiated cpymad.madx.Madx object. None sequence str the sequence to re cycle. None start str element to start the new cycle from. None View Source def re_cycle_sequence ( madx : Madx , sequence : str = \"lhcb1\" , start : str = \"IP3\" ) -> None : \"\"\" Re-cycle the provided sequence from a different starting point. Args: madx (Madx): an instantiated cpymad.madx.Madx object. sequence (str): the sequence to re cycle. start (str): element to start the new cycle from. \"\"\" logger . debug ( f \"Re-cycling sequence ' { sequence } ' from {start}\" ) madx . command . seqedit ( sequence = sequence ) madx . command . flatten () madx . command . cycle ( start = start ) madx . command . ende dit ()","title":"re_cycle_sequence"},{"location":"reference/pyhdtoolkit/cpymadtools/track/","text":"Module pyhdtoolkit.cpymadtools.track Module cpymadtools.track Created on 2020.02.03 View Source \"\"\" Module cpymadtools.track ------------------------ Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to manipulate MAD-X TRACK functionality through a cpymad.madx.Madx object. \"\"\" from typing import Tuple import pandas as pd from cpymad.madx import Madx from loguru import logger # ----- Utlites ----- # def track_single_particle ( madx : Madx , initial_coordinates : Tuple [ float , float , float , float , float , float ], nturns : int , sequence : str = None , ) -> pd . DataFrame : \"\"\" Tracks a single particle for nturns, based on its initial coordinates. Args: madx (Madx): an instantiated cpymad.madx.Madx object. initial_coordinates (Tuple[float, float, float, float, float, float]): a tuple with the X, PX, Y, PY, T, PT starting coordinates the particle to track. nturns (int): the number of turns to track for. sequence (str): the sequence to use for tracking. If no value is provided, it is assumed that a sequence is already defined and in use, and this one will be picked up by MAD-X. Returns: A copy of the track table's dataframe, with as columns the coordinates x, px, y, py, t, pt, s and e (energy). \"\"\" start = initial_coordinates if isinstance ( sequence , str ): logger . debug ( f \"Using sequence ' { sequence } ' for tracking\" ) madx . use ( sequence = sequence ) logger . debug ( f \"Tracking coordinates with initial X, PX, Y, PY, T, PT of ' { initial_coordinates } '\" ) madx . command . track () madx . command . start ( X = start [ 0 ], PX = start [ 1 ], Y = start [ 2 ], PY = start [ 3 ], T = start [ 4 ], PT = start [ 5 ], ) madx . command . run ( turns = nturns ) madx . command . endtrack () return madx . table [ \"track.obs0001.p0001\" ] . dframe () . copy () Functions track_single_particle def track_single_particle ( madx : cpymad . madx . Madx , initial_coordinates : Tuple [ float , float , float , float , float , float ], nturns : int , sequence : str = None ) -> pandas . core . frame . DataFrame Tracks a single particle for nturns, based on its initial coordinates. Parameters: Name Type Description Default madx Madx an instantiated cpymad.madx.Madx object. None initial_coordinates Tuple[float, float, float, float, float, float] a tuple with the X, PX, Y, PY, T, PT starting coordinates the particle to track. None nturns int the number of turns to track for. None sequence str the sequence to use for tracking. If no value is provided, it is assumed that a sequence is already defined and in use, and this one will be picked up by MAD-X. None Returns: Type Description None A copy of the track table's dataframe, with as columns the coordinates x, px, y, py, t, pt, s and e (energy). View Source def track_single_particle ( madx : Madx , initial_coordinates : Tuple [ float , float , float , float , float , float ], nturns : int , sequence : str = None , ) -> pd . DataFrame : \"\"\" Tracks a single particle for nturns, based on its initial coordinates. Args: madx (Madx): an instantiated cpymad.madx.Madx object. initial_coordinates (Tuple[float, float, float, float, float, float]): a tuple with the X, PX, Y, PY, T, PT starting coordinates the particle to track. nturns (int): the number of turns to track for. sequence (str): the sequence to use for tracking. If no value is provided, it is assumed that a sequence is already defined and in use, and this one will be picked up by MAD-X. Returns: A copy of the track table' s dataframe , with as columns the coordinates x , px , y , py , t , pt , s and e ( energy ). \"\"\" start = initial_coordinates if isinstance(sequence, str): logger.debug(f\" Using sequence '{sequence}' for tracking \") madx.use(sequence=sequence) logger.debug(f\" Tracking coordinates with initial X , PX , Y , PY , T , PT of '{initial_coordinates}'\") madx.command.track() madx.command.start( X=start[0], PX=start[1], Y=start[2], PY=start[3], T=start[4], PT=start[5], ) madx.command.run(turns=nturns) madx.command.endtrack() return madx.table[\" track . obs0001 . p0001 \"].dframe().copy()","title":"Track"},{"location":"reference/pyhdtoolkit/cpymadtools/track/#module-pyhdtoolkitcpymadtoolstrack","text":"Module cpymadtools.track Created on 2020.02.03 View Source \"\"\" Module cpymadtools.track ------------------------ Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to manipulate MAD-X TRACK functionality through a cpymad.madx.Madx object. \"\"\" from typing import Tuple import pandas as pd from cpymad.madx import Madx from loguru import logger # ----- Utlites ----- # def track_single_particle ( madx : Madx , initial_coordinates : Tuple [ float , float , float , float , float , float ], nturns : int , sequence : str = None , ) -> pd . DataFrame : \"\"\" Tracks a single particle for nturns, based on its initial coordinates. Args: madx (Madx): an instantiated cpymad.madx.Madx object. initial_coordinates (Tuple[float, float, float, float, float, float]): a tuple with the X, PX, Y, PY, T, PT starting coordinates the particle to track. nturns (int): the number of turns to track for. sequence (str): the sequence to use for tracking. If no value is provided, it is assumed that a sequence is already defined and in use, and this one will be picked up by MAD-X. Returns: A copy of the track table's dataframe, with as columns the coordinates x, px, y, py, t, pt, s and e (energy). \"\"\" start = initial_coordinates if isinstance ( sequence , str ): logger . debug ( f \"Using sequence ' { sequence } ' for tracking\" ) madx . use ( sequence = sequence ) logger . debug ( f \"Tracking coordinates with initial X, PX, Y, PY, T, PT of ' { initial_coordinates } '\" ) madx . command . track () madx . command . start ( X = start [ 0 ], PX = start [ 1 ], Y = start [ 2 ], PY = start [ 3 ], T = start [ 4 ], PT = start [ 5 ], ) madx . command . run ( turns = nturns ) madx . command . endtrack () return madx . table [ \"track.obs0001.p0001\" ] . dframe () . copy ()","title":"Module pyhdtoolkit.cpymadtools.track"},{"location":"reference/pyhdtoolkit/cpymadtools/track/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/cpymadtools/track/#track_single_particle","text":"def track_single_particle ( madx : cpymad . madx . Madx , initial_coordinates : Tuple [ float , float , float , float , float , float ], nturns : int , sequence : str = None ) -> pandas . core . frame . DataFrame Tracks a single particle for nturns, based on its initial coordinates. Parameters: Name Type Description Default madx Madx an instantiated cpymad.madx.Madx object. None initial_coordinates Tuple[float, float, float, float, float, float] a tuple with the X, PX, Y, PY, T, PT starting coordinates the particle to track. None nturns int the number of turns to track for. None sequence str the sequence to use for tracking. If no value is provided, it is assumed that a sequence is already defined and in use, and this one will be picked up by MAD-X. None Returns: Type Description None A copy of the track table's dataframe, with as columns the coordinates x, px, y, py, t, pt, s and e (energy). View Source def track_single_particle ( madx : Madx , initial_coordinates : Tuple [ float , float , float , float , float , float ], nturns : int , sequence : str = None , ) -> pd . DataFrame : \"\"\" Tracks a single particle for nturns, based on its initial coordinates. Args: madx (Madx): an instantiated cpymad.madx.Madx object. initial_coordinates (Tuple[float, float, float, float, float, float]): a tuple with the X, PX, Y, PY, T, PT starting coordinates the particle to track. nturns (int): the number of turns to track for. sequence (str): the sequence to use for tracking. If no value is provided, it is assumed that a sequence is already defined and in use, and this one will be picked up by MAD-X. Returns: A copy of the track table' s dataframe , with as columns the coordinates x , px , y , py , t , pt , s and e ( energy ). \"\"\" start = initial_coordinates if isinstance(sequence, str): logger.debug(f\" Using sequence '{sequence}' for tracking \") madx.use(sequence=sequence) logger.debug(f\" Tracking coordinates with initial X , PX , Y , PY , T , PT of '{initial_coordinates}'\") madx.command.track() madx.command.start( X=start[0], PX=start[1], Y=start[2], PY=start[3], T=start[4], PT=start[5], ) madx.command.run(turns=nturns) madx.command.endtrack() return madx.table[\" track . obs0001 . p0001 \"].dframe().copy()","title":"track_single_particle"},{"location":"reference/pyhdtoolkit/cpymadtools/twiss/","text":"Module pyhdtoolkit.cpymadtools.twiss Module cpymadtools.twiss Created on 2020.02.03 View Source \"\"\" Module cpymadtools.twiss ------------------------ Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to manipulate MAD-X TWISS functionality through a cpymad.madx.Madx object. \"\"\" from typing import Sequence import numpy as np import tfs from cpymad.madx import Madx from loguru import logger from pyhdtoolkit.cpymadtools.constants import DEFAULT_TWISS_COLUMNS # ----- Utlites ----- # def get_pattern_twiss ( madx : Madx , patterns : Sequence [ str ] = [ \"\" ], columns : Sequence [ str ] = None , ** kwargs , ) -> tfs . TfsDataFrame : \"\"\" Extract the `TWISS` table for desired variables, and for certain elements matching a pattern. Additionally, the `SUMM` table is also returned in the form of the TfsDataFrame's headers dictionary. Warning: Although the `pattern` parameter should accept a regex, MAD-X does not implement actual regexes. Please refer to the MAD-X manual, section `Regular Expressions` for details on what is implemented in MAD-X itself. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. patterns (Sequence[str]): the different element patterns (such as `MQX` or `BPM`) to be applied to the command, which will determine the rows in the returned DataFrame. Defaults to [\"\"] which will select all elements. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Defaults to None, which will return all available columns. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as `chrom`, `ripken`, `centre` or starting coordinates with `betax`, 'betay` etc. Returns: A TfsDataFrame with the selected columns for all elements matching the provided patterns, and the internal `summ` table as header dict. \"\"\" logger . trace ( \"Clearing 'TWISS' flag\" ) madx . select ( flag = \"twiss\" , clear = True ) for pattern in patterns : logger . trace ( f \"Adding pattern { pattern } to 'TWISS' flag\" ) madx . select ( flag = \"twiss\" , pattern = pattern , column = columns ) madx . twiss ( ** kwargs ) logger . trace ( \"Extracting relevant parts of the TWISS table\" ) twiss_df = tfs . TfsDataFrame ( madx . table . twiss . dframe () . copy ()) twiss_df . headers = { var . upper (): madx . table . summ [ var ][ 0 ] for var in madx . table . summ } twiss_df = twiss_df [ madx . table . twiss . selected_columns ()] . iloc [ np . array ( madx . table . twiss . selected_rows ()) . astype ( bool ) ] logger . trace ( \"Clearing 'TWISS' flag\" ) madx . select ( flag = \"twiss\" , clear = True ) return twiss_df def get_twiss_tfs ( madx : Madx ) -> tfs . TfsDataFrame : \"\"\" Returns a tfs.TfsDataFrame from the Madx instance's twiss dframe, typically in the way we're used to getting it from MAD-X outputting the TWISS (uppercase names, colnames, summ table in headers). Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. Returns: A tfs.TfsDataFrame. \"\"\" logger . info ( \"Exporting internal TWISS and SUMM tables to TfsDataFrame\" ) twiss_tfs = tfs . TfsDataFrame ( madx . table . twiss . dframe ()) twiss_tfs . name = [ element [: - 2 ] for element in twiss_tfs . name ] twiss_tfs . columns = twiss_tfs . columns . str . upper () twiss_tfs = twiss_tfs . set_index ( \"NAME\" ) twiss_tfs . index = twiss_tfs . index . str . upper () twiss_tfs . headers = { var . upper (): madx . table . summ [ var ][ 0 ] for var in madx . table . summ } return twiss_tfs Variables DEFAULT_TWISS_COLUMNS Functions get_pattern_twiss def get_pattern_twiss ( madx : cpymad . madx . Madx , patterns : Sequence [ str ] = [ '' ], columns : Sequence [ str ] = None , ** kwargs ) -> tfs . handler . TfsDataFrame Extract the TWISS table for desired variables, and for certain elements matching a pattern. Additionally, the SUMM table is also returned in the form of the TfsDataFrame's headers dictionary. Warning: Although the pattern parameter should accept a regex, MAD-X does not implement actual regexes. Please refer to the MAD-X manual, section Regular Expressions for details on what is implemented in MAD-X itself. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. patterns (Sequence[str]): the different element patterns (such as MQX or BPM ) to be applied to the command, which will determine the rows in the returned DataFrame. Defaults to [\"\"] which will select all elements. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Defaults to None, which will return all available columns. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as chrom , ripken , centre or starting coordinates with betax , 'betay` etc. Returns: A TfsDataFrame with the selected columns for all elements matching the provided patterns, and the internal summ table as header dict. View Source def get_pattern_twiss ( madx : Madx , patterns : Sequence [ str ] = [ \"\" ] , columns : Sequence [ str ] = None , ** kwargs , ) -> tfs . TfsDataFrame : \" \"\" Extract the `TWISS` table for desired variables, and for certain elements matching a pattern. Additionally, the `SUMM` table is also returned in the form of the TfsDataFrame's headers dictionary. Warning: Although the `pattern` parameter should accept a regex, MAD-X does not implement actual regexes. Please refer to the MAD-X manual, section `Regular Expressions` for details on what is implemented in MAD-X itself. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. patterns (Sequence[str]): the different element patterns (such as `MQX` or `BPM`) to be applied to the command, which will determine the rows in the returned DataFrame. Defaults to [ \"\" ] which will select all elements. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Defaults to None, which will return all available columns. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as `chrom`, `ripken`, `centre` or starting coordinates with `betax`, 'betay` etc. Returns: A TfsDataFrame with the selected columns for all elements matching the provided patterns, and the internal `summ` table as header dict. \"\" \" logger . trace ( \"Clearing 'TWISS' flag\" ) madx . select ( flag = \"twiss\" , clear = True ) for pattern in patterns : logger . trace ( f \"Adding pattern {pattern} to 'TWISS' flag\" ) madx . select ( flag = \"twiss\" , pattern = pattern , column = columns ) madx . twiss ( ** kwargs ) logger . trace ( \"Extracting relevant parts of the TWISS table\" ) twiss_df = tfs . TfsDataFrame ( madx . table . twiss . dframe (). copy ()) twiss_df . headers = { var . upper () : madx . table . summ [ var ][ 0 ] for var in madx . table . summ } twiss_df = twiss_df [ madx . table . twiss . selected_columns () ] . iloc [ np . array ( madx . table . twiss . selected_rows ()). astype ( bool ) ] logger . trace ( \"Clearing 'TWISS' flag\" ) madx . select ( flag = \"twiss\" , clear = True ) return twiss_df get_twiss_tfs def get_twiss_tfs ( madx : cpymad . madx . Madx ) -> tfs . handler . TfsDataFrame Returns a tfs.TfsDataFrame from the Madx instance's twiss dframe, typically in the way we're used to getting it from MAD-X outputting the TWISS (uppercase names, colnames, summ table in headers). Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None Returns: Type Description None A tfs.TfsDataFrame. View Source def get_twiss_tfs ( madx : Madx ) -> tfs . TfsDataFrame : \"\"\" Returns a tfs.TfsDataFrame from the Madx instance's twiss dframe, typically in the way we're used to getting it from MAD-X outputting the TWISS (uppercase names, colnames, summ table in headers). Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. Returns: A tfs.TfsDataFrame. \"\"\" logger . info ( \"Exporting internal TWISS and SUMM tables to TfsDataFrame\" ) twiss_tfs = tfs . TfsDataFrame ( madx . table . twiss . dframe ()) twiss_tfs . name = [ element [:- 2 ] for element in twiss_tfs . name ] twiss_tfs . columns = twiss_tfs . columns . str . upper () twiss_tfs = twiss_tfs . set_index ( \"NAME\" ) twiss_tfs . index = twiss_tfs . index . str . upper () twiss_tfs . headers = { var . upper () : madx . table . summ [ var ][ 0 ] for var in madx . table . summ } return twiss_tfs","title":"Twiss"},{"location":"reference/pyhdtoolkit/cpymadtools/twiss/#module-pyhdtoolkitcpymadtoolstwiss","text":"Module cpymadtools.twiss Created on 2020.02.03 View Source \"\"\" Module cpymadtools.twiss ------------------------ Created on 2020.02.03 :author: Felix Soubelet (felix.soubelet@cern.ch) A module with functions to manipulate MAD-X TWISS functionality through a cpymad.madx.Madx object. \"\"\" from typing import Sequence import numpy as np import tfs from cpymad.madx import Madx from loguru import logger from pyhdtoolkit.cpymadtools.constants import DEFAULT_TWISS_COLUMNS # ----- Utlites ----- # def get_pattern_twiss ( madx : Madx , patterns : Sequence [ str ] = [ \"\" ], columns : Sequence [ str ] = None , ** kwargs , ) -> tfs . TfsDataFrame : \"\"\" Extract the `TWISS` table for desired variables, and for certain elements matching a pattern. Additionally, the `SUMM` table is also returned in the form of the TfsDataFrame's headers dictionary. Warning: Although the `pattern` parameter should accept a regex, MAD-X does not implement actual regexes. Please refer to the MAD-X manual, section `Regular Expressions` for details on what is implemented in MAD-X itself. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. patterns (Sequence[str]): the different element patterns (such as `MQX` or `BPM`) to be applied to the command, which will determine the rows in the returned DataFrame. Defaults to [\"\"] which will select all elements. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Defaults to None, which will return all available columns. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as `chrom`, `ripken`, `centre` or starting coordinates with `betax`, 'betay` etc. Returns: A TfsDataFrame with the selected columns for all elements matching the provided patterns, and the internal `summ` table as header dict. \"\"\" logger . trace ( \"Clearing 'TWISS' flag\" ) madx . select ( flag = \"twiss\" , clear = True ) for pattern in patterns : logger . trace ( f \"Adding pattern { pattern } to 'TWISS' flag\" ) madx . select ( flag = \"twiss\" , pattern = pattern , column = columns ) madx . twiss ( ** kwargs ) logger . trace ( \"Extracting relevant parts of the TWISS table\" ) twiss_df = tfs . TfsDataFrame ( madx . table . twiss . dframe () . copy ()) twiss_df . headers = { var . upper (): madx . table . summ [ var ][ 0 ] for var in madx . table . summ } twiss_df = twiss_df [ madx . table . twiss . selected_columns ()] . iloc [ np . array ( madx . table . twiss . selected_rows ()) . astype ( bool ) ] logger . trace ( \"Clearing 'TWISS' flag\" ) madx . select ( flag = \"twiss\" , clear = True ) return twiss_df def get_twiss_tfs ( madx : Madx ) -> tfs . TfsDataFrame : \"\"\" Returns a tfs.TfsDataFrame from the Madx instance's twiss dframe, typically in the way we're used to getting it from MAD-X outputting the TWISS (uppercase names, colnames, summ table in headers). Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. Returns: A tfs.TfsDataFrame. \"\"\" logger . info ( \"Exporting internal TWISS and SUMM tables to TfsDataFrame\" ) twiss_tfs = tfs . TfsDataFrame ( madx . table . twiss . dframe ()) twiss_tfs . name = [ element [: - 2 ] for element in twiss_tfs . name ] twiss_tfs . columns = twiss_tfs . columns . str . upper () twiss_tfs = twiss_tfs . set_index ( \"NAME\" ) twiss_tfs . index = twiss_tfs . index . str . upper () twiss_tfs . headers = { var . upper (): madx . table . summ [ var ][ 0 ] for var in madx . table . summ } return twiss_tfs","title":"Module pyhdtoolkit.cpymadtools.twiss"},{"location":"reference/pyhdtoolkit/cpymadtools/twiss/#variables","text":"DEFAULT_TWISS_COLUMNS","title":"Variables"},{"location":"reference/pyhdtoolkit/cpymadtools/twiss/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/cpymadtools/twiss/#get_pattern_twiss","text":"def get_pattern_twiss ( madx : cpymad . madx . Madx , patterns : Sequence [ str ] = [ '' ], columns : Sequence [ str ] = None , ** kwargs ) -> tfs . handler . TfsDataFrame Extract the TWISS table for desired variables, and for certain elements matching a pattern. Additionally, the SUMM table is also returned in the form of the TfsDataFrame's headers dictionary. Warning: Although the pattern parameter should accept a regex, MAD-X does not implement actual regexes. Please refer to the MAD-X manual, section Regular Expressions for details on what is implemented in MAD-X itself. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. patterns (Sequence[str]): the different element patterns (such as MQX or BPM ) to be applied to the command, which will determine the rows in the returned DataFrame. Defaults to [\"\"] which will select all elements. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Defaults to None, which will return all available columns. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as chrom , ripken , centre or starting coordinates with betax , 'betay` etc. Returns: A TfsDataFrame with the selected columns for all elements matching the provided patterns, and the internal summ table as header dict. View Source def get_pattern_twiss ( madx : Madx , patterns : Sequence [ str ] = [ \"\" ] , columns : Sequence [ str ] = None , ** kwargs , ) -> tfs . TfsDataFrame : \" \"\" Extract the `TWISS` table for desired variables, and for certain elements matching a pattern. Additionally, the `SUMM` table is also returned in the form of the TfsDataFrame's headers dictionary. Warning: Although the `pattern` parameter should accept a regex, MAD-X does not implement actual regexes. Please refer to the MAD-X manual, section `Regular Expressions` for details on what is implemented in MAD-X itself. Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. patterns (Sequence[str]): the different element patterns (such as `MQX` or `BPM`) to be applied to the command, which will determine the rows in the returned DataFrame. Defaults to [ \"\" ] which will select all elements. columns (Sequence[str]): the variables to be returned, as columns in the DataFrame. Defaults to None, which will return all available columns. Keyword Args: Any keyword argument that can be given to the MAD-X TWISS command, such as `chrom`, `ripken`, `centre` or starting coordinates with `betax`, 'betay` etc. Returns: A TfsDataFrame with the selected columns for all elements matching the provided patterns, and the internal `summ` table as header dict. \"\" \" logger . trace ( \"Clearing 'TWISS' flag\" ) madx . select ( flag = \"twiss\" , clear = True ) for pattern in patterns : logger . trace ( f \"Adding pattern {pattern} to 'TWISS' flag\" ) madx . select ( flag = \"twiss\" , pattern = pattern , column = columns ) madx . twiss ( ** kwargs ) logger . trace ( \"Extracting relevant parts of the TWISS table\" ) twiss_df = tfs . TfsDataFrame ( madx . table . twiss . dframe (). copy ()) twiss_df . headers = { var . upper () : madx . table . summ [ var ][ 0 ] for var in madx . table . summ } twiss_df = twiss_df [ madx . table . twiss . selected_columns () ] . iloc [ np . array ( madx . table . twiss . selected_rows ()). astype ( bool ) ] logger . trace ( \"Clearing 'TWISS' flag\" ) madx . select ( flag = \"twiss\" , clear = True ) return twiss_df","title":"get_pattern_twiss"},{"location":"reference/pyhdtoolkit/cpymadtools/twiss/#get_twiss_tfs","text":"def get_twiss_tfs ( madx : cpymad . madx . Madx ) -> tfs . handler . TfsDataFrame Returns a tfs.TfsDataFrame from the Madx instance's twiss dframe, typically in the way we're used to getting it from MAD-X outputting the TWISS (uppercase names, colnames, summ table in headers). Parameters: Name Type Description Default madx cpymad.madx.Madx an instanciated cpymad Madx object. None Returns: Type Description None A tfs.TfsDataFrame. View Source def get_twiss_tfs ( madx : Madx ) -> tfs . TfsDataFrame : \"\"\" Returns a tfs.TfsDataFrame from the Madx instance's twiss dframe, typically in the way we're used to getting it from MAD-X outputting the TWISS (uppercase names, colnames, summ table in headers). Args: madx (cpymad.madx.Madx): an instanciated cpymad Madx object. Returns: A tfs.TfsDataFrame. \"\"\" logger . info ( \"Exporting internal TWISS and SUMM tables to TfsDataFrame\" ) twiss_tfs = tfs . TfsDataFrame ( madx . table . twiss . dframe ()) twiss_tfs . name = [ element [:- 2 ] for element in twiss_tfs . name ] twiss_tfs . columns = twiss_tfs . columns . str . upper () twiss_tfs = twiss_tfs . set_index ( \"NAME\" ) twiss_tfs . index = twiss_tfs . index . str . upper () twiss_tfs . headers = { var . upper () : madx . table . summ [ var ][ 0 ] for var in madx . table . summ } return twiss_tfs","title":"get_twiss_tfs"},{"location":"reference/pyhdtoolkit/maths/","text":"Module pyhdtoolkit.maths None None Sub-modules pyhdtoolkit.maths.nonconvex_phase_sync pyhdtoolkit.maths.stats_fitting pyhdtoolkit.maths.utils","title":"Index"},{"location":"reference/pyhdtoolkit/maths/#module-pyhdtoolkitmaths","text":"None None","title":"Module pyhdtoolkit.maths"},{"location":"reference/pyhdtoolkit/maths/#sub-modules","text":"pyhdtoolkit.maths.nonconvex_phase_sync pyhdtoolkit.maths.stats_fitting pyhdtoolkit.maths.utils","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/","text":"Module pyhdtoolkit.maths.nonconvex_phase_sync Module maths.nonconvex_phase_sync Created on 2020.01.13 View Source \"\"\" Module maths.nonconvex_phase_sync --------------------------------- Created on 2020.01.13 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 implementation of the Nonconvex Phase Synchronisation method found in the following paper (DOI: 10.1137/16M105808X, the algorithm reproduced is page 8). Methodology and Use Case ======================== We consider that from measurements, we can only obtain noisy relative phase advances mu_{i} - mu_{j} and want a converging solution to reconstruct the different individual mu_{1}, ...., mu_{n} values. From measurements, we construct a hermitian matrix C in the shape of: C_{ij} = z_{i} * bar(z_{j}) = exp(i * (mu_{i} - mu_{j})) A mock one with random values (500 by 500 as we have 500 BPMs per plane in the LHC) would be: c_matrix = np.exp(1j * np.random.rand(500, 500)) Considering 4 BPMs, the measurement matrix would be: M_matrix = [[mu_{1 -> 1}, mu_{1 -> 2}, mu_{1 -> 3}, mu_{1 -> 4}], [mu_{2 -> 1}, mu_{2 -> 2}, mu_{2 -> 3}, mu_{2 -> 4}], [mu_{3 -> 1}, mu_{3 -> 2}, mu_{3 -> 3}, mu_{3 -> 4}], [mu_{4 -> 1}, mu_{4 -> 2}, mu_{4 -> 3}, mu_{4 -> 4}]] Note two particular properties here: - Because our measurements are phase differences, the M_matrix will necessarily have zeros on its diagonal (mu_{k -> k} = 0). - By definition, since mu_{a -> b} = - mu_{b -> a}, M_matrix is symmetric. - Also note that for all computations, M_matrix needs to be initialised in radians! We can very simply get our C_matrix (see page 1 of referenced paper) with `numpy.exp` which, applied to a `numpy.ndarray` applies the exponential function element-wise. See reference at https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html Then follows: C_matrix = np.exp(1j * M_matrix) Note that M_matrix being symmetric, then c_matrix will be Hermitian. Note that M_matrix having zeros in its diagonal, c_matrix will have (1 + 0j) on its diagonal. With added noise to those values (noise should be included in M_matrix in the case of measurements), we can reconstruct a good estimator of the original values through the EVM method, provided in the class below. \"\"\" import numpy as np from loguru import logger class PhaseReconstructor: \"\"\" Class algorithm to reconstruct your phase values. Make sure to provide vectors as `numpy.ndarray` with shape (1, N), N being the dimension. \"\"\" __slots__ = { \"c_matrix\" : \"Hermitian square matrix from your measurements\" , \"c_matrix_eigenvalues\" : \"Eigenvalues of c_matrix\" , \"c_matrix_eigenvectors\" : \"Eigenvectors of c_matrix\" , \"space_dimension\" : \"Dimension of your measurement space\" , } def __init__ ( self , measurements_hermitian_matrix: np . ndarray ) -> None: \"\"\" Initialize your reconstructor object from measurements. Args: measurements_hermitian_matrix: a `numpy.ndarray` object built from measurements, see module docstring on how to build this matrix. \"\"\" logger . debug ( \"Checking that the provided matrix is Hermitian\" ) if np . allclose ( measurements_hermitian_matrix , np . conj ( measurements_hermitian_matrix ). T ): self . c_matrix: np . ndarray = measurements_hermitian_matrix self . c_matrix_eigenvalues: np . ndarray = np . linalg . eigvalsh ( self . c_matrix ) # Numpy gives the eigenvectors in column form, so transpose is needed there! self . c_matrix_eigenvectors: np . ndarray = np . linalg . eigh ( self . c_matrix )[- 1 ]. T self . space_dimension: int = self . c_matrix . shape [ 0 ] else: logger . exception ( \"Instantiating a PhaseReconstructor with a non hermitian matrix is \" \"not possible\" ) raise ValueError ( \"Provided matrix should be Hermitian\" ) @property def alpha ( self ) -> np . float64: \"\"\" This is a factor used to define the new reconstruction matrix. It is taken either as the operator norm of the hermitian noise matrix, or as the max value between 0 and the opposite of the min eigenvalue of c_matrix (chosen for implementation, since our noise is included in the measurements). See page 8 of the paper for reference. Returns: A real scalar value, because c_matrix is Hermitian and the eigenvalues of real symmetric or complex Hermitian matrices are always real (see G. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, pg. 222.) \"\"\" return np . float64 ( max ( 0 , np . amin ( self . c_matrix_eigenvalues ))) @property def leading_eigenvector ( self ) -> np . ndarray: \"\"\" Returns the leading eigenvector of `self.c_matrix`, which is the eigenvector corresponding to the max eigenvalue (in absolute value). Returns: A `numpy.ndarray` object, corresponding to said eigenvector. \"\"\" return self . c_matrix_eigenvectors [ np . where ( self . c_matrix_eigenvalues == np . amax ( np . absolute ( self . c_matrix_eigenvalues ))) ]. reshape (( 1 , self . space_dimension )) @property def reconstructor_matrix ( self ) -> np . ndarray: \"\"\" This is the reconstructor matrix built from `self.c_matrix` and the `alpha` property. It is the matrix denoted as \\\\widetilde{C} on page 8 of the reference paper. Returns: A `numpy.ndarray`, with same dimension as `self.c_matrix`. \"\"\" return self . c_matrix + self . alpha * np . identity ( self . c_matrix . shape [ 0 ]) def get_eigenvector_estimator ( self , eigenvector: np . ndarray ) -> np . ndarray: \"\"\" Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Args: eigenvector (np.ndarray): a numpy array representing the vector. Returns: A `numpy.ndarray` object of the same dimension as param `eigenvector`. \"\"\" try: return eigenvector / np . absolute ( eigenvector ) except RuntimeWarning: # In case of 0-division, we don't want `inf` values from numpy # Generate a random complex vector with same dimension (since `eigenvector` is of # dimension N * 1, `numpy.ndarray.size` method will give us N). # Remember to initialize a random real and imaginary part. logger . exception ( \"Encountered 0-division, trying normalization\" ) e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) while ( np . absolute ( e_vect @ eigenvector ) == 0 ): # Guarantee that we don't fall back to this edge case. e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) return ( e_vect @ eigenvector / np . absolute ( e_vect @ eigenvector )). reshape ( ( 1 , self . space_dimension ) ) def reconstruct_complex_phases_evm ( self ) -> np . ndarray: \"\"\" Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: The complex form of the result as a 'numpy.ndarray' instance. \"\"\" logger . debug ( \"Getting complex phase results\" ) return self . get_eigenvector_estimator ( self . leading_eigenvector ) @staticmethod def convert_complex_result_to_phase_values ( complex_estimator: np . ndarray , deg: bool = False ) -> np . ndarray: \"\"\" Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A `numpy.ndarray` with the real phase values of the result. \"\"\" logger . debug ( \"Casting complex phases to real values\" ) return np . apply_along_axis ( np . angle , axis = 0 , arr = complex_estimator , deg = deg ) Classes PhaseReconstructor class PhaseReconstructor ( measurements_hermitian_matrix : numpy . ndarray ) View Source class PhaseReconstructor : \" \"\" Class algorithm to reconstruct your phase values. Make sure to provide vectors as `numpy.ndarray` with shape (1, N), N being the dimension. \"\" \" __slots__ = { \"c_matrix\" : \"Hermitian square matrix from your measurements\" , \"c_matrix_eigenvalues\" : \"Eigenvalues of c_matrix\" , \"c_matrix_eigenvectors\" : \"Eigenvectors of c_matrix\" , \"space_dimension\" : \"Dimension of your measurement space\" , } def __init__ ( self , measurements_hermitian_matrix : np . ndarray ) -> None : \" \"\" Initialize your reconstructor object from measurements. Args: measurements_hermitian_matrix: a `numpy.ndarray` object built from measurements, see module docstring on how to build this matrix. \"\" \" logger . debug ( \"Checking that the provided matrix is Hermitian\" ) if np . allclose ( measurements_hermitian_matrix , np . conj ( measurements_hermitian_matrix ). T ) : self . c_matrix : np . ndarray = measurements_hermitian_matrix self . c_matrix_eigenvalues : np . ndarray = np . linalg . eigvalsh ( self . c_matrix ) # Numpy gives the eigenvectors in column form, so transpose is needed there! self . c_matrix_eigenvectors : np . ndarray = np . linalg . eigh ( self . c_matrix ) [ - 1 ] . T self . space_dimension : int = self . c_matrix . shape [ 0 ] else : logger . exception ( \"Instantiating a PhaseReconstructor with a non hermitian matrix is \" \"not possible\" ) raise ValueError ( \"Provided matrix should be Hermitian\" ) @property def alpha ( self ) -> np . float64 : \" \"\" This is a factor used to define the new reconstruction matrix. It is taken either as the operator norm of the hermitian noise matrix, or as the max value between 0 and the opposite of the min eigenvalue of c_matrix (chosen for implementation, since our noise is included in the measurements). See page 8 of the paper for reference. Returns: A real scalar value, because c_matrix is Hermitian and the eigenvalues of real symmetric or complex Hermitian matrices are always real (see G. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, pg. 222.) \"\" \" return np . float64 ( max ( 0 , np . amin ( self . c_matrix_eigenvalues ))) @property def leading_eigenvector ( self ) -> np . ndarray : \" \"\" Returns the leading eigenvector of `self.c_matrix`, which is the eigenvector corresponding to the max eigenvalue (in absolute value). Returns: A `numpy.ndarray` object, corresponding to said eigenvector. \"\" \" return self . c_matrix_eigenvectors [ np . where ( self . c_matrix_eigenvalues == np . amax ( np . absolute ( self . c_matrix_eigenvalues ))) ] . reshape (( 1 , self . space_dimension )) @property def reconstructor_matrix ( self ) -> np . ndarray : \" \"\" This is the reconstructor matrix built from `self.c_matrix` and the `alpha` property. It is the matrix denoted as \\\\ widetilde{C} on page 8 of the reference paper. Returns: A `numpy.ndarray`, with same dimension as `self.c_matrix`. \"\" \" return self . c_matrix + self . alpha * np . identity ( self . c_matrix . shape [ 0 ] ) def get_eigenvector_estimator ( self , eigenvector : np . ndarray ) -> np . ndarray : \" \"\" Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Args: eigenvector (np.ndarray): a numpy array representing the vector. Returns: A `numpy.ndarray` object of the same dimension as param `eigenvector`. \"\" \" try : return eigenvector / np . absolute ( eigenvector ) except RuntimeWarning : # In case of 0-division, we don't want `inf` values from numpy # Generate a random complex vector with same dimension (since `eigenvector` is of # dimension N * 1, `numpy.ndarray.size` method will give us N). # Remember to initialize a random real and imaginary part. logger . exception ( \"Encountered 0-division, trying normalization\" ) e_vect = np . random . randn ( eigenvector . size ) + 1j * np . random . randn ( eigenvector . size ) while ( np . absolute ( e_vect @ eigenvector ) == 0 ) : # Guarantee that we don't fall back to this edge case. e_vect = np . random . randn ( eigenvector . size ) + 1j * np . random . randn ( eigenvector . size ) return ( e_vect @ eigenvector / np . absolute ( e_vect @ eigenvector )). reshape ( ( 1 , self . space_dimension ) ) def reconstruct_complex_phases_evm ( self ) -> np . ndarray : \" \"\" Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: The complex form of the result as a 'numpy.ndarray' instance. \"\" \" logger . debug ( \"Getting complex phase results\" ) return self . get_eigenvector_estimator ( self . leading_eigenvector ) @staticmethod def convert_complex_result_to_phase_values ( complex_estimator : np . ndarray , deg : bool = False ) -> np . ndarray : \" \"\" Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A `numpy.ndarray` with the real phase values of the result. \"\" \" logger . debug ( \"Casting complex phases to real values\" ) return np . apply_along_axis ( np . angle , axis = 0 , arr = complex_estimator , deg = deg ) Static methods convert_complex_result_to_phase_values def convert_complex_result_to_phase_values ( complex_estimator : numpy . ndarray , deg : bool = False ) -> numpy . ndarray Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A numpy.ndarray with the real phase values of the result. View Source @staticmethod def convert_complex_result_to_phase_values ( complex_estimator : np . ndarray , deg : bool = False ) -> np . ndarray : \"\"\" Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A `numpy.ndarray` with the real phase values of the result. \"\"\" logger . debug ( \"Casting complex phases to real values\" ) return np . apply_along_axis ( np . angle , axis = 0 , arr = complex_estimator , deg = deg ) Instance variables alpha This is a factor used to define the new reconstruction matrix. It is taken either as the operator norm of the hermitian noise matrix, or as the max value between 0 and the opposite of the min eigenvalue of c_matrix (chosen for implementation, since our noise is included in the measurements). See page 8 of the paper for reference. c_matrix c_matrix_eigenvalues c_matrix_eigenvectors leading_eigenvector Returns the leading eigenvector of self.c_matrix , which is the eigenvector corresponding to the max eigenvalue (in absolute value). reconstructor_matrix This is the reconstructor matrix built from self.c_matrix and the alpha property. It is the matrix denoted as \\widetilde{C} on page 8 of the reference paper. space_dimension Methods get_eigenvector_estimator def get_eigenvector_estimator ( self , eigenvector : numpy . ndarray ) -> numpy . ndarray Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Parameters: Name Type Description Default eigenvector np.ndarray a numpy array representing the vector. None Returns: Type Description None A numpy.ndarray object of the same dimension as param eigenvector . View Source def get_eigenvector_estimator ( self , eigenvector : np . ndarray ) -> np . ndarray : \" \"\" Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Args: eigenvector (np.ndarray): a numpy array representing the vector. Returns: A `numpy.ndarray` object of the same dimension as param `eigenvector`. \"\" \" try : return eigenvector / np . absolute ( eigenvector ) except RuntimeWarning : # In case of 0-division, we don't want `inf` values from numpy # Generate a random complex vector with same dimension (since `eigenvector` is of # dimension N * 1, `numpy.ndarray.size` method will give us N). # Remember to initialize a random real and imaginary part. logger . exception ( \"Encountered 0-division, trying normalization\" ) e_vect = np . random . randn ( eigenvector . size ) + 1j * np . random . randn ( eigenvector . size ) while ( np . absolute ( e_vect @ eigenvector ) == 0 ) : # Guarantee that we don't fall back to this edge case. e_vect = np . random . randn ( eigenvector . size ) + 1j * np . random . randn ( eigenvector . size ) return ( e_vect @ eigenvector / np . absolute ( e_vect @ eigenvector )). reshape ( ( 1 , self . space_dimension ) ) reconstruct_complex_phases_evm def reconstruct_complex_phases_evm ( self ) -> numpy . ndarray Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: Type Description None The complex form of the result as a 'numpy.ndarray' instance. View Source def reconstruct_complex_phases_evm ( self ) -> np . ndarray : \"\"\" Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: The complex form of the result as a 'numpy.ndarray' instance. \"\"\" logger . debug ( \"Getting complex phase results\" ) return self . get_eigenvector_estimator ( self . leading_eigenvector )","title":"Nonconvex Phase Sync"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#module-pyhdtoolkitmathsnonconvex_phase_sync","text":"Module maths.nonconvex_phase_sync Created on 2020.01.13 View Source \"\"\" Module maths.nonconvex_phase_sync --------------------------------- Created on 2020.01.13 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 implementation of the Nonconvex Phase Synchronisation method found in the following paper (DOI: 10.1137/16M105808X, the algorithm reproduced is page 8). Methodology and Use Case ======================== We consider that from measurements, we can only obtain noisy relative phase advances mu_{i} - mu_{j} and want a converging solution to reconstruct the different individual mu_{1}, ...., mu_{n} values. From measurements, we construct a hermitian matrix C in the shape of: C_{ij} = z_{i} * bar(z_{j}) = exp(i * (mu_{i} - mu_{j})) A mock one with random values (500 by 500 as we have 500 BPMs per plane in the LHC) would be: c_matrix = np.exp(1j * np.random.rand(500, 500)) Considering 4 BPMs, the measurement matrix would be: M_matrix = [[mu_{1 -> 1}, mu_{1 -> 2}, mu_{1 -> 3}, mu_{1 -> 4}], [mu_{2 -> 1}, mu_{2 -> 2}, mu_{2 -> 3}, mu_{2 -> 4}], [mu_{3 -> 1}, mu_{3 -> 2}, mu_{3 -> 3}, mu_{3 -> 4}], [mu_{4 -> 1}, mu_{4 -> 2}, mu_{4 -> 3}, mu_{4 -> 4}]] Note two particular properties here: - Because our measurements are phase differences, the M_matrix will necessarily have zeros on its diagonal (mu_{k -> k} = 0). - By definition, since mu_{a -> b} = - mu_{b -> a}, M_matrix is symmetric. - Also note that for all computations, M_matrix needs to be initialised in radians! We can very simply get our C_matrix (see page 1 of referenced paper) with `numpy.exp` which, applied to a `numpy.ndarray` applies the exponential function element-wise. See reference at https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html Then follows: C_matrix = np.exp(1j * M_matrix) Note that M_matrix being symmetric, then c_matrix will be Hermitian. Note that M_matrix having zeros in its diagonal, c_matrix will have (1 + 0j) on its diagonal. With added noise to those values (noise should be included in M_matrix in the case of measurements), we can reconstruct a good estimator of the original values through the EVM method, provided in the class below. \"\"\" import numpy as np from loguru import logger class PhaseReconstructor: \"\"\" Class algorithm to reconstruct your phase values. Make sure to provide vectors as `numpy.ndarray` with shape (1, N), N being the dimension. \"\"\" __slots__ = { \"c_matrix\" : \"Hermitian square matrix from your measurements\" , \"c_matrix_eigenvalues\" : \"Eigenvalues of c_matrix\" , \"c_matrix_eigenvectors\" : \"Eigenvectors of c_matrix\" , \"space_dimension\" : \"Dimension of your measurement space\" , } def __init__ ( self , measurements_hermitian_matrix: np . ndarray ) -> None: \"\"\" Initialize your reconstructor object from measurements. Args: measurements_hermitian_matrix: a `numpy.ndarray` object built from measurements, see module docstring on how to build this matrix. \"\"\" logger . debug ( \"Checking that the provided matrix is Hermitian\" ) if np . allclose ( measurements_hermitian_matrix , np . conj ( measurements_hermitian_matrix ). T ): self . c_matrix: np . ndarray = measurements_hermitian_matrix self . c_matrix_eigenvalues: np . ndarray = np . linalg . eigvalsh ( self . c_matrix ) # Numpy gives the eigenvectors in column form, so transpose is needed there! self . c_matrix_eigenvectors: np . ndarray = np . linalg . eigh ( self . c_matrix )[- 1 ]. T self . space_dimension: int = self . c_matrix . shape [ 0 ] else: logger . exception ( \"Instantiating a PhaseReconstructor with a non hermitian matrix is \" \"not possible\" ) raise ValueError ( \"Provided matrix should be Hermitian\" ) @property def alpha ( self ) -> np . float64: \"\"\" This is a factor used to define the new reconstruction matrix. It is taken either as the operator norm of the hermitian noise matrix, or as the max value between 0 and the opposite of the min eigenvalue of c_matrix (chosen for implementation, since our noise is included in the measurements). See page 8 of the paper for reference. Returns: A real scalar value, because c_matrix is Hermitian and the eigenvalues of real symmetric or complex Hermitian matrices are always real (see G. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, pg. 222.) \"\"\" return np . float64 ( max ( 0 , np . amin ( self . c_matrix_eigenvalues ))) @property def leading_eigenvector ( self ) -> np . ndarray: \"\"\" Returns the leading eigenvector of `self.c_matrix`, which is the eigenvector corresponding to the max eigenvalue (in absolute value). Returns: A `numpy.ndarray` object, corresponding to said eigenvector. \"\"\" return self . c_matrix_eigenvectors [ np . where ( self . c_matrix_eigenvalues == np . amax ( np . absolute ( self . c_matrix_eigenvalues ))) ]. reshape (( 1 , self . space_dimension )) @property def reconstructor_matrix ( self ) -> np . ndarray: \"\"\" This is the reconstructor matrix built from `self.c_matrix` and the `alpha` property. It is the matrix denoted as \\\\widetilde{C} on page 8 of the reference paper. Returns: A `numpy.ndarray`, with same dimension as `self.c_matrix`. \"\"\" return self . c_matrix + self . alpha * np . identity ( self . c_matrix . shape [ 0 ]) def get_eigenvector_estimator ( self , eigenvector: np . ndarray ) -> np . ndarray: \"\"\" Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Args: eigenvector (np.ndarray): a numpy array representing the vector. Returns: A `numpy.ndarray` object of the same dimension as param `eigenvector`. \"\"\" try: return eigenvector / np . absolute ( eigenvector ) except RuntimeWarning: # In case of 0-division, we don't want `inf` values from numpy # Generate a random complex vector with same dimension (since `eigenvector` is of # dimension N * 1, `numpy.ndarray.size` method will give us N). # Remember to initialize a random real and imaginary part. logger . exception ( \"Encountered 0-division, trying normalization\" ) e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) while ( np . absolute ( e_vect @ eigenvector ) == 0 ): # Guarantee that we don't fall back to this edge case. e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) return ( e_vect @ eigenvector / np . absolute ( e_vect @ eigenvector )). reshape ( ( 1 , self . space_dimension ) ) def reconstruct_complex_phases_evm ( self ) -> np . ndarray: \"\"\" Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: The complex form of the result as a 'numpy.ndarray' instance. \"\"\" logger . debug ( \"Getting complex phase results\" ) return self . get_eigenvector_estimator ( self . leading_eigenvector ) @staticmethod def convert_complex_result_to_phase_values ( complex_estimator: np . ndarray , deg: bool = False ) -> np . ndarray: \"\"\" Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A `numpy.ndarray` with the real phase values of the result. \"\"\" logger . debug ( \"Casting complex phases to real values\" ) return np . apply_along_axis ( np . angle , axis = 0 , arr = complex_estimator , deg = deg )","title":"Module pyhdtoolkit.maths.nonconvex_phase_sync"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#phasereconstructor","text":"class PhaseReconstructor ( measurements_hermitian_matrix : numpy . ndarray ) View Source class PhaseReconstructor : \" \"\" Class algorithm to reconstruct your phase values. Make sure to provide vectors as `numpy.ndarray` with shape (1, N), N being the dimension. \"\" \" __slots__ = { \"c_matrix\" : \"Hermitian square matrix from your measurements\" , \"c_matrix_eigenvalues\" : \"Eigenvalues of c_matrix\" , \"c_matrix_eigenvectors\" : \"Eigenvectors of c_matrix\" , \"space_dimension\" : \"Dimension of your measurement space\" , } def __init__ ( self , measurements_hermitian_matrix : np . ndarray ) -> None : \" \"\" Initialize your reconstructor object from measurements. Args: measurements_hermitian_matrix: a `numpy.ndarray` object built from measurements, see module docstring on how to build this matrix. \"\" \" logger . debug ( \"Checking that the provided matrix is Hermitian\" ) if np . allclose ( measurements_hermitian_matrix , np . conj ( measurements_hermitian_matrix ). T ) : self . c_matrix : np . ndarray = measurements_hermitian_matrix self . c_matrix_eigenvalues : np . ndarray = np . linalg . eigvalsh ( self . c_matrix ) # Numpy gives the eigenvectors in column form, so transpose is needed there! self . c_matrix_eigenvectors : np . ndarray = np . linalg . eigh ( self . c_matrix ) [ - 1 ] . T self . space_dimension : int = self . c_matrix . shape [ 0 ] else : logger . exception ( \"Instantiating a PhaseReconstructor with a non hermitian matrix is \" \"not possible\" ) raise ValueError ( \"Provided matrix should be Hermitian\" ) @property def alpha ( self ) -> np . float64 : \" \"\" This is a factor used to define the new reconstruction matrix. It is taken either as the operator norm of the hermitian noise matrix, or as the max value between 0 and the opposite of the min eigenvalue of c_matrix (chosen for implementation, since our noise is included in the measurements). See page 8 of the paper for reference. Returns: A real scalar value, because c_matrix is Hermitian and the eigenvalues of real symmetric or complex Hermitian matrices are always real (see G. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, pg. 222.) \"\" \" return np . float64 ( max ( 0 , np . amin ( self . c_matrix_eigenvalues ))) @property def leading_eigenvector ( self ) -> np . ndarray : \" \"\" Returns the leading eigenvector of `self.c_matrix`, which is the eigenvector corresponding to the max eigenvalue (in absolute value). Returns: A `numpy.ndarray` object, corresponding to said eigenvector. \"\" \" return self . c_matrix_eigenvectors [ np . where ( self . c_matrix_eigenvalues == np . amax ( np . absolute ( self . c_matrix_eigenvalues ))) ] . reshape (( 1 , self . space_dimension )) @property def reconstructor_matrix ( self ) -> np . ndarray : \" \"\" This is the reconstructor matrix built from `self.c_matrix` and the `alpha` property. It is the matrix denoted as \\\\ widetilde{C} on page 8 of the reference paper. Returns: A `numpy.ndarray`, with same dimension as `self.c_matrix`. \"\" \" return self . c_matrix + self . alpha * np . identity ( self . c_matrix . shape [ 0 ] ) def get_eigenvector_estimator ( self , eigenvector : np . ndarray ) -> np . ndarray : \" \"\" Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Args: eigenvector (np.ndarray): a numpy array representing the vector. Returns: A `numpy.ndarray` object of the same dimension as param `eigenvector`. \"\" \" try : return eigenvector / np . absolute ( eigenvector ) except RuntimeWarning : # In case of 0-division, we don't want `inf` values from numpy # Generate a random complex vector with same dimension (since `eigenvector` is of # dimension N * 1, `numpy.ndarray.size` method will give us N). # Remember to initialize a random real and imaginary part. logger . exception ( \"Encountered 0-division, trying normalization\" ) e_vect = np . random . randn ( eigenvector . size ) + 1j * np . random . randn ( eigenvector . size ) while ( np . absolute ( e_vect @ eigenvector ) == 0 ) : # Guarantee that we don't fall back to this edge case. e_vect = np . random . randn ( eigenvector . size ) + 1j * np . random . randn ( eigenvector . size ) return ( e_vect @ eigenvector / np . absolute ( e_vect @ eigenvector )). reshape ( ( 1 , self . space_dimension ) ) def reconstruct_complex_phases_evm ( self ) -> np . ndarray : \" \"\" Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: The complex form of the result as a 'numpy.ndarray' instance. \"\" \" logger . debug ( \"Getting complex phase results\" ) return self . get_eigenvector_estimator ( self . leading_eigenvector ) @staticmethod def convert_complex_result_to_phase_values ( complex_estimator : np . ndarray , deg : bool = False ) -> np . ndarray : \" \"\" Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A `numpy.ndarray` with the real phase values of the result. \"\" \" logger . debug ( \"Casting complex phases to real values\" ) return np . apply_along_axis ( np . angle , axis = 0 , arr = complex_estimator , deg = deg )","title":"PhaseReconstructor"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#convert_complex_result_to_phase_values","text":"def convert_complex_result_to_phase_values ( complex_estimator : numpy . ndarray , deg : bool = False ) -> numpy . ndarray Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A numpy.ndarray with the real phase values of the result. View Source @staticmethod def convert_complex_result_to_phase_values ( complex_estimator : np . ndarray , deg : bool = False ) -> np . ndarray : \"\"\" Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A `numpy.ndarray` with the real phase values of the result. \"\"\" logger . debug ( \"Casting complex phases to real values\" ) return np . apply_along_axis ( np . angle , axis = 0 , arr = complex_estimator , deg = deg )","title":"convert_complex_result_to_phase_values"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#instance-variables","text":"alpha This is a factor used to define the new reconstruction matrix. It is taken either as the operator norm of the hermitian noise matrix, or as the max value between 0 and the opposite of the min eigenvalue of c_matrix (chosen for implementation, since our noise is included in the measurements). See page 8 of the paper for reference. c_matrix c_matrix_eigenvalues c_matrix_eigenvectors leading_eigenvector Returns the leading eigenvector of self.c_matrix , which is the eigenvector corresponding to the max eigenvalue (in absolute value). reconstructor_matrix This is the reconstructor matrix built from self.c_matrix and the alpha property. It is the matrix denoted as \\widetilde{C} on page 8 of the reference paper. space_dimension","title":"Instance variables"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#methods","text":"","title":"Methods"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#get_eigenvector_estimator","text":"def get_eigenvector_estimator ( self , eigenvector : numpy . ndarray ) -> numpy . ndarray Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Parameters: Name Type Description Default eigenvector np.ndarray a numpy array representing the vector. None Returns: Type Description None A numpy.ndarray object of the same dimension as param eigenvector . View Source def get_eigenvector_estimator ( self , eigenvector : np . ndarray ) -> np . ndarray : \" \"\" Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Args: eigenvector (np.ndarray): a numpy array representing the vector. Returns: A `numpy.ndarray` object of the same dimension as param `eigenvector`. \"\" \" try : return eigenvector / np . absolute ( eigenvector ) except RuntimeWarning : # In case of 0-division, we don't want `inf` values from numpy # Generate a random complex vector with same dimension (since `eigenvector` is of # dimension N * 1, `numpy.ndarray.size` method will give us N). # Remember to initialize a random real and imaginary part. logger . exception ( \"Encountered 0-division, trying normalization\" ) e_vect = np . random . randn ( eigenvector . size ) + 1j * np . random . randn ( eigenvector . size ) while ( np . absolute ( e_vect @ eigenvector ) == 0 ) : # Guarantee that we don't fall back to this edge case. e_vect = np . random . randn ( eigenvector . size ) + 1j * np . random . randn ( eigenvector . size ) return ( e_vect @ eigenvector / np . absolute ( e_vect @ eigenvector )). reshape ( ( 1 , self . space_dimension ) )","title":"get_eigenvector_estimator"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#reconstruct_complex_phases_evm","text":"def reconstruct_complex_phases_evm ( self ) -> numpy . ndarray Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: Type Description None The complex form of the result as a 'numpy.ndarray' instance. View Source def reconstruct_complex_phases_evm ( self ) -> np . ndarray : \"\"\" Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: The complex form of the result as a 'numpy.ndarray' instance. \"\"\" logger . debug ( \"Getting complex phase results\" ) return self . get_eigenvector_estimator ( self . leading_eigenvector )","title":"reconstruct_complex_phases_evm"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/","text":"Module pyhdtoolkit.maths.stats_fitting Module maths.stats_fitting Created on 2020.02.06 View Source \"\"\" Module maths.stats_fitting -------------------------- Created on 2020.02.06 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 module implementing methods to find the best fit of statistical distributions to data. \"\"\" import warnings from typing import Dict , Tuple , Union import matplotlib import matplotlib.pyplot as plt # if omitted, get AttributeError: module 'matplotlib' has no attribute 'axes' import numpy as np import pandas as pd import scipy.stats as st from loguru import logger # Distributions to check # DISTRIBUTIONS : Dict [ st . rv_continuous , str ] = { st . chi : \"Chi\" , st . chi2 : \"Chi-Square\" , st . expon : \"Exponential\" , st . laplace : \"Laplace\" , st . lognorm : \"LogNorm\" , st . norm : \"Normal\" , } def set_distributions_dict ( dist_dict : Dict [ st . rv_continuous , str ]) -> None : \"\"\" Sets DISTRIBUTIONS as the provided dict. This is useful to define only the ones you want to try out. Args: dist_dict Dict[st.rv_continuous, str]: dictionnary with the wanted distributions, in the format of DISTRIBUTIONS, aka scipy.stats generator objects as keys, and a string representation of their name as value. Returns: Nothing, but modifies the global DISTRIBUTIONS dict called by other functions. \"\"\" # pylint: disable=global-statement logger . debug ( \"Setting tested distributions\" ) global DISTRIBUTIONS DISTRIBUTIONS = dist_dict def best_fit_distribution ( data : Union [ pd . Series , np . ndarray ], bins : int = 200 , ax : matplotlib . axes . Axes = None ) -> Tuple [ st . rv_continuous , Tuple [ float , ... ]]: \"\"\" Model data by finding best fit candidate distribution among those in DISTRIBUTIONS. Args: data (Union[pd.Series, np.ndarray]): a pandas Series or numpy array with your distribution data. bins (int): the number of bins to decompose your data in before performing fittings. ax (matplotlib.axes.Axes): the matplotlib axis object on which to plot the pdf of tried functions. This should be provided as the ax on which you plotted your distribution. Returns: A tuple containing the scipy.stats generator corresponding to the best fit candidate, and the parameters to give said generator to get this fit. \"\"\" # pylint: disable=too-many-locals logger . debug ( f \"Getting histogram of original data, in { bins } bins\" ) y , x = np . histogram ( data , bins = bins , density = True ) x = ( x + np . roll ( x , - 1 ))[: - 1 ] / 2.0 logger . debug ( \"Creating initial guess\" ) best_distribution = st . norm best_params = ( 0.0 , 1.0 ) best_sse = np . inf # Estimate distribution parameters from data for distribution , distname in DISTRIBUTIONS . items (): try : with warnings . catch_warnings (): # Ignore warnings from data that can't be fit warnings . filterwarnings ( \"ignore\" ) logger . debug ( f \"Trying to fit distribution ' { distname } '\" ) params = distribution . fit ( data ) * args , loc , scale = params logger . debug ( f \"Calculating PDF goodness of fit and error for distribution ' { distname } '\" ) pdf = distribution . pdf ( x , loc = loc , scale = scale , * args ) sse = np . sum ( np . power ( y - pdf , 2.0 )) try : if ax : logger . debug ( f \"Plotting fitted PDF for distribution ' { distname } '\" ) pd . Series ( pdf , x ) . plot ( ax = ax , label = f \" { distname } fit\" , alpha = 1 , lw = 2 ) except Exception : logger . exception ( f \"Plotting distribution ' { distname } ' failed\" ) logger . debug ( f \"Identifying if distribution ' { distname } ' is a better fit than previous tries\" ) if best_sse > sse > 0 : best_distribution = distribution best_params = params best_sse = sse except Exception : logger . exception ( f \"Trying to fit distribution ' { distname } ' failed and aborted\" ) logger . info ( f \"Found a best fit: ' { DISTRIBUTIONS [ best_distribution ] } ' distribution\" ) return best_distribution , best_params def make_pdf ( distribution : st . rv_continuous , params : Tuple [ float , ... ], size : int = 25_000 ) -> pd . Series : \"\"\" Generate a pandas Series for the distributions's Probability Distribution Function. This Series will have axis values as index, and PDF values as values. Args: distribution (st.rv_continuous): a scipy.stats generator object params (Tuple[float, ...]): the parameters for this generator given back by the fit. size (int): the number of points to evaluate. Returns: A pandas Series object with the PDF as values, corresponding axis values as index. \"\"\" # Separate parts of parameters * args , loc , scale = params logger . debug ( \"Getting sane start and end points of distribution\" ) start = ( distribution . ppf ( 0.01 , * args , loc = loc , scale = scale ) if args else distribution . ppf ( 0.01 , loc = loc , scale = scale ) ) end = ( distribution . ppf ( 0.99 , * args , loc = loc , scale = scale ) if args else distribution . ppf ( 0.99 , loc = loc , scale = scale ) ) logger . debug ( \"Building PDF\" ) x = np . linspace ( start , end , size ) y = distribution . pdf ( x , loc = loc , scale = scale , * args ) return pd . Series ( y , x ) Variables DISTRIBUTIONS Functions best_fit_distribution def best_fit_distribution ( data : Union [ pandas . core . series . Series , numpy . ndarray ], bins : int = 200 , ax : matplotlib . axes . _axes . Axes = None ) -> Tuple [ scipy . stats . _distn_infrastructure . rv_continuous , Tuple [ float , ... ]] Model data by finding best fit candidate distribution among those in DISTRIBUTIONS. Parameters: Name Type Description Default data Union[pd.Series, np.ndarray] a pandas Series or numpy array with your distribution data. None bins int the number of bins to decompose your data in before performing fittings. None ax matplotlib.axes.Axes the matplotlib axis object on which to plot the pdf of tried functions. This should be provided as the ax on which you plotted your distribution. None Returns: Type Description None A tuple containing the scipy.stats generator corresponding to the best fit candidate, and the parameters to give said generator to get this fit. View Source def best_fit_distribution ( data : Union [ pd . Series , np . ndarray ], bins : int = 200 , ax : matplotlib . axes . Axes = None ) -> Tuple [ st . rv_continuous , Tuple [ float , ...]] : \"\"\" Model data by finding best fit candidate distribution among those in DISTRIBUTIONS. Args: data (Union[pd.Series, np.ndarray]): a pandas Series or numpy array with your distribution data. bins (int): the number of bins to decompose your data in before performing fittings. ax (matplotlib.axes.Axes): the matplotlib axis object on which to plot the pdf of tried functions. This should be provided as the ax on which you plotted your distribution. Returns: A tuple containing the scipy.stats generator corresponding to the best fit candidate, and the parameters to give said generator to get this fit. \"\"\" # pylint : disable = too - many - locals logger . debug ( f \"Getting histogram of original data, in {bins} bins\" ) y , x = np . histogram ( data , bins = bins , density = True ) x = ( x + np . roll ( x , - 1 ))[:- 1 ] / 2.0 logger . debug ( \"Creating initial guess\" ) best_distribution = st . norm best_params = ( 0.0 , 1.0 ) best_sse = np . inf # Estimate distribution parameters from data for distribution , distname in DISTRIBUTIONS . items () : try : with warnings . catch_warnings () : # Ignore warnings from data that can't be fit warnings.filterwarnings(\"ignore\") logger.debug(f\"Trying to fit distribution ' { distname } '\") params = distribution.fit(data) *args, loc, scale = params logger.debug(f\"Calculating PDF goodness of fit and error for distribution ' { distname } '\") pdf = distribution.pdf(x, loc=loc, scale=scale, *args) sse = np.sum(np.power(y - pdf, 2.0)) try: if ax: logger.debug(f\"Plotting fitted PDF for distribution ' { distname } '\") pd.Series(pdf, x).plot(ax=ax, label=f\"{distname} fit\", alpha=1, lw=2) except Exception: logger.exception(f\"Plotting distribution ' { distname } ' failed\") logger.debug(f\"Identifying if distribution ' { distname } ' is a better fit than previous tries\") if best_sse > sse > 0: best_distribution = distribution best_params = params best_sse = sse except Exception: logger.exception(f\"Trying to fit distribution ' { distname } ' failed and aborted\") logger.info(f\"Found a best fit: ' { DISTRIBUTIONS [ best_distribution ]} ' distribution \" ) return best_distribution , best_params make_pdf def make_pdf ( distribution : scipy . stats . _distn_infrastructure . rv_continuous , params : Tuple [ float , ... ], size : int = 25000 ) -> pandas . core . series . Series Generate a pandas Series for the distributions's Probability Distribution Function. This Series will have axis values as index, and PDF values as values. Parameters: Name Type Description Default distribution st.rv_continuous a scipy.stats generator object None params Tuple[float, ...] the parameters for this generator given back by the fit. None size int the number of points to evaluate. None Returns: Type Description None A pandas Series object with the PDF as values, corresponding axis values as index. View Source def make_pdf ( distribution : st . rv_continuous , params : Tuple [ float , ...], size : int = 25 _000 ) -> pd . Series : \"\"\" Generate a pandas Series for the distributions' s Probability Distribution Function . This Series will have axis values as index , and PDF values as values . Args : distribution ( st . rv_continuous ) : a scipy . stats generator object params ( Tuple [ float , ...]) : the parameters for this generator given back by the fit . size ( int ) : the number of points to evaluate . Returns : A pandas Series object with the PDF as values , corresponding axis values as index . \"\"\" # Separate parts of parameters *args, loc, scale = params logger.debug(\" Getting sane start and end points of distribution \") start = ( distribution.ppf(0.01, *args, loc=loc, scale=scale) if args else distribution.ppf(0.01, loc=loc, scale=scale) ) end = ( distribution.ppf(0.99, *args, loc=loc, scale=scale) if args else distribution.ppf(0.99, loc=loc, scale=scale) ) logger.debug(\" Building PDF \") x = np.linspace(start, end, size) y = distribution.pdf(x, loc=loc, scale=scale, *args) return pd.Series(y, x) set_distributions_dict def set_distributions_dict ( dist_dict : Dict [ scipy . stats . _distn_infrastructure . rv_continuous , str ] ) -> None Sets DISTRIBUTIONS as the provided dict. This is useful to define only the ones you want to try out. Parameters: Name Type Description Default dist_dict Dict[st.rv_continuous, str] None dictionnary with the wanted distributions, in the format of DISTRIBUTIONS, aka scipy.stats generator objects as keys, and a string representation of their name as value. None Returns: Type Description None Nothing, but modifies the global DISTRIBUTIONS dict called by other functions. View Source def set_distributions_dict ( dist_dict : Dict [ st . rv_continuous , str ]) -> None : \"\"\" Sets DISTRIBUTIONS as the provided dict. This is useful to define only the ones you want to try out. Args: dist_dict Dict[st.rv_continuous, str]: dictionnary with the wanted distributions, in the format of DISTRIBUTIONS, aka scipy.stats generator objects as keys, and a string representation of their name as value. Returns: Nothing, but modifies the global DISTRIBUTIONS dict called by other functions. \"\"\" # pylint : disable = global - statement logger . debug ( \"Setting tested distributions\" ) global DISTRIBUTIONS DISTRIBUTIONS = dist_dict","title":"Stats Fitting"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/#module-pyhdtoolkitmathsstats_fitting","text":"Module maths.stats_fitting Created on 2020.02.06 View Source \"\"\" Module maths.stats_fitting -------------------------- Created on 2020.02.06 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 module implementing methods to find the best fit of statistical distributions to data. \"\"\" import warnings from typing import Dict , Tuple , Union import matplotlib import matplotlib.pyplot as plt # if omitted, get AttributeError: module 'matplotlib' has no attribute 'axes' import numpy as np import pandas as pd import scipy.stats as st from loguru import logger # Distributions to check # DISTRIBUTIONS : Dict [ st . rv_continuous , str ] = { st . chi : \"Chi\" , st . chi2 : \"Chi-Square\" , st . expon : \"Exponential\" , st . laplace : \"Laplace\" , st . lognorm : \"LogNorm\" , st . norm : \"Normal\" , } def set_distributions_dict ( dist_dict : Dict [ st . rv_continuous , str ]) -> None : \"\"\" Sets DISTRIBUTIONS as the provided dict. This is useful to define only the ones you want to try out. Args: dist_dict Dict[st.rv_continuous, str]: dictionnary with the wanted distributions, in the format of DISTRIBUTIONS, aka scipy.stats generator objects as keys, and a string representation of their name as value. Returns: Nothing, but modifies the global DISTRIBUTIONS dict called by other functions. \"\"\" # pylint: disable=global-statement logger . debug ( \"Setting tested distributions\" ) global DISTRIBUTIONS DISTRIBUTIONS = dist_dict def best_fit_distribution ( data : Union [ pd . Series , np . ndarray ], bins : int = 200 , ax : matplotlib . axes . Axes = None ) -> Tuple [ st . rv_continuous , Tuple [ float , ... ]]: \"\"\" Model data by finding best fit candidate distribution among those in DISTRIBUTIONS. Args: data (Union[pd.Series, np.ndarray]): a pandas Series or numpy array with your distribution data. bins (int): the number of bins to decompose your data in before performing fittings. ax (matplotlib.axes.Axes): the matplotlib axis object on which to plot the pdf of tried functions. This should be provided as the ax on which you plotted your distribution. Returns: A tuple containing the scipy.stats generator corresponding to the best fit candidate, and the parameters to give said generator to get this fit. \"\"\" # pylint: disable=too-many-locals logger . debug ( f \"Getting histogram of original data, in { bins } bins\" ) y , x = np . histogram ( data , bins = bins , density = True ) x = ( x + np . roll ( x , - 1 ))[: - 1 ] / 2.0 logger . debug ( \"Creating initial guess\" ) best_distribution = st . norm best_params = ( 0.0 , 1.0 ) best_sse = np . inf # Estimate distribution parameters from data for distribution , distname in DISTRIBUTIONS . items (): try : with warnings . catch_warnings (): # Ignore warnings from data that can't be fit warnings . filterwarnings ( \"ignore\" ) logger . debug ( f \"Trying to fit distribution ' { distname } '\" ) params = distribution . fit ( data ) * args , loc , scale = params logger . debug ( f \"Calculating PDF goodness of fit and error for distribution ' { distname } '\" ) pdf = distribution . pdf ( x , loc = loc , scale = scale , * args ) sse = np . sum ( np . power ( y - pdf , 2.0 )) try : if ax : logger . debug ( f \"Plotting fitted PDF for distribution ' { distname } '\" ) pd . Series ( pdf , x ) . plot ( ax = ax , label = f \" { distname } fit\" , alpha = 1 , lw = 2 ) except Exception : logger . exception ( f \"Plotting distribution ' { distname } ' failed\" ) logger . debug ( f \"Identifying if distribution ' { distname } ' is a better fit than previous tries\" ) if best_sse > sse > 0 : best_distribution = distribution best_params = params best_sse = sse except Exception : logger . exception ( f \"Trying to fit distribution ' { distname } ' failed and aborted\" ) logger . info ( f \"Found a best fit: ' { DISTRIBUTIONS [ best_distribution ] } ' distribution\" ) return best_distribution , best_params def make_pdf ( distribution : st . rv_continuous , params : Tuple [ float , ... ], size : int = 25_000 ) -> pd . Series : \"\"\" Generate a pandas Series for the distributions's Probability Distribution Function. This Series will have axis values as index, and PDF values as values. Args: distribution (st.rv_continuous): a scipy.stats generator object params (Tuple[float, ...]): the parameters for this generator given back by the fit. size (int): the number of points to evaluate. Returns: A pandas Series object with the PDF as values, corresponding axis values as index. \"\"\" # Separate parts of parameters * args , loc , scale = params logger . debug ( \"Getting sane start and end points of distribution\" ) start = ( distribution . ppf ( 0.01 , * args , loc = loc , scale = scale ) if args else distribution . ppf ( 0.01 , loc = loc , scale = scale ) ) end = ( distribution . ppf ( 0.99 , * args , loc = loc , scale = scale ) if args else distribution . ppf ( 0.99 , loc = loc , scale = scale ) ) logger . debug ( \"Building PDF\" ) x = np . linspace ( start , end , size ) y = distribution . pdf ( x , loc = loc , scale = scale , * args ) return pd . Series ( y , x )","title":"Module pyhdtoolkit.maths.stats_fitting"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/#variables","text":"DISTRIBUTIONS","title":"Variables"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/#best_fit_distribution","text":"def best_fit_distribution ( data : Union [ pandas . core . series . Series , numpy . ndarray ], bins : int = 200 , ax : matplotlib . axes . _axes . Axes = None ) -> Tuple [ scipy . stats . _distn_infrastructure . rv_continuous , Tuple [ float , ... ]] Model data by finding best fit candidate distribution among those in DISTRIBUTIONS. Parameters: Name Type Description Default data Union[pd.Series, np.ndarray] a pandas Series or numpy array with your distribution data. None bins int the number of bins to decompose your data in before performing fittings. None ax matplotlib.axes.Axes the matplotlib axis object on which to plot the pdf of tried functions. This should be provided as the ax on which you plotted your distribution. None Returns: Type Description None A tuple containing the scipy.stats generator corresponding to the best fit candidate, and the parameters to give said generator to get this fit. View Source def best_fit_distribution ( data : Union [ pd . Series , np . ndarray ], bins : int = 200 , ax : matplotlib . axes . Axes = None ) -> Tuple [ st . rv_continuous , Tuple [ float , ...]] : \"\"\" Model data by finding best fit candidate distribution among those in DISTRIBUTIONS. Args: data (Union[pd.Series, np.ndarray]): a pandas Series or numpy array with your distribution data. bins (int): the number of bins to decompose your data in before performing fittings. ax (matplotlib.axes.Axes): the matplotlib axis object on which to plot the pdf of tried functions. This should be provided as the ax on which you plotted your distribution. Returns: A tuple containing the scipy.stats generator corresponding to the best fit candidate, and the parameters to give said generator to get this fit. \"\"\" # pylint : disable = too - many - locals logger . debug ( f \"Getting histogram of original data, in {bins} bins\" ) y , x = np . histogram ( data , bins = bins , density = True ) x = ( x + np . roll ( x , - 1 ))[:- 1 ] / 2.0 logger . debug ( \"Creating initial guess\" ) best_distribution = st . norm best_params = ( 0.0 , 1.0 ) best_sse = np . inf # Estimate distribution parameters from data for distribution , distname in DISTRIBUTIONS . items () : try : with warnings . catch_warnings () : # Ignore warnings from data that can't be fit warnings.filterwarnings(\"ignore\") logger.debug(f\"Trying to fit distribution ' { distname } '\") params = distribution.fit(data) *args, loc, scale = params logger.debug(f\"Calculating PDF goodness of fit and error for distribution ' { distname } '\") pdf = distribution.pdf(x, loc=loc, scale=scale, *args) sse = np.sum(np.power(y - pdf, 2.0)) try: if ax: logger.debug(f\"Plotting fitted PDF for distribution ' { distname } '\") pd.Series(pdf, x).plot(ax=ax, label=f\"{distname} fit\", alpha=1, lw=2) except Exception: logger.exception(f\"Plotting distribution ' { distname } ' failed\") logger.debug(f\"Identifying if distribution ' { distname } ' is a better fit than previous tries\") if best_sse > sse > 0: best_distribution = distribution best_params = params best_sse = sse except Exception: logger.exception(f\"Trying to fit distribution ' { distname } ' failed and aborted\") logger.info(f\"Found a best fit: ' { DISTRIBUTIONS [ best_distribution ]} ' distribution \" ) return best_distribution , best_params","title":"best_fit_distribution"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/#make_pdf","text":"def make_pdf ( distribution : scipy . stats . _distn_infrastructure . rv_continuous , params : Tuple [ float , ... ], size : int = 25000 ) -> pandas . core . series . Series Generate a pandas Series for the distributions's Probability Distribution Function. This Series will have axis values as index, and PDF values as values. Parameters: Name Type Description Default distribution st.rv_continuous a scipy.stats generator object None params Tuple[float, ...] the parameters for this generator given back by the fit. None size int the number of points to evaluate. None Returns: Type Description None A pandas Series object with the PDF as values, corresponding axis values as index. View Source def make_pdf ( distribution : st . rv_continuous , params : Tuple [ float , ...], size : int = 25 _000 ) -> pd . Series : \"\"\" Generate a pandas Series for the distributions' s Probability Distribution Function . This Series will have axis values as index , and PDF values as values . Args : distribution ( st . rv_continuous ) : a scipy . stats generator object params ( Tuple [ float , ...]) : the parameters for this generator given back by the fit . size ( int ) : the number of points to evaluate . Returns : A pandas Series object with the PDF as values , corresponding axis values as index . \"\"\" # Separate parts of parameters *args, loc, scale = params logger.debug(\" Getting sane start and end points of distribution \") start = ( distribution.ppf(0.01, *args, loc=loc, scale=scale) if args else distribution.ppf(0.01, loc=loc, scale=scale) ) end = ( distribution.ppf(0.99, *args, loc=loc, scale=scale) if args else distribution.ppf(0.99, loc=loc, scale=scale) ) logger.debug(\" Building PDF \") x = np.linspace(start, end, size) y = distribution.pdf(x, loc=loc, scale=scale, *args) return pd.Series(y, x)","title":"make_pdf"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/#set_distributions_dict","text":"def set_distributions_dict ( dist_dict : Dict [ scipy . stats . _distn_infrastructure . rv_continuous , str ] ) -> None Sets DISTRIBUTIONS as the provided dict. This is useful to define only the ones you want to try out. Parameters: Name Type Description Default dist_dict Dict[st.rv_continuous, str] None dictionnary with the wanted distributions, in the format of DISTRIBUTIONS, aka scipy.stats generator objects as keys, and a string representation of their name as value. None Returns: Type Description None Nothing, but modifies the global DISTRIBUTIONS dict called by other functions. View Source def set_distributions_dict ( dist_dict : Dict [ st . rv_continuous , str ]) -> None : \"\"\" Sets DISTRIBUTIONS as the provided dict. This is useful to define only the ones you want to try out. Args: dist_dict Dict[st.rv_continuous, str]: dictionnary with the wanted distributions, in the format of DISTRIBUTIONS, aka scipy.stats generator objects as keys, and a string representation of their name as value. Returns: Nothing, but modifies the global DISTRIBUTIONS dict called by other functions. \"\"\" # pylint : disable = global - statement logger . debug ( \"Setting tested distributions\" ) global DISTRIBUTIONS DISTRIBUTIONS = dist_dict","title":"set_distributions_dict"},{"location":"reference/pyhdtoolkit/maths/utils/","text":"Module pyhdtoolkit.maths.utils None None View Source from typing import Tuple , Union import numpy as np import pandas as pd from loguru import logger # ----- Miscellaneous Utilites ----- # def get_magnitude ( value : float ) -> int : \"\"\"Return the determined magnitude of the provided value.\"\"\" return int ( np . floor ( np . log10 ( np . abs ( value )))) def get_scaled_values_and_magnitude_string ( values_array : Union [ pd . DataFrame , np . ndarray ], force_magnitude : float = None ) -> Tuple [ Union [ pd . DataFrame , np . ndarray ], str ]: \"\"\" Conveniently scale provided values to the best determined magnitude. Returns scaled values and the magnitude string to use in plots labels. Args: values_array (Union[pd.DataFrame, np.ndarray]): vectorised structure containing the values to scale. force_magnitude (float0: a specific magnitude value to use for the scaling, if desired. Returns: A tuple of the scaled values (same type as the provided ones) and the string to use for the scale in plots labels and legends. Usage: \"\"\" magnitude = get_magnitude ( max ( values_array )) if force_magnitude is None else force_magnitude applied_magnitude = - magnitude logger . trace ( f \"Scaling data by { applied_magnitude } orders of magnitude\" ) scaled_values = values_array * ( 10 ** applied_magnitude ) magnitude_string = \"{\" + f \" { applied_magnitude } \" + \"}\" return scaled_values , magnitude_string Functions get_magnitude def get_magnitude ( value : float ) -> int Return the determined magnitude of the provided value. View Source def get_magnitude ( value : float ) -> int : \"\"\"Return the determined magnitude of the provided value.\"\"\" return int ( np . floor ( np . log10 ( np . abs ( value )))) get_scaled_values_and_magnitude_string def get_scaled_values_and_magnitude_string ( values_array : Union [ pandas . core . frame . DataFrame , numpy . ndarray ], force_magnitude : float = None ) -> Tuple [ Union [ pandas . core . frame . DataFrame , numpy . ndarray ], str ] Conveniently scale provided values to the best determined magnitude. Returns scaled values and the magnitude string to use in plots labels. Parameters: Name Type Description Default values_array Union[pd.DataFrame, np.ndarray] vectorised structure containing the values to scale. None force_magnitude (float0 None a specific magnitude value to use for the scaling, if desired. None Returns: Type Description None A tuple of the scaled values (same type as the provided ones) and the string to use for the scale in plots labels and legends. Usage: | View Source def get_scaled_values_and_magnitude_string ( values_array : Union [ pd . DataFrame , np . ndarray ], force_magnitude : float = None ) -> Tuple [ Union [ pd . DataFrame , np . ndarray ], str ] : \"\"\" Conveniently scale provided values to the best determined magnitude. Returns scaled values and the magnitude string to use in plots labels. Args: values_array (Union[pd.DataFrame, np.ndarray]): vectorised structure containing the values to scale. force_magnitude (float0: a specific magnitude value to use for the scaling, if desired. Returns: A tuple of the scaled values (same type as the provided ones) and the string to use for the scale in plots labels and legends. Usage: \"\"\" magnitude = get_magnitude ( max ( values_array )) if force_magnitude is None else force_magnitude applied_magnitude = - magnitude logger . trace ( f \"Scaling data by {applied_magnitude} orders of magnitude\" ) scaled_values = values_array * ( 10 ** applied_magnitude ) magnitude_string = \"{\" + f \"{applied_magnitude}\" + \"}\" return scaled_values , magnitude_string","title":"Utils"},{"location":"reference/pyhdtoolkit/maths/utils/#module-pyhdtoolkitmathsutils","text":"None None View Source from typing import Tuple , Union import numpy as np import pandas as pd from loguru import logger # ----- Miscellaneous Utilites ----- # def get_magnitude ( value : float ) -> int : \"\"\"Return the determined magnitude of the provided value.\"\"\" return int ( np . floor ( np . log10 ( np . abs ( value )))) def get_scaled_values_and_magnitude_string ( values_array : Union [ pd . DataFrame , np . ndarray ], force_magnitude : float = None ) -> Tuple [ Union [ pd . DataFrame , np . ndarray ], str ]: \"\"\" Conveniently scale provided values to the best determined magnitude. Returns scaled values and the magnitude string to use in plots labels. Args: values_array (Union[pd.DataFrame, np.ndarray]): vectorised structure containing the values to scale. force_magnitude (float0: a specific magnitude value to use for the scaling, if desired. Returns: A tuple of the scaled values (same type as the provided ones) and the string to use for the scale in plots labels and legends. Usage: \"\"\" magnitude = get_magnitude ( max ( values_array )) if force_magnitude is None else force_magnitude applied_magnitude = - magnitude logger . trace ( f \"Scaling data by { applied_magnitude } orders of magnitude\" ) scaled_values = values_array * ( 10 ** applied_magnitude ) magnitude_string = \"{\" + f \" { applied_magnitude } \" + \"}\" return scaled_values , magnitude_string","title":"Module pyhdtoolkit.maths.utils"},{"location":"reference/pyhdtoolkit/maths/utils/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/maths/utils/#get_magnitude","text":"def get_magnitude ( value : float ) -> int Return the determined magnitude of the provided value. View Source def get_magnitude ( value : float ) -> int : \"\"\"Return the determined magnitude of the provided value.\"\"\" return int ( np . floor ( np . log10 ( np . abs ( value ))))","title":"get_magnitude"},{"location":"reference/pyhdtoolkit/maths/utils/#get_scaled_values_and_magnitude_string","text":"def get_scaled_values_and_magnitude_string ( values_array : Union [ pandas . core . frame . DataFrame , numpy . ndarray ], force_magnitude : float = None ) -> Tuple [ Union [ pandas . core . frame . DataFrame , numpy . ndarray ], str ] Conveniently scale provided values to the best determined magnitude. Returns scaled values and the magnitude string to use in plots labels. Parameters: Name Type Description Default values_array Union[pd.DataFrame, np.ndarray] vectorised structure containing the values to scale. None force_magnitude (float0 None a specific magnitude value to use for the scaling, if desired. None Returns: Type Description None A tuple of the scaled values (same type as the provided ones) and the string to use for the scale in plots labels and legends. Usage: | View Source def get_scaled_values_and_magnitude_string ( values_array : Union [ pd . DataFrame , np . ndarray ], force_magnitude : float = None ) -> Tuple [ Union [ pd . DataFrame , np . ndarray ], str ] : \"\"\" Conveniently scale provided values to the best determined magnitude. Returns scaled values and the magnitude string to use in plots labels. Args: values_array (Union[pd.DataFrame, np.ndarray]): vectorised structure containing the values to scale. force_magnitude (float0: a specific magnitude value to use for the scaling, if desired. Returns: A tuple of the scaled values (same type as the provided ones) and the string to use for the scale in plots labels and legends. Usage: \"\"\" magnitude = get_magnitude ( max ( values_array )) if force_magnitude is None else force_magnitude applied_magnitude = - magnitude logger . trace ( f \"Scaling data by {applied_magnitude} orders of magnitude\" ) scaled_values = values_array * ( 10 ** applied_magnitude ) magnitude_string = \"{\" + f \"{applied_magnitude}\" + \"}\" return scaled_values , magnitude_string","title":"get_scaled_values_and_magnitude_string"},{"location":"reference/pyhdtoolkit/optics/","text":"Module pyhdtoolkit.optics optics package ~ ~ ~ ~ ~~ These are miscellaneous utilities to perform optics calculation from simulation outputs. View Source \"\"\" optics package ~~~~~~~~~~~~~~ These are miscellaneous utilities to perform optics calculation from simulation outputs. :copyright: (c) 2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .beam import Beam Sub-modules pyhdtoolkit.optics.beam pyhdtoolkit.optics.ripken pyhdtoolkit.optics.twiss","title":"Index"},{"location":"reference/pyhdtoolkit/optics/#module-pyhdtoolkitoptics","text":"optics package ~ ~ ~ ~ ~~ These are miscellaneous utilities to perform optics calculation from simulation outputs. View Source \"\"\" optics package ~~~~~~~~~~~~~~ These are miscellaneous utilities to perform optics calculation from simulation outputs. :copyright: (c) 2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .beam import Beam","title":"Module pyhdtoolkit.optics"},{"location":"reference/pyhdtoolkit/optics/#sub-modules","text":"pyhdtoolkit.optics.beam pyhdtoolkit.optics.ripken pyhdtoolkit.optics.twiss","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/optics/beam/","text":"Module pyhdtoolkit.optics.beam Module optics.beam Created on 2020.11.11 View Source \"\"\" Module optics.beam ------------------ Created on 2020.11.11 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 module implementing various functionality for simple beam parameter calculations. \"\"\" import numpy as np from scipy import constants class Beam : \"\"\" Class to encompass functionality. \"\"\" def __init__ ( self , energy : float , emittance : float , m0 : float = constants . physical_constants [ \"proton mass energy equivalent in MeV\" ][ 0 ], ) -> None : \"\"\" Args: energy (float): energy of the particles in your beam, in [GeV]. emittance (float): beam emittance, in [m]. m0 (float): rest mass of the beam's particles in MeV. Defaults to that of a proton. \"\"\" self . energy = energy self . emittance = emittance self . rest_mass = m0 @property def gamma_rel ( self ) -> float : \"\"\"Relativistic gamma.\"\"\" return ( 1e3 * self . energy + self . rest_mass ) / self . rest_mass @property def beta_rel ( self ) -> float : \"\"\"Relativistic beta.\"\"\" return np . sqrt ( 1 + 1 / ( self . gamma_rel ** 2 )) @property def brho ( self ) -> float : \"\"\"Beam rigidity [T/m].\"\"\" return ( 1 / 0.3 ) * self . beta_rel * self . energy / constants . c @property def normalized_emittance ( self ) -> float : \"\"\" Normalized emittance [m]. \"\"\" return self . emittance * self . beta_rel * self . gamma_rel @property def rms_emittance ( self ) -> float : \"\"\" Rms emittance [m]. \"\"\" return self . emittance / ( self . beta_rel * self . gamma_rel ) def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = constants . c ) -> float : \"\"\" Revolution frequency. Args: circumference (float): the machine circumference in [m]. Defaults to that of the LHC. speed (float): the particles' speed in the machine, in [m/s]. Defaults to c. \"\"\" return self . beta_rel * speed / circumference def eta ( self , alpha_p : float ) -> float : \"\"\" Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Args: alpha_p (float): momentum compaction factor. \"\"\" return ( 1 / ( self . gamma_rel ** 2 )) - alpha_p @staticmethod def gamma_transition ( alpha_p : float ) -> float : \"\"\" Relativistic gamma corresponding to the transition energy. Args: alpha_p (float): momentum compaction factor. \"\"\" return np . sqrt ( 1 / alpha_p ) Classes Beam class Beam ( energy : float , emittance : float , m0 : float = 938.27208816 ) View Source class Beam : \"\"\" Class to encompass functionality. \"\"\" def __init__ ( self , energy : float , emittance : float , m0 : float = constants . physical_constants [ \"proton mass energy equivalent in MeV\" ][ 0 ] , ) -> None : \"\"\" Args: energy (float): energy of the particles in your beam, in [GeV]. emittance (float): beam emittance, in [m]. m0 (float): rest mass of the beam's particles in MeV. Defaults to that of a proton. \"\"\" self . energy = energy self . emittance = emittance self . rest_mass = m0 @property def gamma_rel ( self ) -> float : \"\"\"Relativistic gamma.\"\"\" return ( 1e3 * self . energy + self . rest_mass ) / self . rest_mass @property def beta_rel ( self ) -> float : \"\"\"Relativistic beta.\"\"\" return np . sqrt ( 1 + 1 / ( self . gamma_rel ** 2 )) @property def brho ( self ) -> float : \"\"\"Beam rigidity [T/m].\"\"\" return ( 1 / 0.3 ) * self . beta_rel * self . energy / constants . c @property def normalized_emittance ( self ) -> float : \"\"\" Normalized emittance [m]. \"\"\" return self . emittance * self . beta_rel * self . gamma_rel @property def rms_emittance ( self ) -> float : \"\"\" Rms emittance [m]. \"\"\" return self . emittance / ( self . beta_rel * self . gamma_rel ) def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = constants . c ) -> float : \"\"\" Revolution frequency. Args: circumference (float): the machine circumference in [m]. Defaults to that of the LHC. speed (float): the particles' speed in the machine, in [m/s]. Defaults to c. \"\"\" return self . beta_rel * speed / circumference def eta ( self , alpha_p : float ) -> float : \"\"\" Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Args: alpha_p (float): momentum compaction factor. \"\"\" return ( 1 / ( self . gamma_rel ** 2 )) - alpha_p @staticmethod def gamma_transition ( alpha_p : float ) -> float : \"\"\" Relativistic gamma corresponding to the transition energy. Args: alpha_p (float): momentum compaction factor. \"\"\" return np . sqrt ( 1 / alpha_p ) Static methods gamma_transition def gamma_transition ( alpha_p : float ) -> float Relativistic gamma corresponding to the transition energy. Parameters: Name Type Description Default alpha_p float momentum compaction factor. None View Source @staticmethod def gamma_transition ( alpha_p : float ) -> float : \"\"\" Relativistic gamma corresponding to the transition energy. Args: alpha_p (float): momentum compaction factor. \"\"\" return np . sqrt ( 1 / alpha_p ) Instance variables beta_rel Relativistic beta. brho Beam rigidity [T/m]. gamma_rel Relativistic gamma. normalized_emittance Normalized emittance [m]. rms_emittance Rms emittance [m]. Methods eta def eta ( self , alpha_p : float ) -> float Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Parameters: Name Type Description Default alpha_p float momentum compaction factor. None View Source def eta ( self , alpha_p : float ) -> float : \"\"\" Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Args: alpha_p (float): momentum compaction factor. \"\"\" return ( 1 / ( self . gamma_rel ** 2 )) - alpha_p revolution_frequency def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = 299792458.0 ) -> float Revolution frequency. Parameters: Name Type Description Default circumference float the machine circumference in [m]. Defaults to that of the LHC. that of the LHC speed float the particles' speed in the machine, in [m/s]. Defaults to c. c View Source def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = constants . c ) -> float : \"\"\" Revolution frequency. Args: circumference (float): the machine circumference in [m]. Defaults to that of the LHC. speed (float): the particles' speed in the machine, in [m/s]. Defaults to c. \"\"\" return self . beta_rel * speed / circumference","title":"Beam"},{"location":"reference/pyhdtoolkit/optics/beam/#module-pyhdtoolkitopticsbeam","text":"Module optics.beam Created on 2020.11.11 View Source \"\"\" Module optics.beam ------------------ Created on 2020.11.11 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 module implementing various functionality for simple beam parameter calculations. \"\"\" import numpy as np from scipy import constants class Beam : \"\"\" Class to encompass functionality. \"\"\" def __init__ ( self , energy : float , emittance : float , m0 : float = constants . physical_constants [ \"proton mass energy equivalent in MeV\" ][ 0 ], ) -> None : \"\"\" Args: energy (float): energy of the particles in your beam, in [GeV]. emittance (float): beam emittance, in [m]. m0 (float): rest mass of the beam's particles in MeV. Defaults to that of a proton. \"\"\" self . energy = energy self . emittance = emittance self . rest_mass = m0 @property def gamma_rel ( self ) -> float : \"\"\"Relativistic gamma.\"\"\" return ( 1e3 * self . energy + self . rest_mass ) / self . rest_mass @property def beta_rel ( self ) -> float : \"\"\"Relativistic beta.\"\"\" return np . sqrt ( 1 + 1 / ( self . gamma_rel ** 2 )) @property def brho ( self ) -> float : \"\"\"Beam rigidity [T/m].\"\"\" return ( 1 / 0.3 ) * self . beta_rel * self . energy / constants . c @property def normalized_emittance ( self ) -> float : \"\"\" Normalized emittance [m]. \"\"\" return self . emittance * self . beta_rel * self . gamma_rel @property def rms_emittance ( self ) -> float : \"\"\" Rms emittance [m]. \"\"\" return self . emittance / ( self . beta_rel * self . gamma_rel ) def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = constants . c ) -> float : \"\"\" Revolution frequency. Args: circumference (float): the machine circumference in [m]. Defaults to that of the LHC. speed (float): the particles' speed in the machine, in [m/s]. Defaults to c. \"\"\" return self . beta_rel * speed / circumference def eta ( self , alpha_p : float ) -> float : \"\"\" Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Args: alpha_p (float): momentum compaction factor. \"\"\" return ( 1 / ( self . gamma_rel ** 2 )) - alpha_p @staticmethod def gamma_transition ( alpha_p : float ) -> float : \"\"\" Relativistic gamma corresponding to the transition energy. Args: alpha_p (float): momentum compaction factor. \"\"\" return np . sqrt ( 1 / alpha_p )","title":"Module pyhdtoolkit.optics.beam"},{"location":"reference/pyhdtoolkit/optics/beam/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/optics/beam/#beam","text":"class Beam ( energy : float , emittance : float , m0 : float = 938.27208816 ) View Source class Beam : \"\"\" Class to encompass functionality. \"\"\" def __init__ ( self , energy : float , emittance : float , m0 : float = constants . physical_constants [ \"proton mass energy equivalent in MeV\" ][ 0 ] , ) -> None : \"\"\" Args: energy (float): energy of the particles in your beam, in [GeV]. emittance (float): beam emittance, in [m]. m0 (float): rest mass of the beam's particles in MeV. Defaults to that of a proton. \"\"\" self . energy = energy self . emittance = emittance self . rest_mass = m0 @property def gamma_rel ( self ) -> float : \"\"\"Relativistic gamma.\"\"\" return ( 1e3 * self . energy + self . rest_mass ) / self . rest_mass @property def beta_rel ( self ) -> float : \"\"\"Relativistic beta.\"\"\" return np . sqrt ( 1 + 1 / ( self . gamma_rel ** 2 )) @property def brho ( self ) -> float : \"\"\"Beam rigidity [T/m].\"\"\" return ( 1 / 0.3 ) * self . beta_rel * self . energy / constants . c @property def normalized_emittance ( self ) -> float : \"\"\" Normalized emittance [m]. \"\"\" return self . emittance * self . beta_rel * self . gamma_rel @property def rms_emittance ( self ) -> float : \"\"\" Rms emittance [m]. \"\"\" return self . emittance / ( self . beta_rel * self . gamma_rel ) def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = constants . c ) -> float : \"\"\" Revolution frequency. Args: circumference (float): the machine circumference in [m]. Defaults to that of the LHC. speed (float): the particles' speed in the machine, in [m/s]. Defaults to c. \"\"\" return self . beta_rel * speed / circumference def eta ( self , alpha_p : float ) -> float : \"\"\" Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Args: alpha_p (float): momentum compaction factor. \"\"\" return ( 1 / ( self . gamma_rel ** 2 )) - alpha_p @staticmethod def gamma_transition ( alpha_p : float ) -> float : \"\"\" Relativistic gamma corresponding to the transition energy. Args: alpha_p (float): momentum compaction factor. \"\"\" return np . sqrt ( 1 / alpha_p )","title":"Beam"},{"location":"reference/pyhdtoolkit/optics/beam/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/optics/beam/#gamma_transition","text":"def gamma_transition ( alpha_p : float ) -> float Relativistic gamma corresponding to the transition energy. Parameters: Name Type Description Default alpha_p float momentum compaction factor. None View Source @staticmethod def gamma_transition ( alpha_p : float ) -> float : \"\"\" Relativistic gamma corresponding to the transition energy. Args: alpha_p (float): momentum compaction factor. \"\"\" return np . sqrt ( 1 / alpha_p )","title":"gamma_transition"},{"location":"reference/pyhdtoolkit/optics/beam/#instance-variables","text":"beta_rel Relativistic beta. brho Beam rigidity [T/m]. gamma_rel Relativistic gamma. normalized_emittance Normalized emittance [m]. rms_emittance Rms emittance [m].","title":"Instance variables"},{"location":"reference/pyhdtoolkit/optics/beam/#methods","text":"","title":"Methods"},{"location":"reference/pyhdtoolkit/optics/beam/#eta","text":"def eta ( self , alpha_p : float ) -> float Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Parameters: Name Type Description Default alpha_p float momentum compaction factor. None View Source def eta ( self , alpha_p : float ) -> float : \"\"\" Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Args: alpha_p (float): momentum compaction factor. \"\"\" return ( 1 / ( self . gamma_rel ** 2 )) - alpha_p","title":"eta"},{"location":"reference/pyhdtoolkit/optics/beam/#revolution_frequency","text":"def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = 299792458.0 ) -> float Revolution frequency. Parameters: Name Type Description Default circumference float the machine circumference in [m]. Defaults to that of the LHC. that of the LHC speed float the particles' speed in the machine, in [m/s]. Defaults to c. c View Source def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = constants . c ) -> float : \"\"\" Revolution frequency. Args: circumference (float): the machine circumference in [m]. Defaults to that of the LHC. speed (float): the particles' speed in the machine, in [m/s]. Defaults to c. \"\"\" return self . beta_rel * speed / circumference","title":"revolution_frequency"},{"location":"reference/pyhdtoolkit/optics/ripken/","text":"Module pyhdtoolkit.optics.ripken None None View Source from typing import Union import numba import numpy as np from loguru import logger # ----- Setup Utilites ----- # def lebedev_beam_size ( beta1_ : Union [ float , np . ndarray ], beta2_ : Union [ float , np . ndarray ], geom_emit_x : float , geom_emit_y : float ) -> Union [ float , np . ndarray ]: \"\"\" Calculate beam size according to the Lebedev-bogacz formula, based on the Ripken-Mais Twiss parameters. The implementation is that of Eq. (A.3.1) in FERMILAB-PUB-10-383-AD, avaliable at the following link: https://arxiv.org/ftp/arxiv/papers/1207/1207.5526.pdf Args: beta1_ (Union[float, np.ndarray]): value(s) for the beta1x or beta1y Ripken parameter. beta2_ (Union[float, np.ndarray]): value(s) for the beta2x or beta2y Ripken parameter. geom_emit_x (float): geometric emittance of the horizontal plane. geom_emit_y (float): geometric emittante of the vertical plane. Returns: The beam size (horizontal or vertical) according to Lebedev & Bogacz, as sqrt(epsx * beta1_^2 + epsy * beta2_^2). \"\"\" logger . trace ( \"Computing beam size according to Lebedev formula: sqrt(epsx * b1_^2 + epsy * b2_^2)\" ) return np . sqrt ( geom_emit_x * beta1_ + geom_emit_y * beta2_ ) # ----- JITed Calculations ----- # @numba . njit () def _beam_size ( coordinates_distribution : np . ndarray , method : str = \"std\" ) -> float : \"\"\" Compute beam size from particle coordinates. Args: coordinates_distribution (np.ndarray): ensemble of coordinates of the particle distributon. method (str): the method of calculation to use, either 'std' (using the standard deviation as the beam size) or 'rms' (root mean square). Returns: The computed beam size. \"\"\" if method == \"std\" : return coordinates_distribution . std () elif method == \"rms\" : return np . sqrt ( np . mean ( np . square ( coordinates_distribution ))) raise NotImplementedError ( f \"Invalid method provided\" ) Functions lebedev_beam_size def lebedev_beam_size ( beta1_ : Union [ float , numpy . ndarray ], beta2_ : Union [ float , numpy . ndarray ], geom_emit_x : float , geom_emit_y : float ) -> Union [ float , numpy . ndarray ] Calculate beam size according to the Lebedev-bogacz formula, based on the Ripken-Mais Twiss parameters. The implementation is that of Eq. (A.3.1) in FERMILAB-PUB-10-383-AD, avaliable at the following link: https://arxiv.org/ftp/arxiv/papers/1207/1207.5526.pdf Parameters: Name Type Description Default beta1_ Union[float, np.ndarray] value(s) for the beta1x or beta1y Ripken parameter. None beta2_ Union[float, np.ndarray] value(s) for the beta2x or beta2y Ripken parameter. None geom_emit_x float geometric emittance of the horizontal plane. None geom_emit_y float geometric emittante of the vertical plane. None Returns: Type Description None The beam size (horizontal or vertical) according to Lebedev & Bogacz, as sqrt(epsx * beta1_^2 + epsy * beta2_^2). View Source def lebedev_beam_size ( beta1_ : Union [ float , np . ndarray ], beta2_ : Union [ float , np . ndarray ], geom_emit_x : float , geom_emit_y : float ) -> Union [ float , np . ndarray ] : \"\"\" Calculate beam size according to the Lebedev-bogacz formula, based on the Ripken-Mais Twiss parameters. The implementation is that of Eq. (A.3.1) in FERMILAB-PUB-10-383-AD, avaliable at the following link: https://arxiv.org/ftp/arxiv/papers/1207/1207.5526.pdf Args: beta1_ (Union[float, np.ndarray]): value(s) for the beta1x or beta1y Ripken parameter. beta2_ (Union[float, np.ndarray]): value(s) for the beta2x or beta2y Ripken parameter. geom_emit_x (float): geometric emittance of the horizontal plane. geom_emit_y (float): geometric emittante of the vertical plane. Returns: The beam size (horizontal or vertical) according to Lebedev & Bogacz, as sqrt(epsx * beta1_^2 + epsy * beta2_^2). \"\"\" logger . trace ( \"Computing beam size according to Lebedev formula: sqrt(epsx * b1_^2 + epsy * b2_^2)\" ) return np . sqrt ( geom_emit_x * beta1_ + geom_emit_y * beta2_ )","title":"Ripken"},{"location":"reference/pyhdtoolkit/optics/ripken/#module-pyhdtoolkitopticsripken","text":"None None View Source from typing import Union import numba import numpy as np from loguru import logger # ----- Setup Utilites ----- # def lebedev_beam_size ( beta1_ : Union [ float , np . ndarray ], beta2_ : Union [ float , np . ndarray ], geom_emit_x : float , geom_emit_y : float ) -> Union [ float , np . ndarray ]: \"\"\" Calculate beam size according to the Lebedev-bogacz formula, based on the Ripken-Mais Twiss parameters. The implementation is that of Eq. (A.3.1) in FERMILAB-PUB-10-383-AD, avaliable at the following link: https://arxiv.org/ftp/arxiv/papers/1207/1207.5526.pdf Args: beta1_ (Union[float, np.ndarray]): value(s) for the beta1x or beta1y Ripken parameter. beta2_ (Union[float, np.ndarray]): value(s) for the beta2x or beta2y Ripken parameter. geom_emit_x (float): geometric emittance of the horizontal plane. geom_emit_y (float): geometric emittante of the vertical plane. Returns: The beam size (horizontal or vertical) according to Lebedev & Bogacz, as sqrt(epsx * beta1_^2 + epsy * beta2_^2). \"\"\" logger . trace ( \"Computing beam size according to Lebedev formula: sqrt(epsx * b1_^2 + epsy * b2_^2)\" ) return np . sqrt ( geom_emit_x * beta1_ + geom_emit_y * beta2_ ) # ----- JITed Calculations ----- # @numba . njit () def _beam_size ( coordinates_distribution : np . ndarray , method : str = \"std\" ) -> float : \"\"\" Compute beam size from particle coordinates. Args: coordinates_distribution (np.ndarray): ensemble of coordinates of the particle distributon. method (str): the method of calculation to use, either 'std' (using the standard deviation as the beam size) or 'rms' (root mean square). Returns: The computed beam size. \"\"\" if method == \"std\" : return coordinates_distribution . std () elif method == \"rms\" : return np . sqrt ( np . mean ( np . square ( coordinates_distribution ))) raise NotImplementedError ( f \"Invalid method provided\" )","title":"Module pyhdtoolkit.optics.ripken"},{"location":"reference/pyhdtoolkit/optics/ripken/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/optics/ripken/#lebedev_beam_size","text":"def lebedev_beam_size ( beta1_ : Union [ float , numpy . ndarray ], beta2_ : Union [ float , numpy . ndarray ], geom_emit_x : float , geom_emit_y : float ) -> Union [ float , numpy . ndarray ] Calculate beam size according to the Lebedev-bogacz formula, based on the Ripken-Mais Twiss parameters. The implementation is that of Eq. (A.3.1) in FERMILAB-PUB-10-383-AD, avaliable at the following link: https://arxiv.org/ftp/arxiv/papers/1207/1207.5526.pdf Parameters: Name Type Description Default beta1_ Union[float, np.ndarray] value(s) for the beta1x or beta1y Ripken parameter. None beta2_ Union[float, np.ndarray] value(s) for the beta2x or beta2y Ripken parameter. None geom_emit_x float geometric emittance of the horizontal plane. None geom_emit_y float geometric emittante of the vertical plane. None Returns: Type Description None The beam size (horizontal or vertical) according to Lebedev & Bogacz, as sqrt(epsx * beta1_^2 + epsy * beta2_^2). View Source def lebedev_beam_size ( beta1_ : Union [ float , np . ndarray ], beta2_ : Union [ float , np . ndarray ], geom_emit_x : float , geom_emit_y : float ) -> Union [ float , np . ndarray ] : \"\"\" Calculate beam size according to the Lebedev-bogacz formula, based on the Ripken-Mais Twiss parameters. The implementation is that of Eq. (A.3.1) in FERMILAB-PUB-10-383-AD, avaliable at the following link: https://arxiv.org/ftp/arxiv/papers/1207/1207.5526.pdf Args: beta1_ (Union[float, np.ndarray]): value(s) for the beta1x or beta1y Ripken parameter. beta2_ (Union[float, np.ndarray]): value(s) for the beta2x or beta2y Ripken parameter. geom_emit_x (float): geometric emittance of the horizontal plane. geom_emit_y (float): geometric emittante of the vertical plane. Returns: The beam size (horizontal or vertical) according to Lebedev & Bogacz, as sqrt(epsx * beta1_^2 + epsy * beta2_^2). \"\"\" logger . trace ( \"Computing beam size according to Lebedev formula: sqrt(epsx * b1_^2 + epsy * b2_^2)\" ) return np . sqrt ( geom_emit_x * beta1_ + geom_emit_y * beta2_ )","title":"lebedev_beam_size"},{"location":"reference/pyhdtoolkit/optics/twiss/","text":"Module pyhdtoolkit.optics.twiss Module optics.twiss Created on 2020.09.07 View Source \"\"\" Module optics.twiss ------------------- Created on 2020.09.07 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 module implementing various functionality for optics calculations from / to twiss parameters. \"\"\" import numba import numpy as np @numba . njit () def courant_snyder_transform ( u_vector : np . ndarray , alpha : float , beta : float ) -> np . ndarray : \"\"\" Perform the Courant-Snyder transform on rergular (nonchaotic) phase-space coordinatess. Specifically, if considering the horizontal plane and noting U = (x, px) the phase-space vector, it returns U_bar = (x_bar, px_bar) according to the transform: U_bar = P * U, where P = [1/sqrt(beta_x) 0 ] [alpha_x/sqrt(beta_x) sqrt(beta_x)] Args: u_vector (np.ndarray): two-dimentional array of phase-space (spatial and momenta) coordinates, either horizontal or vertical. alpha (float): alpha twiss parameter in the appropriate plane. beta (float): beta twiss parameter in the appropriate plane. Returns: The normal phase-space coordinates from the Courant-Snyder transform. \"\"\" p_matrix = np . array ([[ 1 / np . sqrt ( beta ), 0 ], [ alpha / np . sqrt ( beta ), np . sqrt ( beta )]]) return p_matrix @ u_vector Functions courant_snyder_transform def courant_snyder_transform ( u_vector : numpy . ndarray , alpha : float , beta : float ) -> numpy . ndarray Perform the Courant-Snyder transform on rergular (nonchaotic) phase-space coordinatess. Specifically, if considering the horizontal plane and noting U = (x, px) the phase-space vector, it returns U_bar = (x_bar, px_bar) according to the transform: U_bar = P * U, where P = [1/sqrt(beta_x) 0 ] [alpha_x/sqrt(beta_x) sqrt(beta_x)] Parameters: Name Type Description Default u_vector np.ndarray two-dimentional array of phase-space (spatial and momenta) coordinates, either horizontal or vertical. None alpha float alpha twiss parameter in the appropriate plane. None beta float beta twiss parameter in the appropriate plane. None Returns: Type Description None The normal phase-space coordinates from the Courant-Snyder transform. View Source @numba . njit () def courant_snyder_transform ( u_vector : np . ndarray , alpha : float , beta : float ) -> np . ndarray : \"\"\" Perform the Courant-Snyder transform on rergular (nonchaotic) phase-space coordinatess. Specifically, if considering the horizontal plane and noting U = (x, px) the phase-space vector, it returns U_bar = (x_bar, px_bar) according to the transform: U_bar = P * U, where P = [1/sqrt(beta_x) 0 ] [alpha_x/sqrt(beta_x) sqrt(beta_x)] Args: u_vector (np.ndarray): two-dimentional array of phase-space (spatial and momenta) coordinates, either horizontal or vertical. alpha (float): alpha twiss parameter in the appropriate plane. beta (float): beta twiss parameter in the appropriate plane. Returns: The normal phase-space coordinates from the Courant-Snyder transform. \"\"\" p_matrix = np . array ( [ [1 / np.sqrt(beta), 0 ] , [ alpha / np.sqrt(beta), np.sqrt(beta) ] ] ) return p_matrix @ u_vector","title":"Twiss"},{"location":"reference/pyhdtoolkit/optics/twiss/#module-pyhdtoolkitopticstwiss","text":"Module optics.twiss Created on 2020.09.07 View Source \"\"\" Module optics.twiss ------------------- Created on 2020.09.07 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 module implementing various functionality for optics calculations from / to twiss parameters. \"\"\" import numba import numpy as np @numba . njit () def courant_snyder_transform ( u_vector : np . ndarray , alpha : float , beta : float ) -> np . ndarray : \"\"\" Perform the Courant-Snyder transform on rergular (nonchaotic) phase-space coordinatess. Specifically, if considering the horizontal plane and noting U = (x, px) the phase-space vector, it returns U_bar = (x_bar, px_bar) according to the transform: U_bar = P * U, where P = [1/sqrt(beta_x) 0 ] [alpha_x/sqrt(beta_x) sqrt(beta_x)] Args: u_vector (np.ndarray): two-dimentional array of phase-space (spatial and momenta) coordinates, either horizontal or vertical. alpha (float): alpha twiss parameter in the appropriate plane. beta (float): beta twiss parameter in the appropriate plane. Returns: The normal phase-space coordinates from the Courant-Snyder transform. \"\"\" p_matrix = np . array ([[ 1 / np . sqrt ( beta ), 0 ], [ alpha / np . sqrt ( beta ), np . sqrt ( beta )]]) return p_matrix @ u_vector","title":"Module pyhdtoolkit.optics.twiss"},{"location":"reference/pyhdtoolkit/optics/twiss/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/optics/twiss/#courant_snyder_transform","text":"def courant_snyder_transform ( u_vector : numpy . ndarray , alpha : float , beta : float ) -> numpy . ndarray Perform the Courant-Snyder transform on rergular (nonchaotic) phase-space coordinatess. Specifically, if considering the horizontal plane and noting U = (x, px) the phase-space vector, it returns U_bar = (x_bar, px_bar) according to the transform: U_bar = P * U, where P = [1/sqrt(beta_x) 0 ] [alpha_x/sqrt(beta_x) sqrt(beta_x)] Parameters: Name Type Description Default u_vector np.ndarray two-dimentional array of phase-space (spatial and momenta) coordinates, either horizontal or vertical. None alpha float alpha twiss parameter in the appropriate plane. None beta float beta twiss parameter in the appropriate plane. None Returns: Type Description None The normal phase-space coordinates from the Courant-Snyder transform. View Source @numba . njit () def courant_snyder_transform ( u_vector : np . ndarray , alpha : float , beta : float ) -> np . ndarray : \"\"\" Perform the Courant-Snyder transform on rergular (nonchaotic) phase-space coordinatess. Specifically, if considering the horizontal plane and noting U = (x, px) the phase-space vector, it returns U_bar = (x_bar, px_bar) according to the transform: U_bar = P * U, where P = [1/sqrt(beta_x) 0 ] [alpha_x/sqrt(beta_x) sqrt(beta_x)] Args: u_vector (np.ndarray): two-dimentional array of phase-space (spatial and momenta) coordinates, either horizontal or vertical. alpha (float): alpha twiss parameter in the appropriate plane. beta (float): beta twiss parameter in the appropriate plane. Returns: The normal phase-space coordinates from the Courant-Snyder transform. \"\"\" p_matrix = np . array ( [ [1 / np.sqrt(beta), 0 ] , [ alpha / np.sqrt(beta), np.sqrt(beta) ] ] ) return p_matrix @ u_vector","title":"courant_snyder_transform"},{"location":"reference/pyhdtoolkit/plotting/","text":"Module pyhdtoolkit.plotting plotting package ~ ~ ~ ~ ~ ~ ~ These are miscellaneous utilities to integrate to my plots. View Source \"\"\" plotting package ~~~~~~~~~~~~~~~~~~~ These are miscellaneous utilities to integrate to my plots. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .helpers import AnnotationsPlotter Sub-modules pyhdtoolkit.plotting.helpers","title":"Index"},{"location":"reference/pyhdtoolkit/plotting/#module-pyhdtoolkitplotting","text":"plotting package ~ ~ ~ ~ ~ ~ ~ These are miscellaneous utilities to integrate to my plots. View Source \"\"\" plotting package ~~~~~~~~~~~~~~~~~~~ These are miscellaneous utilities to integrate to my plots. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .helpers import AnnotationsPlotter","title":"Module pyhdtoolkit.plotting"},{"location":"reference/pyhdtoolkit/plotting/#sub-modules","text":"pyhdtoolkit.plotting.helpers","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/plotting/helpers/","text":"Module pyhdtoolkit.plotting.helpers Module plotting.helpers Created on 2019.06.15 View Source \"\"\" Module plotting.helpers ----------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions for more descriptive plots. \"\"\" from typing import Tuple import matplotlib.axes class AnnotationsPlotter : \"\"\" A class to encapsulate all useful plotting additional tidbits. \"\"\" @staticmethod def set_arrow_label ( axis : matplotlib . axes . Axes , label : str , arrow_position : Tuple [ float , float ], label_position : Tuple [ float , float ], color : str = \"k\" , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 , ** kwargs , ) -> matplotlib . text . Annotation : \"\"\" Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes `Axes` instance. Original code from Guido Sterbini. Args: axis (matplotlib.axes.Axes): a matplotlib axis to plot on. label (str): label text to print on the axis. arrow_position (Tuple[float, float]): where on the plot to point the tip of the arrow. label_position (Tuple[float, float]): where on the plot the text label (and thus start of the arrow) is. color (str): color parameter for your arrow and label. Defaults to 'k'. arrow_arc_rad (float): angle value defining the upwards / downwards shape of and bending of the arrow. fontsize (int): text size in the box Returns: A matploblit text annotation object. \"\"\" return axis . annotate ( label , xy = arrow_position , xycoords = \"data\" , xytext = label_position , textcoords = \"data\" , size = fontsize , color = color , va = \"center\" , ha = \"center\" , bbox = dict ( boxstyle = \"round4\" , fc = \"w\" , color = color , lw = 2 ), arrowprops = dict ( arrowstyle = \"-|>\" , connectionstyle = \"arc3,rad=\" + str ( arrow_arc_rad ), fc = \"w\" , color = color , lw = 2 , ), ** kwargs , ) Classes AnnotationsPlotter class AnnotationsPlotter ( / , * args , ** kwargs ) View Source class AnnotationsPlotter : \" \"\" A class to encapsulate all useful plotting additional tidbits. \"\" \" @staticmethod def set _arrow_label ( axis : matplotlib . axes . Axes , label : str , arrow_position : Tuple [ float , float ] , label_position : Tuple [ float , float ] , color : str = \"k\" , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 , ** kwargs , ) -> matplotlib . text . Annotation : \" \"\" Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes `Axes` instance. Original code from Guido Sterbini. Args: axis (matplotlib.axes.Axes): a matplotlib axis to plot on. label (str): label text to print on the axis. arrow_position (Tuple[float, float]): where on the plot to point the tip of the arrow. label_position (Tuple[float, float]): where on the plot the text label (and thus start of the arrow) is. color (str): color parameter for your arrow and label. Defaults to 'k'. arrow_arc_rad (float): angle value defining the upwards / downwards shape of and bending of the arrow. fontsize (int): text size in the box Returns: A matploblit text annotation object. \"\" \" return axis . annotate ( label , xy = arrow_position , xycoords = \"data\" , xytext = label_position , textcoords = \"data\" , size = fontsize , color = color , va = \"center\" , ha = \"center\" , bbox = dict ( boxstyle = \"round4\" , fc = \"w\" , color = color , lw = 2 ), arrowprops = dict ( arrowstyle = \"-|>\" , connectionstyle = \"arc3,rad=\" + str ( arrow_arc_rad ), fc = \"w\" , color = color , lw = 2 , ), ** kwargs , ) Static methods set_arrow_label def set_arrow_label ( axis : matplotlib . axes . _axes . Axes , label : str , arrow_position : Tuple [ float , float ], label_position : Tuple [ float , float ], color : str = 'k' , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 , ** kwargs ) -> matplotlib . text . Annotation Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes Axes instance. Original code from Guido Sterbini. Parameters: Name Type Description Default axis matplotlib.axes.Axes a matplotlib axis to plot on. None label str label text to print on the axis. None arrow_position Tuple[float, float] where on the plot to point the tip of the arrow. None label_position Tuple[float, float] where on the plot the text label (and thus start of the arrow) is. None color str color parameter for your arrow and label. Defaults to 'k'. 'k' arrow_arc_rad float angle value defining the upwards / downwards shape of and bending of the arrow. None fontsize int text size in the box None Returns: Type Description None A matploblit text annotation object. View Source @staticmethod def set _arrow_label ( axis : matplotlib . axes . Axes , label : str , arrow_position : Tuple [ float , float ] , label_position : Tuple [ float , float ] , color : str = \"k\" , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 , ** kwargs , ) -> matplotlib . text . Annotation : \" \"\" Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes `Axes` instance. Original code from Guido Sterbini. Args: axis (matplotlib.axes.Axes): a matplotlib axis to plot on. label (str): label text to print on the axis. arrow_position (Tuple[float, float]): where on the plot to point the tip of the arrow. label_position (Tuple[float, float]): where on the plot the text label (and thus start of the arrow) is. color (str): color parameter for your arrow and label. Defaults to 'k'. arrow_arc_rad (float): angle value defining the upwards / downwards shape of and bending of the arrow. fontsize (int): text size in the box Returns: A matploblit text annotation object. \"\" \" return axis . annotate ( label , xy = arrow_position , xycoords = \"data\" , xytext = label_position , textcoords = \"data\" , size = fontsize , color = color , va = \"center\" , ha = \"center\" , bbox = dict ( boxstyle = \"round4\" , fc = \"w\" , color = color , lw = 2 ), arrowprops = dict ( arrowstyle = \"-|>\" , connectionstyle = \"arc3,rad=\" + str ( arrow_arc_rad ), fc = \"w\" , color = color , lw = 2 , ), ** kwargs , )","title":"Helpers"},{"location":"reference/pyhdtoolkit/plotting/helpers/#module-pyhdtoolkitplottinghelpers","text":"Module plotting.helpers Created on 2019.06.15 View Source \"\"\" Module plotting.helpers ----------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions for more descriptive plots. \"\"\" from typing import Tuple import matplotlib.axes class AnnotationsPlotter : \"\"\" A class to encapsulate all useful plotting additional tidbits. \"\"\" @staticmethod def set_arrow_label ( axis : matplotlib . axes . Axes , label : str , arrow_position : Tuple [ float , float ], label_position : Tuple [ float , float ], color : str = \"k\" , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 , ** kwargs , ) -> matplotlib . text . Annotation : \"\"\" Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes `Axes` instance. Original code from Guido Sterbini. Args: axis (matplotlib.axes.Axes): a matplotlib axis to plot on. label (str): label text to print on the axis. arrow_position (Tuple[float, float]): where on the plot to point the tip of the arrow. label_position (Tuple[float, float]): where on the plot the text label (and thus start of the arrow) is. color (str): color parameter for your arrow and label. Defaults to 'k'. arrow_arc_rad (float): angle value defining the upwards / downwards shape of and bending of the arrow. fontsize (int): text size in the box Returns: A matploblit text annotation object. \"\"\" return axis . annotate ( label , xy = arrow_position , xycoords = \"data\" , xytext = label_position , textcoords = \"data\" , size = fontsize , color = color , va = \"center\" , ha = \"center\" , bbox = dict ( boxstyle = \"round4\" , fc = \"w\" , color = color , lw = 2 ), arrowprops = dict ( arrowstyle = \"-|>\" , connectionstyle = \"arc3,rad=\" + str ( arrow_arc_rad ), fc = \"w\" , color = color , lw = 2 , ), ** kwargs , )","title":"Module pyhdtoolkit.plotting.helpers"},{"location":"reference/pyhdtoolkit/plotting/helpers/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/plotting/helpers/#annotationsplotter","text":"class AnnotationsPlotter ( / , * args , ** kwargs ) View Source class AnnotationsPlotter : \" \"\" A class to encapsulate all useful plotting additional tidbits. \"\" \" @staticmethod def set _arrow_label ( axis : matplotlib . axes . Axes , label : str , arrow_position : Tuple [ float , float ] , label_position : Tuple [ float , float ] , color : str = \"k\" , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 , ** kwargs , ) -> matplotlib . text . Annotation : \" \"\" Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes `Axes` instance. Original code from Guido Sterbini. Args: axis (matplotlib.axes.Axes): a matplotlib axis to plot on. label (str): label text to print on the axis. arrow_position (Tuple[float, float]): where on the plot to point the tip of the arrow. label_position (Tuple[float, float]): where on the plot the text label (and thus start of the arrow) is. color (str): color parameter for your arrow and label. Defaults to 'k'. arrow_arc_rad (float): angle value defining the upwards / downwards shape of and bending of the arrow. fontsize (int): text size in the box Returns: A matploblit text annotation object. \"\" \" return axis . annotate ( label , xy = arrow_position , xycoords = \"data\" , xytext = label_position , textcoords = \"data\" , size = fontsize , color = color , va = \"center\" , ha = \"center\" , bbox = dict ( boxstyle = \"round4\" , fc = \"w\" , color = color , lw = 2 ), arrowprops = dict ( arrowstyle = \"-|>\" , connectionstyle = \"arc3,rad=\" + str ( arrow_arc_rad ), fc = \"w\" , color = color , lw = 2 , ), ** kwargs , )","title":"AnnotationsPlotter"},{"location":"reference/pyhdtoolkit/plotting/helpers/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/plotting/helpers/#set_arrow_label","text":"def set_arrow_label ( axis : matplotlib . axes . _axes . Axes , label : str , arrow_position : Tuple [ float , float ], label_position : Tuple [ float , float ], color : str = 'k' , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 , ** kwargs ) -> matplotlib . text . Annotation Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes Axes instance. Original code from Guido Sterbini. Parameters: Name Type Description Default axis matplotlib.axes.Axes a matplotlib axis to plot on. None label str label text to print on the axis. None arrow_position Tuple[float, float] where on the plot to point the tip of the arrow. None label_position Tuple[float, float] where on the plot the text label (and thus start of the arrow) is. None color str color parameter for your arrow and label. Defaults to 'k'. 'k' arrow_arc_rad float angle value defining the upwards / downwards shape of and bending of the arrow. None fontsize int text size in the box None Returns: Type Description None A matploblit text annotation object. View Source @staticmethod def set _arrow_label ( axis : matplotlib . axes . Axes , label : str , arrow_position : Tuple [ float , float ] , label_position : Tuple [ float , float ] , color : str = \"k\" , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 , ** kwargs , ) -> matplotlib . text . Annotation : \" \"\" Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes `Axes` instance. Original code from Guido Sterbini. Args: axis (matplotlib.axes.Axes): a matplotlib axis to plot on. label (str): label text to print on the axis. arrow_position (Tuple[float, float]): where on the plot to point the tip of the arrow. label_position (Tuple[float, float]): where on the plot the text label (and thus start of the arrow) is. color (str): color parameter for your arrow and label. Defaults to 'k'. arrow_arc_rad (float): angle value defining the upwards / downwards shape of and bending of the arrow. fontsize (int): text size in the box Returns: A matploblit text annotation object. \"\" \" return axis . annotate ( label , xy = arrow_position , xycoords = \"data\" , xytext = label_position , textcoords = \"data\" , size = fontsize , color = color , va = \"center\" , ha = \"center\" , bbox = dict ( boxstyle = \"round4\" , fc = \"w\" , color = color , lw = 2 ), arrowprops = dict ( arrowstyle = \"-|>\" , connectionstyle = \"arc3,rad=\" + str ( arrow_arc_rad ), fc = \"w\" , color = color , lw = 2 , ), ** kwargs , )","title":"set_arrow_label"},{"location":"reference/pyhdtoolkit/tfstools/","text":"Module pyhdtoolkit.tfstools tfstools package ~ ~ ~ ~ ~ ~ ~ tfstools is a collection of utilities that integrate within my workflow when manipulating tfs files. View Source \"\"\" tfstools package ~~~~~~~~~~~~~~~~~~~ tfstools is a collection of utilities that integrate within my workflow when manipulating `tfs` files. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .latwiss import plot_latwiss Sub-modules pyhdtoolkit.tfstools.latwiss","title":"Index"},{"location":"reference/pyhdtoolkit/tfstools/#module-pyhdtoolkittfstools","text":"tfstools package ~ ~ ~ ~ ~ ~ ~ tfstools is a collection of utilities that integrate within my workflow when manipulating tfs files. View Source \"\"\" tfstools package ~~~~~~~~~~~~~~~~~~~ tfstools is a collection of utilities that integrate within my workflow when manipulating `tfs` files. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .latwiss import plot_latwiss","title":"Module pyhdtoolkit.tfstools"},{"location":"reference/pyhdtoolkit/tfstools/#sub-modules","text":"pyhdtoolkit.tfstools.latwiss","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/tfstools/latwiss/","text":"Module pyhdtoolkit.tfstools.latwiss Module tfstools.latwiss Created on 2020.10.15 View Source \"\"\" Module tfstools.latwiss -------------------------- Created on 2020.10.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions to elegantly plot the Twiss parameters output of a MADX twiss command, either from a file on disk or a loaded TfsDataFrame. \"\"\" from pathlib import Path from typing import Dict , List , Tuple , Union import matplotlib.axes import matplotlib.patches as patches import matplotlib.pyplot as plt import pandas as pd import tfs from loguru import logger from pyhdtoolkit.utils.defaults import PLOT_PARAMS plt . rcParams . update ( PLOT_PARAMS ) # ----- Plotting Functionality ----- def _plot_lattice_series ( ax : matplotlib . axes . Axes , series : pd . DataFrame , height : float = 1.0 , v_offset : float = 0.0 , color : str = \"r\" , alpha : float = 0.5 , lw : int = 3 , ) -> None : \"\"\" Plots the layout of your machine as a patch of rectangles for different element types. Original code from Guido Sterbini. Args: ax (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. series (pd.DataFrame): a dataframe with your elements' data. height (float): value to reach for the patch on the y axis. v_offset (float): vertical offset for the patch. color (str): color kwarg to transmit to pyplot. alpha (float): alpha kwarg to transmit to pyplot. lw (int): linewidth kwarg to transmit to pyplot. Returns: Nothing, acts directly on the provided axis. \"\"\" # pylint: disable=too-many-arguments ax . add_patch ( patches . Rectangle ( ( series . s - series . l , v_offset - height / 2.0 ), series . l , # width height , # height color = color , alpha = alpha , lw = lw , ) ) def plot_latwiss ( twiss_ouptut : Union [ str , Path , tfs . TfsDataFrame , pd . DataFrame ] = None , title : str = None , figsize : Tuple [ int , int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: twiss_ouptut (Union[str, Path, tfs.TfsDataFrame, pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint: disable=too-many-arguments twiss_df : tfs . TfsDataFrame = _get_tfs_dataframe_from_input ( twiss_ouptut ) twiss_df . columns = [ colname . lower () for colname in twiss_df . columns ] _assert_necessary_columns ( twiss_df , columns = [ \"s\" , \"keyword\" , \"betx\" , \"bety\" , \"dx\" , \"dy\" ]) elements_df = _make_survey_groups ( twiss_df ) logger . info ( \"Setting up figure\" ) figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches (takes a third of figure) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( r \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( r \"$\\theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # Plotting dipole patches, beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : _assert_necessary_columns ( twiss_df , columns = [ \"k0l\" , \"angle\" ]) dipoles_df = elements_df [ \"dipoles\" ] logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows (): if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) elif dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : _assert_necessary_columns ( twiss_df , columns = [ \"k1l\" ]) quadrupoles_df = elements_df [ \"quadrupoles\" ] logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows (): _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : _assert_necessary_columns ( twiss_df , columns = [ \"k2l\" ]) sextupoles_df = elements_df [ \"sextupoles\" ] logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows (): _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = r \"$\\beta_ {x} $\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = r \"$\\beta_ {y} $\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( r \"$\\beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = r \"$D_ {x} $\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = r \"$D_ {y} $\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersion [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as { savefig } \" ) plt . savefig ( savefig , format = \"pdf\" , dpi = 350 ) return figure # ----- Helpers ----1- def _get_tfs_dataframe_from_input ( twiss_input : Union [ str , Path , tfs . TfsDataFrame , pd . DataFrame ] ) -> tfs . TfsDataFrame : \"\"\" Args: twiss_input (Union[str, Path, tfs.TfsDataFrame. pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. Returns: A TfsDataFrame or pd.DataFrame with the data. \"\"\" if isinstance ( twiss_input , ( Path , str )): logger . trace ( \"Loading Twiss dataframe from disk\" ) return tfs . read ( Path ( twiss_input )) if isinstance ( twiss_input , ( pd . DataFrame , tfs . TfsDataFrame )): logger . trace ( \"Copying input dataframe\" ) return twiss_input . copy () logger . error ( \"Expected either a string, Path object or TfsDataFrame, but provided input \" f \"was of type ' { type ( twiss_input ) } '\" ) raise ValueError ( f \"Invalid input type for argument 'twiss_input': { type ( twiss_input ) } \" ) def _assert_necessary_columns ( dataframe : Union [ pd . DataFrame , tfs . TfsDataFrame ], columns : List [ str ]) -> None : \"\"\" Checks the presence of needed inputs for the latwiss plot in the provided dataframe. Will raise a KeyError if any of them is missing. Args: dataframe (Union[pd.DataFrame, tfs.TfsDataFrame]): the dataframe used for the data. columns (List[str]): list of column names to check for. \"\"\" if any ( colname not in dataframe . columns for colname in columns ): logger . error ( \"Some necessary columns are missing in the provided dataframe. \\n \" f \"The required columns are: { columns } \\n \" f \"The detected columns are: { dataframe . columns . to_numpy () } \" ) raise KeyError ( \"Missing columns in the provided dataframe\" ) def _make_survey_groups ( survey_df : pd . DataFrame ) -> Dict [ str , pd . DataFrame ]: \"\"\" Gets a survey dataframe and returns different sub-dataframes corresponding to different magnetic elements. Args: survey_df (pd.DataFrame): machine survey dataframe obtained from your Madx instance, with <instance>.table.survey.dframe(). Returns: A dictionary containing a dataframe for dipoles, focusing quadrupoles, defocusing quadrupoles, sextupoles and octupoles. The keys are self-explanatory. \"\"\" logger . debug ( \"Getting different element groups dframes from MAD-X survey\" ) return { \"dipoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sbend\" , \"rbend\" ])) & ( survey_df . name . str . contains ( \"B\" , case = False )) ], \"quadrupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) ], \"quad_foc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"F\" , case = False )) ], \"quad_defoc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"D\" , case = False )) ], \"sextupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sextupole\" ])) & ( survey_df . name . str . contains ( \"S\" , case = False )) ], \"octupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"octupole\" ])) & ( survey_df . name . str . contains ( \"O\" , case = False )) ], } Variables PLOT_PARAMS Functions plot_latwiss def plot_latwiss ( twiss_ouptut : Union [ str , pathlib . Path , tfs . handler . TfsDataFrame , pandas . core . frame . DataFrame ] = None , title : str = None , figsize : Tuple [ int , int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ) ) -> matplotlib . figure . Figure Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Parameters: Name Type Description Default twiss_ouptut Union[str, Path, tfs.TfsDataFrame, pd.DataFrame] the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. None title str title of your plot. None figsize Tuple[int, int] size of the figure, defaults to (16, 10). None savefig str will save the figure if this is not None, using the string value passed. None xlimits Tuple[float, float] will implement xlim (for the s coordinate) if this is not None, using the tuple passed. None plot_dipoles bool if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. None plot_quadrupoles bool if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. None plot_sextupoles bool if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. None disp_ylim Tuple[float, float] vertical axis limits for the dispersion values. Defaults to (-10, 125). None beta_ylim Tuple[float, float] vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. None k0l_lim Tuple[float, float] vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). None k1l_lim Tuple[float, float] vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). None Returns: Type Description None The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source def plot_latwiss ( twiss_ouptut : Union [ str, Path, tfs.TfsDataFrame, pd.DataFrame ] = None , title : str = None , figsize : Tuple [ int, int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float, float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float, float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float, float ] = None , k0l_lim : Tuple [ float, float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float, float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: twiss_ouptut (Union[str, Path, tfs.TfsDataFrame, pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments twiss_df : tfs . TfsDataFrame = _get_tfs_dataframe_from_input ( twiss_ouptut ) twiss_df . columns = [ colname.lower() for colname in twiss_df.columns ] _assert_necessary_columns ( twiss_df , columns =[ \"s\", \"keyword\", \"betx\", \"bety\", \"dx\", \"dy\" ] ) elements_df = _make_survey_groups ( twiss_df ) logger . info ( \"Setting up figure\" ) figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches ( takes a third of figure ) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( r \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( r \"$\\theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # Plotting dipole patches , beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : _assert_necessary_columns ( twiss_df , columns =[ \"k0l\", \"angle\" ] ) dipoles_df = elements_df [ \"dipoles\" ] logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows () : if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) elif dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : _assert_necessary_columns ( twiss_df , columns =[ \"k1l\" ] ) quadrupoles_df = elements_df [ \"quadrupoles\" ] logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows () : _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : _assert_necessary_columns ( twiss_df , columns =[ \"k2l\" ] ) sextupoles_df = elements_df [ \"sextupoles\" ] logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows () : _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = r \"$\\beta_{x}$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = r \"$\\beta_{y}$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( r \"$\\beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = r \"$D_{x}$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = r \"$D_{y}$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersion [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig , format = \"pdf\" , dpi = 350 ) return figure","title":"Latwiss"},{"location":"reference/pyhdtoolkit/tfstools/latwiss/#module-pyhdtoolkittfstoolslatwiss","text":"Module tfstools.latwiss Created on 2020.10.15 View Source \"\"\" Module tfstools.latwiss -------------------------- Created on 2020.10.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions to elegantly plot the Twiss parameters output of a MADX twiss command, either from a file on disk or a loaded TfsDataFrame. \"\"\" from pathlib import Path from typing import Dict , List , Tuple , Union import matplotlib.axes import matplotlib.patches as patches import matplotlib.pyplot as plt import pandas as pd import tfs from loguru import logger from pyhdtoolkit.utils.defaults import PLOT_PARAMS plt . rcParams . update ( PLOT_PARAMS ) # ----- Plotting Functionality ----- def _plot_lattice_series ( ax : matplotlib . axes . Axes , series : pd . DataFrame , height : float = 1.0 , v_offset : float = 0.0 , color : str = \"r\" , alpha : float = 0.5 , lw : int = 3 , ) -> None : \"\"\" Plots the layout of your machine as a patch of rectangles for different element types. Original code from Guido Sterbini. Args: ax (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. series (pd.DataFrame): a dataframe with your elements' data. height (float): value to reach for the patch on the y axis. v_offset (float): vertical offset for the patch. color (str): color kwarg to transmit to pyplot. alpha (float): alpha kwarg to transmit to pyplot. lw (int): linewidth kwarg to transmit to pyplot. Returns: Nothing, acts directly on the provided axis. \"\"\" # pylint: disable=too-many-arguments ax . add_patch ( patches . Rectangle ( ( series . s - series . l , v_offset - height / 2.0 ), series . l , # width height , # height color = color , alpha = alpha , lw = lw , ) ) def plot_latwiss ( twiss_ouptut : Union [ str , Path , tfs . TfsDataFrame , pd . DataFrame ] = None , title : str = None , figsize : Tuple [ int , int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: twiss_ouptut (Union[str, Path, tfs.TfsDataFrame, pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint: disable=too-many-arguments twiss_df : tfs . TfsDataFrame = _get_tfs_dataframe_from_input ( twiss_ouptut ) twiss_df . columns = [ colname . lower () for colname in twiss_df . columns ] _assert_necessary_columns ( twiss_df , columns = [ \"s\" , \"keyword\" , \"betx\" , \"bety\" , \"dx\" , \"dy\" ]) elements_df = _make_survey_groups ( twiss_df ) logger . info ( \"Setting up figure\" ) figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches (takes a third of figure) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( r \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( r \"$\\theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # Plotting dipole patches, beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : _assert_necessary_columns ( twiss_df , columns = [ \"k0l\" , \"angle\" ]) dipoles_df = elements_df [ \"dipoles\" ] logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows (): if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) elif dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : _assert_necessary_columns ( twiss_df , columns = [ \"k1l\" ]) quadrupoles_df = elements_df [ \"quadrupoles\" ] logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows (): _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : _assert_necessary_columns ( twiss_df , columns = [ \"k2l\" ]) sextupoles_df = elements_df [ \"sextupoles\" ] logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows (): _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = r \"$\\beta_ {x} $\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = r \"$\\beta_ {y} $\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( r \"$\\beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = r \"$D_ {x} $\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = r \"$D_ {y} $\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersion [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as { savefig } \" ) plt . savefig ( savefig , format = \"pdf\" , dpi = 350 ) return figure # ----- Helpers ----1- def _get_tfs_dataframe_from_input ( twiss_input : Union [ str , Path , tfs . TfsDataFrame , pd . DataFrame ] ) -> tfs . TfsDataFrame : \"\"\" Args: twiss_input (Union[str, Path, tfs.TfsDataFrame. pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. Returns: A TfsDataFrame or pd.DataFrame with the data. \"\"\" if isinstance ( twiss_input , ( Path , str )): logger . trace ( \"Loading Twiss dataframe from disk\" ) return tfs . read ( Path ( twiss_input )) if isinstance ( twiss_input , ( pd . DataFrame , tfs . TfsDataFrame )): logger . trace ( \"Copying input dataframe\" ) return twiss_input . copy () logger . error ( \"Expected either a string, Path object or TfsDataFrame, but provided input \" f \"was of type ' { type ( twiss_input ) } '\" ) raise ValueError ( f \"Invalid input type for argument 'twiss_input': { type ( twiss_input ) } \" ) def _assert_necessary_columns ( dataframe : Union [ pd . DataFrame , tfs . TfsDataFrame ], columns : List [ str ]) -> None : \"\"\" Checks the presence of needed inputs for the latwiss plot in the provided dataframe. Will raise a KeyError if any of them is missing. Args: dataframe (Union[pd.DataFrame, tfs.TfsDataFrame]): the dataframe used for the data. columns (List[str]): list of column names to check for. \"\"\" if any ( colname not in dataframe . columns for colname in columns ): logger . error ( \"Some necessary columns are missing in the provided dataframe. \\n \" f \"The required columns are: { columns } \\n \" f \"The detected columns are: { dataframe . columns . to_numpy () } \" ) raise KeyError ( \"Missing columns in the provided dataframe\" ) def _make_survey_groups ( survey_df : pd . DataFrame ) -> Dict [ str , pd . DataFrame ]: \"\"\" Gets a survey dataframe and returns different sub-dataframes corresponding to different magnetic elements. Args: survey_df (pd.DataFrame): machine survey dataframe obtained from your Madx instance, with <instance>.table.survey.dframe(). Returns: A dictionary containing a dataframe for dipoles, focusing quadrupoles, defocusing quadrupoles, sextupoles and octupoles. The keys are self-explanatory. \"\"\" logger . debug ( \"Getting different element groups dframes from MAD-X survey\" ) return { \"dipoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sbend\" , \"rbend\" ])) & ( survey_df . name . str . contains ( \"B\" , case = False )) ], \"quadrupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) ], \"quad_foc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"F\" , case = False )) ], \"quad_defoc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"D\" , case = False )) ], \"sextupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sextupole\" ])) & ( survey_df . name . str . contains ( \"S\" , case = False )) ], \"octupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"octupole\" ])) & ( survey_df . name . str . contains ( \"O\" , case = False )) ], }","title":"Module pyhdtoolkit.tfstools.latwiss"},{"location":"reference/pyhdtoolkit/tfstools/latwiss/#variables","text":"PLOT_PARAMS","title":"Variables"},{"location":"reference/pyhdtoolkit/tfstools/latwiss/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/tfstools/latwiss/#plot_latwiss","text":"def plot_latwiss ( twiss_ouptut : Union [ str , pathlib . Path , tfs . handler . TfsDataFrame , pandas . core . frame . DataFrame ] = None , title : str = None , figsize : Tuple [ int , int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ) ) -> matplotlib . figure . Figure Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Parameters: Name Type Description Default twiss_ouptut Union[str, Path, tfs.TfsDataFrame, pd.DataFrame] the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. None title str title of your plot. None figsize Tuple[int, int] size of the figure, defaults to (16, 10). None savefig str will save the figure if this is not None, using the string value passed. None xlimits Tuple[float, float] will implement xlim (for the s coordinate) if this is not None, using the tuple passed. None plot_dipoles bool if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. None plot_quadrupoles bool if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. None plot_sextupoles bool if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. None disp_ylim Tuple[float, float] vertical axis limits for the dispersion values. Defaults to (-10, 125). None beta_ylim Tuple[float, float] vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. None k0l_lim Tuple[float, float] vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). None k1l_lim Tuple[float, float] vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). None Returns: Type Description None The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source def plot_latwiss ( twiss_ouptut : Union [ str, Path, tfs.TfsDataFrame, pd.DataFrame ] = None , title : str = None , figsize : Tuple [ int, int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float, float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float, float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float, float ] = None , k0l_lim : Tuple [ float, float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float, float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: twiss_ouptut (Union[str, Path, tfs.TfsDataFrame, pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments twiss_df : tfs . TfsDataFrame = _get_tfs_dataframe_from_input ( twiss_ouptut ) twiss_df . columns = [ colname.lower() for colname in twiss_df.columns ] _assert_necessary_columns ( twiss_df , columns =[ \"s\", \"keyword\", \"betx\", \"bety\", \"dx\", \"dy\" ] ) elements_df = _make_survey_groups ( twiss_df ) logger . info ( \"Setting up figure\" ) figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches ( takes a third of figure ) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( r \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( r \"$\\theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # Plotting dipole patches , beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : _assert_necessary_columns ( twiss_df , columns =[ \"k0l\", \"angle\" ] ) dipoles_df = elements_df [ \"dipoles\" ] logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows () : if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) elif dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : _assert_necessary_columns ( twiss_df , columns =[ \"k1l\" ] ) quadrupoles_df = elements_df [ \"quadrupoles\" ] logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows () : _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : _assert_necessary_columns ( twiss_df , columns =[ \"k2l\" ] ) sextupoles_df = elements_df [ \"sextupoles\" ] logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows () : _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = r \"$\\beta_{x}$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = r \"$\\beta_{y}$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( r \"$\\beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = r \"$D_{x}$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = r \"$D_{y}$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersion [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig , format = \"pdf\" , dpi = 350 ) return figure","title":"plot_latwiss"},{"location":"reference/pyhdtoolkit/utils/","text":"Module pyhdtoolkit.utils utils package ~ ~ ~ ~ ~ ~ ~ These are miscellaneous modules with functions that sometime tunr out useful to my workflow. These are mainly wrappers around lower-level tools, or simply just additional niceties. View Source \"\"\" utils package ~~~~~~~~~~~~~~~~~~~ These are miscellaneous modules with functions that sometime tunr out useful to my workflow. These are mainly wrappers around lower-level tools, or simply just additional niceties. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .cmdline import CommandLine from .executors import MultiProcessor , MultiThreader from .printutil import END , Background , Foreground , Styles Sub-modules pyhdtoolkit.utils.cmdline pyhdtoolkit.utils.contexts pyhdtoolkit.utils.defaults pyhdtoolkit.utils.executors pyhdtoolkit.utils.operations pyhdtoolkit.utils.printutil Variables python3 END","title":"Index"},{"location":"reference/pyhdtoolkit/utils/#module-pyhdtoolkitutils","text":"utils package ~ ~ ~ ~ ~ ~ ~ These are miscellaneous modules with functions that sometime tunr out useful to my workflow. These are mainly wrappers around lower-level tools, or simply just additional niceties. View Source \"\"\" utils package ~~~~~~~~~~~~~~~~~~~ These are miscellaneous modules with functions that sometime tunr out useful to my workflow. These are mainly wrappers around lower-level tools, or simply just additional niceties. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .cmdline import CommandLine from .executors import MultiProcessor , MultiThreader from .printutil import END , Background , Foreground , Styles","title":"Module pyhdtoolkit.utils"},{"location":"reference/pyhdtoolkit/utils/#sub-modules","text":"pyhdtoolkit.utils.cmdline pyhdtoolkit.utils.contexts pyhdtoolkit.utils.defaults pyhdtoolkit.utils.executors pyhdtoolkit.utils.operations pyhdtoolkit.utils.printutil","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/utils/#variables","text":"python3 END","title":"Variables"},{"location":"reference/pyhdtoolkit/utils/cmdline/","text":"Module pyhdtoolkit.utils.cmdline Module utils.cmdline Created on 2019.11.06 View Source \"\"\" Module utils.cmdline -------------------- Created on 2019.11.06 :author: Felix Soubelet (felix.soubelet@cern.ch) Utility script to help run commands and access the commandline. \"\"\" import errno import os import signal import subprocess from typing import Mapping , Optional , Tuple from loguru import logger from pyhdtoolkit.utils.contexts import timeit class CommandLine : \"\"\" A high-level object to encapsulate the different methods for interacting with the commandline. \"\"\" @staticmethod def check_pid_exists ( pid : int ) -> bool : \"\"\" Check whether the given PID exists in the current process table. Args: pid (int): the Process ID you want to check. Returns: A boolean stating the result. \"\"\" if pid == 0 : # According to \"man 2 kill\", PID 0 refers to <<every process in the process group of # the calling process>>. Best not to go any further. logger . warning ( \"PID 0 refers to 'every process in calling processes', and should be untouched\" ) return True try : # Sending SIG 0 only checks if process has terminated, we're not actually terminating it os . kill ( pid , 0 ) except OSError as pid_checkout_error : if pid_checkout_error . errno == errno . ESRCH : # ERROR \"No such process\" return False if ( pid_checkout_error . errno == errno . EPERM ): # ERROR \"Operation not permitted\" -> there's a process to deny access to. return True # According to \"man 2 kill\" possible error values are (EINVAL, EPERM, ESRCH), therefore # we should never get here. If so let's be explicit in considering this an error. logger . exception ( \"Could not figure out the provided PID for some reason\" ) raise pid_checkout_error return True @staticmethod def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Optional [ int ], bytes ]: \"\"\" Run command based on `subprocess.Popen` and return the tuple of `(returncode, stdout)`. Note that `stderr` is redirected to `stdout`. `shell` is same to parameter of `Popen`. If the process does not terminate after `timeout` seconds, a `TimeoutExpired` exception will be raised. Args: command (str): string, the command you want to run. shell (bool): same as `Popen` argument. Setting the shell argument to a true value causes subprocess to spawn an intermediate shell process, and tell it to run the command. In other words, using an intermediate shell means that variables, glob patterns, and other special shell features in the command string are processed before the command is ran. Defaults to True. env (Mapping): mapping that defines the environment variables for the new process. timeout (float): same as `Popen.communicate` argument, number of seconds to wait for a response before raising a TimeoutExpired exception. Returns: The tuple of (returncode, stdout). Beware, the stdout will be a byte array (id est b'some returned text'). This output, returned as stdout, needs to be decoded properly before you do anything with it, especially if you intend to log it into a file. While it will most likely be 'utf-8', the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on. Usage: CommandLine.run('echo hello') -> (0, b'hello\\r\\n') modified_env = os.environ.copy() modified_env['ENV_VAR'] = new_value CommandLine.run('echo $ENV_VAR', env=modified_env) -> (0, b'new_value') \"\"\" with timeit ( lambda spanned : logger . info ( f \"Ran command ' { command } ' in a subprocess, in: { spanned : .4f } seconds\" ) ): process = subprocess . Popen ( command , shell = shell , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , env = env ) stdout , _ = process . communicate ( timeout = timeout ) if process . poll () != 0 : logger . warning ( f \"Subprocess command ' { command } ' finished with exit code: { process . poll () } \" ) else : logger . success ( f \"Subprocess command ' { command } ' finished with exit code: { process . poll () } \" ) return process . poll (), stdout @staticmethod def terminate ( pid : int ) -> bool : \"\"\" Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Args: pid (int): the process ID to kill. Returns: A boolean stating the success of the operation. \"\"\" if CommandLine . check_pid_exists ( pid ): os . kill ( pid , signal . SIGTERM ) logger . debug ( f \"Process { pid } has successfully been terminated.\" ) return True logger . error ( f \"Process with ID { pid } could not be terminated.\" ) return False Classes CommandLine class CommandLine ( / , * args , ** kwargs ) View Source class CommandLine : \" \"\" A high-level object to encapsulate the different methods for interacting with the commandline. \"\" \" @staticmethod def check_pid_exists ( pid : int ) -> bool : \" \"\" Check whether the given PID exists in the current process table. Args: pid (int): the Process ID you want to check. Returns: A boolean stating the result. \"\" \" if pid == 0 : # According to \"man 2 kill\", PID 0 refers to <<every process in the process group of # the calling process>>. Best not to go any further. logger . warning ( \"PID 0 refers to 'every process in calling processes', and should be untouched\" ) return True try : # Sending SIG 0 only checks if process has terminated, we're not actually terminating it os . kill ( pid , 0 ) except OSError as pid_checkout_error : if pid_checkout_error . errno == errno . ESRCH : # ERROR \"No such process\" return False if ( pid_checkout_error . errno == errno . EPERM ) : # ERROR \"Operation not permitted\" -> there's a process to deny access to. return True # According to \"man 2 kill\" possible error values are (EINVAL, EPERM, ESRCH), therefore # we should never get here. If so let's be explicit in considering this an error. logger . exception ( \"Could not figure out the provided PID for some reason\" ) raise pid_checkout_error return True @staticmethod def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Optional [ int ] , bytes ] : \" \"\" Run command based on `subprocess.Popen` and return the tuple of `(returncode, stdout)`. Note that `stderr` is redirected to `stdout`. `shell` is same to parameter of `Popen`. If the process does not terminate after `timeout` seconds, a `TimeoutExpired` exception will be raised. Args: command (str): string, the command you want to run. shell (bool): same as `Popen` argument. Setting the shell argument to a true value causes subprocess to spawn an intermediate shell process, and tell it to run the command. In other words, using an intermediate shell means that variables, glob patterns, and other special shell features in the command string are processed before the command is ran. Defaults to True. env (Mapping): mapping that defines the environment variables for the new process. timeout (float): same as `Popen.communicate` argument, number of seconds to wait for a response before raising a TimeoutExpired exception. Returns: The tuple of (returncode, stdout). Beware, the stdout will be a byte array (id est b'some returned text'). This output, returned as stdout, needs to be decoded properly before you do anything with it, especially if you intend to log it into a file. While it will most likely be 'utf-8', the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on. Usage: CommandLine.run('echo hello') -> (0, b'hello \\r\\n ') modified_env = os.environ.copy() modified_env['ENV_VAR'] = new_value CommandLine.run('echo $ENV_VAR', env=modified_env) -> (0, b'new_value') \"\" \" with timeit ( lambda spanned : logger . info ( f \"Ran command '{command}' in a subprocess, in: {spanned:.4f} seconds\" ) ) : process = subprocess . Popen ( command , shell = shell , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , env = env ) stdout , _ = process . communicate ( timeout = timeout ) if process . poll () != 0 : logger . warning ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) else : logger . success ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) return process . poll (), stdout @staticmethod def terminate ( pid : int ) -> bool : \" \"\" Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Args: pid (int): the process ID to kill. Returns: A boolean stating the success of the operation. \"\" \" if CommandLine . check_pid_exists ( pid ) : os . kill ( pid , signal . SIGTERM ) logger . debug ( f \"Process {pid} has successfully been terminated.\" ) return True logger . error ( f \"Process with ID {pid} could not be terminated.\" ) return False Static methods check_pid_exists def check_pid_exists ( pid : int ) -> bool Check whether the given PID exists in the current process table. Parameters: Name Type Description Default pid int the Process ID you want to check. None Returns: Type Description None A boolean stating the result. View Source @staticmethod def check_pid_exists ( pid : int ) -> bool : \"\"\" Check whether the given PID exists in the current process table. Args: pid (int): the Process ID you want to check. Returns: A boolean stating the result. \"\"\" if pid == 0 : # According to \"man 2 kill\" , PID 0 refers to << every process in the process group of # the calling process >> . Best not to go any further . logger . warning ( \"PID 0 refers to 'every process in calling processes', and should be untouched\" ) return True try : # Sending SIG 0 only checks if process has terminated , we 're not actually terminating it os.kill(pid, 0) except OSError as pid_checkout_error: if pid_checkout_error.errno == errno.ESRCH: # ERROR \"No such process\" return False if ( pid_checkout_error.errno == errno.EPERM ): # ERROR \"Operation not permitted\" -> there' s a process to deny access to . return True # According to \"man 2 kill\" possible error values are ( EINVAL , EPERM , ESRCH ), therefore # we should never get here . If so let ' s be explicit in considering this an error . logger . exception ( \"Could not figure out the provided PID for some reason\" ) raise pid_checkout_error return True run def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Union [ int , NoneType ], bytes ] Run command based on subprocess.Popen and return the tuple of (returncode, stdout) . Note that stderr is redirected to stdout . shell is same to parameter of Popen . If the process does not terminate after timeout seconds, a TimeoutExpired exception will be raised. Args : command ( str ) : string , the command you want to run . shell ( bool ) : same as `Popen` argument . Set ting the shell argument to a true value causes subprocess to spawn an intermediate shell process , and tell it to run the command . In other words , using an intermediate shell means that variables , glob patterns , and other special shell features in the command string are processed before the command is ran . Defaults to True . env ( Mapping ) : mapping that defines the environment variables for the new process . timeout ( float ) : same as `Popen.communicate` argument , number of seconds to wait for a response before raising a TimeoutExpired exception . Returns : The tuple of ( returncode , stdout ). Beware , the stdout will be a byte array ( id est b 'some returned text' ). This output , returned as stdout , needs to be decoded properly before you do anything with it , especially if you intend to log it into a file . While it will most likely be 'utf-8' , the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on . Usage : CommandLine . run ( 'echo hello' ) -> ( 0 , b 'hello ') modified_env = os . environ . copy () modified_env [ 'ENV_VAR' ] = new_value CommandLine . run ( 'echo $ENV_VAR' , env = modified_env ) -> ( 0 , b 'new_value' ) View Source @staticmethod def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Optional [ int ] , bytes ] : \" \"\" Run command based on `subprocess.Popen` and return the tuple of `(returncode, stdout)`. Note that `stderr` is redirected to `stdout`. `shell` is same to parameter of `Popen`. If the process does not terminate after `timeout` seconds, a `TimeoutExpired` exception will be raised. Args: command (str): string, the command you want to run. shell (bool): same as `Popen` argument. Setting the shell argument to a true value causes subprocess to spawn an intermediate shell process, and tell it to run the command. In other words, using an intermediate shell means that variables, glob patterns, and other special shell features in the command string are processed before the command is ran. Defaults to True. env (Mapping): mapping that defines the environment variables for the new process. timeout (float): same as `Popen.communicate` argument, number of seconds to wait for a response before raising a TimeoutExpired exception. Returns: The tuple of (returncode, stdout). Beware, the stdout will be a byte array (id est b'some returned text'). This output, returned as stdout, needs to be decoded properly before you do anything with it, especially if you intend to log it into a file. While it will most likely be 'utf-8', the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on. Usage: CommandLine.run('echo hello') -> (0, b'hello \\r\\n ') modified_env = os.environ.copy() modified_env['ENV_VAR'] = new_value CommandLine.run('echo $ENV_VAR', env=modified_env) -> (0, b'new_value') \"\" \" with timeit ( lambda spanned : logger . info ( f \"Ran command '{command}' in a subprocess, in: {spanned:.4f} seconds\" ) ) : process = subprocess . Popen ( command , shell = shell , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , env = env ) stdout , _ = process . communicate ( timeout = timeout ) if process . poll () != 0 : logger . warning ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) else : logger . success ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) return process . poll (), stdout terminate def terminate ( pid : int ) -> bool Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Parameters: Name Type Description Default pid int the process ID to kill. None Returns: Type Description None A boolean stating the success of the operation. View Source @ staticmethod def terminate ( pid : int ) -> bool : \"\"\" Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Args: pid (int): the process ID to kill. Returns: A boolean stating the success of the operation. \"\"\" if CommandLine . check_pid_exists ( pid ): os . kill ( pid , signal . SIGTERM ) logger . debug ( f \"Process {pid} has successfully been terminated.\" ) return True logger . error ( f \"Process with ID {pid} could not be terminated.\" ) return False","title":"Cmdline"},{"location":"reference/pyhdtoolkit/utils/cmdline/#module-pyhdtoolkitutilscmdline","text":"Module utils.cmdline Created on 2019.11.06 View Source \"\"\" Module utils.cmdline -------------------- Created on 2019.11.06 :author: Felix Soubelet (felix.soubelet@cern.ch) Utility script to help run commands and access the commandline. \"\"\" import errno import os import signal import subprocess from typing import Mapping , Optional , Tuple from loguru import logger from pyhdtoolkit.utils.contexts import timeit class CommandLine : \"\"\" A high-level object to encapsulate the different methods for interacting with the commandline. \"\"\" @staticmethod def check_pid_exists ( pid : int ) -> bool : \"\"\" Check whether the given PID exists in the current process table. Args: pid (int): the Process ID you want to check. Returns: A boolean stating the result. \"\"\" if pid == 0 : # According to \"man 2 kill\", PID 0 refers to <<every process in the process group of # the calling process>>. Best not to go any further. logger . warning ( \"PID 0 refers to 'every process in calling processes', and should be untouched\" ) return True try : # Sending SIG 0 only checks if process has terminated, we're not actually terminating it os . kill ( pid , 0 ) except OSError as pid_checkout_error : if pid_checkout_error . errno == errno . ESRCH : # ERROR \"No such process\" return False if ( pid_checkout_error . errno == errno . EPERM ): # ERROR \"Operation not permitted\" -> there's a process to deny access to. return True # According to \"man 2 kill\" possible error values are (EINVAL, EPERM, ESRCH), therefore # we should never get here. If so let's be explicit in considering this an error. logger . exception ( \"Could not figure out the provided PID for some reason\" ) raise pid_checkout_error return True @staticmethod def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Optional [ int ], bytes ]: \"\"\" Run command based on `subprocess.Popen` and return the tuple of `(returncode, stdout)`. Note that `stderr` is redirected to `stdout`. `shell` is same to parameter of `Popen`. If the process does not terminate after `timeout` seconds, a `TimeoutExpired` exception will be raised. Args: command (str): string, the command you want to run. shell (bool): same as `Popen` argument. Setting the shell argument to a true value causes subprocess to spawn an intermediate shell process, and tell it to run the command. In other words, using an intermediate shell means that variables, glob patterns, and other special shell features in the command string are processed before the command is ran. Defaults to True. env (Mapping): mapping that defines the environment variables for the new process. timeout (float): same as `Popen.communicate` argument, number of seconds to wait for a response before raising a TimeoutExpired exception. Returns: The tuple of (returncode, stdout). Beware, the stdout will be a byte array (id est b'some returned text'). This output, returned as stdout, needs to be decoded properly before you do anything with it, especially if you intend to log it into a file. While it will most likely be 'utf-8', the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on. Usage: CommandLine.run('echo hello') -> (0, b'hello\\r\\n') modified_env = os.environ.copy() modified_env['ENV_VAR'] = new_value CommandLine.run('echo $ENV_VAR', env=modified_env) -> (0, b'new_value') \"\"\" with timeit ( lambda spanned : logger . info ( f \"Ran command ' { command } ' in a subprocess, in: { spanned : .4f } seconds\" ) ): process = subprocess . Popen ( command , shell = shell , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , env = env ) stdout , _ = process . communicate ( timeout = timeout ) if process . poll () != 0 : logger . warning ( f \"Subprocess command ' { command } ' finished with exit code: { process . poll () } \" ) else : logger . success ( f \"Subprocess command ' { command } ' finished with exit code: { process . poll () } \" ) return process . poll (), stdout @staticmethod def terminate ( pid : int ) -> bool : \"\"\" Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Args: pid (int): the process ID to kill. Returns: A boolean stating the success of the operation. \"\"\" if CommandLine . check_pid_exists ( pid ): os . kill ( pid , signal . SIGTERM ) logger . debug ( f \"Process { pid } has successfully been terminated.\" ) return True logger . error ( f \"Process with ID { pid } could not be terminated.\" ) return False","title":"Module pyhdtoolkit.utils.cmdline"},{"location":"reference/pyhdtoolkit/utils/cmdline/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/utils/cmdline/#commandline","text":"class CommandLine ( / , * args , ** kwargs ) View Source class CommandLine : \" \"\" A high-level object to encapsulate the different methods for interacting with the commandline. \"\" \" @staticmethod def check_pid_exists ( pid : int ) -> bool : \" \"\" Check whether the given PID exists in the current process table. Args: pid (int): the Process ID you want to check. Returns: A boolean stating the result. \"\" \" if pid == 0 : # According to \"man 2 kill\", PID 0 refers to <<every process in the process group of # the calling process>>. Best not to go any further. logger . warning ( \"PID 0 refers to 'every process in calling processes', and should be untouched\" ) return True try : # Sending SIG 0 only checks if process has terminated, we're not actually terminating it os . kill ( pid , 0 ) except OSError as pid_checkout_error : if pid_checkout_error . errno == errno . ESRCH : # ERROR \"No such process\" return False if ( pid_checkout_error . errno == errno . EPERM ) : # ERROR \"Operation not permitted\" -> there's a process to deny access to. return True # According to \"man 2 kill\" possible error values are (EINVAL, EPERM, ESRCH), therefore # we should never get here. If so let's be explicit in considering this an error. logger . exception ( \"Could not figure out the provided PID for some reason\" ) raise pid_checkout_error return True @staticmethod def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Optional [ int ] , bytes ] : \" \"\" Run command based on `subprocess.Popen` and return the tuple of `(returncode, stdout)`. Note that `stderr` is redirected to `stdout`. `shell` is same to parameter of `Popen`. If the process does not terminate after `timeout` seconds, a `TimeoutExpired` exception will be raised. Args: command (str): string, the command you want to run. shell (bool): same as `Popen` argument. Setting the shell argument to a true value causes subprocess to spawn an intermediate shell process, and tell it to run the command. In other words, using an intermediate shell means that variables, glob patterns, and other special shell features in the command string are processed before the command is ran. Defaults to True. env (Mapping): mapping that defines the environment variables for the new process. timeout (float): same as `Popen.communicate` argument, number of seconds to wait for a response before raising a TimeoutExpired exception. Returns: The tuple of (returncode, stdout). Beware, the stdout will be a byte array (id est b'some returned text'). This output, returned as stdout, needs to be decoded properly before you do anything with it, especially if you intend to log it into a file. While it will most likely be 'utf-8', the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on. Usage: CommandLine.run('echo hello') -> (0, b'hello \\r\\n ') modified_env = os.environ.copy() modified_env['ENV_VAR'] = new_value CommandLine.run('echo $ENV_VAR', env=modified_env) -> (0, b'new_value') \"\" \" with timeit ( lambda spanned : logger . info ( f \"Ran command '{command}' in a subprocess, in: {spanned:.4f} seconds\" ) ) : process = subprocess . Popen ( command , shell = shell , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , env = env ) stdout , _ = process . communicate ( timeout = timeout ) if process . poll () != 0 : logger . warning ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) else : logger . success ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) return process . poll (), stdout @staticmethod def terminate ( pid : int ) -> bool : \" \"\" Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Args: pid (int): the process ID to kill. Returns: A boolean stating the success of the operation. \"\" \" if CommandLine . check_pid_exists ( pid ) : os . kill ( pid , signal . SIGTERM ) logger . debug ( f \"Process {pid} has successfully been terminated.\" ) return True logger . error ( f \"Process with ID {pid} could not be terminated.\" ) return False","title":"CommandLine"},{"location":"reference/pyhdtoolkit/utils/cmdline/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/utils/cmdline/#check_pid_exists","text":"def check_pid_exists ( pid : int ) -> bool Check whether the given PID exists in the current process table. Parameters: Name Type Description Default pid int the Process ID you want to check. None Returns: Type Description None A boolean stating the result. View Source @staticmethod def check_pid_exists ( pid : int ) -> bool : \"\"\" Check whether the given PID exists in the current process table. Args: pid (int): the Process ID you want to check. Returns: A boolean stating the result. \"\"\" if pid == 0 : # According to \"man 2 kill\" , PID 0 refers to << every process in the process group of # the calling process >> . Best not to go any further . logger . warning ( \"PID 0 refers to 'every process in calling processes', and should be untouched\" ) return True try : # Sending SIG 0 only checks if process has terminated , we 're not actually terminating it os.kill(pid, 0) except OSError as pid_checkout_error: if pid_checkout_error.errno == errno.ESRCH: # ERROR \"No such process\" return False if ( pid_checkout_error.errno == errno.EPERM ): # ERROR \"Operation not permitted\" -> there' s a process to deny access to . return True # According to \"man 2 kill\" possible error values are ( EINVAL , EPERM , ESRCH ), therefore # we should never get here . If so let ' s be explicit in considering this an error . logger . exception ( \"Could not figure out the provided PID for some reason\" ) raise pid_checkout_error return True","title":"check_pid_exists"},{"location":"reference/pyhdtoolkit/utils/cmdline/#run","text":"def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Union [ int , NoneType ], bytes ] Run command based on subprocess.Popen and return the tuple of (returncode, stdout) . Note that stderr is redirected to stdout . shell is same to parameter of Popen . If the process does not terminate after timeout seconds, a TimeoutExpired exception will be raised. Args : command ( str ) : string , the command you want to run . shell ( bool ) : same as `Popen` argument . Set ting the shell argument to a true value causes subprocess to spawn an intermediate shell process , and tell it to run the command . In other words , using an intermediate shell means that variables , glob patterns , and other special shell features in the command string are processed before the command is ran . Defaults to True . env ( Mapping ) : mapping that defines the environment variables for the new process . timeout ( float ) : same as `Popen.communicate` argument , number of seconds to wait for a response before raising a TimeoutExpired exception . Returns : The tuple of ( returncode , stdout ). Beware , the stdout will be a byte array ( id est b 'some returned text' ). This output , returned as stdout , needs to be decoded properly before you do anything with it , especially if you intend to log it into a file . While it will most likely be 'utf-8' , the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on . Usage : CommandLine . run ( 'echo hello' ) -> ( 0 , b 'hello ') modified_env = os . environ . copy () modified_env [ 'ENV_VAR' ] = new_value CommandLine . run ( 'echo $ENV_VAR' , env = modified_env ) -> ( 0 , b 'new_value' ) View Source @staticmethod def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Optional [ int ] , bytes ] : \" \"\" Run command based on `subprocess.Popen` and return the tuple of `(returncode, stdout)`. Note that `stderr` is redirected to `stdout`. `shell` is same to parameter of `Popen`. If the process does not terminate after `timeout` seconds, a `TimeoutExpired` exception will be raised. Args: command (str): string, the command you want to run. shell (bool): same as `Popen` argument. Setting the shell argument to a true value causes subprocess to spawn an intermediate shell process, and tell it to run the command. In other words, using an intermediate shell means that variables, glob patterns, and other special shell features in the command string are processed before the command is ran. Defaults to True. env (Mapping): mapping that defines the environment variables for the new process. timeout (float): same as `Popen.communicate` argument, number of seconds to wait for a response before raising a TimeoutExpired exception. Returns: The tuple of (returncode, stdout). Beware, the stdout will be a byte array (id est b'some returned text'). This output, returned as stdout, needs to be decoded properly before you do anything with it, especially if you intend to log it into a file. While it will most likely be 'utf-8', the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on. Usage: CommandLine.run('echo hello') -> (0, b'hello \\r\\n ') modified_env = os.environ.copy() modified_env['ENV_VAR'] = new_value CommandLine.run('echo $ENV_VAR', env=modified_env) -> (0, b'new_value') \"\" \" with timeit ( lambda spanned : logger . info ( f \"Ran command '{command}' in a subprocess, in: {spanned:.4f} seconds\" ) ) : process = subprocess . Popen ( command , shell = shell , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , env = env ) stdout , _ = process . communicate ( timeout = timeout ) if process . poll () != 0 : logger . warning ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) else : logger . success ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) return process . poll (), stdout","title":"run"},{"location":"reference/pyhdtoolkit/utils/cmdline/#terminate","text":"def terminate ( pid : int ) -> bool Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Parameters: Name Type Description Default pid int the process ID to kill. None Returns: Type Description None A boolean stating the success of the operation. View Source @ staticmethod def terminate ( pid : int ) -> bool : \"\"\" Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Args: pid (int): the process ID to kill. Returns: A boolean stating the success of the operation. \"\"\" if CommandLine . check_pid_exists ( pid ): os . kill ( pid , signal . SIGTERM ) logger . debug ( f \"Process {pid} has successfully been terminated.\" ) return True logger . error ( f \"Process with ID {pid} could not be terminated.\" ) return False","title":"terminate"},{"location":"reference/pyhdtoolkit/utils/contexts/","text":"Module pyhdtoolkit.utils.contexts Module utils.contexts Provides contexts to use functions in. View Source \"\"\" Module utils.contexts --------------------- Provides contexts to use functions in. \"\"\" import time from contextlib import contextmanager from typing import Callable , Iterator @contextmanager def timeit ( function : Callable ) -> Iterator [ None ]: \"\"\" Returns the time elapsed when executing code in the context via `function`. Original code from @jaimecp89 Args: function (Callable): any callable taking one argument. Was conceived with a lambda in mind. Returns: The elapsed time as an argument for the provided function. Usage: with timeit(lambda spanned: logger.debug(f'Did some stuff in {spanned} seconds')): some_stuff() some_other_stuff() \"\"\" start_time = time . time () try : yield finally : time_used = time . time () - start_time function ( time_used ) Functions timeit def timeit ( function : Callable ) -> Iterator [ NoneType ] Returns the time elapsed when executing code in the context via function . Original code from @jaimecp89 Parameters: Name Type Description Default function Callable any callable taking one argument. Was conceived with a lambda in mind. None Returns: Type Description None The elapsed time as an argument for the provided function. Usage: with timeit(lambda spanned: logger.debug(f'Did some stuff in {spanned} seconds')): some_stuff() some_other_stuff() | View Source @contextmanager def timeit ( function : Callable ) -> Iterator [ None ] : \"\"\" Returns the time elapsed when executing code in the context via `function`. Original code from @jaimecp89 Args: function (Callable): any callable taking one argument. Was conceived with a lambda in mind. Returns: The elapsed time as an argument for the provided function. Usage: with timeit(lambda spanned: logger.debug(f'Did some stuff in {spanned} seconds')): some_stuff() some_other_stuff() \"\"\" start_time = time . time () try : yield finally : time_used = time . time () - start_time function ( time_used )","title":"Contexts"},{"location":"reference/pyhdtoolkit/utils/contexts/#module-pyhdtoolkitutilscontexts","text":"Module utils.contexts Provides contexts to use functions in. View Source \"\"\" Module utils.contexts --------------------- Provides contexts to use functions in. \"\"\" import time from contextlib import contextmanager from typing import Callable , Iterator @contextmanager def timeit ( function : Callable ) -> Iterator [ None ]: \"\"\" Returns the time elapsed when executing code in the context via `function`. Original code from @jaimecp89 Args: function (Callable): any callable taking one argument. Was conceived with a lambda in mind. Returns: The elapsed time as an argument for the provided function. Usage: with timeit(lambda spanned: logger.debug(f'Did some stuff in {spanned} seconds')): some_stuff() some_other_stuff() \"\"\" start_time = time . time () try : yield finally : time_used = time . time () - start_time function ( time_used )","title":"Module pyhdtoolkit.utils.contexts"},{"location":"reference/pyhdtoolkit/utils/contexts/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/utils/contexts/#timeit","text":"def timeit ( function : Callable ) -> Iterator [ NoneType ] Returns the time elapsed when executing code in the context via function . Original code from @jaimecp89 Parameters: Name Type Description Default function Callable any callable taking one argument. Was conceived with a lambda in mind. None Returns: Type Description None The elapsed time as an argument for the provided function. Usage: with timeit(lambda spanned: logger.debug(f'Did some stuff in {spanned} seconds')): some_stuff() some_other_stuff() | View Source @contextmanager def timeit ( function : Callable ) -> Iterator [ None ] : \"\"\" Returns the time elapsed when executing code in the context via `function`. Original code from @jaimecp89 Args: function (Callable): any callable taking one argument. Was conceived with a lambda in mind. Returns: The elapsed time as an argument for the provided function. Usage: with timeit(lambda spanned: logger.debug(f'Did some stuff in {spanned} seconds')): some_stuff() some_other_stuff() \"\"\" start_time = time . time () try : yield finally : time_used = time . time () - start_time function ( time_used )","title":"timeit"},{"location":"reference/pyhdtoolkit/utils/defaults/","text":"Module pyhdtoolkit.utils.defaults Module utils.defaults Created on 2019.11.12 View Source \"\"\" Module utils.defaults --------------------- Created on 2019.11.12 :author: Felix Soubelet (felix.soubelet@cern.ch) Provides defaults to import for different settings. \"\"\" import sys from pathlib import Path from typing import Dict , Union from loguru import logger ANACONDA_INSTALL = Path () . home () / \"anaconda3\" OMC_PYTHON = ANACONDA_INSTALL / \"envs\" / \"OMC\" / \"bin\" / \"python\" WORK_REPOSITORIES = Path . home () / \"Repositories\" / \"Work\" BETABEAT_REPO = WORK_REPOSITORIES / \"Beta-Beat.src\" OMC3_REPO = WORK_REPOSITORIES / \"omc3\" TBT_CONVERTER_SCRIPT = OMC3_REPO / \"omc3\" / \"tbt_converter.py\" LOGURU_FORMAT = ( \"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | \" \"<level> {level: <8} </level> | \" \"<cyan> {name} </cyan>:<cyan> {line} </cyan> - \" \"<level> {message} </level>\" ) # Set those with matplotlib.pyplot.rcParams.update(PLOT_PARAMS). # Will ALWAYS be overwritten by later on definition PLOT_PARAMS : Dict [ str , Union [ float , bool , str , tuple ]] = { # ------ Axes ------ # \"axes.linewidth\" : 0.8 , # Linewidth of axes edges \"axes.grid\" : False , # Do not display grid \"axes.labelsize\" : 25 , # Fontsize of the x and y axis labels \"axes.titlesize\" : 27 , # Fontsize of the axes title \"axes.formatter.limits\" : ( - 3 , 5 ), # Switch to scientific notations when order of magnitude reaches 1e3 # \"axes.formatter.useoffset\": False, # Do not use the annoying offset on top of yticks \"axes.formatter.use_mathtext\" : True , # Format with i.e 10^{4} instead of 1e4 # ------ Date Formats ------ # \"date.autoformatter.year\" : \"%Y\" , # AutoDateFormatter setting for years display \"date.autoformatter.month\" : \"%Y-%m\" , # AutoDateFormatter setting for months display \"date.autoformatter.day\" : \"%Y-%m- %d \" , # AutoDateFormatter setting for days display \"date.autoformatter.hour\" : \"%m- %d %H\" , # AutoDateFormatter setting for seconds display \"date.autoformatter.minute\" : \" %d %H:%M\" , # AutoDateFormatter setting for minutes display \"date.autoformatter.second\" : \"%H:%M:%S\" , # AutoDateFormatter setting for seconds display \"date.autoformatter.microsecond\" : \"%M:%S. %f \" , # AutoDateFormatter setting for microseconds # ------ General Figure ------ # \"figure.autolayout\" : True , # Adjust subplot params to fit the figure (tight_layout) \"figure.dpi\" : 300 , # Figure dots per inch \"figure.figsize\" : ( 18 , 11 ), # Size of the figure \"figure.max_open_warning\" : 10 , # Max number of figures to open before warning \"figure.titlesize\" : 30 , # Size of the figure title # ------ Fonts ------ # \"font.family\" : \"sans-serif\" , # Font family # \"font.sans-serif\": \"Helvetica\", # Sans-Serif font to use \"font.style\" : \"normal\" , # Style to apply to text font # ------- Legend ------ # \"legend.fancybox\" : True , # Use rounded box for legend background \"legend.fontsize\" : 22 , # Legend text font size \"legend.loc\" : \"best\" , # Default legend location # ------ Lines ------ # \"lines.linewidth\" : 1 , # Line width, in points \"lines.markersize\" : 5 , # Marker size, in points \"lines.antialiased\" : True , # Apply anti-aliasing to lines display # ------ Patches ------ # \"patch.linewidth\" : 1 , # Width of patches edge lines \"patch.antialiased\" : True , # Apply anti-aliasing to patches display # ------ Paths ------ # \"path.simplify\" : True , # Reduce file size by removing \"invisible\" points # ------ Saving ------ # \"savefig.dpi\" : 350 , # Saved figure dots per inch \"savefig.format\" : \"pdf\" , # Saved figure file format \"savefig.bbox\" : \"tight\" , # Careful: incompatible with pipe-based animation backends # ------ Text ------ # \"text.antialiased\" : True , # Apply anti-aliasing to text elements \"text.color\" : \"black\" , # Default text color \"text.usetex\" : False , # Do not use LaTeX for text handling (I don't have a local installation) # ------ Ticks ------ # \"xtick.labelsize\" : 20 , # Fontsize of the x axis tick labels \"ytick.labelsize\" : 20 , # Fontsize of the y axis tick labels } def config_logger ( level : str = \"INFO\" ) -> None : \"\"\" Resets the logger object from loguru, with `sys.stdout` as a sink and the aforedefined format. This comes down to personnal preference. \"\"\" logger . remove () logger . add ( sys . stdout , format = LOGURU_FORMAT , level = level . upper ()) Variables ANACONDA_INSTALL BETABEAT_REPO LOGURU_FORMAT OMC3_REPO OMC_PYTHON PLOT_PARAMS TBT_CONVERTER_SCRIPT WORK_REPOSITORIES Functions config_logger def config_logger ( level : str = 'INFO' ) -> None Resets the logger object from loguru, with sys.stdout as a sink and the aforedefined format. This comes down to personnal preference. View Source def config_logger ( level : str = \"INFO\" ) -> None : \"\"\" Resets the logger object from loguru, with `sys.stdout` as a sink and the aforedefined format. This comes down to personnal preference. \"\"\" logger . remove () logger . add ( sys . stdout , format = LOGURU_FORMAT , level = level . upper ())","title":"Defaults"},{"location":"reference/pyhdtoolkit/utils/defaults/#module-pyhdtoolkitutilsdefaults","text":"Module utils.defaults Created on 2019.11.12 View Source \"\"\" Module utils.defaults --------------------- Created on 2019.11.12 :author: Felix Soubelet (felix.soubelet@cern.ch) Provides defaults to import for different settings. \"\"\" import sys from pathlib import Path from typing import Dict , Union from loguru import logger ANACONDA_INSTALL = Path () . home () / \"anaconda3\" OMC_PYTHON = ANACONDA_INSTALL / \"envs\" / \"OMC\" / \"bin\" / \"python\" WORK_REPOSITORIES = Path . home () / \"Repositories\" / \"Work\" BETABEAT_REPO = WORK_REPOSITORIES / \"Beta-Beat.src\" OMC3_REPO = WORK_REPOSITORIES / \"omc3\" TBT_CONVERTER_SCRIPT = OMC3_REPO / \"omc3\" / \"tbt_converter.py\" LOGURU_FORMAT = ( \"<green>{time:YYYY-MM-DD HH:mm:ss}</green> | \" \"<level> {level: <8} </level> | \" \"<cyan> {name} </cyan>:<cyan> {line} </cyan> - \" \"<level> {message} </level>\" ) # Set those with matplotlib.pyplot.rcParams.update(PLOT_PARAMS). # Will ALWAYS be overwritten by later on definition PLOT_PARAMS : Dict [ str , Union [ float , bool , str , tuple ]] = { # ------ Axes ------ # \"axes.linewidth\" : 0.8 , # Linewidth of axes edges \"axes.grid\" : False , # Do not display grid \"axes.labelsize\" : 25 , # Fontsize of the x and y axis labels \"axes.titlesize\" : 27 , # Fontsize of the axes title \"axes.formatter.limits\" : ( - 3 , 5 ), # Switch to scientific notations when order of magnitude reaches 1e3 # \"axes.formatter.useoffset\": False, # Do not use the annoying offset on top of yticks \"axes.formatter.use_mathtext\" : True , # Format with i.e 10^{4} instead of 1e4 # ------ Date Formats ------ # \"date.autoformatter.year\" : \"%Y\" , # AutoDateFormatter setting for years display \"date.autoformatter.month\" : \"%Y-%m\" , # AutoDateFormatter setting for months display \"date.autoformatter.day\" : \"%Y-%m- %d \" , # AutoDateFormatter setting for days display \"date.autoformatter.hour\" : \"%m- %d %H\" , # AutoDateFormatter setting for seconds display \"date.autoformatter.minute\" : \" %d %H:%M\" , # AutoDateFormatter setting for minutes display \"date.autoformatter.second\" : \"%H:%M:%S\" , # AutoDateFormatter setting for seconds display \"date.autoformatter.microsecond\" : \"%M:%S. %f \" , # AutoDateFormatter setting for microseconds # ------ General Figure ------ # \"figure.autolayout\" : True , # Adjust subplot params to fit the figure (tight_layout) \"figure.dpi\" : 300 , # Figure dots per inch \"figure.figsize\" : ( 18 , 11 ), # Size of the figure \"figure.max_open_warning\" : 10 , # Max number of figures to open before warning \"figure.titlesize\" : 30 , # Size of the figure title # ------ Fonts ------ # \"font.family\" : \"sans-serif\" , # Font family # \"font.sans-serif\": \"Helvetica\", # Sans-Serif font to use \"font.style\" : \"normal\" , # Style to apply to text font # ------- Legend ------ # \"legend.fancybox\" : True , # Use rounded box for legend background \"legend.fontsize\" : 22 , # Legend text font size \"legend.loc\" : \"best\" , # Default legend location # ------ Lines ------ # \"lines.linewidth\" : 1 , # Line width, in points \"lines.markersize\" : 5 , # Marker size, in points \"lines.antialiased\" : True , # Apply anti-aliasing to lines display # ------ Patches ------ # \"patch.linewidth\" : 1 , # Width of patches edge lines \"patch.antialiased\" : True , # Apply anti-aliasing to patches display # ------ Paths ------ # \"path.simplify\" : True , # Reduce file size by removing \"invisible\" points # ------ Saving ------ # \"savefig.dpi\" : 350 , # Saved figure dots per inch \"savefig.format\" : \"pdf\" , # Saved figure file format \"savefig.bbox\" : \"tight\" , # Careful: incompatible with pipe-based animation backends # ------ Text ------ # \"text.antialiased\" : True , # Apply anti-aliasing to text elements \"text.color\" : \"black\" , # Default text color \"text.usetex\" : False , # Do not use LaTeX for text handling (I don't have a local installation) # ------ Ticks ------ # \"xtick.labelsize\" : 20 , # Fontsize of the x axis tick labels \"ytick.labelsize\" : 20 , # Fontsize of the y axis tick labels } def config_logger ( level : str = \"INFO\" ) -> None : \"\"\" Resets the logger object from loguru, with `sys.stdout` as a sink and the aforedefined format. This comes down to personnal preference. \"\"\" logger . remove () logger . add ( sys . stdout , format = LOGURU_FORMAT , level = level . upper ())","title":"Module pyhdtoolkit.utils.defaults"},{"location":"reference/pyhdtoolkit/utils/defaults/#variables","text":"ANACONDA_INSTALL BETABEAT_REPO LOGURU_FORMAT OMC3_REPO OMC_PYTHON PLOT_PARAMS TBT_CONVERTER_SCRIPT WORK_REPOSITORIES","title":"Variables"},{"location":"reference/pyhdtoolkit/utils/defaults/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/utils/defaults/#config_logger","text":"def config_logger ( level : str = 'INFO' ) -> None Resets the logger object from loguru, with sys.stdout as a sink and the aforedefined format. This comes down to personnal preference. View Source def config_logger ( level : str = \"INFO\" ) -> None : \"\"\" Resets the logger object from loguru, with `sys.stdout` as a sink and the aforedefined format. This comes down to personnal preference. \"\"\" logger . remove () logger . add ( sys . stdout , format = LOGURU_FORMAT , level = level . upper ())","title":"config_logger"},{"location":"reference/pyhdtoolkit/utils/executors/","text":"Module pyhdtoolkit.utils.executors Module utils.executors Created on 2019.12.09 View Source \"\"\" Module utils.executors ---------------------- Created on 2019.12.09 :author: Felix Soubelet A module providing two classes to execute functions + arguments couples through either a multiprocessing approach, or a multithreading approach. Here are a few tidbits to keep in mind: - There can only be one thread running at any given time in a python process because of the GIL. - Multiprocessing is parallelism. Multithreading is concurrency. - Multiprocessing is for increasing speed. Multithreading is for hiding latency. - Multiprocessing is best for computations. Multithreading is best for IO. - If you have CPU heavy tasks, use multiprocessing with n_process = n_cores and never more. Never. - If you have IO heavy tasks, use multithreading with n_threads = m * n_cores with m a number bigger than 1 that you can tweak on your own. Try many values and choose the one with the best speedup because there isn\u2019t a general rule. For instance the default value of m in ThreadPoolExecutor is set to 5 which I think is quite random. \"\"\" from concurrent import futures from typing import Callable , List from loguru import logger class MultiProcessor : \"\"\" A class to easily wrap a multi-processing context manager call to a function. Reminder: multiprocessing is good for cpu-heavy tasks. Reminder: only picklable objects can be executed and returned. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_cpu_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ] : \"\"\" Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_processes (int): the number of processes to fire up. No more than your number of cores! If n_processes is `None` or not given, ProcessPoolExecutor will default it to the number of processors on the machine. Returns: A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multiprocessing with {n_processes} processes\" ) with futures . ProcessPoolExecutor ( n_processes ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_processes} processes finished\" ) return list ( results ) class MultiThreader : \"\"\" A class to easily wrap a multi-threading context manager call to a function. Reminder: multithreading is good for IO-heavy tasks. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_io_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ] : \"\"\" Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_threads (int): the number of threads to fire up. If n_threads is `None` or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. Returns: A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multithreading with {n_threads} threads\" ) with futures . ThreadPoolExecutor ( n_threads ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_threads} threads finished\" ) return list ( results ) Classes MultiProcessor class MultiProcessor ( / , * args , ** kwargs ) View Source class MultiProcessor : \"\"\" A class to easily wrap a multi-processing context manager call to a function. Reminder: multiprocessing is good for cpu-heavy tasks. Reminder: only picklable objects can be executed and returned. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_cpu_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_processes (int): the number of processes to fire up. No more than your number of cores! If n_processes is `None` or not given, ProcessPoolExecutor will default it to the number of processors on the machine. Returns: A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multiprocessing with {n_processes} processes\" ) with futures . ProcessPoolExecutor ( n_processes ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_processes} processes finished\" ) return list ( results ) Static methods execute_function def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ] Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Parameters: Name Type Description Default func Callable the function to call. None func_args list list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. None n_processes int the number of processes to fire up. No more than your number of cores! If n_processes is None or not given, ProcessPoolExecutor will default it to the number of processors on the machine. None Returns: Type Description None A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. View Source @ staticmethod def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_processes (int): the number of processes to fire up. No more than your number of cores! If n_processes is `None` or not given, ProcessPoolExecutor will default it to the number of processors on the machine. Returns: A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multiprocessing with {n_processes} processes\" ) with futures . ProcessPoolExecutor ( n_processes ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_processes} processes finished\" ) return list ( results ) MultiThreader class MultiThreader ( / , * args , ** kwargs ) View Source class MultiThreader : \"\"\" A class to easily wrap a multi-threading context manager call to a function. Reminder: multithreading is good for IO-heavy tasks. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_io_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_threads (int): the number of threads to fire up. If n_threads is `None` or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. Returns: A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multithreading with {n_threads} threads\" ) with futures . ThreadPoolExecutor ( n_threads ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_threads} threads finished\" ) return list ( results ) Static methods execute_function def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ] Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Parameters: Name Type Description Default func Callable the function to call. None func_args list list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. None n_threads int the number of threads to fire up. If n_threads is None or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. None Returns: Type Description None A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. View Source @ staticmethod def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_threads (int): the number of threads to fire up. If n_threads is `None` or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. Returns: A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multithreading with {n_threads} threads\" ) with futures . ThreadPoolExecutor ( n_threads ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_threads} threads finished\" ) return list ( results )","title":"Executors"},{"location":"reference/pyhdtoolkit/utils/executors/#module-pyhdtoolkitutilsexecutors","text":"Module utils.executors Created on 2019.12.09 View Source \"\"\" Module utils.executors ---------------------- Created on 2019.12.09 :author: Felix Soubelet A module providing two classes to execute functions + arguments couples through either a multiprocessing approach, or a multithreading approach. Here are a few tidbits to keep in mind: - There can only be one thread running at any given time in a python process because of the GIL. - Multiprocessing is parallelism. Multithreading is concurrency. - Multiprocessing is for increasing speed. Multithreading is for hiding latency. - Multiprocessing is best for computations. Multithreading is best for IO. - If you have CPU heavy tasks, use multiprocessing with n_process = n_cores and never more. Never. - If you have IO heavy tasks, use multithreading with n_threads = m * n_cores with m a number bigger than 1 that you can tweak on your own. Try many values and choose the one with the best speedup because there isn\u2019t a general rule. For instance the default value of m in ThreadPoolExecutor is set to 5 which I think is quite random. \"\"\" from concurrent import futures from typing import Callable , List from loguru import logger class MultiProcessor : \"\"\" A class to easily wrap a multi-processing context manager call to a function. Reminder: multiprocessing is good for cpu-heavy tasks. Reminder: only picklable objects can be executed and returned. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_cpu_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ] : \"\"\" Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_processes (int): the number of processes to fire up. No more than your number of cores! If n_processes is `None` or not given, ProcessPoolExecutor will default it to the number of processors on the machine. Returns: A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multiprocessing with {n_processes} processes\" ) with futures . ProcessPoolExecutor ( n_processes ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_processes} processes finished\" ) return list ( results ) class MultiThreader : \"\"\" A class to easily wrap a multi-threading context manager call to a function. Reminder: multithreading is good for IO-heavy tasks. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_io_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ] : \"\"\" Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_threads (int): the number of threads to fire up. If n_threads is `None` or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. Returns: A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multithreading with {n_threads} threads\" ) with futures . ThreadPoolExecutor ( n_threads ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_threads} threads finished\" ) return list ( results )","title":"Module pyhdtoolkit.utils.executors"},{"location":"reference/pyhdtoolkit/utils/executors/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/utils/executors/#multiprocessor","text":"class MultiProcessor ( / , * args , ** kwargs ) View Source class MultiProcessor : \"\"\" A class to easily wrap a multi-processing context manager call to a function. Reminder: multiprocessing is good for cpu-heavy tasks. Reminder: only picklable objects can be executed and returned. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_cpu_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_processes (int): the number of processes to fire up. No more than your number of cores! If n_processes is `None` or not given, ProcessPoolExecutor will default it to the number of processors on the machine. Returns: A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multiprocessing with {n_processes} processes\" ) with futures . ProcessPoolExecutor ( n_processes ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_processes} processes finished\" ) return list ( results )","title":"MultiProcessor"},{"location":"reference/pyhdtoolkit/utils/executors/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/utils/executors/#execute_function","text":"def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ] Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Parameters: Name Type Description Default func Callable the function to call. None func_args list list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. None n_processes int the number of processes to fire up. No more than your number of cores! If n_processes is None or not given, ProcessPoolExecutor will default it to the number of processors on the machine. None Returns: Type Description None A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. View Source @ staticmethod def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_processes (int): the number of processes to fire up. No more than your number of cores! If n_processes is `None` or not given, ProcessPoolExecutor will default it to the number of processors on the machine. Returns: A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multiprocessing with {n_processes} processes\" ) with futures . ProcessPoolExecutor ( n_processes ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_processes} processes finished\" ) return list ( results )","title":"execute_function"},{"location":"reference/pyhdtoolkit/utils/executors/#multithreader","text":"class MultiThreader ( / , * args , ** kwargs ) View Source class MultiThreader : \"\"\" A class to easily wrap a multi-threading context manager call to a function. Reminder: multithreading is good for IO-heavy tasks. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_io_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_threads (int): the number of threads to fire up. If n_threads is `None` or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. Returns: A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multithreading with {n_threads} threads\" ) with futures . ThreadPoolExecutor ( n_threads ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_threads} threads finished\" ) return list ( results )","title":"MultiThreader"},{"location":"reference/pyhdtoolkit/utils/executors/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/utils/executors/#execute_function_1","text":"def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ] Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Parameters: Name Type Description Default func Callable the function to call. None func_args list list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. None n_threads int the number of threads to fire up. If n_threads is None or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. None Returns: Type Description None A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. View Source @ staticmethod def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_threads (int): the number of threads to fire up. If n_threads is `None` or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. Returns: A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multithreading with {n_threads} threads\" ) with futures . ThreadPoolExecutor ( n_threads ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_threads} threads finished\" ) return list ( results )","title":"execute_function"},{"location":"reference/pyhdtoolkit/utils/operations/","text":"Module pyhdtoolkit.utils.operations Module utils.operations Created on 2019.11.12 View Source \"\"\" Module utils.operations ----------------------- Created on 2019.11.12 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection classes with utility functions to perform common / convenient operations on the classic Python structures. \"\"\" import copy import itertools import math import random import re from functools import reduce from typing import Callable , Dict , List , Sequence , Tuple , Union class ListOperations : \"\"\" A class to group some common / useful operations on lists. \"\"\" @staticmethod def all_unique ( sequence : Sequence ) -> bool : \"\"\" Returns True if all the values in a flat list are unique, False otherwise. Args: sequence (Sequence): a sequence of elements. Returns: True if all elements are unique, False otherwise. \"\"\" return len ( sequence ) == len ( set ( sequence )) @staticmethod def average_by ( sequence : Sequence , function : Callable = lambda x : x ) -> float : \"\"\" Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Args: sequence (Sequence): a sequence of elements. function (Callable): function to apply to elements of the sequence. Returns: The average of each element's result through `function`. Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 \"\"\" return float ( sum ( map ( function , sequence ), 0.0 ) / len ( sequence )) @staticmethod def bifurcate ( sequence : Sequence , filters : List [ bool ]) -> Sequence : \"\"\" Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Args: sequence (Sequence): a sequence of elements. filters (List[bool]): a list of booleans. Returns: A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] \"\"\" return [ [ x for i , x in enumerate ( sequence ) if filters [ i ]], [ x for i , x in enumerate ( sequence ) if not filters [ i ]], ] @staticmethod def bifurcate_by ( sequence : Sequence , function : Callable ) -> list : \"\"\" Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of lst, that should return a boolean. Returns: A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] \"\"\" return [[ x for x in sequence if function ( x )], [ x for x in sequence if not function ( x )]] @staticmethod def chunk_list ( sequence : Sequence , size : int ) -> Sequence : \"\"\" Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Args: sequence (Sequence): a sequence of elements. size (int): the size of the wanted sublists. Returns: A list of lists of length `size` (except maybe the last element), with elements from `lst`. Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] \"\"\" if size > len ( sequence ) : return sequence return list ( map ( lambda x : sequence [ x * size : x * size + size ], list ( range ( math . ceil ( len ( sequence ) / size ))),) ) @staticmethod def deep_flatten ( sequence : Sequence ) -> list : \"\"\" Deep flattens a list, no matter the nesting levels. This is a recursive approach. Args: sequence (Sequence): a sequence of elements. Returns: A list with all elements of `lst`, but flattened. Usage: deep_flatten([[\" a \", \" b \"], [1, 2], None, [True, False]]) -> [\" a \", \" b \", 1, 2, None True, False] \"\"\" return ( [ elem for sublist in sequence for elem in ListOperations . deep_flatten ( sublist )] if isinstance ( sequence , list ) else [ sequence ] ) @staticmethod def eval_none ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False \"\"\" return not any ( map ( function , sequence )) @staticmethod def eval_some ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False \"\"\" return any ( map ( function , sequence )) @staticmethod def get_indices ( element , sequence : Sequence ) -> List [ int ] : \"\"\" Return all array indices at which number is located. Args: element: any reference element to check. sequence (Sequence): a sequence containing objects comparable to `elements`. A string can be compared to an int in Python, custom objects probably won't be comparable. Returns: A list of all indices at which `element` is found in `sequence`. Empty list if `element` is not present in `sequence` at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] \"\"\" return [ i for ( y , i ) in zip ( sequence , range ( len ( sequence ))) if element == y ] @staticmethod def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ] : \"\"\" Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of `sequence` that should return a boolean. Returns: A dict with keys \" True \" and \" False \", each having as value a list of all elements of `lst` that were evaluated to respectively `True` or `False` through `function`. Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} \"\"\" groups = {} for key in list ( map ( function , sequence )) : groups [ key ] = [ item for item in sequence if function ( item ) == key ] return groups @staticmethod def has_duplicates ( sequence : Sequence ) -> bool : \"\"\" Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Args: sequence (Sequence): a sequence of elements. Returns: A boolean indicating the presence of duplicates in `lst`. Usage: has_duplicates([1, 2, 1]) -> True \"\"\" return len ( sequence ) ! = len ( set ( sequence )) @staticmethod def sample ( sequence : Sequence ) -> list : \"\"\" Returns a random element from an array. Args: sequence (Sequence): a sequence of elements. Returns: A random element from `lst` in a list (to manage potentially nested lists as input). \"\"\" return sequence [ random . randint ( 0 , len ( sequence ) - 1 )] @staticmethod def sanitize_list ( sequence : Sequence ) -> list : \"\"\" Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Args: sequence (Sequence): a sequence of elements. Returns: The sequence without falsy values. Usage: sanitize_list([1, False, \" a \", 2, \"\", None, 6, 0]) -> [1, \" a \", 2, 6] \"\"\" return list ( filter ( bool , sequence )) @staticmethod def shuffle ( sequence : Sequence ) -> Sequence : \"\"\" Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm (https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle) to reorder the elements. Args: sequence (Sequence): a sequence of elements. Returns: The `lst` with original elements at a random index. \"\"\" temp_list = copy . deepcopy ( sequence ) amount_to_shuffle = len ( temp_list ) while amount_to_shuffle > 1 : rand_index = int ( math . floor ( random . random () * amount_to_shuffle )) amount_to_shuffle -= 1 temp_list [ rand_index ], temp_list [ amount_to_shuffle ] = ( temp_list [ amount_to_shuffle ], temp_list [ rand_index ], ) return temp_list @staticmethod def spread ( sequence : Sequence ) -> list : \"\"\" Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in `lst` are iterables! Args: sequence (Sequence): a sequence of elements. Returns: The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] \"\"\" return list ( itertools . chain . from_iterable ( sequence )) @staticmethod def symmetric_difference_by ( lst_1: Sequence , lst_2: Sequence , function : Callable ) -> list : \"\"\" Returns the symmetric difference (https://en.wikipedia.org/wiki/Symmetric_difference) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] \"\"\" _ lst_1 , _ lst_2 = set ( map ( function , lst_1 )), set ( map ( function , lst_2 )) return [ item for item in lst_1 if function ( item ) not in _ lst_2 ] + [ item for item in lst_2 if function ( item ) not in _ lst_1 ] @staticmethod def union_by ( lst_1: Sequence , lst_2: Sequence , function : Callable ) -> list : \"\"\" Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union (https://en.wikipedia.org/wiki/Union_(set_theory)) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] \"\"\" _ lst_1 = set ( map ( function , lst_1 )) return sorted ( list ( set ( lst_1 + [ item for item in lst_2 if function ( item ) not in _ lst_1 ]))) @staticmethod def zipper ( * args , fillvalue = None ) -> list : \"\"\" Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Args: *args: a number (>= 2) of different iterables. fillvalue: value to use in case of length mismatch. Returns: A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\" a \", \" b \", \" c \"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] \"\"\" max_length = max ( len ( lst ) for lst in args ) return [ [ args [ k ][ i ] if i < len ( args [ k ]) else fillvalue for k in range ( len ( args ))] for i in range ( max_length ) ] class MiscellaneousOperations : \"\"\" A class to group some misc. operations that don't pertain to classic structures. \"\"\" @staticmethod def longest_item ( * args ) : \"\"\" Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Args: *args: any number (>= 2) of iterables. Returns: The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) \"\"\" return max ( args , key = len ) @staticmethod def map_values ( obj : dict , function : Callable ) -> dict : \"\"\" Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Args: obj: a dictionary. function (Callable): a callable on values of `obj`. Returns: A new dictionary with the results. Usage: map_values( {\" a \": list(range(5)), \" b \": list(range(10)), \" c \": list(range(15))}, lambda x: len(x) ) -> {\" a \": 5, \" b \": 10, \" c \": 15} \"\"\" ret = {} for key in obj : ret [ key ] = function ( obj [ key ]) return ret class NumberOperations : \"\"\" A class to group some common / useful operations on numbers. \"\"\" @staticmethod def clamp_number ( num : Union [ int , float ], a_val: Union [ int , float ], b_val: Union [ int , float ] ) -> Union [ int , float ] : \"\"\" Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Args: num (Union[int, float]): a number (float / int) a_val (Union[int, float]): a number (float / int) b_val (Union[int, float]): a number (float / int) Returns: A number (float / int), being the nearest to `num` in the range [`a_val`, `b_val`]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 \"\"\" return max ( min ( num , max ( a_val , b_val )), min ( a_val , b_val )) @staticmethod def degrees_to_radians ( deg_value: Union [ int , float ], decompose : bool = False ) -> Union [ Tuple [ float , str , str ], int , float ] : \"\"\" Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Args: deg_value (Union[int, float]): angle value in degrees. decompose (bool): boolean option to return a more verbose result. Defaults to False. Returns: The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \" pi \", \" rad \") \"\"\" if decompose : return deg_value / 180 , \"pi\" , \"rad\" return ( deg_value * math . pi ) / 180.0 @staticmethod def greatest_common_divisor ( numbers_list: Sequence ) -> Union [ int , float ] : \"\"\" Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in `numbers_list`. Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 \"\"\" return reduce ( math . gcd , numbers_list ) @staticmethod def is_divisible_by ( dividend : Union [ int , float ], divisor : Union [ int , float ]) -> bool : \"\"\" Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Args: dividend (Union[int, float]): a number. divisor (Union[int, float]): a number. Returns: A boolean stating if `dividend` can be divided by `divisor`. \"\"\" return dividend % divisor == 0 @staticmethod def least_common_multiple ( * args ) -> int : \"\"\" Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 \"\"\" numbers = list ( ListOperations . spread ( list ( args ))) def _ lcm ( number1 , number2 ) : \"\"\"A least common multiple method for two numbers only\"\"\" return int ( number1 * number2 / math . gcd ( number1 , number2 )) return reduce ( lambda x , y : _ lcm ( x , y ), numbers ) @staticmethod def radians_to_degrees ( rad_value: Union [ int , float ]) -> Union [ int , float ] : \"\"\" Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Args: rad_value (Union[int, float]): angle value in degrees. Returns: The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 \"\"\" return ( rad_value * 180.0 ) / math . pi class StringOperations : \"\"\" A class to group some common / useful operations on strings. \"\"\" @staticmethod def camel_case ( text : str ) -> str : \"\"\" Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Args: text (str): a string. Returns: The same string best adapted to camel_case. Usage: camel_case(\" a_snake_case_name \") -> \" aSnakeCaseName \" camel_case(\" A Title Case Name \") -> \" aTitleCaseName \" \"\"\" text = re . sub ( r \"(\\s|_|-)+\" , \" \" , text ). title (). replace ( \" \" , \"\" ) return text [ 0 ]. lower () + text [ 1 : ] @staticmethod def capitalize ( text : str , lower_rest: bool = False ) -> str : \"\"\" Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Args: text (str): a string. lower_rest (bool): boolean option to lower all elements starting from the second. Returns: The `string`, capitalized. Usage: capitalize(\" astringtocapitalize \") -> \" Astringtocapitalize \" capitalize(\" astRIngTocApItalizE \", lower_rest=True) -> \" Astringtocapitalize \" \"\"\" return text [ : 1 ]. upper () + ( text [ 1 : ]. lower () if lower_rest else text [ 1 : ]) @staticmethod def is_anagram ( str_1: str , str_2: str ) -> bool : \"\"\" Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Args: str_1 (str): a string. str_2 (str): a string. Returns: A boolean stating whether `str_1` is an anagram of `str_2` or not. Usage: is_anagram(\" Tom Marvolo Riddle \", \" I am Lord Voldemort \") -> True is_anagram(\" A first string \", \" Definitely not an anagram \") -> False \"\"\" _ str1 , _ str2 = ( str_1 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), str_2 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), ) return sorted ( _ str1 . lower ()) == sorted ( _ str2 . lower ()) @staticmethod def is_palindrome ( text : str ) -> bool : \"\"\" Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Args: text (str): a string. Returns: A boolean stating whether `string` is a palindrome or not. Usage: is_palindrome(\" racecar \") -> True is_palindrome(\" definitelynot \") -> False \"\"\" s_reverse = re . sub ( r \" [ \\ W_ ] \", \"\", text.lower()) return s_reverse == s_reverse[::-1] @staticmethod def kebab_case(text: str) -> str: \"\"\" Converts a string to kebab - case . Break the string into words and combine them adding - as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to kebab_case . Usage : kebab_case ( \"camel Case\" ) -> \"camel-case\" kebab_case ( \"snake_case\" ) -> \"snake-case\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" - \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \", lambda mo: mo.group(0).lower(), text, ), ) @staticmethod def snake_case(text: str) -> str: \"\"\" Converts a string to snake_case . Break the string into words and combine them adding _ as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to snake_case . Usage : snake_case ( \"A bunch of words\" ) -> \"a_bunch_of_words\" snake_case ( \"camelCase\" ) -> \"camelcase\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" _ \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \" , lambda mo : mo . group ( 0 ). lower (), text , ), ) Classes ListOperations class ListOperations ( / , * args , ** kwargs ) View Source class ListOperations : \"\"\" A class to group some common / useful operations on lists. \"\"\" @ staticmethod def all_unique ( sequence : Sequence ) -> bool : \"\"\" Returns True if all the values in a flat list are unique, False otherwise. Args: sequence (Sequence): a sequence of elements. Returns: True if all elements are unique, False otherwise. \"\"\" return len ( sequence ) == len ( set ( sequence )) @ staticmethod def average_by ( sequence : Sequence , function : Callable = lambda x : x ) -> float : \"\"\" Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Args: sequence (Sequence): a sequence of elements. function (Callable): function to apply to elements of the sequence. Returns: The average of each element's result through `function`. Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 \"\"\" return float ( sum ( map ( function , sequence ), 0.0 ) / len ( sequence )) @ staticmethod def bifurcate ( sequence : Sequence , filters : List [ bool ]) -> Sequence : \"\"\" Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Args: sequence (Sequence): a sequence of elements. filters (List[bool]): a list of booleans. Returns: A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] \"\"\" return [ [ x for i , x in enumerate ( sequence ) if filters [ i ]], [ x for i , x in enumerate ( sequence ) if not filters [ i ]], ] @ staticmethod def bifurcate_by ( sequence : Sequence , function : Callable ) -> list : \"\"\" Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of lst, that should return a boolean. Returns: A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] \"\"\" return [[ x for x in sequence if function ( x )], [ x for x in sequence if not function ( x )]] @ staticmethod def chunk_list ( sequence : Sequence , size : int ) -> Sequence : \"\"\" Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Args: sequence (Sequence): a sequence of elements. size (int): the size of the wanted sublists. Returns: A list of lists of length `size` (except maybe the last element), with elements from `lst`. Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] \"\"\" if size > len ( sequence ): return sequence return list ( map ( lambda x : sequence [ x * size : x * size + size ], list ( range ( math . ceil ( len ( sequence ) / size ))),) ) @ staticmethod def deep_flatten ( sequence : Sequence ) -> list : \"\"\" Deep flattens a list, no matter the nesting levels. This is a recursive approach. Args: sequence (Sequence): a sequence of elements. Returns: A list with all elements of `lst`, but flattened. Usage: deep_flatten([[\"a\", \"b\"], [1, 2], None, [True, False]]) -> [\"a\", \"b\", 1, 2, None True, False] \"\"\" return ( [ elem for sublist in sequence for elem in ListOperations . deep_flatten ( sublist )] if isinstance ( sequence , list ) else [ sequence ] ) @ staticmethod def eval_none ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False \"\"\" return not any ( map ( function , sequence )) @ staticmethod def eval_some ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False \"\"\" return any ( map ( function , sequence )) @ staticmethod def get_indices ( element , sequence : Sequence ) -> List [ int ]: \"\"\" Return all array indices at which number is located. Args: element: any reference element to check. sequence (Sequence): a sequence containing objects comparable to `elements`. A string can be compared to an int in Python, custom objects probably won't be comparable. Returns: A list of all indices at which `element` is found in `sequence`. Empty list if `element` is not present in `sequence` at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] \"\"\" return [ i for ( y , i ) in zip ( sequence , range ( len ( sequence ))) if element == y ] @ staticmethod def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ]: \"\"\" Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of `sequence` that should return a boolean. Returns: A dict with keys \"True\" and \"False\", each having as value a list of all elements of `lst` that were evaluated to respectively `True` or `False` through `function`. Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} \"\"\" groups = {} for key in list ( map ( function , sequence )): groups [ key ] = [ item for item in sequence if function ( item ) == key ] return groups @ staticmethod def has_duplicates ( sequence : Sequence ) -> bool : \"\"\" Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Args: sequence (Sequence): a sequence of elements. Returns: A boolean indicating the presence of duplicates in `lst`. Usage: has_duplicates([1, 2, 1]) -> True \"\"\" return len ( sequence ) != len ( set ( sequence )) @ staticmethod def sample ( sequence : Sequence ) -> list : \"\"\" Returns a random element from an array. Args: sequence (Sequence): a sequence of elements. Returns: A random element from `lst` in a list (to manage potentially nested lists as input). \"\"\" return sequence [ random . randint ( 0 , len ( sequence ) - 1 )] @ staticmethod def sanitize_list ( sequence : Sequence ) -> list : \"\"\" Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Args: sequence (Sequence): a sequence of elements. Returns: The sequence without falsy values. Usage: sanitize_list([1, False, \"a\", 2, \"\", None, 6, 0]) -> [1, \"a\", 2, 6] \"\"\" return list ( filter ( bool , sequence )) @ staticmethod def shuffle ( sequence : Sequence ) -> Sequence : \"\"\" Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm (https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle) to reorder the elements. Args: sequence (Sequence): a sequence of elements. Returns: The `lst` with original elements at a random index. \"\"\" temp_list = copy . deepcopy ( sequence ) amount_to_shuffle = len ( temp_list ) while amount_to_shuffle > 1 : rand_index = int ( math . floor ( random . random () * amount_to_shuffle )) amount_to_shuffle -= 1 temp_list [ rand_index ], temp_list [ amount_to_shuffle ] = ( temp_list [ amount_to_shuffle ], temp_list [ rand_index ], ) return temp_list @ staticmethod def spread ( sequence : Sequence ) -> list : \"\"\" Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in `lst` are iterables! Args: sequence (Sequence): a sequence of elements. Returns: The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] \"\"\" return list ( itertools . chain . from_iterable ( sequence )) @ staticmethod def symmetric_difference_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \"\"\" Returns the symmetric difference (https://en.wikipedia.org/wiki/Symmetric_difference) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] \"\"\" _lst_1 , _lst_2 = set ( map ( function , lst_1 )), set ( map ( function , lst_2 )) return [ item for item in lst_1 if function ( item ) not in _lst_2 ] + [ item for item in lst_2 if function ( item ) not in _lst_1 ] @ staticmethod def union_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \"\"\" Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union (https://en.wikipedia.org/wiki/Union_(set_theory)) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] \"\"\" _lst_1 = set ( map ( function , lst_1 )) return sorted ( list ( set ( lst_1 + [ item for item in lst_2 if function ( item ) not in _lst_1 ]))) @ staticmethod def zipper ( * args , fillvalue = None ) -> list : \"\"\" Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Args: *args: a number (>= 2) of different iterables. fillvalue: value to use in case of length mismatch. Returns: A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\"a\", \"b\", \"c\"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] \"\"\" max_length = max ( len ( lst ) for lst in args ) return [ [ args [ k ][ i ] if i < len ( args [ k ]) else fillvalue for k in range ( len ( args ))] for i in range ( max_length ) ] Static methods all_unique def all_unique ( sequence : Sequence ) -> bool Returns True if all the values in a flat list are unique, False otherwise. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None Returns: Type Description None True if all elements are unique, False otherwise. View Source @staticmethod def all_unique ( sequence : Sequence ) -> bool : \"\"\" Returns True if all the values in a flat list are unique, False otherwise. Args: sequence (Sequence): a sequence of elements. Returns: True if all elements are unique, False otherwise. \"\"\" return len ( sequence ) == len ( set ( sequence )) average_by def average_by ( sequence : Sequence , function : Callable = < function ListOperations .< lambda > at 0x7fbb1cf32c20 > ) -> float Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Parameters: Name Type Description Default sequence Sequence a sequence of elements. None function Callable function to apply to elements of the sequence. None Returns: Type Description None The average of each element's result through function . Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 | View Source @staticmethod def average_by ( sequence : Sequence , function : Callable = lambda x : x ) -> float : \" \"\" Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Args: sequence (Sequence): a sequence of elements. function (Callable): function to apply to elements of the sequence. Returns: The average of each element's result through `function`. Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 \"\" \" return float ( sum ( map ( function , sequence ), 0.0 ) / len ( sequence )) bifurcate def bifurcate ( sequence : Sequence , filters : List [ bool ] ) -> Sequence Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None filters List[bool] a list of booleans. None Returns: Type Description None A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] | View Source @staticmethod def bifurcate ( sequence : Sequence , filters : List [ bool ] ) -> Sequence : \"\"\" Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Args: sequence (Sequence): a sequence of elements. filters (List[bool]): a list of booleans. Returns: A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] \"\"\" return [ [x for i, x in enumerate(sequence) if filters[i ] ] , [ x for i, x in enumerate(sequence) if not filters[i ] ] , ] bifurcate_by def bifurcate_by ( sequence : Sequence , function : Callable ) -> list Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None function Callable a callable on the elements of lst, that should return a boolean. None Returns: Type Description None A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] | View Source @staticmethod def bifurcate_by ( sequence : Sequence , function : Callable ) -> list : \"\"\" Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of lst, that should return a boolean. Returns: A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] \"\"\" return [ [x for x in sequence if function(x) ] , [ x for x in sequence if not function(x) ] ] chunk_list def chunk_list ( sequence : Sequence , size : int ) -> Sequence Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None size int the size of the wanted sublists. None Returns: Type Description None A list of lists of length size (except maybe the last element), with elements from lst . Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] | View Source @staticmethod def chunk_list ( sequence : Sequence , size : int ) -> Sequence : \" \"\" Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Args: sequence (Sequence): a sequence of elements. size (int): the size of the wanted sublists. Returns: A list of lists of length `size` (except maybe the last element), with elements from `lst`. Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] \"\" \" if size > len ( sequence ) : return sequence return list ( map ( lambda x : sequence [ x * size : x * size + size ] , list ( range ( math . ceil ( len ( sequence ) / size ))),) ) deep_flatten def deep_flatten ( sequence : Sequence ) -> list Deep flattens a list, no matter the nesting levels. This is a recursive approach. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None Returns: Type Description None A list with all elements of lst , but flattened. Usage: deep_flatten([[\"a\", \"b\"], [1, 2], None, [True, False]]) -> [\"a\", \"b\", 1, 2, None True, False] | View Source @staticmethod def deep_flatten ( sequence : Sequence ) -> list : \"\"\" Deep flattens a list, no matter the nesting levels. This is a recursive approach. Args: sequence (Sequence): a sequence of elements. Returns: A list with all elements of `lst`, but flattened. Usage: deep_flatten([[\" a \", \" b \"], [1, 2], None, [True, False]]) -> [\" a \", \" b \", 1, 2, None True, False] \"\"\" return ( [ elem for sublist in sequence for elem in ListOperations.deep_flatten(sublist) ] if isinstance ( sequence , list ) else [ sequence ] ) eval_none def eval_none ( sequence : Sequence , function : Callable = < function ListOperations .< lambda > at 0x7fbb1cf32f80 > ) -> bool Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None function Callable a callable on elements of sequence that should return a boolean. None Returns: Type Description None A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False | View Source @staticmethod def eval_none ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \" \"\" Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False \"\" \" return not any ( map ( function , sequence )) eval_some def eval_some ( sequence : Sequence , function : Callable = < function ListOperations .< lambda > at 0x7fbb1cfd00e0 > ) -> bool Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None function Callable a callable on elements of sequence that should return a boolean. None Returns: Type Description None A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False | View Source @staticmethod def eval_some ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \" \"\" Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False \"\" \" return any ( map ( function , sequence )) get_indices def get_indices ( element , sequence : Sequence ) -> List [ int ] Return all array indices at which number is located. Parameters: Name Type Description Default element None any reference element to check. None sequence Sequence a sequence containing objects comparable to elements . A string can be compared to an int in Python, custom objects probably won't be comparable. None Returns: Type Description None A list of all indices at which element is found in sequence . Empty list if element is not present in sequence at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] | View Source @staticmethod def get_indices ( element , sequence : Sequence ) -> List [ int ] : \" \"\" Return all array indices at which number is located. Args: element: any reference element to check. sequence (Sequence): a sequence containing objects comparable to `elements`. A string can be compared to an int in Python, custom objects probably won't be comparable. Returns: A list of all indices at which `element` is found in `sequence`. Empty list if `element` is not present in `sequence` at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] \"\" \" return [ i for ( y , i ) in zip ( sequence , range ( len ( sequence ))) if element == y ] group_by def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ] Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None function Callable a callable on the elements of sequence that should return a boolean. None Returns: Type Description None A dict with keys \"True\" and \"False\", each having as value a list of all elements of lst that were evaluated to respectively True or False through function . Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} | View Source @staticmethod def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ] : \" \"\" Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of `sequence` that should return a boolean. Returns: A dict with keys \" True \" and \" False \", each having as value a list of all elements of `lst` that were evaluated to respectively `True` or `False` through `function`. Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} \"\" \" groups = {} for key in list ( map ( function , sequence )) : groups [ key ] = [ item for item in sequence if function ( item ) == key ] return groups has_duplicates def has_duplicates ( sequence : Sequence ) -> bool Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None Returns: Type Description None A boolean indicating the presence of duplicates in lst . Usage: has_duplicates([1, 2, 1]) -> True | View Source @staticmethod def has_duplicates ( sequence : Sequence ) -> bool : \" \"\" Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Args: sequence (Sequence): a sequence of elements. Returns: A boolean indicating the presence of duplicates in `lst`. Usage: has_duplicates([1, 2, 1]) -> True \"\" \" return len ( sequence ) != len ( set ( sequence )) sample def sample ( sequence : Sequence ) -> list Returns a random element from an array. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None Returns: Type Description None A random element from lst in a list (to manage potentially nested lists as input). View Source @staticmethod def sample ( sequence : Sequence ) -> list : \" \"\" Returns a random element from an array. Args: sequence (Sequence): a sequence of elements. Returns: A random element from `lst` in a list (to manage potentially nested lists as input). \"\" \" return sequence [ random . randint ( 0 , len ( sequence ) - 1 ) ] sanitize_list def sanitize_list ( sequence : Sequence ) -> list Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Parameters: Name Type Description Default sequence Sequence a sequence of elements. None Returns: Type Description None The sequence without falsy values. Usage: sanitize_list([1, False, \"a\", 2, \"\", None, 6, 0]) -> [1, \"a\", 2, 6] | View Source @staticmethod def sanitize_list ( sequence : Sequence ) -> list : \"\"\" Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Args: sequence (Sequence): a sequence of elements. Returns: The sequence without falsy values. Usage: sanitize_list([1, False, \" a \", 2, \"\", None, 6, 0]) -> [1, \" a \", 2, 6] \"\"\" return list ( filter ( bool , sequence )) shuffle def shuffle ( sequence : Sequence ) -> Sequence Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm ( https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle ) to reorder the elements. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None Returns: Type Description None The lst with original elements at a random index. View Source @staticmethod def shuffle ( sequence : Sequence ) -> Sequence : \"\"\" Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm (https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle) to reorder the elements. Args: sequence (Sequence): a sequence of elements. Returns: The `lst` with original elements at a random index. \"\"\" temp_list = copy . deepcopy ( sequence ) amount_to_shuffle = len ( temp_list ) while amount_to_shuffle > 1 : rand_index = int ( math . floor ( random . random () * amount_to_shuffle )) amount_to_shuffle -= 1 temp_list [ rand_index ] , temp_list [ amount_to_shuffle ] = ( temp_list [ amount_to_shuffle ] , temp_list [ rand_index ] , ) return temp_list spread def spread ( sequence : Sequence ) -> list Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in lst are iterables! Parameters: Name Type Description Default sequence Sequence a sequence of elements. None Returns: Type Description None The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] | View Source @staticmethod def spread ( sequence : Sequence ) -> list : \" \"\" Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in `lst` are iterables! Args: sequence (Sequence): a sequence of elements. Returns: The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] \"\" \" return list ( itertools . chain . from_iterable ( sequence )) symmetric_difference_by def symmetric_difference_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list Returns the symmetric difference ( https://en.wikipedia.org/wiki/Symmetric_difference ) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Parameters: Name Type Description Default lst_1 Sequence a sequence of elements. None lst_2 Sequence a sequence of elements. None function Callable a callable on elements of lst_1 and lst_2 . None Returns: Type Description None A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] | View Source @staticmethod def symmetric_difference_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \" \"\" Returns the symmetric difference (https://en.wikipedia.org/wiki/Symmetric_difference) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] \"\" \" _lst_1 , _lst_2 = set ( map ( function , lst_1 )), set ( map ( function , lst_2 )) return [ item for item in lst_1 if function ( item ) not in _lst_2 ] + [ item for item in lst_2 if function ( item ) not in _lst_1 ] union_by def union_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union ( https://en.wikipedia.org/wiki/Union_(set_theory )) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Parameters: Name Type Description Default lst_1 Sequence a sequence of elements. None lst_2 Sequence a sequence of elements. None function Callable a callable on elements of lst_1 and lst_2 . None Returns: Type Description None A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] | View Source @staticmethod def union_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \" \"\" Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union (https://en.wikipedia.org/wiki/Union_(set_theory)) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] \"\" \" _lst_1 = set ( map ( function , lst_1 )) return sorted ( list ( set ( lst_1 + [ item for item in lst_2 if function ( item ) not in _lst_1 ] ))) zipper def zipper ( * args , fillvalue = None ) -> list Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Parameters: Name Type Description Default *args None a number (>= 2) of different iterables. None fillvalue None value to use in case of length mismatch. None Returns: Type Description None A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\"a\", \"b\", \"c\"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] | View Source @staticmethod def zipper ( * args , fillvalue = None ) -> list : \"\"\" Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Args: *args: a number (>= 2) of different iterables. fillvalue: value to use in case of length mismatch. Returns: A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\" a \", \" b \", \" c \"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] \"\"\" max_length = max ( len ( lst ) for lst in args ) return [ [args[k ][ i ] if i < len ( args [ k ] ) else fillvalue for k in range ( len ( args )) ] for i in range ( max_length ) ] MiscellaneousOperations class MiscellaneousOperations ( / , * args , ** kwargs ) View Source class MiscellaneousOperations : \"\"\" A class to group some misc. operations that don't pertain to classic structures. \"\"\" @staticmethod def longest_item ( * args ) : \"\"\" Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Args: *args: any number (>= 2) of iterables. Returns: The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) \"\"\" return max ( args , key = len ) @staticmethod def map_values ( obj : dict , function : Callable ) -> dict : \"\"\" Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Args: obj: a dictionary. function (Callable): a callable on values of `obj`. Returns: A new dictionary with the results. Usage: map_values( {\" a \": list(range(5)), \" b \": list(range(10)), \" c \": list(range(15))}, lambda x: len(x) ) -> {\" a \": 5, \" b \": 10, \" c \": 15} \"\"\" ret = {} for key in obj : ret [ key ] = function ( obj [ key ] ) return ret Static methods longest_item def longest_item ( * args ) Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Parameters: Name Type Description Default *args None any number (>= 2) of iterables. None Returns: Type Description None The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) | View Source @staticmethod def longest_item ( * args ) : \"\"\" Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Args: *args: any number (>= 2) of iterables. Returns: The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) \"\"\" return max ( args , key = len ) map_values def map_values ( obj : dict , function : Callable ) -> dict Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Parameters: Name Type Description Default obj None a dictionary. None function Callable a callable on values of obj . None Returns: Type Description None A new dictionary with the results. Usage: map_values( {\"a\": list(range(5)), \"b\": list(range(10)), \"c\": list(range(15))}, lambda x: len(x) ) -> {\"a\": 5, \"b\": 10, \"c\": 15} | View Source @staticmethod def map_values ( obj : dict , function : Callable ) -> dict : \"\"\" Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Args: obj: a dictionary. function (Callable): a callable on values of `obj`. Returns: A new dictionary with the results. Usage: map_values( {\" a \": list(range(5)), \" b \": list(range(10)), \" c \": list(range(15))}, lambda x: len(x) ) -> {\" a \": 5, \" b \": 10, \" c \": 15} \"\"\" ret = {} for key in obj : ret [ key ] = function ( obj [ key ] ) return ret NumberOperations class NumberOperations ( / , * args , ** kwargs ) View Source class NumberOperations : \" \"\" A class to group some common / useful operations on numbers. \"\" \" @staticmethod def clamp_number ( num : Union [ int , float ] , a_val : Union [ int , float ] , b_val : Union [ int , float ] ) -> Union [ int , float ] : \" \"\" Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Args: num (Union[int, float]): a number (float / int) a_val (Union[int, float]): a number (float / int) b_val (Union[int, float]): a number (float / int) Returns: A number (float / int), being the nearest to `num` in the range [`a_val`, `b_val`]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 \"\" \" return max ( min ( num , max ( a_val , b_val )), min ( a_val , b_val )) @staticmethod def degrees_to_radians ( deg_value : Union [ int , float ] , decompose : bool = False ) -> Union [ Tuple [ float , str , str ] , int , float ] : \" \"\" Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Args: deg_value (Union[int, float]): angle value in degrees. decompose (bool): boolean option to return a more verbose result. Defaults to False. Returns: The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \" pi \", \" rad \") \"\" \" if decompose : return deg_value / 180 , \"pi\" , \"rad\" return ( deg_value * math . pi ) / 180.0 @staticmethod def greatest_common_divisor ( numbers_list : Sequence ) -> Union [ int , float ] : \" \"\" Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in `numbers_list`. Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 \"\" \" return reduce ( math . gcd , numbers_list ) @staticmethod def is_divisible_by ( dividend : Union [ int , float ] , divisor : Union [ int , float ] ) -> bool : \" \"\" Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Args: dividend (Union[int, float]): a number. divisor (Union[int, float]): a number. Returns: A boolean stating if `dividend` can be divided by `divisor`. \"\" \" return dividend % divisor == 0 @staticmethod def least_common_multiple ( * args ) -> int : \" \"\" Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 \"\" \" numbers = list ( ListOperations . spread ( list ( args ))) def _lcm ( number1 , number2 ) : \" \"\" A least common multiple method for two numbers only \"\" \" return int ( number1 * number2 / math . gcd ( number1 , number2 )) return reduce ( lambda x , y : _lcm ( x , y ), numbers ) @staticmethod def radians_to_degrees ( rad_value : Union [ int , float ] ) -> Union [ int , float ] : \" \"\" Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Args: rad_value (Union[int, float]): angle value in degrees. Returns: The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 \"\" \" return ( rad_value * 180.0 ) / math . pi Static methods clamp_number def clamp_number ( num : Union [ int , float ], a_val : Union [ int , float ], b_val : Union [ int , float ] ) -> Union [ int , float ] Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Parameters: Name Type Description Default num Union[int, float] a number (float / int) None a_val Union[int, float] a number (float / int) None b_val Union[int, float] a number (float / int) None Returns: Type Description None A number (float / int), being the nearest to num in the range [ a_val , b_val ]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 | View Source @staticmethod def clamp_number ( num : Union [ int , float ] , a_val : Union [ int , float ] , b_val : Union [ int , float ] ) -> Union [ int , float ] : \" \"\" Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Args: num (Union[int, float]): a number (float / int) a_val (Union[int, float]): a number (float / int) b_val (Union[int, float]): a number (float / int) Returns: A number (float / int), being the nearest to `num` in the range [`a_val`, `b_val`]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 \"\" \" return max ( min ( num , max ( a_val , b_val )), min ( a_val , b_val )) degrees_to_radians def degrees_to_radians ( deg_value : Union [ int , float ], decompose : bool = False ) -> Union [ Tuple [ float , str , str ], int , float ] Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Parameters: Name Type Description Default deg_value Union[int, float] angle value in degrees. None decompose bool boolean option to return a more verbose result. Defaults to False. False Returns: Type Description None The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \"pi\", \"rad\") | View Source @staticmethod def degrees_to_radians ( deg_value : Union [ int, float ] , decompose : bool = False ) -> Union [ Tuple[float, str, str ] , int , float ]: \"\"\" Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Args: deg_value (Union[int, float]): angle value in degrees. decompose (bool): boolean option to return a more verbose result. Defaults to False. Returns: The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \" pi \", \" rad \") \"\"\" if decompose : return deg_value / 180 , \"pi\" , \"rad\" return ( deg_value * math . pi ) / 180.0 greatest_common_divisor def greatest_common_divisor ( numbers_list : Sequence ) -> Union [ int , float ] Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in numbers_list . Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 View Source @staticmethod def greatest_common_divisor ( numbers_list : Sequence ) -> Union [ int , float ] : \" \"\" Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in `numbers_list`. Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 \"\" \" return reduce ( math . gcd , numbers_list ) is_divisible_by def is_divisible_by ( dividend : Union [ int , float ], divisor : Union [ int , float ] ) -> bool Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Parameters: Name Type Description Default dividend Union[int, float] a number. None divisor Union[int, float] a number. None Returns: Type Description None A boolean stating if dividend can be divided by divisor . View Source @staticmethod def is_divisible_by ( dividend : Union [ int , float ] , divisor : Union [ int , float ] ) -> bool : \" \"\" Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Args: dividend (Union[int, float]): a number. divisor (Union[int, float]): a number. Returns: A boolean stating if `dividend` can be divided by `divisor`. \"\" \" return dividend % divisor == 0 least_common_multiple def least_common_multiple ( * args ) -> int Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 View Source @staticmethod def least_common_multiple ( * args ) -> int : \"\"\" Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 \"\"\" numbers = list ( ListOperations . spread ( list ( args ))) def _lcm ( number1 , number2 ) : \"\"\"A least common multiple method for two numbers only\"\"\" return int ( number1 * number2 / math . gcd ( number1 , number2 )) return reduce ( lambda x , y : _lcm ( x , y ), numbers ) radians_to_degrees def radians_to_degrees ( rad_value : Union [ int , float ] ) -> Union [ int , float ] Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Parameters: Name Type Description Default rad_value Union[int, float] angle value in degrees. None Returns: Type Description None The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 | View Source @staticmethod def radians_to_degrees ( rad_value : Union [ int, float ] ) -> Union [ int, float ] : \"\"\" Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Args: rad_value (Union[int, float]): angle value in degrees. Returns: The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 \"\"\" return ( rad_value * 180.0 ) / math . pi StringOperations class StringOperations ( / , * args , ** kwargs ) View Source class StringOperations : \"\"\" A class to group some common / useful operations on strings. \"\"\" @staticmethod def camel_case ( text : str ) -> str : \"\"\" Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Args: text (str): a string. Returns: The same string best adapted to camel_case. Usage: camel_case(\" a_snake_case_name \") -> \" aSnakeCaseName \" camel_case(\" A Title Case Name \") -> \" aTitleCaseName \" \"\"\" text = re . sub ( r \"(\\s|_|-)+\" , \" \" , text ). title (). replace ( \" \" , \"\" ) return text [ 0 ]. lower () + text [ 1 : ] @staticmethod def capitalize ( text : str , lower_rest: bool = False ) -> str : \"\"\" Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Args: text (str): a string. lower_rest (bool): boolean option to lower all elements starting from the second. Returns: The `string`, capitalized. Usage: capitalize(\" astringtocapitalize \") -> \" Astringtocapitalize \" capitalize(\" astRIngTocApItalizE \", lower_rest=True) -> \" Astringtocapitalize \" \"\"\" return text [ : 1 ]. upper () + ( text [ 1 : ]. lower () if lower_rest else text [ 1 : ]) @staticmethod def is_anagram ( str_1: str , str_2: str ) -> bool : \"\"\" Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Args: str_1 (str): a string. str_2 (str): a string. Returns: A boolean stating whether `str_1` is an anagram of `str_2` or not. Usage: is_anagram(\" Tom Marvolo Riddle \", \" I am Lord Voldemort \") -> True is_anagram(\" A first string \", \" Definitely not an anagram \") -> False \"\"\" _ str1 , _ str2 = ( str_1 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), str_2 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), ) return sorted ( _ str1 . lower ()) == sorted ( _ str2 . lower ()) @staticmethod def is_palindrome ( text : str ) -> bool : \"\"\" Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Args: text (str): a string. Returns: A boolean stating whether `string` is a palindrome or not. Usage: is_palindrome(\" racecar \") -> True is_palindrome(\" definitelynot \") -> False \"\"\" s_reverse = re . sub ( r \" [ \\ W_ ] \", \"\", text.lower()) return s_reverse == s_reverse[::-1] @staticmethod def kebab_case(text: str) -> str: \"\"\" Converts a string to kebab - case . Break the string into words and combine them adding - as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to kebab_case . Usage : kebab_case ( \"camel Case\" ) -> \"camel-case\" kebab_case ( \"snake_case\" ) -> \"snake-case\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" - \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \", lambda mo: mo.group(0).lower(), text, ), ) @staticmethod def snake_case(text: str) -> str: \"\"\" Converts a string to snake_case . Break the string into words and combine them adding _ as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to snake_case . Usage : snake_case ( \"A bunch of words\" ) -> \"a_bunch_of_words\" snake_case ( \"camelCase\" ) -> \"camelcase\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" _ \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \" , lambda mo : mo . group ( 0 ). lower (), text , ), ) Static methods camel_case def camel_case ( text : str ) -> str Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Parameters: Name Type Description Default text str a string. None Returns: Type Description None The same string best adapted to camel_case. Usage: camel_case(\"a_snake_case_name\") -> \"aSnakeCaseName\" camel_case(\"A Title Case Name\") -> \"aTitleCaseName\" | View Source @staticmethod def camel_case ( text : str ) -> str : \"\"\" Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Args: text (str): a string. Returns: The same string best adapted to camel_case. Usage: camel_case(\" a_snake_case_name \") -> \" aSnakeCaseName \" camel_case(\" A Title Case Name \") -> \" aTitleCaseName \" \"\"\" text = re . sub ( r \"(\\s|_|-)+\" , \" \" , text ). title (). replace ( \" \" , \"\" ) return text [ 0 ] . lower () + text [ 1: ] capitalize def capitalize ( text : str , lower_rest : bool = False ) -> str Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Parameters: Name Type Description Default text str a string. None lower_rest bool boolean option to lower all elements starting from the second. None Returns: Type Description None The string , capitalized. Usage: capitalize(\"astringtocapitalize\") -> \"Astringtocapitalize\" capitalize(\"astRIngTocApItalizE\", lower_rest=True) -> \"Astringtocapitalize\" | View Source @staticmethod def capitalize ( text : str , lower_rest : bool = False ) -> str : \" \"\" Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Args: text (str): a string. lower_rest (bool): boolean option to lower all elements starting from the second. Returns: The `string`, capitalized. Usage: capitalize(\" astringtocapitalize \") -> \" Astringtocapitalize \" capitalize(\" astRIngTocApItalizE \", lower_rest=True) -> \" Astringtocapitalize \" \"\" \" return text [ : 1 ] . upper () + ( text [ 1 : ] . lower () if lower_rest else text [ 1 : ] ) is_anagram def is_anagram ( str_1 : str , str_2 : str ) -> bool Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Parameters: Name Type Description Default str_1 str a string. None str_2 str a string. None Returns: Type Description None A boolean stating whether str_1 is an anagram of str_2 or not. Usage: is_anagram(\"Tom Marvolo Riddle\", \"I am Lord Voldemort\") -> True is_anagram(\"A first string\", \"Definitely not an anagram\") -> False | View Source @staticmethod def is_anagram ( str_1 : str , str_2 : str ) -> bool : \" \"\" Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Args: str_1 (str): a string. str_2 (str): a string. Returns: A boolean stating whether `str_1` is an anagram of `str_2` or not. Usage: is_anagram(\" Tom Marvolo Riddle \", \" I am Lord Voldemort \") -> True is_anagram(\" A first string \", \" Definitely not an anagram \") -> False \"\" \" _str1 , _str2 = ( str_1 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), str_2 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), ) return sorted ( _str1 . lower ()) == sorted ( _str2 . lower ()) is_palindrome def is_palindrome ( text : str ) -> bool Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Parameters: Name Type Description Default text str a string. None Returns: Type Description None A boolean stating whether string is a palindrome or not. Usage: is_palindrome(\"racecar\") -> True is_palindrome(\"definitelynot\") -> False | View Source @staticmethod def is_palindrome ( text : str ) -> bool : \"\"\" Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Args: text (str): a string. Returns: A boolean stating whether `string` is a palindrome or not. Usage: is_palindrome(\" racecar \") -> True is_palindrome(\" definitelynot \") -> False \"\"\" s_reverse = re . sub ( r \" [ \\ W_ ] \", \" \" , text . lower ()) return s_reverse == s_reverse [ ::- 1 ] kebab_case def kebab_case ( text : str ) -> str Converts a string to kebab-case. Break the string into words and combine them adding - as a separator, using a regexp. Parameters: Name Type Description Default text str a string. None Returns: Type Description None The same string best adapted to kebab_case. Usage: kebab_case(\"camel Case\") -> \"camel-case\" kebab_case(\"snake_case\") -> \"snake-case\" | View Source @staticmethod def kebab_case ( text : str ) -> str : \"\"\" Converts a string to kebab-case. Break the string into words and combine them adding - as a separator, using a regexp. Args: text (str): a string. Returns: The same string best adapted to kebab_case. Usage: kebab_case(\" camel Case \") -> \" camel - case \" kebab_case(\" snake_case \") -> \" snake - case \" \"\"\" return re . sub ( r \"(\\s|_|-)+\" , \"-\" , re . sub ( r \"[A-Z]{2,}(?=[A-Z][a-z]+[0-9]*|\\b)|[A-Z]?[a-z]+[0-9]*|[A-Z]|[0-9]+\" , lambda mo : mo . group ( 0 ). lower (), text , ), ) snake_case def snake_case ( text : str ) -> str Converts a string to snake_case. Break the string into words and combine them adding _ as a separator, using a regexp. Parameters: Name Type Description Default text str a string. None Returns: Type Description None The same string best adapted to snake_case. Usage: snake_case(\"A bunch of words\") -> \"a_bunch_of_words\" snake_case(\"camelCase\") -> \"camelcase\" | View Source @staticmethod def snake_case ( text : str ) -> str : \"\"\" Converts a string to snake_case. Break the string into words and combine them adding _ as a separator, using a regexp. Args: text (str): a string. Returns: The same string best adapted to snake_case. Usage: snake_case(\" A bunch of words \") -> \" a_bunch_of_words \" snake_case(\" camelCase \") -> \" camelcase \" \"\"\" return re . sub ( r \"(\\s|_|-)+\" , \"_\" , re . sub ( r \"[A-Z]{2,}(?=[A-Z][a-z]+[0-9]*|\\b)|[A-Z]?[a-z]+[0-9]*|[A-Z]|[0-9]+\" , lambda mo : mo . group ( 0 ). lower (), text , ), )","title":"Operations"},{"location":"reference/pyhdtoolkit/utils/operations/#module-pyhdtoolkitutilsoperations","text":"Module utils.operations Created on 2019.11.12 View Source \"\"\" Module utils.operations ----------------------- Created on 2019.11.12 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection classes with utility functions to perform common / convenient operations on the classic Python structures. \"\"\" import copy import itertools import math import random import re from functools import reduce from typing import Callable , Dict , List , Sequence , Tuple , Union class ListOperations : \"\"\" A class to group some common / useful operations on lists. \"\"\" @staticmethod def all_unique ( sequence : Sequence ) -> bool : \"\"\" Returns True if all the values in a flat list are unique, False otherwise. Args: sequence (Sequence): a sequence of elements. Returns: True if all elements are unique, False otherwise. \"\"\" return len ( sequence ) == len ( set ( sequence )) @staticmethod def average_by ( sequence : Sequence , function : Callable = lambda x : x ) -> float : \"\"\" Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Args: sequence (Sequence): a sequence of elements. function (Callable): function to apply to elements of the sequence. Returns: The average of each element's result through `function`. Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 \"\"\" return float ( sum ( map ( function , sequence ), 0.0 ) / len ( sequence )) @staticmethod def bifurcate ( sequence : Sequence , filters : List [ bool ]) -> Sequence : \"\"\" Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Args: sequence (Sequence): a sequence of elements. filters (List[bool]): a list of booleans. Returns: A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] \"\"\" return [ [ x for i , x in enumerate ( sequence ) if filters [ i ]], [ x for i , x in enumerate ( sequence ) if not filters [ i ]], ] @staticmethod def bifurcate_by ( sequence : Sequence , function : Callable ) -> list : \"\"\" Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of lst, that should return a boolean. Returns: A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] \"\"\" return [[ x for x in sequence if function ( x )], [ x for x in sequence if not function ( x )]] @staticmethod def chunk_list ( sequence : Sequence , size : int ) -> Sequence : \"\"\" Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Args: sequence (Sequence): a sequence of elements. size (int): the size of the wanted sublists. Returns: A list of lists of length `size` (except maybe the last element), with elements from `lst`. Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] \"\"\" if size > len ( sequence ) : return sequence return list ( map ( lambda x : sequence [ x * size : x * size + size ], list ( range ( math . ceil ( len ( sequence ) / size ))),) ) @staticmethod def deep_flatten ( sequence : Sequence ) -> list : \"\"\" Deep flattens a list, no matter the nesting levels. This is a recursive approach. Args: sequence (Sequence): a sequence of elements. Returns: A list with all elements of `lst`, but flattened. Usage: deep_flatten([[\" a \", \" b \"], [1, 2], None, [True, False]]) -> [\" a \", \" b \", 1, 2, None True, False] \"\"\" return ( [ elem for sublist in sequence for elem in ListOperations . deep_flatten ( sublist )] if isinstance ( sequence , list ) else [ sequence ] ) @staticmethod def eval_none ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False \"\"\" return not any ( map ( function , sequence )) @staticmethod def eval_some ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False \"\"\" return any ( map ( function , sequence )) @staticmethod def get_indices ( element , sequence : Sequence ) -> List [ int ] : \"\"\" Return all array indices at which number is located. Args: element: any reference element to check. sequence (Sequence): a sequence containing objects comparable to `elements`. A string can be compared to an int in Python, custom objects probably won't be comparable. Returns: A list of all indices at which `element` is found in `sequence`. Empty list if `element` is not present in `sequence` at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] \"\"\" return [ i for ( y , i ) in zip ( sequence , range ( len ( sequence ))) if element == y ] @staticmethod def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ] : \"\"\" Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of `sequence` that should return a boolean. Returns: A dict with keys \" True \" and \" False \", each having as value a list of all elements of `lst` that were evaluated to respectively `True` or `False` through `function`. Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} \"\"\" groups = {} for key in list ( map ( function , sequence )) : groups [ key ] = [ item for item in sequence if function ( item ) == key ] return groups @staticmethod def has_duplicates ( sequence : Sequence ) -> bool : \"\"\" Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Args: sequence (Sequence): a sequence of elements. Returns: A boolean indicating the presence of duplicates in `lst`. Usage: has_duplicates([1, 2, 1]) -> True \"\"\" return len ( sequence ) ! = len ( set ( sequence )) @staticmethod def sample ( sequence : Sequence ) -> list : \"\"\" Returns a random element from an array. Args: sequence (Sequence): a sequence of elements. Returns: A random element from `lst` in a list (to manage potentially nested lists as input). \"\"\" return sequence [ random . randint ( 0 , len ( sequence ) - 1 )] @staticmethod def sanitize_list ( sequence : Sequence ) -> list : \"\"\" Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Args: sequence (Sequence): a sequence of elements. Returns: The sequence without falsy values. Usage: sanitize_list([1, False, \" a \", 2, \"\", None, 6, 0]) -> [1, \" a \", 2, 6] \"\"\" return list ( filter ( bool , sequence )) @staticmethod def shuffle ( sequence : Sequence ) -> Sequence : \"\"\" Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm (https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle) to reorder the elements. Args: sequence (Sequence): a sequence of elements. Returns: The `lst` with original elements at a random index. \"\"\" temp_list = copy . deepcopy ( sequence ) amount_to_shuffle = len ( temp_list ) while amount_to_shuffle > 1 : rand_index = int ( math . floor ( random . random () * amount_to_shuffle )) amount_to_shuffle -= 1 temp_list [ rand_index ], temp_list [ amount_to_shuffle ] = ( temp_list [ amount_to_shuffle ], temp_list [ rand_index ], ) return temp_list @staticmethod def spread ( sequence : Sequence ) -> list : \"\"\" Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in `lst` are iterables! Args: sequence (Sequence): a sequence of elements. Returns: The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] \"\"\" return list ( itertools . chain . from_iterable ( sequence )) @staticmethod def symmetric_difference_by ( lst_1: Sequence , lst_2: Sequence , function : Callable ) -> list : \"\"\" Returns the symmetric difference (https://en.wikipedia.org/wiki/Symmetric_difference) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] \"\"\" _ lst_1 , _ lst_2 = set ( map ( function , lst_1 )), set ( map ( function , lst_2 )) return [ item for item in lst_1 if function ( item ) not in _ lst_2 ] + [ item for item in lst_2 if function ( item ) not in _ lst_1 ] @staticmethod def union_by ( lst_1: Sequence , lst_2: Sequence , function : Callable ) -> list : \"\"\" Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union (https://en.wikipedia.org/wiki/Union_(set_theory)) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] \"\"\" _ lst_1 = set ( map ( function , lst_1 )) return sorted ( list ( set ( lst_1 + [ item for item in lst_2 if function ( item ) not in _ lst_1 ]))) @staticmethod def zipper ( * args , fillvalue = None ) -> list : \"\"\" Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Args: *args: a number (>= 2) of different iterables. fillvalue: value to use in case of length mismatch. Returns: A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\" a \", \" b \", \" c \"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] \"\"\" max_length = max ( len ( lst ) for lst in args ) return [ [ args [ k ][ i ] if i < len ( args [ k ]) else fillvalue for k in range ( len ( args ))] for i in range ( max_length ) ] class MiscellaneousOperations : \"\"\" A class to group some misc. operations that don't pertain to classic structures. \"\"\" @staticmethod def longest_item ( * args ) : \"\"\" Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Args: *args: any number (>= 2) of iterables. Returns: The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) \"\"\" return max ( args , key = len ) @staticmethod def map_values ( obj : dict , function : Callable ) -> dict : \"\"\" Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Args: obj: a dictionary. function (Callable): a callable on values of `obj`. Returns: A new dictionary with the results. Usage: map_values( {\" a \": list(range(5)), \" b \": list(range(10)), \" c \": list(range(15))}, lambda x: len(x) ) -> {\" a \": 5, \" b \": 10, \" c \": 15} \"\"\" ret = {} for key in obj : ret [ key ] = function ( obj [ key ]) return ret class NumberOperations : \"\"\" A class to group some common / useful operations on numbers. \"\"\" @staticmethod def clamp_number ( num : Union [ int , float ], a_val: Union [ int , float ], b_val: Union [ int , float ] ) -> Union [ int , float ] : \"\"\" Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Args: num (Union[int, float]): a number (float / int) a_val (Union[int, float]): a number (float / int) b_val (Union[int, float]): a number (float / int) Returns: A number (float / int), being the nearest to `num` in the range [`a_val`, `b_val`]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 \"\"\" return max ( min ( num , max ( a_val , b_val )), min ( a_val , b_val )) @staticmethod def degrees_to_radians ( deg_value: Union [ int , float ], decompose : bool = False ) -> Union [ Tuple [ float , str , str ], int , float ] : \"\"\" Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Args: deg_value (Union[int, float]): angle value in degrees. decompose (bool): boolean option to return a more verbose result. Defaults to False. Returns: The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \" pi \", \" rad \") \"\"\" if decompose : return deg_value / 180 , \"pi\" , \"rad\" return ( deg_value * math . pi ) / 180.0 @staticmethod def greatest_common_divisor ( numbers_list: Sequence ) -> Union [ int , float ] : \"\"\" Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in `numbers_list`. Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 \"\"\" return reduce ( math . gcd , numbers_list ) @staticmethod def is_divisible_by ( dividend : Union [ int , float ], divisor : Union [ int , float ]) -> bool : \"\"\" Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Args: dividend (Union[int, float]): a number. divisor (Union[int, float]): a number. Returns: A boolean stating if `dividend` can be divided by `divisor`. \"\"\" return dividend % divisor == 0 @staticmethod def least_common_multiple ( * args ) -> int : \"\"\" Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 \"\"\" numbers = list ( ListOperations . spread ( list ( args ))) def _ lcm ( number1 , number2 ) : \"\"\"A least common multiple method for two numbers only\"\"\" return int ( number1 * number2 / math . gcd ( number1 , number2 )) return reduce ( lambda x , y : _ lcm ( x , y ), numbers ) @staticmethod def radians_to_degrees ( rad_value: Union [ int , float ]) -> Union [ int , float ] : \"\"\" Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Args: rad_value (Union[int, float]): angle value in degrees. Returns: The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 \"\"\" return ( rad_value * 180.0 ) / math . pi class StringOperations : \"\"\" A class to group some common / useful operations on strings. \"\"\" @staticmethod def camel_case ( text : str ) -> str : \"\"\" Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Args: text (str): a string. Returns: The same string best adapted to camel_case. Usage: camel_case(\" a_snake_case_name \") -> \" aSnakeCaseName \" camel_case(\" A Title Case Name \") -> \" aTitleCaseName \" \"\"\" text = re . sub ( r \"(\\s|_|-)+\" , \" \" , text ). title (). replace ( \" \" , \"\" ) return text [ 0 ]. lower () + text [ 1 : ] @staticmethod def capitalize ( text : str , lower_rest: bool = False ) -> str : \"\"\" Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Args: text (str): a string. lower_rest (bool): boolean option to lower all elements starting from the second. Returns: The `string`, capitalized. Usage: capitalize(\" astringtocapitalize \") -> \" Astringtocapitalize \" capitalize(\" astRIngTocApItalizE \", lower_rest=True) -> \" Astringtocapitalize \" \"\"\" return text [ : 1 ]. upper () + ( text [ 1 : ]. lower () if lower_rest else text [ 1 : ]) @staticmethod def is_anagram ( str_1: str , str_2: str ) -> bool : \"\"\" Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Args: str_1 (str): a string. str_2 (str): a string. Returns: A boolean stating whether `str_1` is an anagram of `str_2` or not. Usage: is_anagram(\" Tom Marvolo Riddle \", \" I am Lord Voldemort \") -> True is_anagram(\" A first string \", \" Definitely not an anagram \") -> False \"\"\" _ str1 , _ str2 = ( str_1 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), str_2 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), ) return sorted ( _ str1 . lower ()) == sorted ( _ str2 . lower ()) @staticmethod def is_palindrome ( text : str ) -> bool : \"\"\" Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Args: text (str): a string. Returns: A boolean stating whether `string` is a palindrome or not. Usage: is_palindrome(\" racecar \") -> True is_palindrome(\" definitelynot \") -> False \"\"\" s_reverse = re . sub ( r \" [ \\ W_ ] \", \"\", text.lower()) return s_reverse == s_reverse[::-1] @staticmethod def kebab_case(text: str) -> str: \"\"\" Converts a string to kebab - case . Break the string into words and combine them adding - as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to kebab_case . Usage : kebab_case ( \"camel Case\" ) -> \"camel-case\" kebab_case ( \"snake_case\" ) -> \"snake-case\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" - \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \", lambda mo: mo.group(0).lower(), text, ), ) @staticmethod def snake_case(text: str) -> str: \"\"\" Converts a string to snake_case . Break the string into words and combine them adding _ as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to snake_case . Usage : snake_case ( \"A bunch of words\" ) -> \"a_bunch_of_words\" snake_case ( \"camelCase\" ) -> \"camelcase\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" _ \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \" , lambda mo : mo . group ( 0 ). lower (), text , ), )","title":"Module pyhdtoolkit.utils.operations"},{"location":"reference/pyhdtoolkit/utils/operations/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/utils/operations/#listoperations","text":"class ListOperations ( / , * args , ** kwargs ) View Source class ListOperations : \"\"\" A class to group some common / useful operations on lists. \"\"\" @ staticmethod def all_unique ( sequence : Sequence ) -> bool : \"\"\" Returns True if all the values in a flat list are unique, False otherwise. Args: sequence (Sequence): a sequence of elements. Returns: True if all elements are unique, False otherwise. \"\"\" return len ( sequence ) == len ( set ( sequence )) @ staticmethod def average_by ( sequence : Sequence , function : Callable = lambda x : x ) -> float : \"\"\" Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Args: sequence (Sequence): a sequence of elements. function (Callable): function to apply to elements of the sequence. Returns: The average of each element's result through `function`. Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 \"\"\" return float ( sum ( map ( function , sequence ), 0.0 ) / len ( sequence )) @ staticmethod def bifurcate ( sequence : Sequence , filters : List [ bool ]) -> Sequence : \"\"\" Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Args: sequence (Sequence): a sequence of elements. filters (List[bool]): a list of booleans. Returns: A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] \"\"\" return [ [ x for i , x in enumerate ( sequence ) if filters [ i ]], [ x for i , x in enumerate ( sequence ) if not filters [ i ]], ] @ staticmethod def bifurcate_by ( sequence : Sequence , function : Callable ) -> list : \"\"\" Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of lst, that should return a boolean. Returns: A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] \"\"\" return [[ x for x in sequence if function ( x )], [ x for x in sequence if not function ( x )]] @ staticmethod def chunk_list ( sequence : Sequence , size : int ) -> Sequence : \"\"\" Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Args: sequence (Sequence): a sequence of elements. size (int): the size of the wanted sublists. Returns: A list of lists of length `size` (except maybe the last element), with elements from `lst`. Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] \"\"\" if size > len ( sequence ): return sequence return list ( map ( lambda x : sequence [ x * size : x * size + size ], list ( range ( math . ceil ( len ( sequence ) / size ))),) ) @ staticmethod def deep_flatten ( sequence : Sequence ) -> list : \"\"\" Deep flattens a list, no matter the nesting levels. This is a recursive approach. Args: sequence (Sequence): a sequence of elements. Returns: A list with all elements of `lst`, but flattened. Usage: deep_flatten([[\"a\", \"b\"], [1, 2], None, [True, False]]) -> [\"a\", \"b\", 1, 2, None True, False] \"\"\" return ( [ elem for sublist in sequence for elem in ListOperations . deep_flatten ( sublist )] if isinstance ( sequence , list ) else [ sequence ] ) @ staticmethod def eval_none ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False \"\"\" return not any ( map ( function , sequence )) @ staticmethod def eval_some ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False \"\"\" return any ( map ( function , sequence )) @ staticmethod def get_indices ( element , sequence : Sequence ) -> List [ int ]: \"\"\" Return all array indices at which number is located. Args: element: any reference element to check. sequence (Sequence): a sequence containing objects comparable to `elements`. A string can be compared to an int in Python, custom objects probably won't be comparable. Returns: A list of all indices at which `element` is found in `sequence`. Empty list if `element` is not present in `sequence` at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] \"\"\" return [ i for ( y , i ) in zip ( sequence , range ( len ( sequence ))) if element == y ] @ staticmethod def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ]: \"\"\" Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of `sequence` that should return a boolean. Returns: A dict with keys \"True\" and \"False\", each having as value a list of all elements of `lst` that were evaluated to respectively `True` or `False` through `function`. Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} \"\"\" groups = {} for key in list ( map ( function , sequence )): groups [ key ] = [ item for item in sequence if function ( item ) == key ] return groups @ staticmethod def has_duplicates ( sequence : Sequence ) -> bool : \"\"\" Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Args: sequence (Sequence): a sequence of elements. Returns: A boolean indicating the presence of duplicates in `lst`. Usage: has_duplicates([1, 2, 1]) -> True \"\"\" return len ( sequence ) != len ( set ( sequence )) @ staticmethod def sample ( sequence : Sequence ) -> list : \"\"\" Returns a random element from an array. Args: sequence (Sequence): a sequence of elements. Returns: A random element from `lst` in a list (to manage potentially nested lists as input). \"\"\" return sequence [ random . randint ( 0 , len ( sequence ) - 1 )] @ staticmethod def sanitize_list ( sequence : Sequence ) -> list : \"\"\" Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Args: sequence (Sequence): a sequence of elements. Returns: The sequence without falsy values. Usage: sanitize_list([1, False, \"a\", 2, \"\", None, 6, 0]) -> [1, \"a\", 2, 6] \"\"\" return list ( filter ( bool , sequence )) @ staticmethod def shuffle ( sequence : Sequence ) -> Sequence : \"\"\" Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm (https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle) to reorder the elements. Args: sequence (Sequence): a sequence of elements. Returns: The `lst` with original elements at a random index. \"\"\" temp_list = copy . deepcopy ( sequence ) amount_to_shuffle = len ( temp_list ) while amount_to_shuffle > 1 : rand_index = int ( math . floor ( random . random () * amount_to_shuffle )) amount_to_shuffle -= 1 temp_list [ rand_index ], temp_list [ amount_to_shuffle ] = ( temp_list [ amount_to_shuffle ], temp_list [ rand_index ], ) return temp_list @ staticmethod def spread ( sequence : Sequence ) -> list : \"\"\" Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in `lst` are iterables! Args: sequence (Sequence): a sequence of elements. Returns: The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] \"\"\" return list ( itertools . chain . from_iterable ( sequence )) @ staticmethod def symmetric_difference_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \"\"\" Returns the symmetric difference (https://en.wikipedia.org/wiki/Symmetric_difference) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] \"\"\" _lst_1 , _lst_2 = set ( map ( function , lst_1 )), set ( map ( function , lst_2 )) return [ item for item in lst_1 if function ( item ) not in _lst_2 ] + [ item for item in lst_2 if function ( item ) not in _lst_1 ] @ staticmethod def union_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \"\"\" Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union (https://en.wikipedia.org/wiki/Union_(set_theory)) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] \"\"\" _lst_1 = set ( map ( function , lst_1 )) return sorted ( list ( set ( lst_1 + [ item for item in lst_2 if function ( item ) not in _lst_1 ]))) @ staticmethod def zipper ( * args , fillvalue = None ) -> list : \"\"\" Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Args: *args: a number (>= 2) of different iterables. fillvalue: value to use in case of length mismatch. Returns: A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\"a\", \"b\", \"c\"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] \"\"\" max_length = max ( len ( lst ) for lst in args ) return [ [ args [ k ][ i ] if i < len ( args [ k ]) else fillvalue for k in range ( len ( args ))] for i in range ( max_length ) ]","title":"ListOperations"},{"location":"reference/pyhdtoolkit/utils/operations/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/utils/operations/#all_unique","text":"def all_unique ( sequence : Sequence ) -> bool Returns True if all the values in a flat list are unique, False otherwise. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None Returns: Type Description None True if all elements are unique, False otherwise. View Source @staticmethod def all_unique ( sequence : Sequence ) -> bool : \"\"\" Returns True if all the values in a flat list are unique, False otherwise. Args: sequence (Sequence): a sequence of elements. Returns: True if all elements are unique, False otherwise. \"\"\" return len ( sequence ) == len ( set ( sequence ))","title":"all_unique"},{"location":"reference/pyhdtoolkit/utils/operations/#average_by","text":"def average_by ( sequence : Sequence , function : Callable = < function ListOperations .< lambda > at 0x7fbb1cf32c20 > ) -> float Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Parameters: Name Type Description Default sequence Sequence a sequence of elements. None function Callable function to apply to elements of the sequence. None Returns: Type Description None The average of each element's result through function . Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 | View Source @staticmethod def average_by ( sequence : Sequence , function : Callable = lambda x : x ) -> float : \" \"\" Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Args: sequence (Sequence): a sequence of elements. function (Callable): function to apply to elements of the sequence. Returns: The average of each element's result through `function`. Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 \"\" \" return float ( sum ( map ( function , sequence ), 0.0 ) / len ( sequence ))","title":"average_by"},{"location":"reference/pyhdtoolkit/utils/operations/#bifurcate","text":"def bifurcate ( sequence : Sequence , filters : List [ bool ] ) -> Sequence Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None filters List[bool] a list of booleans. None Returns: Type Description None A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] | View Source @staticmethod def bifurcate ( sequence : Sequence , filters : List [ bool ] ) -> Sequence : \"\"\" Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Args: sequence (Sequence): a sequence of elements. filters (List[bool]): a list of booleans. Returns: A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] \"\"\" return [ [x for i, x in enumerate(sequence) if filters[i ] ] , [ x for i, x in enumerate(sequence) if not filters[i ] ] , ]","title":"bifurcate"},{"location":"reference/pyhdtoolkit/utils/operations/#bifurcate_by","text":"def bifurcate_by ( sequence : Sequence , function : Callable ) -> list Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None function Callable a callable on the elements of lst, that should return a boolean. None Returns: Type Description None A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] | View Source @staticmethod def bifurcate_by ( sequence : Sequence , function : Callable ) -> list : \"\"\" Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of lst, that should return a boolean. Returns: A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] \"\"\" return [ [x for x in sequence if function(x) ] , [ x for x in sequence if not function(x) ] ]","title":"bifurcate_by"},{"location":"reference/pyhdtoolkit/utils/operations/#chunk_list","text":"def chunk_list ( sequence : Sequence , size : int ) -> Sequence Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None size int the size of the wanted sublists. None Returns: Type Description None A list of lists of length size (except maybe the last element), with elements from lst . Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] | View Source @staticmethod def chunk_list ( sequence : Sequence , size : int ) -> Sequence : \" \"\" Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Args: sequence (Sequence): a sequence of elements. size (int): the size of the wanted sublists. Returns: A list of lists of length `size` (except maybe the last element), with elements from `lst`. Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] \"\" \" if size > len ( sequence ) : return sequence return list ( map ( lambda x : sequence [ x * size : x * size + size ] , list ( range ( math . ceil ( len ( sequence ) / size ))),) )","title":"chunk_list"},{"location":"reference/pyhdtoolkit/utils/operations/#deep_flatten","text":"def deep_flatten ( sequence : Sequence ) -> list Deep flattens a list, no matter the nesting levels. This is a recursive approach. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None Returns: Type Description None A list with all elements of lst , but flattened. Usage: deep_flatten([[\"a\", \"b\"], [1, 2], None, [True, False]]) -> [\"a\", \"b\", 1, 2, None True, False] | View Source @staticmethod def deep_flatten ( sequence : Sequence ) -> list : \"\"\" Deep flattens a list, no matter the nesting levels. This is a recursive approach. Args: sequence (Sequence): a sequence of elements. Returns: A list with all elements of `lst`, but flattened. Usage: deep_flatten([[\" a \", \" b \"], [1, 2], None, [True, False]]) -> [\" a \", \" b \", 1, 2, None True, False] \"\"\" return ( [ elem for sublist in sequence for elem in ListOperations.deep_flatten(sublist) ] if isinstance ( sequence , list ) else [ sequence ] )","title":"deep_flatten"},{"location":"reference/pyhdtoolkit/utils/operations/#eval_none","text":"def eval_none ( sequence : Sequence , function : Callable = < function ListOperations .< lambda > at 0x7fbb1cf32f80 > ) -> bool Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None function Callable a callable on elements of sequence that should return a boolean. None Returns: Type Description None A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False | View Source @staticmethod def eval_none ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \" \"\" Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False \"\" \" return not any ( map ( function , sequence ))","title":"eval_none"},{"location":"reference/pyhdtoolkit/utils/operations/#eval_some","text":"def eval_some ( sequence : Sequence , function : Callable = < function ListOperations .< lambda > at 0x7fbb1cfd00e0 > ) -> bool Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None function Callable a callable on elements of sequence that should return a boolean. None Returns: Type Description None A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False | View Source @staticmethod def eval_some ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \" \"\" Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False \"\" \" return any ( map ( function , sequence ))","title":"eval_some"},{"location":"reference/pyhdtoolkit/utils/operations/#get_indices","text":"def get_indices ( element , sequence : Sequence ) -> List [ int ] Return all array indices at which number is located. Parameters: Name Type Description Default element None any reference element to check. None sequence Sequence a sequence containing objects comparable to elements . A string can be compared to an int in Python, custom objects probably won't be comparable. None Returns: Type Description None A list of all indices at which element is found in sequence . Empty list if element is not present in sequence at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] | View Source @staticmethod def get_indices ( element , sequence : Sequence ) -> List [ int ] : \" \"\" Return all array indices at which number is located. Args: element: any reference element to check. sequence (Sequence): a sequence containing objects comparable to `elements`. A string can be compared to an int in Python, custom objects probably won't be comparable. Returns: A list of all indices at which `element` is found in `sequence`. Empty list if `element` is not present in `sequence` at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] \"\" \" return [ i for ( y , i ) in zip ( sequence , range ( len ( sequence ))) if element == y ]","title":"get_indices"},{"location":"reference/pyhdtoolkit/utils/operations/#group_by","text":"def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ] Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None function Callable a callable on the elements of sequence that should return a boolean. None Returns: Type Description None A dict with keys \"True\" and \"False\", each having as value a list of all elements of lst that were evaluated to respectively True or False through function . Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} | View Source @staticmethod def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ] : \" \"\" Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of `sequence` that should return a boolean. Returns: A dict with keys \" True \" and \" False \", each having as value a list of all elements of `lst` that were evaluated to respectively `True` or `False` through `function`. Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} \"\" \" groups = {} for key in list ( map ( function , sequence )) : groups [ key ] = [ item for item in sequence if function ( item ) == key ] return groups","title":"group_by"},{"location":"reference/pyhdtoolkit/utils/operations/#has_duplicates","text":"def has_duplicates ( sequence : Sequence ) -> bool Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None Returns: Type Description None A boolean indicating the presence of duplicates in lst . Usage: has_duplicates([1, 2, 1]) -> True | View Source @staticmethod def has_duplicates ( sequence : Sequence ) -> bool : \" \"\" Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Args: sequence (Sequence): a sequence of elements. Returns: A boolean indicating the presence of duplicates in `lst`. Usage: has_duplicates([1, 2, 1]) -> True \"\" \" return len ( sequence ) != len ( set ( sequence ))","title":"has_duplicates"},{"location":"reference/pyhdtoolkit/utils/operations/#sample","text":"def sample ( sequence : Sequence ) -> list Returns a random element from an array. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None Returns: Type Description None A random element from lst in a list (to manage potentially nested lists as input). View Source @staticmethod def sample ( sequence : Sequence ) -> list : \" \"\" Returns a random element from an array. Args: sequence (Sequence): a sequence of elements. Returns: A random element from `lst` in a list (to manage potentially nested lists as input). \"\" \" return sequence [ random . randint ( 0 , len ( sequence ) - 1 ) ]","title":"sample"},{"location":"reference/pyhdtoolkit/utils/operations/#sanitize_list","text":"def sanitize_list ( sequence : Sequence ) -> list Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Parameters: Name Type Description Default sequence Sequence a sequence of elements. None Returns: Type Description None The sequence without falsy values. Usage: sanitize_list([1, False, \"a\", 2, \"\", None, 6, 0]) -> [1, \"a\", 2, 6] | View Source @staticmethod def sanitize_list ( sequence : Sequence ) -> list : \"\"\" Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Args: sequence (Sequence): a sequence of elements. Returns: The sequence without falsy values. Usage: sanitize_list([1, False, \" a \", 2, \"\", None, 6, 0]) -> [1, \" a \", 2, 6] \"\"\" return list ( filter ( bool , sequence ))","title":"sanitize_list"},{"location":"reference/pyhdtoolkit/utils/operations/#shuffle","text":"def shuffle ( sequence : Sequence ) -> Sequence Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm ( https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle ) to reorder the elements. Parameters: Name Type Description Default sequence Sequence a sequence of elements. None Returns: Type Description None The lst with original elements at a random index. View Source @staticmethod def shuffle ( sequence : Sequence ) -> Sequence : \"\"\" Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm (https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle) to reorder the elements. Args: sequence (Sequence): a sequence of elements. Returns: The `lst` with original elements at a random index. \"\"\" temp_list = copy . deepcopy ( sequence ) amount_to_shuffle = len ( temp_list ) while amount_to_shuffle > 1 : rand_index = int ( math . floor ( random . random () * amount_to_shuffle )) amount_to_shuffle -= 1 temp_list [ rand_index ] , temp_list [ amount_to_shuffle ] = ( temp_list [ amount_to_shuffle ] , temp_list [ rand_index ] , ) return temp_list","title":"shuffle"},{"location":"reference/pyhdtoolkit/utils/operations/#spread","text":"def spread ( sequence : Sequence ) -> list Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in lst are iterables! Parameters: Name Type Description Default sequence Sequence a sequence of elements. None Returns: Type Description None The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] | View Source @staticmethod def spread ( sequence : Sequence ) -> list : \" \"\" Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in `lst` are iterables! Args: sequence (Sequence): a sequence of elements. Returns: The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] \"\" \" return list ( itertools . chain . from_iterable ( sequence ))","title":"spread"},{"location":"reference/pyhdtoolkit/utils/operations/#symmetric_difference_by","text":"def symmetric_difference_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list Returns the symmetric difference ( https://en.wikipedia.org/wiki/Symmetric_difference ) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Parameters: Name Type Description Default lst_1 Sequence a sequence of elements. None lst_2 Sequence a sequence of elements. None function Callable a callable on elements of lst_1 and lst_2 . None Returns: Type Description None A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] | View Source @staticmethod def symmetric_difference_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \" \"\" Returns the symmetric difference (https://en.wikipedia.org/wiki/Symmetric_difference) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] \"\" \" _lst_1 , _lst_2 = set ( map ( function , lst_1 )), set ( map ( function , lst_2 )) return [ item for item in lst_1 if function ( item ) not in _lst_2 ] + [ item for item in lst_2 if function ( item ) not in _lst_1 ]","title":"symmetric_difference_by"},{"location":"reference/pyhdtoolkit/utils/operations/#union_by","text":"def union_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union ( https://en.wikipedia.org/wiki/Union_(set_theory )) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Parameters: Name Type Description Default lst_1 Sequence a sequence of elements. None lst_2 Sequence a sequence of elements. None function Callable a callable on elements of lst_1 and lst_2 . None Returns: Type Description None A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] | View Source @staticmethod def union_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \" \"\" Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union (https://en.wikipedia.org/wiki/Union_(set_theory)) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] \"\" \" _lst_1 = set ( map ( function , lst_1 )) return sorted ( list ( set ( lst_1 + [ item for item in lst_2 if function ( item ) not in _lst_1 ] )))","title":"union_by"},{"location":"reference/pyhdtoolkit/utils/operations/#zipper","text":"def zipper ( * args , fillvalue = None ) -> list Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Parameters: Name Type Description Default *args None a number (>= 2) of different iterables. None fillvalue None value to use in case of length mismatch. None Returns: Type Description None A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\"a\", \"b\", \"c\"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] | View Source @staticmethod def zipper ( * args , fillvalue = None ) -> list : \"\"\" Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Args: *args: a number (>= 2) of different iterables. fillvalue: value to use in case of length mismatch. Returns: A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\" a \", \" b \", \" c \"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] \"\"\" max_length = max ( len ( lst ) for lst in args ) return [ [args[k ][ i ] if i < len ( args [ k ] ) else fillvalue for k in range ( len ( args )) ] for i in range ( max_length ) ]","title":"zipper"},{"location":"reference/pyhdtoolkit/utils/operations/#miscellaneousoperations","text":"class MiscellaneousOperations ( / , * args , ** kwargs ) View Source class MiscellaneousOperations : \"\"\" A class to group some misc. operations that don't pertain to classic structures. \"\"\" @staticmethod def longest_item ( * args ) : \"\"\" Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Args: *args: any number (>= 2) of iterables. Returns: The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) \"\"\" return max ( args , key = len ) @staticmethod def map_values ( obj : dict , function : Callable ) -> dict : \"\"\" Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Args: obj: a dictionary. function (Callable): a callable on values of `obj`. Returns: A new dictionary with the results. Usage: map_values( {\" a \": list(range(5)), \" b \": list(range(10)), \" c \": list(range(15))}, lambda x: len(x) ) -> {\" a \": 5, \" b \": 10, \" c \": 15} \"\"\" ret = {} for key in obj : ret [ key ] = function ( obj [ key ] ) return ret","title":"MiscellaneousOperations"},{"location":"reference/pyhdtoolkit/utils/operations/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/utils/operations/#longest_item","text":"def longest_item ( * args ) Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Parameters: Name Type Description Default *args None any number (>= 2) of iterables. None Returns: Type Description None The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) | View Source @staticmethod def longest_item ( * args ) : \"\"\" Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Args: *args: any number (>= 2) of iterables. Returns: The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) \"\"\" return max ( args , key = len )","title":"longest_item"},{"location":"reference/pyhdtoolkit/utils/operations/#map_values","text":"def map_values ( obj : dict , function : Callable ) -> dict Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Parameters: Name Type Description Default obj None a dictionary. None function Callable a callable on values of obj . None Returns: Type Description None A new dictionary with the results. Usage: map_values( {\"a\": list(range(5)), \"b\": list(range(10)), \"c\": list(range(15))}, lambda x: len(x) ) -> {\"a\": 5, \"b\": 10, \"c\": 15} | View Source @staticmethod def map_values ( obj : dict , function : Callable ) -> dict : \"\"\" Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Args: obj: a dictionary. function (Callable): a callable on values of `obj`. Returns: A new dictionary with the results. Usage: map_values( {\" a \": list(range(5)), \" b \": list(range(10)), \" c \": list(range(15))}, lambda x: len(x) ) -> {\" a \": 5, \" b \": 10, \" c \": 15} \"\"\" ret = {} for key in obj : ret [ key ] = function ( obj [ key ] ) return ret","title":"map_values"},{"location":"reference/pyhdtoolkit/utils/operations/#numberoperations","text":"class NumberOperations ( / , * args , ** kwargs ) View Source class NumberOperations : \" \"\" A class to group some common / useful operations on numbers. \"\" \" @staticmethod def clamp_number ( num : Union [ int , float ] , a_val : Union [ int , float ] , b_val : Union [ int , float ] ) -> Union [ int , float ] : \" \"\" Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Args: num (Union[int, float]): a number (float / int) a_val (Union[int, float]): a number (float / int) b_val (Union[int, float]): a number (float / int) Returns: A number (float / int), being the nearest to `num` in the range [`a_val`, `b_val`]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 \"\" \" return max ( min ( num , max ( a_val , b_val )), min ( a_val , b_val )) @staticmethod def degrees_to_radians ( deg_value : Union [ int , float ] , decompose : bool = False ) -> Union [ Tuple [ float , str , str ] , int , float ] : \" \"\" Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Args: deg_value (Union[int, float]): angle value in degrees. decompose (bool): boolean option to return a more verbose result. Defaults to False. Returns: The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \" pi \", \" rad \") \"\" \" if decompose : return deg_value / 180 , \"pi\" , \"rad\" return ( deg_value * math . pi ) / 180.0 @staticmethod def greatest_common_divisor ( numbers_list : Sequence ) -> Union [ int , float ] : \" \"\" Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in `numbers_list`. Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 \"\" \" return reduce ( math . gcd , numbers_list ) @staticmethod def is_divisible_by ( dividend : Union [ int , float ] , divisor : Union [ int , float ] ) -> bool : \" \"\" Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Args: dividend (Union[int, float]): a number. divisor (Union[int, float]): a number. Returns: A boolean stating if `dividend` can be divided by `divisor`. \"\" \" return dividend % divisor == 0 @staticmethod def least_common_multiple ( * args ) -> int : \" \"\" Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 \"\" \" numbers = list ( ListOperations . spread ( list ( args ))) def _lcm ( number1 , number2 ) : \" \"\" A least common multiple method for two numbers only \"\" \" return int ( number1 * number2 / math . gcd ( number1 , number2 )) return reduce ( lambda x , y : _lcm ( x , y ), numbers ) @staticmethod def radians_to_degrees ( rad_value : Union [ int , float ] ) -> Union [ int , float ] : \" \"\" Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Args: rad_value (Union[int, float]): angle value in degrees. Returns: The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 \"\" \" return ( rad_value * 180.0 ) / math . pi","title":"NumberOperations"},{"location":"reference/pyhdtoolkit/utils/operations/#static-methods_2","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/utils/operations/#clamp_number","text":"def clamp_number ( num : Union [ int , float ], a_val : Union [ int , float ], b_val : Union [ int , float ] ) -> Union [ int , float ] Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Parameters: Name Type Description Default num Union[int, float] a number (float / int) None a_val Union[int, float] a number (float / int) None b_val Union[int, float] a number (float / int) None Returns: Type Description None A number (float / int), being the nearest to num in the range [ a_val , b_val ]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 | View Source @staticmethod def clamp_number ( num : Union [ int , float ] , a_val : Union [ int , float ] , b_val : Union [ int , float ] ) -> Union [ int , float ] : \" \"\" Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Args: num (Union[int, float]): a number (float / int) a_val (Union[int, float]): a number (float / int) b_val (Union[int, float]): a number (float / int) Returns: A number (float / int), being the nearest to `num` in the range [`a_val`, `b_val`]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 \"\" \" return max ( min ( num , max ( a_val , b_val )), min ( a_val , b_val ))","title":"clamp_number"},{"location":"reference/pyhdtoolkit/utils/operations/#degrees_to_radians","text":"def degrees_to_radians ( deg_value : Union [ int , float ], decompose : bool = False ) -> Union [ Tuple [ float , str , str ], int , float ] Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Parameters: Name Type Description Default deg_value Union[int, float] angle value in degrees. None decompose bool boolean option to return a more verbose result. Defaults to False. False Returns: Type Description None The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \"pi\", \"rad\") | View Source @staticmethod def degrees_to_radians ( deg_value : Union [ int, float ] , decompose : bool = False ) -> Union [ Tuple[float, str, str ] , int , float ]: \"\"\" Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Args: deg_value (Union[int, float]): angle value in degrees. decompose (bool): boolean option to return a more verbose result. Defaults to False. Returns: The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \" pi \", \" rad \") \"\"\" if decompose : return deg_value / 180 , \"pi\" , \"rad\" return ( deg_value * math . pi ) / 180.0","title":"degrees_to_radians"},{"location":"reference/pyhdtoolkit/utils/operations/#greatest_common_divisor","text":"def greatest_common_divisor ( numbers_list : Sequence ) -> Union [ int , float ] Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in numbers_list . Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 View Source @staticmethod def greatest_common_divisor ( numbers_list : Sequence ) -> Union [ int , float ] : \" \"\" Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in `numbers_list`. Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 \"\" \" return reduce ( math . gcd , numbers_list )","title":"greatest_common_divisor"},{"location":"reference/pyhdtoolkit/utils/operations/#is_divisible_by","text":"def is_divisible_by ( dividend : Union [ int , float ], divisor : Union [ int , float ] ) -> bool Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Parameters: Name Type Description Default dividend Union[int, float] a number. None divisor Union[int, float] a number. None Returns: Type Description None A boolean stating if dividend can be divided by divisor . View Source @staticmethod def is_divisible_by ( dividend : Union [ int , float ] , divisor : Union [ int , float ] ) -> bool : \" \"\" Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Args: dividend (Union[int, float]): a number. divisor (Union[int, float]): a number. Returns: A boolean stating if `dividend` can be divided by `divisor`. \"\" \" return dividend % divisor == 0","title":"is_divisible_by"},{"location":"reference/pyhdtoolkit/utils/operations/#least_common_multiple","text":"def least_common_multiple ( * args ) -> int Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 View Source @staticmethod def least_common_multiple ( * args ) -> int : \"\"\" Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 \"\"\" numbers = list ( ListOperations . spread ( list ( args ))) def _lcm ( number1 , number2 ) : \"\"\"A least common multiple method for two numbers only\"\"\" return int ( number1 * number2 / math . gcd ( number1 , number2 )) return reduce ( lambda x , y : _lcm ( x , y ), numbers )","title":"least_common_multiple"},{"location":"reference/pyhdtoolkit/utils/operations/#radians_to_degrees","text":"def radians_to_degrees ( rad_value : Union [ int , float ] ) -> Union [ int , float ] Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Parameters: Name Type Description Default rad_value Union[int, float] angle value in degrees. None Returns: Type Description None The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 | View Source @staticmethod def radians_to_degrees ( rad_value : Union [ int, float ] ) -> Union [ int, float ] : \"\"\" Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Args: rad_value (Union[int, float]): angle value in degrees. Returns: The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 \"\"\" return ( rad_value * 180.0 ) / math . pi","title":"radians_to_degrees"},{"location":"reference/pyhdtoolkit/utils/operations/#stringoperations","text":"class StringOperations ( / , * args , ** kwargs ) View Source class StringOperations : \"\"\" A class to group some common / useful operations on strings. \"\"\" @staticmethod def camel_case ( text : str ) -> str : \"\"\" Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Args: text (str): a string. Returns: The same string best adapted to camel_case. Usage: camel_case(\" a_snake_case_name \") -> \" aSnakeCaseName \" camel_case(\" A Title Case Name \") -> \" aTitleCaseName \" \"\"\" text = re . sub ( r \"(\\s|_|-)+\" , \" \" , text ). title (). replace ( \" \" , \"\" ) return text [ 0 ]. lower () + text [ 1 : ] @staticmethod def capitalize ( text : str , lower_rest: bool = False ) -> str : \"\"\" Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Args: text (str): a string. lower_rest (bool): boolean option to lower all elements starting from the second. Returns: The `string`, capitalized. Usage: capitalize(\" astringtocapitalize \") -> \" Astringtocapitalize \" capitalize(\" astRIngTocApItalizE \", lower_rest=True) -> \" Astringtocapitalize \" \"\"\" return text [ : 1 ]. upper () + ( text [ 1 : ]. lower () if lower_rest else text [ 1 : ]) @staticmethod def is_anagram ( str_1: str , str_2: str ) -> bool : \"\"\" Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Args: str_1 (str): a string. str_2 (str): a string. Returns: A boolean stating whether `str_1` is an anagram of `str_2` or not. Usage: is_anagram(\" Tom Marvolo Riddle \", \" I am Lord Voldemort \") -> True is_anagram(\" A first string \", \" Definitely not an anagram \") -> False \"\"\" _ str1 , _ str2 = ( str_1 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), str_2 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), ) return sorted ( _ str1 . lower ()) == sorted ( _ str2 . lower ()) @staticmethod def is_palindrome ( text : str ) -> bool : \"\"\" Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Args: text (str): a string. Returns: A boolean stating whether `string` is a palindrome or not. Usage: is_palindrome(\" racecar \") -> True is_palindrome(\" definitelynot \") -> False \"\"\" s_reverse = re . sub ( r \" [ \\ W_ ] \", \"\", text.lower()) return s_reverse == s_reverse[::-1] @staticmethod def kebab_case(text: str) -> str: \"\"\" Converts a string to kebab - case . Break the string into words and combine them adding - as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to kebab_case . Usage : kebab_case ( \"camel Case\" ) -> \"camel-case\" kebab_case ( \"snake_case\" ) -> \"snake-case\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" - \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \", lambda mo: mo.group(0).lower(), text, ), ) @staticmethod def snake_case(text: str) -> str: \"\"\" Converts a string to snake_case . Break the string into words and combine them adding _ as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to snake_case . Usage : snake_case ( \"A bunch of words\" ) -> \"a_bunch_of_words\" snake_case ( \"camelCase\" ) -> \"camelcase\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" _ \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \" , lambda mo : mo . group ( 0 ). lower (), text , ), )","title":"StringOperations"},{"location":"reference/pyhdtoolkit/utils/operations/#static-methods_3","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/utils/operations/#camel_case","text":"def camel_case ( text : str ) -> str Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Parameters: Name Type Description Default text str a string. None Returns: Type Description None The same string best adapted to camel_case. Usage: camel_case(\"a_snake_case_name\") -> \"aSnakeCaseName\" camel_case(\"A Title Case Name\") -> \"aTitleCaseName\" | View Source @staticmethod def camel_case ( text : str ) -> str : \"\"\" Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Args: text (str): a string. Returns: The same string best adapted to camel_case. Usage: camel_case(\" a_snake_case_name \") -> \" aSnakeCaseName \" camel_case(\" A Title Case Name \") -> \" aTitleCaseName \" \"\"\" text = re . sub ( r \"(\\s|_|-)+\" , \" \" , text ). title (). replace ( \" \" , \"\" ) return text [ 0 ] . lower () + text [ 1: ]","title":"camel_case"},{"location":"reference/pyhdtoolkit/utils/operations/#capitalize","text":"def capitalize ( text : str , lower_rest : bool = False ) -> str Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Parameters: Name Type Description Default text str a string. None lower_rest bool boolean option to lower all elements starting from the second. None Returns: Type Description None The string , capitalized. Usage: capitalize(\"astringtocapitalize\") -> \"Astringtocapitalize\" capitalize(\"astRIngTocApItalizE\", lower_rest=True) -> \"Astringtocapitalize\" | View Source @staticmethod def capitalize ( text : str , lower_rest : bool = False ) -> str : \" \"\" Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Args: text (str): a string. lower_rest (bool): boolean option to lower all elements starting from the second. Returns: The `string`, capitalized. Usage: capitalize(\" astringtocapitalize \") -> \" Astringtocapitalize \" capitalize(\" astRIngTocApItalizE \", lower_rest=True) -> \" Astringtocapitalize \" \"\" \" return text [ : 1 ] . upper () + ( text [ 1 : ] . lower () if lower_rest else text [ 1 : ] )","title":"capitalize"},{"location":"reference/pyhdtoolkit/utils/operations/#is_anagram","text":"def is_anagram ( str_1 : str , str_2 : str ) -> bool Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Parameters: Name Type Description Default str_1 str a string. None str_2 str a string. None Returns: Type Description None A boolean stating whether str_1 is an anagram of str_2 or not. Usage: is_anagram(\"Tom Marvolo Riddle\", \"I am Lord Voldemort\") -> True is_anagram(\"A first string\", \"Definitely not an anagram\") -> False | View Source @staticmethod def is_anagram ( str_1 : str , str_2 : str ) -> bool : \" \"\" Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Args: str_1 (str): a string. str_2 (str): a string. Returns: A boolean stating whether `str_1` is an anagram of `str_2` or not. Usage: is_anagram(\" Tom Marvolo Riddle \", \" I am Lord Voldemort \") -> True is_anagram(\" A first string \", \" Definitely not an anagram \") -> False \"\" \" _str1 , _str2 = ( str_1 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), str_2 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), ) return sorted ( _str1 . lower ()) == sorted ( _str2 . lower ())","title":"is_anagram"},{"location":"reference/pyhdtoolkit/utils/operations/#is_palindrome","text":"def is_palindrome ( text : str ) -> bool Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Parameters: Name Type Description Default text str a string. None Returns: Type Description None A boolean stating whether string is a palindrome or not. Usage: is_palindrome(\"racecar\") -> True is_palindrome(\"definitelynot\") -> False | View Source @staticmethod def is_palindrome ( text : str ) -> bool : \"\"\" Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Args: text (str): a string. Returns: A boolean stating whether `string` is a palindrome or not. Usage: is_palindrome(\" racecar \") -> True is_palindrome(\" definitelynot \") -> False \"\"\" s_reverse = re . sub ( r \" [ \\ W_ ] \", \" \" , text . lower ()) return s_reverse == s_reverse [ ::- 1 ]","title":"is_palindrome"},{"location":"reference/pyhdtoolkit/utils/operations/#kebab_case","text":"def kebab_case ( text : str ) -> str Converts a string to kebab-case. Break the string into words and combine them adding - as a separator, using a regexp. Parameters: Name Type Description Default text str a string. None Returns: Type Description None The same string best adapted to kebab_case. Usage: kebab_case(\"camel Case\") -> \"camel-case\" kebab_case(\"snake_case\") -> \"snake-case\" | View Source @staticmethod def kebab_case ( text : str ) -> str : \"\"\" Converts a string to kebab-case. Break the string into words and combine them adding - as a separator, using a regexp. Args: text (str): a string. Returns: The same string best adapted to kebab_case. Usage: kebab_case(\" camel Case \") -> \" camel - case \" kebab_case(\" snake_case \") -> \" snake - case \" \"\"\" return re . sub ( r \"(\\s|_|-)+\" , \"-\" , re . sub ( r \"[A-Z]{2,}(?=[A-Z][a-z]+[0-9]*|\\b)|[A-Z]?[a-z]+[0-9]*|[A-Z]|[0-9]+\" , lambda mo : mo . group ( 0 ). lower (), text , ), )","title":"kebab_case"},{"location":"reference/pyhdtoolkit/utils/operations/#snake_case","text":"def snake_case ( text : str ) -> str Converts a string to snake_case. Break the string into words and combine them adding _ as a separator, using a regexp. Parameters: Name Type Description Default text str a string. None Returns: Type Description None The same string best adapted to snake_case. Usage: snake_case(\"A bunch of words\") -> \"a_bunch_of_words\" snake_case(\"camelCase\") -> \"camelcase\" | View Source @staticmethod def snake_case ( text : str ) -> str : \"\"\" Converts a string to snake_case. Break the string into words and combine them adding _ as a separator, using a regexp. Args: text (str): a string. Returns: The same string best adapted to snake_case. Usage: snake_case(\" A bunch of words \") -> \" a_bunch_of_words \" snake_case(\" camelCase \") -> \" camelcase \" \"\"\" return re . sub ( r \"(\\s|_|-)+\" , \"_\" , re . sub ( r \"[A-Z]{2,}(?=[A-Z][a-z]+[0-9]*|\\b)|[A-Z]?[a-z]+[0-9]*|[A-Z]|[0-9]+\" , lambda mo : mo . group ( 0 ). lower (), text , ), )","title":"snake_case"},{"location":"reference/pyhdtoolkit/utils/printutil/","text":"Module pyhdtoolkit.utils.printutil Module utils.printutil Created on 2019.12.11 View Source \"\"\" Module utils.printutil ---------------------- Created on 2019.12.11 :author: Felix Soubelet (felix.soubelet@cern.ch) A class utility class to allow me printing text in color, bold, etc. \"\"\" END = \"\\033[0m\" class Background : \"\"\" ANSI color escape sequences for the background of a terminal output. \"\"\" black = \"\\033[40m\" blue = \"\\033[44m\" cyan = \"\\033[46m\" green = \"\\033[42m\" grey = \"\\033[47m\" magenta = \"\\033[45m\" red = \"\\033[41m\" yellow = \"\\033[43m\" class Foreground : \"\"\" ANSI color escape sequences for the foreground of a terminal output. \"\"\" blue = \"\\033[94m\" cyan = \"\\033[96m\" dark_blue = \"\\033[34m\" dark_cyan = \"\\033[36m\" dark_green = \"\\033[32m\" dark_grey = \"\\033[90m\" dark_red = \"\\033[31m\" dark_yellow = \"\\033[33m\" green = \"\\033[92m\" grey = \"\\033[37m\" magenta = \"\\033[35m\" pink = \"\\033[95m\" red = \"\\033[91m\" yellow = \"\\033[93m\" white = \"\\033[30m\" class Styles : \"\"\" ANSI style escape sequences for a terminal output. \"\"\" all_off = \"\\033[0m\" bold = \"\\033[1m\" concealed = \"\\033[7m\" disable = \"\\033[02m\" reverse = \"\\033[7m\" strikethrough = \"\\033[09m\" underscore = \"\\033[4m\" Variables END Classes Background class Background ( / , * args , ** kwargs ) View Source class Background: \"\"\" ANSI color escape sequences for the background of a terminal output. \"\"\" black = \"\\033[40m\" blue = \"\\033[44m\" cyan = \"\\033[46m\" green = \"\\033[42m\" grey = \"\\033[47m\" magenta = \"\\033[45m\" red = \"\\033[41m\" yellow = \"\\033[43m\" Class variables black blue cyan green grey magenta red yellow Foreground class Foreground ( / , * args , ** kwargs ) View Source class Foreground: \"\"\" ANSI color escape sequences for the foreground of a terminal output . \"\"\" blue = \" \\033 [94m\" cyan = \" \\033 [96m\" dark_blue = \" \\033 [34m\" dark_cyan = \" \\033 [36m\" dark_green = \" \\033 [32m\" dark_grey = \" \\033 [90m\" dark_red = \" \\033 [31m\" dark_yellow = \" \\033 [33m\" green = \" \\033 [92m\" grey = \" \\033 [37m\" magenta = \" \\033 [35m\" pink = \" \\033 [95m\" red = \" \\033 [91m\" yellow = \" \\033 [93m\" white = \" \\033 [30m\" Class variables blue cyan dark_blue dark_cyan dark_green dark_grey dark_red dark_yellow green grey magenta pink red white yellow Styles class Styles ( / , * args , ** kwargs ) View Source class Styles: \"\"\" ANSI style escape sequences for a terminal output. \"\"\" all_off = \"\\033[0m\" bold = \"\\033[1m\" concealed = \"\\033[7m\" disable = \"\\033[02m\" reverse = \"\\033[7m\" strikethrough = \"\\033[09m\" underscore = \"\\033[4m\" Class variables all_off bold concealed disable reverse strikethrough underscore","title":"Printutil"},{"location":"reference/pyhdtoolkit/utils/printutil/#module-pyhdtoolkitutilsprintutil","text":"Module utils.printutil Created on 2019.12.11 View Source \"\"\" Module utils.printutil ---------------------- Created on 2019.12.11 :author: Felix Soubelet (felix.soubelet@cern.ch) A class utility class to allow me printing text in color, bold, etc. \"\"\" END = \"\\033[0m\" class Background : \"\"\" ANSI color escape sequences for the background of a terminal output. \"\"\" black = \"\\033[40m\" blue = \"\\033[44m\" cyan = \"\\033[46m\" green = \"\\033[42m\" grey = \"\\033[47m\" magenta = \"\\033[45m\" red = \"\\033[41m\" yellow = \"\\033[43m\" class Foreground : \"\"\" ANSI color escape sequences for the foreground of a terminal output. \"\"\" blue = \"\\033[94m\" cyan = \"\\033[96m\" dark_blue = \"\\033[34m\" dark_cyan = \"\\033[36m\" dark_green = \"\\033[32m\" dark_grey = \"\\033[90m\" dark_red = \"\\033[31m\" dark_yellow = \"\\033[33m\" green = \"\\033[92m\" grey = \"\\033[37m\" magenta = \"\\033[35m\" pink = \"\\033[95m\" red = \"\\033[91m\" yellow = \"\\033[93m\" white = \"\\033[30m\" class Styles : \"\"\" ANSI style escape sequences for a terminal output. \"\"\" all_off = \"\\033[0m\" bold = \"\\033[1m\" concealed = \"\\033[7m\" disable = \"\\033[02m\" reverse = \"\\033[7m\" strikethrough = \"\\033[09m\" underscore = \"\\033[4m\"","title":"Module pyhdtoolkit.utils.printutil"},{"location":"reference/pyhdtoolkit/utils/printutil/#variables","text":"END","title":"Variables"},{"location":"reference/pyhdtoolkit/utils/printutil/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/utils/printutil/#background","text":"class Background ( / , * args , ** kwargs ) View Source class Background: \"\"\" ANSI color escape sequences for the background of a terminal output. \"\"\" black = \"\\033[40m\" blue = \"\\033[44m\" cyan = \"\\033[46m\" green = \"\\033[42m\" grey = \"\\033[47m\" magenta = \"\\033[45m\" red = \"\\033[41m\" yellow = \"\\033[43m\"","title":"Background"},{"location":"reference/pyhdtoolkit/utils/printutil/#class-variables","text":"black blue cyan green grey magenta red yellow","title":"Class variables"},{"location":"reference/pyhdtoolkit/utils/printutil/#foreground","text":"class Foreground ( / , * args , ** kwargs ) View Source class Foreground: \"\"\" ANSI color escape sequences for the foreground of a terminal output . \"\"\" blue = \" \\033 [94m\" cyan = \" \\033 [96m\" dark_blue = \" \\033 [34m\" dark_cyan = \" \\033 [36m\" dark_green = \" \\033 [32m\" dark_grey = \" \\033 [90m\" dark_red = \" \\033 [31m\" dark_yellow = \" \\033 [33m\" green = \" \\033 [92m\" grey = \" \\033 [37m\" magenta = \" \\033 [35m\" pink = \" \\033 [95m\" red = \" \\033 [91m\" yellow = \" \\033 [93m\" white = \" \\033 [30m\"","title":"Foreground"},{"location":"reference/pyhdtoolkit/utils/printutil/#class-variables_1","text":"blue cyan dark_blue dark_cyan dark_green dark_grey dark_red dark_yellow green grey magenta pink red white yellow","title":"Class variables"},{"location":"reference/pyhdtoolkit/utils/printutil/#styles","text":"class Styles ( / , * args , ** kwargs ) View Source class Styles: \"\"\" ANSI style escape sequences for a terminal output. \"\"\" all_off = \"\\033[0m\" bold = \"\\033[1m\" concealed = \"\\033[7m\" disable = \"\\033[02m\" reverse = \"\\033[7m\" strikethrough = \"\\033[09m\" underscore = \"\\033[4m\"","title":"Styles"},{"location":"reference/pyhdtoolkit/utils/printutil/#class-variables_2","text":"all_off bold concealed disable reverse strikethrough underscore","title":"Class variables"}]}