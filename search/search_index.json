{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"pyhdtoolkit \u267b\ufe0f An all-in-one package for Python work in my PhD \u267b\ufe0f Link to documentation . License Copyright \u00a9 2019-2020 Felix Soubelet. MIT License","title":"Home"},{"location":"#license","text":"Copyright \u00a9 2019-2020 Felix Soubelet. MIT License","title":"License"},{"location":"docs/About_PyhDToolkit/","text":"About PyhDToolkit Purpose This package is meant to be an all-in-one collection of utilities and scripts I use in my PhD work. Most of the codes here have their use in my day-to-day work, but not necessarily in our team's softwares. Functionality For now, PyhDToolkit provides some of the following features: Useful tools to integrate with cpymad , a Python bindings library for the MAD-X code, including generators, matching routines and plotting utilities. A maths module to incorporate useful methods used in analysis. A plotting module for my favorite defaults and helpers. An optics module for particle accelerator physics related calculations and analysis. A scripts module to handle different simulations setups. A tfstools module similar to cpymadtools , with functionality revolving around handling tfs files and plotting their contents. A utils module for various utilities. Roadmap In addition to developping current modules, more will be added to better incorporate with the workhorse softwares of the OMC team, notably tfs-pandas and omc3 . Foreseen development includes: Expansion of existing modules, particularly the optics module to include most simple calculations on beam properties. An omcwrapper module to handle different usecases of the omc3 package. A sixtracklibtools module for utility functions surrounding the use of sixtracklib .","title":"About"},{"location":"docs/About_PyhDToolkit/#about-pyhdtoolkit","text":"","title":"About PyhDToolkit"},{"location":"docs/About_PyhDToolkit/#purpose","text":"This package is meant to be an all-in-one collection of utilities and scripts I use in my PhD work. Most of the codes here have their use in my day-to-day work, but not necessarily in our team's softwares.","title":"Purpose"},{"location":"docs/About_PyhDToolkit/#functionality","text":"For now, PyhDToolkit provides some of the following features: Useful tools to integrate with cpymad , a Python bindings library for the MAD-X code, including generators, matching routines and plotting utilities. A maths module to incorporate useful methods used in analysis. A plotting module for my favorite defaults and helpers. An optics module for particle accelerator physics related calculations and analysis. A scripts module to handle different simulations setups. A tfstools module similar to cpymadtools , with functionality revolving around handling tfs files and plotting their contents. A utils module for various utilities.","title":"Functionality"},{"location":"docs/About_PyhDToolkit/#roadmap","text":"In addition to developping current modules, more will be added to better incorporate with the workhorse softwares of the OMC team, notably tfs-pandas and omc3 . Foreseen development includes: Expansion of existing modules, particularly the optics module to include most simple calculations on beam properties. An omcwrapper module to handle different usecases of the omc3 package. A sixtracklibtools module for utility functions surrounding the use of sixtracklib .","title":"Roadmap"},{"location":"docs/Getting_Started/","text":"Getting Started Installation This code is compatible with Python 3.7+ . There are two possible methods for using this package: either as a Python package with pip , or as a Docker image. With pip You can now install this simply in a virtual environment with: > pip install pyhdtoolkit Installation in a virtual environment Don't know what a virtual environment is or how to set it up? Here is a good primer on virtual environments by RealPython. How about a development environment? Sure thing. This repository uses Poetry as a packaging and build tool. To set yourself up, get a local copy through VCS and run: poetry install This repository follows the Google docstring format, uses Black as a code formatter with a default enforced line length of 100 characters, and Pylint as a linter. You can format the code with make format and lint it (which will format first) with make lint . Testing builds are ensured after each commit through Github Actions. You can run tests locally with the predefined make tests , or through poetry run pytest <options> for customized options. How can I easily reproduce your research done with this? This repository comes with an environment.yml file to reproduce my work conda environment, feel free to use it. If you checked out from version control, you can install this environment and add it to your ipython kernel by running make condaenv . You can also make use of a fully-fetched one through Docker as explained below. With Docker You can directly pull a pre-built image from Dockerhub (with tag latest being an automated build) with: > docker pull fsoubelet/simenv You can then run a server from within the container and bind a local directory to work on. Assuming you pulled the provided image from Dockerhub, run a jupyterlab server on port 8888 with the command: > docker run --rm -p 8888 :8888 -e JUPYTER_ENABLE_LAB = yes -v <host_dir_to_mount>:/home/jovyan/work fsoubelet/simenv","title":"Getting Started"},{"location":"docs/Getting_Started/#getting-started","text":"","title":"Getting Started"},{"location":"docs/Getting_Started/#installation","text":"This code is compatible with Python 3.7+ . There are two possible methods for using this package: either as a Python package with pip , or as a Docker image.","title":"Installation"},{"location":"docs/Getting_Started/#with-pip","text":"You can now install this simply in a virtual environment with: > pip install pyhdtoolkit Installation in a virtual environment Don't know what a virtual environment is or how to set it up? Here is a good primer on virtual environments by RealPython. How about a development environment? Sure thing. This repository uses Poetry as a packaging and build tool. To set yourself up, get a local copy through VCS and run: poetry install This repository follows the Google docstring format, uses Black as a code formatter with a default enforced line length of 100 characters, and Pylint as a linter. You can format the code with make format and lint it (which will format first) with make lint . Testing builds are ensured after each commit through Github Actions. You can run tests locally with the predefined make tests , or through poetry run pytest <options> for customized options. How can I easily reproduce your research done with this? This repository comes with an environment.yml file to reproduce my work conda environment, feel free to use it. If you checked out from version control, you can install this environment and add it to your ipython kernel by running make condaenv . You can also make use of a fully-fetched one through Docker as explained below.","title":"With pip"},{"location":"docs/Getting_Started/#with-docker","text":"You can directly pull a pre-built image from Dockerhub (with tag latest being an automated build) with: > docker pull fsoubelet/simenv You can then run a server from within the container and bind a local directory to work on. Assuming you pulled the provided image from Dockerhub, run a jupyterlab server on port 8888 with the command: > docker run --rm -p 8888 :8888 -e JUPYTER_ENABLE_LAB = yes -v <host_dir_to_mount>:/home/jovyan/work fsoubelet/simenv","title":"With Docker"},{"location":"reference/pyhdtoolkit/","text":"Module pyhdtoolkit pyhdtoolkit Library ~ ~ ~ ~ ~ ~ ~ pyhdtoolkit is a utility library, written in Python, for my PhD needs. Mainly particle accelerator physics studies and plotting. :copyright: \u00a9 2019-2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. View Source \"\"\" pyhdtoolkit Library ~~~~~~~~~~~~~~~~~~~ pyhdtoolkit is a utility library, written in Python, for my PhD needs. Mainly particle accelerator physics studies and plotting. :copyright: (c) 2019-2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" # Set default logging handler to avoid \"No handler found\" warnings. __title__ = \"pyhdtoolkit\" __description__ = \"An all-in-one toolkit package to easy my Python work in my PhD.\" __url__ = \"https://github.com/fsoubelet/PyhDToolkit\" __version__ = \"0.6.0\" __author__ = \"Felix Soubelet\" __author_email__ = \"felix.soubelet@cern.ch\" __license__ = \"MIT\" Sub-modules pyhdtoolkit.cpymadtools pyhdtoolkit.maths pyhdtoolkit.optics pyhdtoolkit.plotting pyhdtoolkit.scripts pyhdtoolkit.tfstools pyhdtoolkit.utils","title":"Index"},{"location":"reference/pyhdtoolkit/#module-pyhdtoolkit","text":"pyhdtoolkit Library ~ ~ ~ ~ ~ ~ ~ pyhdtoolkit is a utility library, written in Python, for my PhD needs. Mainly particle accelerator physics studies and plotting. :copyright: \u00a9 2019-2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. View Source \"\"\" pyhdtoolkit Library ~~~~~~~~~~~~~~~~~~~ pyhdtoolkit is a utility library, written in Python, for my PhD needs. Mainly particle accelerator physics studies and plotting. :copyright: (c) 2019-2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" # Set default logging handler to avoid \"No handler found\" warnings. __title__ = \"pyhdtoolkit\" __description__ = \"An all-in-one toolkit package to easy my Python work in my PhD.\" __url__ = \"https://github.com/fsoubelet/PyhDToolkit\" __version__ = \"0.6.0\" __author__ = \"Felix Soubelet\" __author_email__ = \"felix.soubelet@cern.ch\" __license__ = \"MIT\"","title":"Module pyhdtoolkit"},{"location":"reference/pyhdtoolkit/#sub-modules","text":"pyhdtoolkit.cpymadtools pyhdtoolkit.maths pyhdtoolkit.optics pyhdtoolkit.plotting pyhdtoolkit.scripts pyhdtoolkit.tfstools pyhdtoolkit.utils","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/cpymadtools/","text":"Module pyhdtoolkit.cpymadtools cpymadtools package ~ ~ ~ ~ ~ ~ ~ cpymadtools is a collection of utilities that integrate within my workflow with the cpymad library. :copyright: \u00a9 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. View Source \"\"\" cpymadtools package ~~~~~~~~~~~~~~~~~~~ cpymadtools is a collection of utilities that integrate within my workflow with the `cpymad` library. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from loguru import logger from .helpers import LatticeMatcher , Parameters from .lattice_generators import LatticeGenerator from .latwiss import LaTwiss from .plotters import AperturePlotter , DynamicAperturePlotter , PhaseSpacePlotter , TuneDiagramPlotter Sub-modules pyhdtoolkit.cpymadtools.helpers pyhdtoolkit.cpymadtools.lattice_generators pyhdtoolkit.cpymadtools.latwiss pyhdtoolkit.cpymadtools.plotters","title":"Index"},{"location":"reference/pyhdtoolkit/cpymadtools/#module-pyhdtoolkitcpymadtools","text":"cpymadtools package ~ ~ ~ ~ ~ ~ ~ cpymadtools is a collection of utilities that integrate within my workflow with the cpymad library. :copyright: \u00a9 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. View Source \"\"\" cpymadtools package ~~~~~~~~~~~~~~~~~~~ cpymadtools is a collection of utilities that integrate within my workflow with the `cpymad` library. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from loguru import logger from .helpers import LatticeMatcher , Parameters from .lattice_generators import LatticeGenerator from .latwiss import LaTwiss from .plotters import AperturePlotter , DynamicAperturePlotter , PhaseSpacePlotter , TuneDiagramPlotter","title":"Module pyhdtoolkit.cpymadtools"},{"location":"reference/pyhdtoolkit/cpymadtools/#sub-modules","text":"pyhdtoolkit.cpymadtools.helpers pyhdtoolkit.cpymadtools.lattice_generators pyhdtoolkit.cpymadtools.latwiss pyhdtoolkit.cpymadtools.plotters","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/cpymadtools/helpers/","text":"Module pyhdtoolkit.cpymadtools.helpers Module cpymadtools.helpers Created on 2019.06.15 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A collection of functions for performing different common operations on a cpymad.madx.Madx object. View Source \"\"\" Module cpymadtools.helpers -------------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions for performing different common operations on a cpymad.madx.Madx object. \"\"\" from typing import Dict , List import numpy as np from loguru import logger try : from cpymad.madx import Madx except ModuleNotFoundError : Madx = None class LatticeMatcher : \"\"\" A class with functions to perform MAD-X matchings. \"\"\" @staticmethod def perform_tune_matching ( cpymad_instance : Madx , sequence_name : str , q1_target : float , q2_target : float , variables : List [ str ] = [ \"kqf\" , \"kqd\" ], ) -> None : \"\"\" Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for tunes. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. q1_target (float): horizontal tune to match to. q2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\"kqf\", \"ksd\"] as it is a common name for quadrupole strengths (foc / defoc). \"\"\" matching_routine : str = _create_tune_matching_routine ( sequence_name , q1_target , q2_target , variables ) logger . debug ( \"Sending matching routine to cpymad\" ) cpymad_instance . input ( matching_routine ) @staticmethod def perform_chroma_matching ( cpymad_instance : Madx , sequence_name : str , dq1_target : float , dq2_target : float , variables : List [ str ] = [ \"ksf\" , \"ksd\" ], ) -> None : \"\"\" Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for chromaticities. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. dq1_target (float): horizontal tune to match to. dq2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\"ksf\", \"ksd\"] as it is a common name for sextupole strengths (foc / defoc). \"\"\" matching_routine : str = _create_chromaticity_matching_routine ( sequence_name , dq1_target , dq2_target , variables ) logger . debug ( \"Sending matching routine to cpymad\" ) cpymad_instance . input ( matching_routine ) class Parameters : \"\"\" A class to compute different beam and machine parameters. \"\"\" @staticmethod def beam_parameters ( pc_gev : float , en_x_m : float , en_y_m : float , deltap_p : float , verbose : bool = False , ) -> Dict [ str , float ]: \"\"\"Calculate beam parameters from provided values. Args: pc_gev (float): particle momentum. en_x_m (float): horizontal emittance, in meters. en_y_m (float): vertical emittance, in meters. deltap_p (float): momentum deviation. verbose (bool): bolean, whether to print out a summary of parameters or not. Returns: A dictionnary with the calculated values. \"\"\" e0_gev = 0.9382720813 e_tot_gev = np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) gamma_r = e_tot_gev / e0_gev beta_r = pc_gev / np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) parameters : Dict [ str , float ] = { \"pc_GeV\" : pc_gev , # Particle momentum [GeV] \"B_rho_Tm\" : 3.3356 * pc_gev , # Beam rigidity [T/m] \"E_0_GeV\" : e0_gev , # Rest mass energy [GeV] \"E_tot_GeV\" : e_tot_gev , # Total beam energy [GeV] \"E_kin_GeV\" : e_tot_gev - e0_gev , # Kinectic beam energy [GeV] \"gamma_r\" : gamma_r , # Relativistic gamma \"beta_r\" : beta_r , # Relativistic beta \"en_x_m\" : en_x_m , # Horizontal emittance [m] \"en_y_m\" : en_y_m , # Vertical emittance [m] \"eg_x_m\" : en_x_m / gamma_r / beta_r , # Horizontal geometrical emittance \"eg_y_m\" : en_y_m / gamma_r / beta_r , # Vertical geometrical emittance \"deltap_p\" : deltap_p , # Momentum deviation } if verbose : logger . trace ( \"Outputing computed parameter values\" ) print ( f \"\"\"Particle type: proton Beam momentum = { parameters [ \"pc_GeV\" ] : 2.3f } GeV/c Normalized x-emittance = { parameters [ \"en_x_m\" ] * 1e6 : 2.3f } mm mrad Normalized y-emittance = { parameters [ \"en_y_m\" ] * 1e6 : 2.3f } mm mrad Momentum deviation deltap/p = { parameters [ \"deltap_p\" ] } -> Beam total energy = { parameters [ \"E_tot_GeV\" ] : 2.3f } GeV -> Beam kinetic energy = { parameters [ \"E_kin_GeV\" ] : 2.3f } GeV -> Beam rigidity = { parameters [ \"B_rho_Tm\" ] : 2.3f } Tm -> Relativistic beta = { parameters [ \"beta_r\" ] : 2.5f } -> Relativistic gamma = { parameters [ \"gamma_r\" ] : 2.3f } -> Geometrical x emittance = { parameters [ \"eg_x_m\" ] * 1e6 : 2.3f } mm mrad -> Geometrical y emittance = { parameters [ \"eg_y_m\" ] * 1e6 : 2.3f } mm mrad \"\"\" ) return parameters def _create_tune_matching_routine ( sequence_name : str , q1_target : float , q2_target : float , variables : List [ str ] = [ \"kqf\" , \"kqd\" ], ) -> str : \"\"\" Create the string for a tune matching routine with provided parameters. Args: sequence_name (str): name of the sequence you want to activate for the tune matching. q1_target (float): horizontal tune to match to. q2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\"kqf\", \"kqd\"] as it is a common name for quadrupole strengths (foc / defoc). Returns: The string to input in MADX to perform the matching. \"\"\" logger . debug ( f \"Creating tune matching routine with for sequence ' { sequence_name } ' with target \" f \"tunes { q1_target } and { q2_target } \" ) matching_routine_string : str = f \"\"\" !MATCHING SEQUENCE match, sequence= { sequence_name } ;\"\"\" for variable in variables : matching_routine_string += f \" \\n vary, name= { variable } , step=0.00001;\" matching_routine_string += f \"\"\" global, sequence= { sequence_name } , Q1= { q1_target } ; global, sequence= { sequence_name } , Q2= { q2_target } ; Lmdif, calls=1000, tolerance=1.0e-21; endmatch; twiss; \"\"\" return matching_routine_string def _create_chromaticity_matching_routine ( sequence_name : str , dq1_target : float , dq2_target : float , variables : List [ str ] = [ \"ksf\" , \"ksd\" ], ) -> str : \"\"\" Create the string for a chromaticity matching routine with provided parameters. Args: sequence_name (str): name of the sequence you want to activate for the tune matching. dq1_target (float): horizontal chromaticity to match to. dq2_target (float): vertical chromaticity to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\"ksf\", \"ksd\"] as it is a common name for sextupole strengths (foc / defoc). Returns: The string to input in MADX to perform the matching. \"\"\" logger . debug ( f \"Creating chromaticity matching routine with for sequence ' { sequence_name } ' with target \" f \"chromaticities { dq1_target } and { dq2_target } \" ) matching_routine_string : str = f \"\"\" !MATCHING SEQUENCE match, sequence= { sequence_name } ;\"\"\" for variable in variables : matching_routine_string += f \" \\n vary, name= { variable } , step=0.00001;\" matching_routine_string += f \"\"\" global, sequence= { sequence_name } , dq1= { dq1_target } ; global, sequence= { sequence_name } , dq2= { dq2_target } ; Lmdif, calls=1000, tolerance=1.0e-21; endmatch; twiss; \"\"\" return matching_routine_string Classes LatticeMatcher class LatticeMatcher ( / , * args , ** kwargs ) A class with functions to perform MAD-X matchings. View Source class LatticeMatcher : \"\"\" A class with functions to perform MAD-X matchings. \"\"\" @staticmethod def perform_tune_matching ( cpymad_instance : Madx , sequence_name : str , q1_target : float , q2_target : float , variables : List [ str ] = [ \"kqf\", \"kqd\" ] , ) -> None : \"\"\" Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for tunes. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. q1_target (float): horizontal tune to match to. q2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\" kqf \", \" ksd \"] as it is a common name for quadrupole strengths (foc / defoc). \"\"\" matching_routine : str = _create_tune_matching_routine ( sequence_name , q1_target , q2_target , variables ) logger . debug ( \"Sending matching routine to cpymad\" ) cpymad_instance . input ( matching_routine ) @staticmethod def perform_chroma_matching ( cpymad_instance : Madx , sequence_name : str , dq1_target : float , dq2_target : float , variables : List [ str ] = [ \"ksf\", \"ksd\" ] , ) -> None : \"\"\" Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for chromaticities. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. dq1_target (float): horizontal tune to match to. dq2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\" ksf \", \" ksd \"] as it is a common name for sextupole strengths (foc / defoc). \"\"\" matching_routine : str = _create_chromaticity_matching_routine ( sequence_name , dq1_target , dq2_target , variables ) logger . debug ( \"Sending matching routine to cpymad\" ) cpymad_instance . input ( matching_routine ) Static methods perform_chroma_matching def perform_chroma_matching ( cpymad_instance : cpymad . madx . Madx , sequence_name : str , dq1_target : float , dq2_target : float , variables : List [ str ] = [ 'ksf' , 'ksd' ] ) -> None Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for chromaticities. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. dq1_target (float): horizontal tune to match to. dq2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\"ksf\", \"ksd\"] as it is a common name for sextupole strengths (foc / defoc). View Source @staticmethod def perform_chroma_matching ( cpymad_instance : Madx , sequence_name : str , dq1_target : float , dq2_target : float , variables : List [ str ] = [ \"ksf\", \"ksd\" ] , ) -> None : \"\"\" Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for chromaticities. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. dq1_target (float): horizontal tune to match to. dq2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\" ksf \", \" ksd \"] as it is a common name for sextupole strengths (foc / defoc). \"\"\" matching_routine : str = _create_chromaticity_matching_routine ( sequence_name , dq1_target , dq2_target , variables ) logger . debug ( \"Sending matching routine to cpymad\" ) cpymad_instance . input ( matching_routine ) perform_tune_matching def perform_tune_matching ( cpymad_instance : cpymad . madx . Madx , sequence_name : str , q1_target : float , q2_target : float , variables : List [ str ] = [ 'kqf' , 'kqd' ] ) -> None Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for tunes. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. q1_target (float): horizontal tune to match to. q2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\"kqf\", \"ksd\"] as it is a common name for quadrupole strengths (foc / defoc). View Source @staticmethod def perform_tune_matching ( cpymad_instance : Madx , sequence_name : str , q1_target : float , q2_target : float , variables : List [ str ] = [ \"kqf\", \"kqd\" ] , ) -> None : \"\"\" Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for tunes. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. q1_target (float): horizontal tune to match to. q2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\" kqf \", \" ksd \"] as it is a common name for quadrupole strengths (foc / defoc). \"\"\" matching_routine : str = _create_tune_matching_routine ( sequence_name , q1_target , q2_target , variables ) logger . debug ( \"Sending matching routine to cpymad\" ) cpymad_instance . input ( matching_routine ) Parameters class Parameters ( / , * args , ** kwargs ) A class to compute different beam and machine parameters. View Source class Parameters : \"\"\" A class to compute different beam and machine parameters. \"\"\" @staticmethod def beam_parameters ( pc_gev : float , en_x_m : float , en_y_m : float , deltap_p : float , verbose : bool = False , ) -> Dict [ str, float ] : \"\"\"Calculate beam parameters from provided values. Args: pc_gev (float): particle momentum. en_x_m (float): horizontal emittance, in meters. en_y_m (float): vertical emittance, in meters. deltap_p (float): momentum deviation. verbose (bool): bolean, whether to print out a summary of parameters or not. Returns: A dictionnary with the calculated values. \"\"\" e0_gev = 0.9382720813 e_tot_gev = np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) gamma_r = e_tot_gev / e0_gev beta_r = pc_gev / np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) parameters : Dict [ str, float ] = { \"pc_GeV\" : pc_gev , # Particle momentum [ GeV ] \"B_rho_Tm\" : 3.3356 * pc_gev , # Beam rigidity [ T/m ] \"E_0_GeV\" : e0_gev , # Rest mass energy [ GeV ] \"E_tot_GeV\" : e_tot_gev , # Total beam energy [ GeV ] \"E_kin_GeV\" : e_tot_gev - e0_gev , # Kinectic beam energy [ GeV ] \"gamma_r\" : gamma_r , # Relativistic gamma \"beta_r\" : beta_r , # Relativistic beta \"en_x_m\" : en_x_m , # Horizontal emittance [ m ] \"en_y_m\" : en_y_m , # Vertical emittance [ m ] \"eg_x_m\" : en_x_m / gamma_r / beta_r , # Horizontal geometrical emittance \"eg_y_m\" : en_y_m / gamma_r / beta_r , # Vertical geometrical emittance \"deltap_p\" : deltap_p , # Momentum deviation } if verbose : logger . trace ( \"Outputing computed parameter values\" ) print ( f \"\"\"Particle type: proton Beam momentum = {parameters[\" pc_GeV \"]:2.3f} GeV/c Normalized x-emittance = {parameters[\" en_x_m \"] * 1e6:2.3f} mm mrad Normalized y-emittance = {parameters[\" en_y_m \"] * 1e6:2.3f} mm mrad Momentum deviation deltap/p = {parameters[\" deltap_p \"]} -> Beam total energy = {parameters[\" E_tot_GeV \"]:2.3f} GeV -> Beam kinetic energy = {parameters[\" E_kin_GeV \"]:2.3f} GeV -> Beam rigidity = {parameters[\" B_rho_Tm \"]:2.3f} Tm -> Relativistic beta = {parameters[\" beta_r \"]:2.5f} -> Relativistic gamma = {parameters[\" gamma_r \"]:2.3f} -> Geometrical x emittance = {parameters[\" eg_x_m \"] * 1e6:2.3f} mm mrad -> Geometrical y emittance = {parameters[\" eg_y_m \"] * 1e6:2.3f} mm mrad \"\"\" ) return parameters Static methods beam_parameters def beam_parameters ( pc_gev : float , en_x_m : float , en_y_m : float , deltap_p : float , verbose : bool = False ) -> Dict [ str , float ] Calculate beam parameters from provided values. Args: pc_gev (float): particle momentum. en_x_m (float): horizontal emittance, in meters. en_y_m (float): vertical emittance, in meters. deltap_p (float): momentum deviation. verbose (bool): bolean, whether to print out a summary of parameters or not. Returns: A dictionnary with the calculated values. View Source @staticmethod def beam_parameters ( pc_gev : float , en_x_m : float , en_y_m : float , deltap_p : float , verbose : bool = False , ) -> Dict [ str, float ] : \"\"\"Calculate beam parameters from provided values. Args: pc_gev (float): particle momentum. en_x_m (float): horizontal emittance, in meters. en_y_m (float): vertical emittance, in meters. deltap_p (float): momentum deviation. verbose (bool): bolean, whether to print out a summary of parameters or not. Returns: A dictionnary with the calculated values. \"\"\" e0_gev = 0.9382720813 e_tot_gev = np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) gamma_r = e_tot_gev / e0_gev beta_r = pc_gev / np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) parameters : Dict [ str, float ] = { \"pc_GeV\" : pc_gev , # Particle momentum [ GeV ] \"B_rho_Tm\" : 3.3356 * pc_gev , # Beam rigidity [ T/m ] \"E_0_GeV\" : e0_gev , # Rest mass energy [ GeV ] \"E_tot_GeV\" : e_tot_gev , # Total beam energy [ GeV ] \"E_kin_GeV\" : e_tot_gev - e0_gev , # Kinectic beam energy [ GeV ] \"gamma_r\" : gamma_r , # Relativistic gamma \"beta_r\" : beta_r , # Relativistic beta \"en_x_m\" : en_x_m , # Horizontal emittance [ m ] \"en_y_m\" : en_y_m , # Vertical emittance [ m ] \"eg_x_m\" : en_x_m / gamma_r / beta_r , # Horizontal geometrical emittance \"eg_y_m\" : en_y_m / gamma_r / beta_r , # Vertical geometrical emittance \"deltap_p\" : deltap_p , # Momentum deviation } if verbose : logger . trace ( \"Outputing computed parameter values\" ) print ( f \"\"\"Particle type: proton Beam momentum = {parameters[\" pc_GeV \"]:2.3f} GeV/c Normalized x-emittance = {parameters[\" en_x_m \"] * 1e6:2.3f} mm mrad Normalized y-emittance = {parameters[\" en_y_m \"] * 1e6:2.3f} mm mrad Momentum deviation deltap/p = {parameters[\" deltap_p \"]} -> Beam total energy = {parameters[\" E_tot_GeV \"]:2.3f} GeV -> Beam kinetic energy = {parameters[\" E_kin_GeV \"]:2.3f} GeV -> Beam rigidity = {parameters[\" B_rho_Tm \"]:2.3f} Tm -> Relativistic beta = {parameters[\" beta_r \"]:2.5f} -> Relativistic gamma = {parameters[\" gamma_r \"]:2.3f} -> Geometrical x emittance = {parameters[\" eg_x_m \"] * 1e6:2.3f} mm mrad -> Geometrical y emittance = {parameters[\" eg_y_m \"] * 1e6:2.3f} mm mrad \"\"\" ) return parameters","title":"Helpers"},{"location":"reference/pyhdtoolkit/cpymadtools/helpers/#module-pyhdtoolkitcpymadtoolshelpers","text":"","title":"Module pyhdtoolkit.cpymadtools.helpers"},{"location":"reference/pyhdtoolkit/cpymadtools/helpers/#module-cpymadtoolshelpers","text":"Created on 2019.06.15 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A collection of functions for performing different common operations on a cpymad.madx.Madx object. View Source \"\"\" Module cpymadtools.helpers -------------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions for performing different common operations on a cpymad.madx.Madx object. \"\"\" from typing import Dict , List import numpy as np from loguru import logger try : from cpymad.madx import Madx except ModuleNotFoundError : Madx = None class LatticeMatcher : \"\"\" A class with functions to perform MAD-X matchings. \"\"\" @staticmethod def perform_tune_matching ( cpymad_instance : Madx , sequence_name : str , q1_target : float , q2_target : float , variables : List [ str ] = [ \"kqf\" , \"kqd\" ], ) -> None : \"\"\" Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for tunes. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. q1_target (float): horizontal tune to match to. q2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\"kqf\", \"ksd\"] as it is a common name for quadrupole strengths (foc / defoc). \"\"\" matching_routine : str = _create_tune_matching_routine ( sequence_name , q1_target , q2_target , variables ) logger . debug ( \"Sending matching routine to cpymad\" ) cpymad_instance . input ( matching_routine ) @staticmethod def perform_chroma_matching ( cpymad_instance : Madx , sequence_name : str , dq1_target : float , dq2_target : float , variables : List [ str ] = [ \"ksf\" , \"ksd\" ], ) -> None : \"\"\" Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for chromaticities. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. dq1_target (float): horizontal tune to match to. dq2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\"ksf\", \"ksd\"] as it is a common name for sextupole strengths (foc / defoc). \"\"\" matching_routine : str = _create_chromaticity_matching_routine ( sequence_name , dq1_target , dq2_target , variables ) logger . debug ( \"Sending matching routine to cpymad\" ) cpymad_instance . input ( matching_routine ) class Parameters : \"\"\" A class to compute different beam and machine parameters. \"\"\" @staticmethod def beam_parameters ( pc_gev : float , en_x_m : float , en_y_m : float , deltap_p : float , verbose : bool = False , ) -> Dict [ str , float ]: \"\"\"Calculate beam parameters from provided values. Args: pc_gev (float): particle momentum. en_x_m (float): horizontal emittance, in meters. en_y_m (float): vertical emittance, in meters. deltap_p (float): momentum deviation. verbose (bool): bolean, whether to print out a summary of parameters or not. Returns: A dictionnary with the calculated values. \"\"\" e0_gev = 0.9382720813 e_tot_gev = np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) gamma_r = e_tot_gev / e0_gev beta_r = pc_gev / np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) parameters : Dict [ str , float ] = { \"pc_GeV\" : pc_gev , # Particle momentum [GeV] \"B_rho_Tm\" : 3.3356 * pc_gev , # Beam rigidity [T/m] \"E_0_GeV\" : e0_gev , # Rest mass energy [GeV] \"E_tot_GeV\" : e_tot_gev , # Total beam energy [GeV] \"E_kin_GeV\" : e_tot_gev - e0_gev , # Kinectic beam energy [GeV] \"gamma_r\" : gamma_r , # Relativistic gamma \"beta_r\" : beta_r , # Relativistic beta \"en_x_m\" : en_x_m , # Horizontal emittance [m] \"en_y_m\" : en_y_m , # Vertical emittance [m] \"eg_x_m\" : en_x_m / gamma_r / beta_r , # Horizontal geometrical emittance \"eg_y_m\" : en_y_m / gamma_r / beta_r , # Vertical geometrical emittance \"deltap_p\" : deltap_p , # Momentum deviation } if verbose : logger . trace ( \"Outputing computed parameter values\" ) print ( f \"\"\"Particle type: proton Beam momentum = { parameters [ \"pc_GeV\" ] : 2.3f } GeV/c Normalized x-emittance = { parameters [ \"en_x_m\" ] * 1e6 : 2.3f } mm mrad Normalized y-emittance = { parameters [ \"en_y_m\" ] * 1e6 : 2.3f } mm mrad Momentum deviation deltap/p = { parameters [ \"deltap_p\" ] } -> Beam total energy = { parameters [ \"E_tot_GeV\" ] : 2.3f } GeV -> Beam kinetic energy = { parameters [ \"E_kin_GeV\" ] : 2.3f } GeV -> Beam rigidity = { parameters [ \"B_rho_Tm\" ] : 2.3f } Tm -> Relativistic beta = { parameters [ \"beta_r\" ] : 2.5f } -> Relativistic gamma = { parameters [ \"gamma_r\" ] : 2.3f } -> Geometrical x emittance = { parameters [ \"eg_x_m\" ] * 1e6 : 2.3f } mm mrad -> Geometrical y emittance = { parameters [ \"eg_y_m\" ] * 1e6 : 2.3f } mm mrad \"\"\" ) return parameters def _create_tune_matching_routine ( sequence_name : str , q1_target : float , q2_target : float , variables : List [ str ] = [ \"kqf\" , \"kqd\" ], ) -> str : \"\"\" Create the string for a tune matching routine with provided parameters. Args: sequence_name (str): name of the sequence you want to activate for the tune matching. q1_target (float): horizontal tune to match to. q2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\"kqf\", \"kqd\"] as it is a common name for quadrupole strengths (foc / defoc). Returns: The string to input in MADX to perform the matching. \"\"\" logger . debug ( f \"Creating tune matching routine with for sequence ' { sequence_name } ' with target \" f \"tunes { q1_target } and { q2_target } \" ) matching_routine_string : str = f \"\"\" !MATCHING SEQUENCE match, sequence= { sequence_name } ;\"\"\" for variable in variables : matching_routine_string += f \" \\n vary, name= { variable } , step=0.00001;\" matching_routine_string += f \"\"\" global, sequence= { sequence_name } , Q1= { q1_target } ; global, sequence= { sequence_name } , Q2= { q2_target } ; Lmdif, calls=1000, tolerance=1.0e-21; endmatch; twiss; \"\"\" return matching_routine_string def _create_chromaticity_matching_routine ( sequence_name : str , dq1_target : float , dq2_target : float , variables : List [ str ] = [ \"ksf\" , \"ksd\" ], ) -> str : \"\"\" Create the string for a chromaticity matching routine with provided parameters. Args: sequence_name (str): name of the sequence you want to activate for the tune matching. dq1_target (float): horizontal chromaticity to match to. dq2_target (float): vertical chromaticity to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\"ksf\", \"ksd\"] as it is a common name for sextupole strengths (foc / defoc). Returns: The string to input in MADX to perform the matching. \"\"\" logger . debug ( f \"Creating chromaticity matching routine with for sequence ' { sequence_name } ' with target \" f \"chromaticities { dq1_target } and { dq2_target } \" ) matching_routine_string : str = f \"\"\" !MATCHING SEQUENCE match, sequence= { sequence_name } ;\"\"\" for variable in variables : matching_routine_string += f \" \\n vary, name= { variable } , step=0.00001;\" matching_routine_string += f \"\"\" global, sequence= { sequence_name } , dq1= { dq1_target } ; global, sequence= { sequence_name } , dq2= { dq2_target } ; Lmdif, calls=1000, tolerance=1.0e-21; endmatch; twiss; \"\"\" return matching_routine_string","title":"Module cpymadtools.helpers"},{"location":"reference/pyhdtoolkit/cpymadtools/helpers/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/cpymadtools/helpers/#latticematcher","text":"class LatticeMatcher ( / , * args , ** kwargs ) A class with functions to perform MAD-X matchings. View Source class LatticeMatcher : \"\"\" A class with functions to perform MAD-X matchings. \"\"\" @staticmethod def perform_tune_matching ( cpymad_instance : Madx , sequence_name : str , q1_target : float , q2_target : float , variables : List [ str ] = [ \"kqf\", \"kqd\" ] , ) -> None : \"\"\" Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for tunes. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. q1_target (float): horizontal tune to match to. q2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\" kqf \", \" ksd \"] as it is a common name for quadrupole strengths (foc / defoc). \"\"\" matching_routine : str = _create_tune_matching_routine ( sequence_name , q1_target , q2_target , variables ) logger . debug ( \"Sending matching routine to cpymad\" ) cpymad_instance . input ( matching_routine ) @staticmethod def perform_chroma_matching ( cpymad_instance : Madx , sequence_name : str , dq1_target : float , dq2_target : float , variables : List [ str ] = [ \"ksf\", \"ksd\" ] , ) -> None : \"\"\" Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for chromaticities. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. dq1_target (float): horizontal tune to match to. dq2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\" ksf \", \" ksd \"] as it is a common name for sextupole strengths (foc / defoc). \"\"\" matching_routine : str = _create_chromaticity_matching_routine ( sequence_name , dq1_target , dq2_target , variables ) logger . debug ( \"Sending matching routine to cpymad\" ) cpymad_instance . input ( matching_routine )","title":"LatticeMatcher"},{"location":"reference/pyhdtoolkit/cpymadtools/helpers/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/cpymadtools/helpers/#perform_chroma_matching","text":"def perform_chroma_matching ( cpymad_instance : cpymad . madx . Madx , sequence_name : str , dq1_target : float , dq2_target : float , variables : List [ str ] = [ 'ksf' , 'ksd' ] ) -> None Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for chromaticities. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. dq1_target (float): horizontal tune to match to. dq2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\"ksf\", \"ksd\"] as it is a common name for sextupole strengths (foc / defoc). View Source @staticmethod def perform_chroma_matching ( cpymad_instance : Madx , sequence_name : str , dq1_target : float , dq2_target : float , variables : List [ str ] = [ \"ksf\", \"ksd\" ] , ) -> None : \"\"\" Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for chromaticities. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. dq1_target (float): horizontal tune to match to. dq2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\" ksf \", \" ksd \"] as it is a common name for sextupole strengths (foc / defoc). \"\"\" matching_routine : str = _create_chromaticity_matching_routine ( sequence_name , dq1_target , dq2_target , variables ) logger . debug ( \"Sending matching routine to cpymad\" ) cpymad_instance . input ( matching_routine )","title":"perform_chroma_matching"},{"location":"reference/pyhdtoolkit/cpymadtools/helpers/#perform_tune_matching","text":"def perform_tune_matching ( cpymad_instance : cpymad . madx . Madx , sequence_name : str , q1_target : float , q2_target : float , variables : List [ str ] = [ 'kqf' , 'kqd' ] ) -> None Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for tunes. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. q1_target (float): horizontal tune to match to. q2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\"kqf\", \"ksd\"] as it is a common name for quadrupole strengths (foc / defoc). View Source @staticmethod def perform_tune_matching ( cpymad_instance : Madx , sequence_name : str , q1_target : float , q2_target : float , variables : List [ str ] = [ \"kqf\", \"kqd\" ] , ) -> None : \"\"\" Provided with an active Cpymad class after having ran a script, will run an additional matching command to reach the provided values for tunes. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. sequence_name (str): name of the sequence you want to activate for the tune matching. q1_target (float): horizontal tune to match to. q2_target (float): vertical tune to match to. variables (List[str]): the variables names to 'vary' in the MADX routine. Defaults to [\" kqf \", \" ksd \"] as it is a common name for quadrupole strengths (foc / defoc). \"\"\" matching_routine : str = _create_tune_matching_routine ( sequence_name , q1_target , q2_target , variables ) logger . debug ( \"Sending matching routine to cpymad\" ) cpymad_instance . input ( matching_routine )","title":"perform_tune_matching"},{"location":"reference/pyhdtoolkit/cpymadtools/helpers/#parameters","text":"class Parameters ( / , * args , ** kwargs ) A class to compute different beam and machine parameters. View Source class Parameters : \"\"\" A class to compute different beam and machine parameters. \"\"\" @staticmethod def beam_parameters ( pc_gev : float , en_x_m : float , en_y_m : float , deltap_p : float , verbose : bool = False , ) -> Dict [ str, float ] : \"\"\"Calculate beam parameters from provided values. Args: pc_gev (float): particle momentum. en_x_m (float): horizontal emittance, in meters. en_y_m (float): vertical emittance, in meters. deltap_p (float): momentum deviation. verbose (bool): bolean, whether to print out a summary of parameters or not. Returns: A dictionnary with the calculated values. \"\"\" e0_gev = 0.9382720813 e_tot_gev = np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) gamma_r = e_tot_gev / e0_gev beta_r = pc_gev / np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) parameters : Dict [ str, float ] = { \"pc_GeV\" : pc_gev , # Particle momentum [ GeV ] \"B_rho_Tm\" : 3.3356 * pc_gev , # Beam rigidity [ T/m ] \"E_0_GeV\" : e0_gev , # Rest mass energy [ GeV ] \"E_tot_GeV\" : e_tot_gev , # Total beam energy [ GeV ] \"E_kin_GeV\" : e_tot_gev - e0_gev , # Kinectic beam energy [ GeV ] \"gamma_r\" : gamma_r , # Relativistic gamma \"beta_r\" : beta_r , # Relativistic beta \"en_x_m\" : en_x_m , # Horizontal emittance [ m ] \"en_y_m\" : en_y_m , # Vertical emittance [ m ] \"eg_x_m\" : en_x_m / gamma_r / beta_r , # Horizontal geometrical emittance \"eg_y_m\" : en_y_m / gamma_r / beta_r , # Vertical geometrical emittance \"deltap_p\" : deltap_p , # Momentum deviation } if verbose : logger . trace ( \"Outputing computed parameter values\" ) print ( f \"\"\"Particle type: proton Beam momentum = {parameters[\" pc_GeV \"]:2.3f} GeV/c Normalized x-emittance = {parameters[\" en_x_m \"] * 1e6:2.3f} mm mrad Normalized y-emittance = {parameters[\" en_y_m \"] * 1e6:2.3f} mm mrad Momentum deviation deltap/p = {parameters[\" deltap_p \"]} -> Beam total energy = {parameters[\" E_tot_GeV \"]:2.3f} GeV -> Beam kinetic energy = {parameters[\" E_kin_GeV \"]:2.3f} GeV -> Beam rigidity = {parameters[\" B_rho_Tm \"]:2.3f} Tm -> Relativistic beta = {parameters[\" beta_r \"]:2.5f} -> Relativistic gamma = {parameters[\" gamma_r \"]:2.3f} -> Geometrical x emittance = {parameters[\" eg_x_m \"] * 1e6:2.3f} mm mrad -> Geometrical y emittance = {parameters[\" eg_y_m \"] * 1e6:2.3f} mm mrad \"\"\" ) return parameters","title":"Parameters"},{"location":"reference/pyhdtoolkit/cpymadtools/helpers/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/cpymadtools/helpers/#beam_parameters","text":"def beam_parameters ( pc_gev : float , en_x_m : float , en_y_m : float , deltap_p : float , verbose : bool = False ) -> Dict [ str , float ] Calculate beam parameters from provided values. Args: pc_gev (float): particle momentum. en_x_m (float): horizontal emittance, in meters. en_y_m (float): vertical emittance, in meters. deltap_p (float): momentum deviation. verbose (bool): bolean, whether to print out a summary of parameters or not. Returns: A dictionnary with the calculated values. View Source @staticmethod def beam_parameters ( pc_gev : float , en_x_m : float , en_y_m : float , deltap_p : float , verbose : bool = False , ) -> Dict [ str, float ] : \"\"\"Calculate beam parameters from provided values. Args: pc_gev (float): particle momentum. en_x_m (float): horizontal emittance, in meters. en_y_m (float): vertical emittance, in meters. deltap_p (float): momentum deviation. verbose (bool): bolean, whether to print out a summary of parameters or not. Returns: A dictionnary with the calculated values. \"\"\" e0_gev = 0.9382720813 e_tot_gev = np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) gamma_r = e_tot_gev / e0_gev beta_r = pc_gev / np . sqrt ( pc_gev ** 2 + e0_gev ** 2 ) parameters : Dict [ str, float ] = { \"pc_GeV\" : pc_gev , # Particle momentum [ GeV ] \"B_rho_Tm\" : 3.3356 * pc_gev , # Beam rigidity [ T/m ] \"E_0_GeV\" : e0_gev , # Rest mass energy [ GeV ] \"E_tot_GeV\" : e_tot_gev , # Total beam energy [ GeV ] \"E_kin_GeV\" : e_tot_gev - e0_gev , # Kinectic beam energy [ GeV ] \"gamma_r\" : gamma_r , # Relativistic gamma \"beta_r\" : beta_r , # Relativistic beta \"en_x_m\" : en_x_m , # Horizontal emittance [ m ] \"en_y_m\" : en_y_m , # Vertical emittance [ m ] \"eg_x_m\" : en_x_m / gamma_r / beta_r , # Horizontal geometrical emittance \"eg_y_m\" : en_y_m / gamma_r / beta_r , # Vertical geometrical emittance \"deltap_p\" : deltap_p , # Momentum deviation } if verbose : logger . trace ( \"Outputing computed parameter values\" ) print ( f \"\"\"Particle type: proton Beam momentum = {parameters[\" pc_GeV \"]:2.3f} GeV/c Normalized x-emittance = {parameters[\" en_x_m \"] * 1e6:2.3f} mm mrad Normalized y-emittance = {parameters[\" en_y_m \"] * 1e6:2.3f} mm mrad Momentum deviation deltap/p = {parameters[\" deltap_p \"]} -> Beam total energy = {parameters[\" E_tot_GeV \"]:2.3f} GeV -> Beam kinetic energy = {parameters[\" E_kin_GeV \"]:2.3f} GeV -> Beam rigidity = {parameters[\" B_rho_Tm \"]:2.3f} Tm -> Relativistic beta = {parameters[\" beta_r \"]:2.5f} -> Relativistic gamma = {parameters[\" gamma_r \"]:2.3f} -> Geometrical x emittance = {parameters[\" eg_x_m \"] * 1e6:2.3f} mm mrad -> Geometrical y emittance = {parameters[\" eg_y_m \"] * 1e6:2.3f} mm mrad \"\"\" ) return parameters","title":"beam_parameters"},{"location":"reference/pyhdtoolkit/cpymadtools/lattice_generators/","text":"Module pyhdtoolkit.cpymadtools.lattice_generators Module cpymadtools.lattice_generators Created on 2019.06.15 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A collection of functions for generating different lattices for cpymad.madx.Madx input. View Source \"\"\" Module cpymadtools.lattice_generators ------------------------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions for generating different lattices for cpymad.madx.Madx input. \"\"\" class LatticeGenerator : \"\"\" A simple class to handle said functions. \"\"\" @staticmethod def generate_base_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_onesext_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, ks1, 0}; mod: multipole, knl:={0, 0, ks2, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_oneoct_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, 0, koct}; mod: multipole, knl:={0, 0, 0, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_tripleterrors_study_reference () -> str : \"\"\" Generate generic script for reference Twiss, to use in a `cpymad.madx.Madx` object. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 twiss; \"\"\" @staticmethod def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str : \"\"\" Generate generic script for tf_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. tf_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For field errors ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma Rr = 0.05; ! Radius for field errors (??) ON_B2R = 1; ! Activate field errors B2r = {tf_error}; ! Set field errors magnitude -> Units of B2 error (will be in 1E-4) exec, SetEfcomp_Q; ! Assign field errors !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\" @staticmethod def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str : \"\"\" Generate generic script for ms_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. ms_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet MSErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For longitudinal missalignments ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma ealign, ds := {ms_error} * 1E-3 * TGAUSS(GCUTR); ! Gaussian missalignments in meters !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\" Classes LatticeGenerator class LatticeGenerator ( / , * args , ** kwargs ) A simple class to handle said functions. View Source class LatticeGenerator : \"\"\" A simple class to handle said functions. \"\"\" @staticmethod def generate_base_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_onesext_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, ks1, 0}; mod: multipole, knl:={0, 0, ks2, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_oneoct_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, 0, koct}; mod: multipole, knl:={0, 0, 0, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_tripleterrors_study_reference () -> str : \"\"\" Generate generic script for reference Twiss, to use in a `cpymad.madx.Madx` object. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 twiss; \"\"\" @staticmethod def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str : \"\"\" Generate generic script for tf_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. tf_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For field errors ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma Rr = 0.05; ! Radius for field errors (??) ON_B2R = 1; ! Activate field errors B2r = {tf_error}; ! Set field errors magnitude -> Units of B2 error (will be in 1E-4) exec, SetEfcomp_Q; ! Assign field errors !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\" @staticmethod def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str : \"\"\" Generate generic script for ms_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. ms_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet MSErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For longitudinal missalignments ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma ealign, ds := {ms_error} * 1E-3 * TGAUSS(GCUTR); ! Gaussian missalignments in meters !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\" Static methods generate_base_cas_lattice def generate_base_cas_lattice ( ) -> str Simple function to help unclutter the notebook. Returns: A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_base_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" generate_oneoct_cas_lattice def generate_oneoct_cas_lattice ( ) -> str Simple function to help unclutter the notebook. Returns: A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_oneoct_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, 0, koct}; mod: multipole, knl:={0, 0, 0, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" generate_onesext_cas_lattice def generate_onesext_cas_lattice ( ) -> str Simple function to help unclutter the notebook. Returns: A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_onesext_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, ks1, 0}; mod: multipole, knl:={0, 0, ks2, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" generate_tripleterrors_study_mserror_job def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str Generate generic script for ms_error Twiss, to use in a cpymad.madx.Madx object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. ms_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str : \"\"\" Generate generic script for ms_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. ms_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet MSErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For longitudinal missalignments ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma ealign, ds := {ms_error} * 1E-3 * TGAUSS(GCUTR); ! Gaussian missalignments in meters !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\" generate_tripleterrors_study_reference def generate_tripleterrors_study_reference ( ) -> str Generate generic script for reference Twiss, to use in a cpymad.madx.Madx object. Returns: A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_tripleterrors_study_reference () -> str : \"\"\" Generate generic script for reference Twiss, to use in a `cpymad.madx.Madx` object. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 twiss; \"\"\" generate_tripleterrors_study_tferror_job def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str Generate generic script for tf_error Twiss, to use in a cpymad.madx.Madx object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. tf_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str : \"\"\" Generate generic script for tf_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. tf_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For field errors ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma Rr = 0.05; ! Radius for field errors (??) ON_B2R = 1; ! Activate field errors B2r = {tf_error}; ! Set field errors magnitude -> Units of B2 error (will be in 1E-4) exec, SetEfcomp_Q; ! Assign field errors !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\"","title":"Lattice Generators"},{"location":"reference/pyhdtoolkit/cpymadtools/lattice_generators/#module-pyhdtoolkitcpymadtoolslattice_generators","text":"","title":"Module pyhdtoolkit.cpymadtools.lattice_generators"},{"location":"reference/pyhdtoolkit/cpymadtools/lattice_generators/#module-cpymadtoolslattice_generators","text":"Created on 2019.06.15 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A collection of functions for generating different lattices for cpymad.madx.Madx input. View Source \"\"\" Module cpymadtools.lattice_generators ------------------------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions for generating different lattices for cpymad.madx.Madx input. \"\"\" class LatticeGenerator : \"\"\" A simple class to handle said functions. \"\"\" @staticmethod def generate_base_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_onesext_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, ks1, 0}; mod: multipole, knl:={0, 0, ks2, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_oneoct_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, 0, koct}; mod: multipole, knl:={0, 0, 0, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_tripleterrors_study_reference () -> str : \"\"\" Generate generic script for reference Twiss, to use in a `cpymad.madx.Madx` object. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 twiss; \"\"\" @staticmethod def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str : \"\"\" Generate generic script for tf_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. tf_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For field errors ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma Rr = 0.05; ! Radius for field errors (??) ON_B2R = 1; ! Activate field errors B2r = {tf_error}; ! Set field errors magnitude -> Units of B2 error (will be in 1E-4) exec, SetEfcomp_Q; ! Assign field errors !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\" @staticmethod def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str : \"\"\" Generate generic script for ms_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. ms_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet MSErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For longitudinal missalignments ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma ealign, ds := {ms_error} * 1E-3 * TGAUSS(GCUTR); ! Gaussian missalignments in meters !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\"","title":"Module cpymadtools.lattice_generators"},{"location":"reference/pyhdtoolkit/cpymadtools/lattice_generators/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/cpymadtools/lattice_generators/#latticegenerator","text":"class LatticeGenerator ( / , * args , ** kwargs ) A simple class to handle said functions. View Source class LatticeGenerator : \"\"\" A simple class to handle said functions. \"\"\" @staticmethod def generate_base_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_onesext_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, ks1, 0}; mod: multipole, knl:={0, 0, ks2, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_oneoct_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, 0, koct}; mod: multipole, knl:={0, 0, 0, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\" @staticmethod def generate_tripleterrors_study_reference () -> str : \"\"\" Generate generic script for reference Twiss, to use in a `cpymad.madx.Madx` object. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 twiss; \"\"\" @staticmethod def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str : \"\"\" Generate generic script for tf_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. tf_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For field errors ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma Rr = 0.05; ! Radius for field errors (??) ON_B2R = 1; ! Activate field errors B2r = {tf_error}; ! Set field errors magnitude -> Units of B2 error (will be in 1E-4) exec, SetEfcomp_Q; ! Assign field errors !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\" @staticmethod def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str : \"\"\" Generate generic script for ms_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. ms_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet MSErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For longitudinal missalignments ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma ealign, ds := {ms_error} * 1E-3 * TGAUSS(GCUTR); ! Gaussian missalignments in meters !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\"","title":"LatticeGenerator"},{"location":"reference/pyhdtoolkit/cpymadtools/lattice_generators/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/cpymadtools/lattice_generators/#generate_base_cas_lattice","text":"def generate_base_cas_lattice ( ) -> str Simple function to help unclutter the notebook. Returns: A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_base_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\"","title":"generate_base_cas_lattice"},{"location":"reference/pyhdtoolkit/cpymadtools/lattice_generators/#generate_oneoct_cas_lattice","text":"def generate_oneoct_cas_lattice ( ) -> str Simple function to help unclutter the notebook. Returns: A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_oneoct_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, 0, koct}; mod: multipole, knl:={0, 0, 0, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\"","title":"generate_oneoct_cas_lattice"},{"location":"reference/pyhdtoolkit/cpymadtools/lattice_generators/#generate_onesext_cas_lattice","text":"def generate_onesext_cas_lattice ( ) -> str Simple function to help unclutter the notebook. Returns: A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_onesext_cas_lattice () -> str : \"\"\" Simple function to help unclutter the notebook. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" option, -info, -warn; TITLE, \u2019CAS2019 Project Team 3\u2019; ! PARAMETERS circumference = 1000.0; ncell = 24; lcell = circumference/ncell; lq = 3.00; angleBending = 2.0*pi/(4*ncell); ! STRENGTHS kqf = 0.0228 * lq; kqd = -0.0228 * lq; lsex = 0.00001; ks1 = 0; ks2 = 0; ! ELEMENTS mb:multipole, knl:={angleBending}; qf: multipole, knl:={0, kqf}; qd: multipole, knl:={0, kqd}; msf: multipole, knl:={0, 0, ksf}; msd: multipole, knl:={0, 0, ksd}; mof: multipole, knl:={0, 0, ks1, 0}; mod: multipole, knl:={0, 0, ks2, 0}; ! DECLARE SEQUENCE CAS3: sequence, refer=centre, l=circumference; start_machine: marker, at = 0; n = 1; qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mof: mof, at=(n-1)*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mod: mod, at=(n-1)*lcell + 0.50*lcell + 3*lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; while (n < ncell+1) { qf: qf, at=(n-1)*lcell; msf: msf, at=(n-1)*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.15*lcell; mb: mb, at=(n-1)*lcell + 0.35*lcell; qd: qd, at=(n-1)*lcell + 0.50*lcell; msd: msd, at=(n-1)*lcell + 0.50*lcell + lsex/2.0; mb: mb, at=(n-1)*lcell + 0.65*lcell; mb: mb, at=(n-1)*lcell + 0.85*lcell; at=(n-1)*lcell; n = n + 1; } end_machine: marker at=circumference; endsequence; ! MAKE BEAM beam, particle=proton, sequence=CAS3, energy=20.0; ! ACTIVATE SEQUENCE use, sequence=CAS3; select,flag=interpolate, class=drift, slice=5, range=#s/#e; ksf = 0; ksd = 0; ! INTERPOLATE select, flag=interpolate, class=drift, slice=10, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=5, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; ! TWISS select,flag=twiss, clear; select,flag=twiss, column=name ,s, x, y, betx, bety, mux, muy, dx, dy; twiss; \"\"\"","title":"generate_onesext_cas_lattice"},{"location":"reference/pyhdtoolkit/cpymadtools/lattice_generators/#generate_tripleterrors_study_mserror_job","text":"def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str Generate generic script for ms_error Twiss, to use in a cpymad.madx.Madx object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. ms_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_tripleterrors_study_mserror_job ( rand_seed : str , ms_error : str ) -> str : \"\"\" Generate generic script for ms_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. ms_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet MSErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For longitudinal missalignments ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma ealign, ds := {ms_error} * 1E-3 * TGAUSS(GCUTR); ! Gaussian missalignments in meters !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\"","title":"generate_tripleterrors_study_mserror_job"},{"location":"reference/pyhdtoolkit/cpymadtools/lattice_generators/#generate_tripleterrors_study_reference","text":"def generate_tripleterrors_study_reference ( ) -> str Generate generic script for reference Twiss, to use in a cpymad.madx.Madx object. Returns: A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_tripleterrors_study_reference () -> str : \"\"\" Generate generic script for reference Twiss, to use in a `cpymad.madx.Madx` object. Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 twiss; \"\"\"","title":"generate_tripleterrors_study_reference"},{"location":"reference/pyhdtoolkit/cpymadtools/lattice_generators/#generate_tripleterrors_study_tferror_job","text":"def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str Generate generic script for tf_error Twiss, to use in a cpymad.madx.Madx object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. tf_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your cpymad.madx.Madx object. View Source @staticmethod def generate_tripleterrors_study_tferror_job ( rand_seed : str , tf_error : str ) -> str : \"\"\" Generate generic script for tf_error Twiss, to use in a `cpymad.madx.Madx` object. Args: rand_seed (str): the random seed to provide MAD for the errors distributions. tf_error (str): the misalignment error value (along the s axis). Returns: A string you can input into your `cpymad.madx.Madx` object. \"\"\" return f \"\"\" !####################### Make macros available ####################### option, -echo, -warn, -info; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / beta_beat . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / lhc . macros . madx \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / madx / lib / hllhc . macros . madx \"; title, \" HLLHC Triplet TFErrors to Beta - Beating \"; !####################### Call optics files ####################### call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / lhcrunIII . seq \"; call, file = \" / afs / cern . ch / work / f / fesoubel / public / Repositories / Beta - Beat . src / model / accelerators / lhc / hllhc1 .3 / main . seq \"; call, file = \" / afs / cern . ch / eng / lhc / optics / V6 .5 / errors / Esubroutines . madx \"; !####################### Calling modifiers for 15cm optics ####################### call, file = \" / afs / cern . ch / eng / lhc / optics / HLLHCV1 .3 / opt_150_150_150_150 . madx \"; !####################### Create beam ####################### exec, define_nominal_beams(); !####################### Flatten and set START point at ? ####################### exec, cycle_sequences(); !####################### Default crossing scheme ####################### exec, set_default_crossing_scheme(); !####################### Selecting to use Beam 1 ####################### use, period = LHCB1; !####################### Tune matching and Twiss nominal ####################### option, echo, warn, info; exec, match_tunes(62.31, 60.32, 1); ! Since we're using beam 1 exec, do_twiss_elements(LHCB1, \" . / twiss_nominal . dat \", 0.0); !####################### For field errors ####################### eoption, add, seed = {rand_seed}; ! Different seed every time select, flag=error, clear; select, flag=error, pattern = ^MQXF.*[RL][15]; ! Only triplets quadrupoles around IP1 and IP5 GCUTR = 3; ! Cut gaussians at 3 sigma Rr = 0.05; ! Radius for field errors (??) ON_B2R = 1; ! Activate field errors B2r = {tf_error}; ! Set field errors magnitude -> Units of B2 error (will be in 1E-4) exec, SetEfcomp_Q; ! Assign field errors !####################### Saving errors to file ####################### !esave, file=\" . / errors_file . dat \"; ! Will save the errors of chosen type. !####################### Tune matching and Twiss with errors ####################### exec, match_tunes(62.31, 60.32, 1); exec, do_twiss_elements(LHCB1, \" . / twiss_errors . dat \", 0.0); \"\"\"","title":"generate_tripleterrors_study_tferror_job"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/","text":"Module pyhdtoolkit.cpymadtools.latwiss Module cpymadtools.latwiss Created on 2019.06.15 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A collection of functions to elegantly plot the Twiss parameters output of a cpymad.madx.Madx instance after it has ran. View Source \"\"\" Module cpymadtools.latwiss -------------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions to elegantly plot the Twiss parameters output of a cpymad.madx.Madx instance after it has ran. \"\"\" from typing import Dict , Tuple import matplotlib import matplotlib.axes import matplotlib.patches as patches import matplotlib.pyplot as plt import pandas as pd from loguru import logger from pyhdtoolkit.plotting.settings import PLOT_PARAMS try : from cpymad.madx import Madx except ModuleNotFoundError : Madx = None plt . rcParams . update ( PLOT_PARAMS ) class LaTwiss : \"\"\" A class to manage plotting the machine survey as well as an elegant plot for elements as well as Twiss parameters. \"\"\" @staticmethod def _plot_lattice_series ( ax : matplotlib . axes . Axes , series : pd . DataFrame , height : float = 1.0 , v_offset : float = 0.0 , color : str = \"r\" , alpha : float = 0.5 , lw : int = 3 , ) -> None : \"\"\" Plots the layout of your machine as a patch of rectangles for different element types. Original code from Guido Sterbini. Args: ax (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. series (pd.DataFrame): a dataframe with your elements' data. height (float): value to reach for the patch on the y axis. v_offset (float): vertical offset for the patch. color (str): color kwarg to transmit to pyplot. alpha (float): alpha kwarg to transmit to pyplot. lw (int): linewidth kwarg to transmit to pyplot. \"\"\" ax . add_patch ( patches . Rectangle ( ( series . s - series . l , v_offset - height / 2.0 ), series . l , # width height , # height color = color , alpha = alpha , lw = lw , ) ) @staticmethod def plot_latwiss ( cpymad_instance : Madx , title : str , figsize : Tuple [ int , int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint: disable=too-many-arguments logger . debug ( \"Getting Twiss dataframe from cpymad\" ) twiss_df = cpymad_instance . table . twiss . dframe () figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches (takes a third of figure) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( \"$ \\\\ theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # All elements can be defined as a 'multipole', but dipoles can also be defined as # 'rbend' or 'sbend', quadrupoles as 'quadrupoles' and sextupoles as 'sextupoles' logger . debug ( \"Extracting element-specific dataframes\" ) quadrupoles_df = twiss_df [ ( twiss_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( twiss_df . name . str . contains ( \"Q\" , case = False )) ] dipoles_df = twiss_df [ ( twiss_df . keyword . isin ([ \"multipole\" , \"rbend\" , \"sbend\" ])) & ( twiss_df . name . str . contains ( \"B\" , case = False )) ] sextupoles_df = twiss_df [ ( twiss_df . keyword . isin ([ \"multipole\" , \"sextupole\" ])) & ( twiss_df . name . str . contains ( \"S\" , case = False )) ] # Plotting dipole patches, beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows (): if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) if dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows (): LaTwiss . _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows (): LaTwiss . _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid ( ( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = \"$ \\\\ beta_x$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = \"$ \\\\ beta_y$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( \"$ \\\\ beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = \"$D_x$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = \"$D_y$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersions [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 500 ) return figure @staticmethod def plot_machine_survey ( cpymad_instance : Madx , title : str = \"Machine Layout\" , figsize : Tuple [ int , int ] = ( 16 , 11 ), savefig : str = None , show_elements : bool = False , high_orders : bool = False , ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing the machine geometry in 2D. Original code is from Guido Sterbini. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. show_elements (bool): if True, will try to plot by differentiating elements. Experimental, defaults to False. high_orders (bool): if True, plot sextupoles and octupoles when show_elements is True, otherwise only up to quadrupoles. Defaults to False. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" logger . debug ( \"Getting machine survey from cpymad\" ) cpymad_instance . input ( \"survey;\" ) survey = cpymad_instance . table . survey . dframe () figure = plt . figure ( figsize = figsize ) if show_elements : logger . debug ( \"Plotting survey with elements differentiation\" ) element_dfs = _make_survey_groups ( survey ) plt . scatter ( element_dfs [ \"dipoles\" ] . z , element_dfs [ \"dipoles\" ] . x , marker = \".\" , c = element_dfs [ \"dipoles\" ] . s , cmap = \"copper\" , label = \"Dipoles\" , ) plt . scatter ( element_dfs [ \"quad_foc\" ] . z , element_dfs [ \"quad_foc\" ] . x , marker = \"o\" , color = \"blue\" , label = \"QF\" , ) plt . scatter ( element_dfs [ \"quad_defoc\" ] . z , element_dfs [ \"quad_defoc\" ] . x , marker = \"o\" , color = \"red\" , label = \"QD\" , ) if high_orders : logger . debug ( \"Plotting high order magnetic elements (up to octupoles)\" ) plt . scatter ( element_dfs [ \"sextupoles\" ] . z , element_dfs [ \"sextupoles\" ] . x , marker = \".\" , color = \"m\" , label = \"MS\" , ) plt . scatter ( element_dfs [ \"octupoles\" ] . z , element_dfs [ \"octupoles\" ] . x , marker = \".\" , color = \"cyan\" , label = \"MO\" , ) plt . legend ( loc = 2 ) else : logger . debug ( \"Plotting survey without elements differentiation\" ) plt . scatter ( survey . z , survey . x , c = survey . s ) plt . axis ( \"equal\" ) plt . colorbar () . set_label ( \"s [m]\" ) plt . xlabel ( \"z [m]\" ) plt . ylabel ( \"x [m]\" ) plt . title ( title ) if savefig : logger . info ( f \"Saving machine survey plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 500 ) return figure # ---------------------- Private Utilities ---------------------- # def _make_survey_groups ( survey_df : pd . DataFrame ) -> Dict [ str , pd . DataFrame ]: \"\"\" Gets a survey dataframe and returns different sub-dataframes corresponding to different magnetic elements. Args: survey_df (pd.DataFrame): machine survey dataframe obtained from your Madx instance, with <instance>.table.survey.dframe(). Returns: A dictionary containing a dataframe for dipoles, focusing quadrupoles, defocusing quadrupoles, sextupoles and octupoles. The keys are self-explanatory. \"\"\" logger . debug ( \"Getting different element groups dframes from MAD-X survey\" ) return { \"dipoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sbend\" , \"rbend\" ])) & ( survey_df . name . str . contains ( \"B\" , case = False )) ], \"quad_foc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"F\" , case = False )) ], \"quad_defoc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"D\" , case = False )) ], \"sextupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sextupole\" ])) & ( survey_df . name . str . contains ( \"S\" , case = False )) ], \"octupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"octupole\" ])) & ( survey_df . name . str . contains ( \"O\" , case = False )) ], } def _synchronise_grids ( axis_1 : matplotlib . axes . Axes , axis_2 : matplotlib . axes . Axes ) -> None : \"\"\" !!! warning Experimental! This is currently not stable and may disappear in a future release. Little trick to make both y axis synchronise on their grid lines when plotting in dual axis. Only the second provided axis will be altered. Somehow doesn't work well yet with ticks not starting from 0 up. Args: axis_1 (matplotlib.axes.Axes): a matplotlib axis object. axis_2 (matplotlib.axes.Axes): a matplotlib axis object sharing the x axis with axis_1. Returns: Nothing, alters the y axis on the provided axis_2. \"\"\" logger . warning ( \"Grid synchronization is experimental and may mess up your vertical axis\" ) ylim_1 = axis_1 . get_ylim () len_1 = ylim_1 [ 1 ] - ylim_1 [ 0 ] yticks_1 = axis_1 . get_yticks () relative_distance = [( y - ylim_1 [ 0 ]) / len_1 for y in yticks_1 ] ylim_2 = list ( axis_2 . get_ylim ()) ylim_2 = [ e - ylim_2 [ 0 ] for e in ylim_2 ] # can be a weird offset, fix this len_2 = ylim_2 [ 1 ] - ylim_2 [ 0 ] yticks_2 = [ ry * len_2 + ylim_2 [ 0 ] for ry in relative_distance ] axis_2 . set_yticks ( yticks_2 ) axis_2 . set_ylim ( ylim_2 ) axis_1 . yaxis . grid ( True , which = \"major\" ) axis_2 . yaxis . grid ( True , which = \"major\" ) Variables PLOT_PARAMS Classes LaTwiss class LaTwiss ( / , * args , ** kwargs ) A class to manage plotting the machine survey as well as an elegant plot for elements as well as Twiss parameters. View Source class LaTwiss : \"\"\" A class to manage plotting the machine survey as well as an elegant plot for elements as well as Twiss parameters. \"\"\" @staticmethod def _plot_lattice_series ( ax : matplotlib . axes . Axes , series : pd . DataFrame , height : float = 1.0 , v_offset : float = 0.0 , color : str = \"r\" , alpha : float = 0.5 , lw : int = 3 , ) -> None : \"\"\" Plots the layout of your machine as a patch of rectangles for different element types. Original code from Guido Sterbini. Args: ax (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. series (pd.DataFrame): a dataframe with your elements' data. height (float): value to reach for the patch on the y axis. v_offset (float): vertical offset for the patch. color (str): color kwarg to transmit to pyplot. alpha (float): alpha kwarg to transmit to pyplot. lw (int): linewidth kwarg to transmit to pyplot. \"\"\" ax . add_patch ( patches . Rectangle ( ( series . s - series . l , v_offset - height / 2.0 ), series . l , # width height , # height color = color , alpha = alpha , lw = lw , ) ) @staticmethod def plot_latwiss ( cpymad_instance : Madx , title : str , figsize : Tuple [ int, int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float, float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float, float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float, float ] = None , k0l_lim : Tuple [ float, float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float, float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments logger . debug ( \"Getting Twiss dataframe from cpymad\" ) twiss_df = cpymad_instance . table . twiss . dframe () figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches ( takes a third of figure ) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( \"$\\\\theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # All elements can be defined as a 'multipole' , but dipoles can also be defined as # 'rbend' or 'sbend' , quadrupoles as 'quadrupoles' and sextupoles as 'sextupoles' logger . debug ( \"Extracting element-specific dataframes\" ) quadrupoles_df = twiss_df [ (twiss_df.keyword.isin([\"multipole\", \"quadrupole\" ] )) & ( twiss_df . name . str . contains ( \"Q\" , case = False )) ] dipoles_df = twiss_df [ (twiss_df.keyword.isin([\"multipole\", \"rbend\", \"sbend\" ] )) & ( twiss_df . name . str . contains ( \"B\" , case = False )) ] sextupoles_df = twiss_df [ (twiss_df.keyword.isin([\"multipole\", \"sextupole\" ] )) & ( twiss_df . name . str . contains ( \"S\" , case = False )) ] # Plotting dipole patches , beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows () : if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) if dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid ( ( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = \"$\\\\beta_x$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = \"$\\\\beta_y$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( \"$\\\\beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = \"$D_x$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = \"$D_y$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersions [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 500 ) return figure @staticmethod def plot_machine_survey ( cpymad_instance : Madx , title : str = \"Machine Layout\" , figsize : Tuple [ int, int ] = ( 16 , 11 ), savefig : str = None , show_elements : bool = False , high_orders : bool = False , ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing the machine geometry in 2D. Original code is from Guido Sterbini. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. show_elements (bool): if True, will try to plot by differentiating elements. Experimental, defaults to False. high_orders (bool): if True, plot sextupoles and octupoles when show_elements is True, otherwise only up to quadrupoles. Defaults to False. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" logger . debug ( \"Getting machine survey from cpymad\" ) cpymad_instance . input ( \"survey;\" ) survey = cpymad_instance . table . survey . dframe () figure = plt . figure ( figsize = figsize ) if show_elements : logger . debug ( \"Plotting survey with elements differentiation\" ) element_dfs = _make_survey_groups ( survey ) plt . scatter ( element_dfs [ \"dipoles\" ] . z , element_dfs [ \"dipoles\" ] . x , marker = \".\" , c = element_dfs [ \"dipoles\" ] . s , cmap = \"copper\" , label = \"Dipoles\" , ) plt . scatter ( element_dfs [ \"quad_foc\" ] . z , element_dfs [ \"quad_foc\" ] . x , marker = \"o\" , color = \"blue\" , label = \"QF\" , ) plt . scatter ( element_dfs [ \"quad_defoc\" ] . z , element_dfs [ \"quad_defoc\" ] . x , marker = \"o\" , color = \"red\" , label = \"QD\" , ) if high_orders : logger . debug ( \"Plotting high order magnetic elements (up to octupoles)\" ) plt . scatter ( element_dfs [ \"sextupoles\" ] . z , element_dfs [ \"sextupoles\" ] . x , marker = \".\" , color = \"m\" , label = \"MS\" , ) plt . scatter ( element_dfs [ \"octupoles\" ] . z , element_dfs [ \"octupoles\" ] . x , marker = \".\" , color = \"cyan\" , label = \"MO\" , ) plt . legend ( loc = 2 ) else : logger . debug ( \"Plotting survey without elements differentiation\" ) plt . scatter ( survey . z , survey . x , c = survey . s ) plt . axis ( \"equal\" ) plt . colorbar (). set_label ( \"s [m]\" ) plt . xlabel ( \"z [m]\" ) plt . ylabel ( \"x [m]\" ) plt . title ( title ) if savefig : logger . info ( f \"Saving machine survey plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 500 ) return figure Static methods plot_latwiss def plot_latwiss ( cpymad_instance : cpymad . madx . Madx , title : str , figsize : Tuple [ int , int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ) ) -> matplotlib . figure . Figure Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_latwiss ( cpymad_instance : Madx , title : str , figsize : Tuple [ int, int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float, float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float, float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float, float ] = None , k0l_lim : Tuple [ float, float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float, float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments logger . debug ( \"Getting Twiss dataframe from cpymad\" ) twiss_df = cpymad_instance . table . twiss . dframe () figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches ( takes a third of figure ) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( \"$\\\\theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # All elements can be defined as a 'multipole' , but dipoles can also be defined as # 'rbend' or 'sbend' , quadrupoles as 'quadrupoles' and sextupoles as 'sextupoles' logger . debug ( \"Extracting element-specific dataframes\" ) quadrupoles_df = twiss_df [ (twiss_df.keyword.isin([\"multipole\", \"quadrupole\" ] )) & ( twiss_df . name . str . contains ( \"Q\" , case = False )) ] dipoles_df = twiss_df [ (twiss_df.keyword.isin([\"multipole\", \"rbend\", \"sbend\" ] )) & ( twiss_df . name . str . contains ( \"B\" , case = False )) ] sextupoles_df = twiss_df [ (twiss_df.keyword.isin([\"multipole\", \"sextupole\" ] )) & ( twiss_df . name . str . contains ( \"S\" , case = False )) ] # Plotting dipole patches , beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows () : if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) if dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid ( ( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = \"$\\\\beta_x$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = \"$\\\\beta_y$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( \"$\\\\beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = \"$D_x$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = \"$D_y$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersions [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 500 ) return figure plot_machine_survey def plot_machine_survey ( cpymad_instance : cpymad . madx . Madx , title : str = 'Machine Layout' , figsize : Tuple [ int , int ] = ( 16 , 11 ), savefig : str = None , show_elements : bool = False , high_orders : bool = False ) -> matplotlib . figure . Figure Provided with an active Cpymad class after having ran a script, will create a plot representing the machine geometry in 2D. Original code is from Guido Sterbini. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. show_elements (bool): if True, will try to plot by differentiating elements. Experimental, defaults to False. high_orders (bool): if True, plot sextupoles and octupoles when show_elements is True, otherwise only up to quadrupoles. Defaults to False. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_machine_survey ( cpymad_instance : Madx , title : str = \"Machine Layout\" , figsize : Tuple [ int, int ] = ( 16 , 11 ), savefig : str = None , show_elements : bool = False , high_orders : bool = False , ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing the machine geometry in 2D. Original code is from Guido Sterbini. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. show_elements (bool): if True, will try to plot by differentiating elements. Experimental, defaults to False. high_orders (bool): if True, plot sextupoles and octupoles when show_elements is True, otherwise only up to quadrupoles. Defaults to False. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" logger . debug ( \"Getting machine survey from cpymad\" ) cpymad_instance . input ( \"survey;\" ) survey = cpymad_instance . table . survey . dframe () figure = plt . figure ( figsize = figsize ) if show_elements : logger . debug ( \"Plotting survey with elements differentiation\" ) element_dfs = _make_survey_groups ( survey ) plt . scatter ( element_dfs [ \"dipoles\" ] . z , element_dfs [ \"dipoles\" ] . x , marker = \".\" , c = element_dfs [ \"dipoles\" ] . s , cmap = \"copper\" , label = \"Dipoles\" , ) plt . scatter ( element_dfs [ \"quad_foc\" ] . z , element_dfs [ \"quad_foc\" ] . x , marker = \"o\" , color = \"blue\" , label = \"QF\" , ) plt . scatter ( element_dfs [ \"quad_defoc\" ] . z , element_dfs [ \"quad_defoc\" ] . x , marker = \"o\" , color = \"red\" , label = \"QD\" , ) if high_orders : logger . debug ( \"Plotting high order magnetic elements (up to octupoles)\" ) plt . scatter ( element_dfs [ \"sextupoles\" ] . z , element_dfs [ \"sextupoles\" ] . x , marker = \".\" , color = \"m\" , label = \"MS\" , ) plt . scatter ( element_dfs [ \"octupoles\" ] . z , element_dfs [ \"octupoles\" ] . x , marker = \".\" , color = \"cyan\" , label = \"MO\" , ) plt . legend ( loc = 2 ) else : logger . debug ( \"Plotting survey without elements differentiation\" ) plt . scatter ( survey . z , survey . x , c = survey . s ) plt . axis ( \"equal\" ) plt . colorbar (). set_label ( \"s [m]\" ) plt . xlabel ( \"z [m]\" ) plt . ylabel ( \"x [m]\" ) plt . title ( title ) if savefig : logger . info ( f \"Saving machine survey plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 500 ) return figure","title":"Latwiss"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/#module-pyhdtoolkitcpymadtoolslatwiss","text":"","title":"Module pyhdtoolkit.cpymadtools.latwiss"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/#module-cpymadtoolslatwiss","text":"Created on 2019.06.15 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A collection of functions to elegantly plot the Twiss parameters output of a cpymad.madx.Madx instance after it has ran. View Source \"\"\" Module cpymadtools.latwiss -------------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions to elegantly plot the Twiss parameters output of a cpymad.madx.Madx instance after it has ran. \"\"\" from typing import Dict , Tuple import matplotlib import matplotlib.axes import matplotlib.patches as patches import matplotlib.pyplot as plt import pandas as pd from loguru import logger from pyhdtoolkit.plotting.settings import PLOT_PARAMS try : from cpymad.madx import Madx except ModuleNotFoundError : Madx = None plt . rcParams . update ( PLOT_PARAMS ) class LaTwiss : \"\"\" A class to manage plotting the machine survey as well as an elegant plot for elements as well as Twiss parameters. \"\"\" @staticmethod def _plot_lattice_series ( ax : matplotlib . axes . Axes , series : pd . DataFrame , height : float = 1.0 , v_offset : float = 0.0 , color : str = \"r\" , alpha : float = 0.5 , lw : int = 3 , ) -> None : \"\"\" Plots the layout of your machine as a patch of rectangles for different element types. Original code from Guido Sterbini. Args: ax (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. series (pd.DataFrame): a dataframe with your elements' data. height (float): value to reach for the patch on the y axis. v_offset (float): vertical offset for the patch. color (str): color kwarg to transmit to pyplot. alpha (float): alpha kwarg to transmit to pyplot. lw (int): linewidth kwarg to transmit to pyplot. \"\"\" ax . add_patch ( patches . Rectangle ( ( series . s - series . l , v_offset - height / 2.0 ), series . l , # width height , # height color = color , alpha = alpha , lw = lw , ) ) @staticmethod def plot_latwiss ( cpymad_instance : Madx , title : str , figsize : Tuple [ int , int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint: disable=too-many-arguments logger . debug ( \"Getting Twiss dataframe from cpymad\" ) twiss_df = cpymad_instance . table . twiss . dframe () figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches (takes a third of figure) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( \"$ \\\\ theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # All elements can be defined as a 'multipole', but dipoles can also be defined as # 'rbend' or 'sbend', quadrupoles as 'quadrupoles' and sextupoles as 'sextupoles' logger . debug ( \"Extracting element-specific dataframes\" ) quadrupoles_df = twiss_df [ ( twiss_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( twiss_df . name . str . contains ( \"Q\" , case = False )) ] dipoles_df = twiss_df [ ( twiss_df . keyword . isin ([ \"multipole\" , \"rbend\" , \"sbend\" ])) & ( twiss_df . name . str . contains ( \"B\" , case = False )) ] sextupoles_df = twiss_df [ ( twiss_df . keyword . isin ([ \"multipole\" , \"sextupole\" ])) & ( twiss_df . name . str . contains ( \"S\" , case = False )) ] # Plotting dipole patches, beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows (): if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) if dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows (): LaTwiss . _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows (): LaTwiss . _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid ( ( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = \"$ \\\\ beta_x$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = \"$ \\\\ beta_y$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( \"$ \\\\ beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = \"$D_x$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = \"$D_y$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersions [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 500 ) return figure @staticmethod def plot_machine_survey ( cpymad_instance : Madx , title : str = \"Machine Layout\" , figsize : Tuple [ int , int ] = ( 16 , 11 ), savefig : str = None , show_elements : bool = False , high_orders : bool = False , ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing the machine geometry in 2D. Original code is from Guido Sterbini. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. show_elements (bool): if True, will try to plot by differentiating elements. Experimental, defaults to False. high_orders (bool): if True, plot sextupoles and octupoles when show_elements is True, otherwise only up to quadrupoles. Defaults to False. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" logger . debug ( \"Getting machine survey from cpymad\" ) cpymad_instance . input ( \"survey;\" ) survey = cpymad_instance . table . survey . dframe () figure = plt . figure ( figsize = figsize ) if show_elements : logger . debug ( \"Plotting survey with elements differentiation\" ) element_dfs = _make_survey_groups ( survey ) plt . scatter ( element_dfs [ \"dipoles\" ] . z , element_dfs [ \"dipoles\" ] . x , marker = \".\" , c = element_dfs [ \"dipoles\" ] . s , cmap = \"copper\" , label = \"Dipoles\" , ) plt . scatter ( element_dfs [ \"quad_foc\" ] . z , element_dfs [ \"quad_foc\" ] . x , marker = \"o\" , color = \"blue\" , label = \"QF\" , ) plt . scatter ( element_dfs [ \"quad_defoc\" ] . z , element_dfs [ \"quad_defoc\" ] . x , marker = \"o\" , color = \"red\" , label = \"QD\" , ) if high_orders : logger . debug ( \"Plotting high order magnetic elements (up to octupoles)\" ) plt . scatter ( element_dfs [ \"sextupoles\" ] . z , element_dfs [ \"sextupoles\" ] . x , marker = \".\" , color = \"m\" , label = \"MS\" , ) plt . scatter ( element_dfs [ \"octupoles\" ] . z , element_dfs [ \"octupoles\" ] . x , marker = \".\" , color = \"cyan\" , label = \"MO\" , ) plt . legend ( loc = 2 ) else : logger . debug ( \"Plotting survey without elements differentiation\" ) plt . scatter ( survey . z , survey . x , c = survey . s ) plt . axis ( \"equal\" ) plt . colorbar () . set_label ( \"s [m]\" ) plt . xlabel ( \"z [m]\" ) plt . ylabel ( \"x [m]\" ) plt . title ( title ) if savefig : logger . info ( f \"Saving machine survey plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 500 ) return figure # ---------------------- Private Utilities ---------------------- # def _make_survey_groups ( survey_df : pd . DataFrame ) -> Dict [ str , pd . DataFrame ]: \"\"\" Gets a survey dataframe and returns different sub-dataframes corresponding to different magnetic elements. Args: survey_df (pd.DataFrame): machine survey dataframe obtained from your Madx instance, with <instance>.table.survey.dframe(). Returns: A dictionary containing a dataframe for dipoles, focusing quadrupoles, defocusing quadrupoles, sextupoles and octupoles. The keys are self-explanatory. \"\"\" logger . debug ( \"Getting different element groups dframes from MAD-X survey\" ) return { \"dipoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sbend\" , \"rbend\" ])) & ( survey_df . name . str . contains ( \"B\" , case = False )) ], \"quad_foc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"F\" , case = False )) ], \"quad_defoc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"D\" , case = False )) ], \"sextupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sextupole\" ])) & ( survey_df . name . str . contains ( \"S\" , case = False )) ], \"octupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"octupole\" ])) & ( survey_df . name . str . contains ( \"O\" , case = False )) ], } def _synchronise_grids ( axis_1 : matplotlib . axes . Axes , axis_2 : matplotlib . axes . Axes ) -> None : \"\"\" !!! warning Experimental! This is currently not stable and may disappear in a future release. Little trick to make both y axis synchronise on their grid lines when plotting in dual axis. Only the second provided axis will be altered. Somehow doesn't work well yet with ticks not starting from 0 up. Args: axis_1 (matplotlib.axes.Axes): a matplotlib axis object. axis_2 (matplotlib.axes.Axes): a matplotlib axis object sharing the x axis with axis_1. Returns: Nothing, alters the y axis on the provided axis_2. \"\"\" logger . warning ( \"Grid synchronization is experimental and may mess up your vertical axis\" ) ylim_1 = axis_1 . get_ylim () len_1 = ylim_1 [ 1 ] - ylim_1 [ 0 ] yticks_1 = axis_1 . get_yticks () relative_distance = [( y - ylim_1 [ 0 ]) / len_1 for y in yticks_1 ] ylim_2 = list ( axis_2 . get_ylim ()) ylim_2 = [ e - ylim_2 [ 0 ] for e in ylim_2 ] # can be a weird offset, fix this len_2 = ylim_2 [ 1 ] - ylim_2 [ 0 ] yticks_2 = [ ry * len_2 + ylim_2 [ 0 ] for ry in relative_distance ] axis_2 . set_yticks ( yticks_2 ) axis_2 . set_ylim ( ylim_2 ) axis_1 . yaxis . grid ( True , which = \"major\" ) axis_2 . yaxis . grid ( True , which = \"major\" )","title":"Module cpymadtools.latwiss"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/#variables","text":"PLOT_PARAMS","title":"Variables"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/#latwiss","text":"class LaTwiss ( / , * args , ** kwargs ) A class to manage plotting the machine survey as well as an elegant plot for elements as well as Twiss parameters. View Source class LaTwiss : \"\"\" A class to manage plotting the machine survey as well as an elegant plot for elements as well as Twiss parameters. \"\"\" @staticmethod def _plot_lattice_series ( ax : matplotlib . axes . Axes , series : pd . DataFrame , height : float = 1.0 , v_offset : float = 0.0 , color : str = \"r\" , alpha : float = 0.5 , lw : int = 3 , ) -> None : \"\"\" Plots the layout of your machine as a patch of rectangles for different element types. Original code from Guido Sterbini. Args: ax (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. series (pd.DataFrame): a dataframe with your elements' data. height (float): value to reach for the patch on the y axis. v_offset (float): vertical offset for the patch. color (str): color kwarg to transmit to pyplot. alpha (float): alpha kwarg to transmit to pyplot. lw (int): linewidth kwarg to transmit to pyplot. \"\"\" ax . add_patch ( patches . Rectangle ( ( series . s - series . l , v_offset - height / 2.0 ), series . l , # width height , # height color = color , alpha = alpha , lw = lw , ) ) @staticmethod def plot_latwiss ( cpymad_instance : Madx , title : str , figsize : Tuple [ int, int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float, float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float, float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float, float ] = None , k0l_lim : Tuple [ float, float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float, float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments logger . debug ( \"Getting Twiss dataframe from cpymad\" ) twiss_df = cpymad_instance . table . twiss . dframe () figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches ( takes a third of figure ) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( \"$\\\\theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # All elements can be defined as a 'multipole' , but dipoles can also be defined as # 'rbend' or 'sbend' , quadrupoles as 'quadrupoles' and sextupoles as 'sextupoles' logger . debug ( \"Extracting element-specific dataframes\" ) quadrupoles_df = twiss_df [ (twiss_df.keyword.isin([\"multipole\", \"quadrupole\" ] )) & ( twiss_df . name . str . contains ( \"Q\" , case = False )) ] dipoles_df = twiss_df [ (twiss_df.keyword.isin([\"multipole\", \"rbend\", \"sbend\" ] )) & ( twiss_df . name . str . contains ( \"B\" , case = False )) ] sextupoles_df = twiss_df [ (twiss_df.keyword.isin([\"multipole\", \"sextupole\" ] )) & ( twiss_df . name . str . contains ( \"S\" , case = False )) ] # Plotting dipole patches , beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows () : if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) if dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid ( ( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = \"$\\\\beta_x$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = \"$\\\\beta_y$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( \"$\\\\beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = \"$D_x$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = \"$D_y$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersions [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 500 ) return figure @staticmethod def plot_machine_survey ( cpymad_instance : Madx , title : str = \"Machine Layout\" , figsize : Tuple [ int, int ] = ( 16 , 11 ), savefig : str = None , show_elements : bool = False , high_orders : bool = False , ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing the machine geometry in 2D. Original code is from Guido Sterbini. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. show_elements (bool): if True, will try to plot by differentiating elements. Experimental, defaults to False. high_orders (bool): if True, plot sextupoles and octupoles when show_elements is True, otherwise only up to quadrupoles. Defaults to False. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" logger . debug ( \"Getting machine survey from cpymad\" ) cpymad_instance . input ( \"survey;\" ) survey = cpymad_instance . table . survey . dframe () figure = plt . figure ( figsize = figsize ) if show_elements : logger . debug ( \"Plotting survey with elements differentiation\" ) element_dfs = _make_survey_groups ( survey ) plt . scatter ( element_dfs [ \"dipoles\" ] . z , element_dfs [ \"dipoles\" ] . x , marker = \".\" , c = element_dfs [ \"dipoles\" ] . s , cmap = \"copper\" , label = \"Dipoles\" , ) plt . scatter ( element_dfs [ \"quad_foc\" ] . z , element_dfs [ \"quad_foc\" ] . x , marker = \"o\" , color = \"blue\" , label = \"QF\" , ) plt . scatter ( element_dfs [ \"quad_defoc\" ] . z , element_dfs [ \"quad_defoc\" ] . x , marker = \"o\" , color = \"red\" , label = \"QD\" , ) if high_orders : logger . debug ( \"Plotting high order magnetic elements (up to octupoles)\" ) plt . scatter ( element_dfs [ \"sextupoles\" ] . z , element_dfs [ \"sextupoles\" ] . x , marker = \".\" , color = \"m\" , label = \"MS\" , ) plt . scatter ( element_dfs [ \"octupoles\" ] . z , element_dfs [ \"octupoles\" ] . x , marker = \".\" , color = \"cyan\" , label = \"MO\" , ) plt . legend ( loc = 2 ) else : logger . debug ( \"Plotting survey without elements differentiation\" ) plt . scatter ( survey . z , survey . x , c = survey . s ) plt . axis ( \"equal\" ) plt . colorbar (). set_label ( \"s [m]\" ) plt . xlabel ( \"z [m]\" ) plt . ylabel ( \"x [m]\" ) plt . title ( title ) if savefig : logger . info ( f \"Saving machine survey plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 500 ) return figure","title":"LaTwiss"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/#plot_latwiss","text":"def plot_latwiss ( cpymad_instance : cpymad . madx . Madx , title : str , figsize : Tuple [ int , int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ) ) -> matplotlib . figure . Figure Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_latwiss ( cpymad_instance : Madx , title : str , figsize : Tuple [ int, int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float, float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float, float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float, float ] = None , k0l_lim : Tuple [ float, float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float, float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments logger . debug ( \"Getting Twiss dataframe from cpymad\" ) twiss_df = cpymad_instance . table . twiss . dframe () figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches ( takes a third of figure ) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( \"$\\\\theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # All elements can be defined as a 'multipole' , but dipoles can also be defined as # 'rbend' or 'sbend' , quadrupoles as 'quadrupoles' and sextupoles as 'sextupoles' logger . debug ( \"Extracting element-specific dataframes\" ) quadrupoles_df = twiss_df [ (twiss_df.keyword.isin([\"multipole\", \"quadrupole\" ] )) & ( twiss_df . name . str . contains ( \"Q\" , case = False )) ] dipoles_df = twiss_df [ (twiss_df.keyword.isin([\"multipole\", \"rbend\", \"sbend\" ] )) & ( twiss_df . name . str . contains ( \"B\" , case = False )) ] sextupoles_df = twiss_df [ (twiss_df.keyword.isin([\"multipole\", \"sextupole\" ] )) & ( twiss_df . name . str . contains ( \"S\" , case = False )) ] # Plotting dipole patches , beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows () : if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) if dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid ( ( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = \"$\\\\beta_x$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = \"$\\\\beta_y$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( \"$\\\\beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = \"$D_x$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = \"$D_y$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersions [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 500 ) return figure","title":"plot_latwiss"},{"location":"reference/pyhdtoolkit/cpymadtools/latwiss/#plot_machine_survey","text":"def plot_machine_survey ( cpymad_instance : cpymad . madx . Madx , title : str = 'Machine Layout' , figsize : Tuple [ int , int ] = ( 16 , 11 ), savefig : str = None , show_elements : bool = False , high_orders : bool = False ) -> matplotlib . figure . Figure Provided with an active Cpymad class after having ran a script, will create a plot representing the machine geometry in 2D. Original code is from Guido Sterbini. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. show_elements (bool): if True, will try to plot by differentiating elements. Experimental, defaults to False. high_orders (bool): if True, plot sextupoles and octupoles when show_elements is True, otherwise only up to quadrupoles. Defaults to False. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_machine_survey ( cpymad_instance : Madx , title : str = \"Machine Layout\" , figsize : Tuple [ int, int ] = ( 16 , 11 ), savefig : str = None , show_elements : bool = False , high_orders : bool = False , ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing the machine geometry in 2D. Original code is from Guido Sterbini. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. show_elements (bool): if True, will try to plot by differentiating elements. Experimental, defaults to False. high_orders (bool): if True, plot sextupoles and octupoles when show_elements is True, otherwise only up to quadrupoles. Defaults to False. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" logger . debug ( \"Getting machine survey from cpymad\" ) cpymad_instance . input ( \"survey;\" ) survey = cpymad_instance . table . survey . dframe () figure = plt . figure ( figsize = figsize ) if show_elements : logger . debug ( \"Plotting survey with elements differentiation\" ) element_dfs = _make_survey_groups ( survey ) plt . scatter ( element_dfs [ \"dipoles\" ] . z , element_dfs [ \"dipoles\" ] . x , marker = \".\" , c = element_dfs [ \"dipoles\" ] . s , cmap = \"copper\" , label = \"Dipoles\" , ) plt . scatter ( element_dfs [ \"quad_foc\" ] . z , element_dfs [ \"quad_foc\" ] . x , marker = \"o\" , color = \"blue\" , label = \"QF\" , ) plt . scatter ( element_dfs [ \"quad_defoc\" ] . z , element_dfs [ \"quad_defoc\" ] . x , marker = \"o\" , color = \"red\" , label = \"QD\" , ) if high_orders : logger . debug ( \"Plotting high order magnetic elements (up to octupoles)\" ) plt . scatter ( element_dfs [ \"sextupoles\" ] . z , element_dfs [ \"sextupoles\" ] . x , marker = \".\" , color = \"m\" , label = \"MS\" , ) plt . scatter ( element_dfs [ \"octupoles\" ] . z , element_dfs [ \"octupoles\" ] . x , marker = \".\" , color = \"cyan\" , label = \"MO\" , ) plt . legend ( loc = 2 ) else : logger . debug ( \"Plotting survey without elements differentiation\" ) plt . scatter ( survey . z , survey . x , c = survey . s ) plt . axis ( \"equal\" ) plt . colorbar (). set_label ( \"s [m]\" ) plt . xlabel ( \"z [m]\" ) plt . ylabel ( \"x [m]\" ) plt . title ( title ) if savefig : logger . info ( f \"Saving machine survey plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 500 ) return figure","title":"plot_machine_survey"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/","text":"Module pyhdtoolkit.cpymadtools.plotters Module cpymadtools.plotters Created on 2019.12.08 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A collection of functions to plot different output results from a cpymad.madx.Madx object's simulation results. View Source \"\"\" Module cpymadtools.plotters --------------------------- Created on 2019.12.08 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions to plot different output results from a cpymad.madx.Madx object's simulation results. \"\"\" from pathlib import Path from typing import Dict , Tuple import matplotlib import matplotlib.pyplot as plt import numpy as np import pandas as pd from loguru import logger from matplotlib import colors as mcolors from pyhdtoolkit.optics.twiss import courant_snyder_transform from pyhdtoolkit.plotting.settings import PLOT_PARAMS try : from cpymad.madx import Madx except ModuleNotFoundError : Madx = None plt . rcParams . update ( PLOT_PARAMS ) COLORS_DICT = dict ( mcolors . BASE_COLORS , ** mcolors . CSS4_COLORS ) BY_HSV = sorted ( ( tuple ( mcolors . rgb_to_hsv ( mcolors . to_rgba ( color )[: 3 ])), name ) for name , color in COLORS_DICT . items () ) SORTED_COLORS = [ name for hsv , name in BY_HSV ] class AperturePlotter : \"\"\" A class to plot the physical aperture of your machine. \"\"\" @staticmethod def plot_aperture ( cpymad_instance : Madx , beam_params : Dict [ str , float ], figsize : Tuple [ int , int ] = ( 13 , 20 ), xlimits : Tuple [ float , float ] = None , hplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. beam_params (Dict[str, float]): a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. figsize (str): size of the figure, defaults to (15, 15). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. hplane_ylim (Tuple[float, float]): the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). vplane_ylim (Tuple[float, float]): the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint: disable=too-many-arguments # We need to interpolate in order to get high resolution along the s direction logger . debug ( \"Running interpolation in cpymad\" ) cpymad_instance . input ( \"\"\" select, flag=interpolate, class=drift, slice=4, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=8, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; select, flag=interpolate, class=rbend, slice=10, range=#s/#e; twiss; \"\"\" ) logger . debug ( \"Getting Twiss dframe from cpymad\" ) twiss_hr : pd . DataFrame = cpymad_instance . table . twiss . dframe () twiss_hr [ \"betatronic_envelope_x\" ] = np . sqrt ( twiss_hr . betx . values * beam_params [ \"eg_y_m\" ]) twiss_hr [ \"betatronic_envelope_y\" ] = np . sqrt ( twiss_hr . bety . values * beam_params [ \"eg_y_m\" ]) twiss_hr [ \"dispersive_envelope_x\" ] = twiss_hr . dx . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"dispersive_envelope_y\" ] = twiss_hr . dy . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"envelope_x\" ] = np . sqrt ( twiss_hr . betatronic_envelope_x . values ** 2 + ( twiss_hr . dx . values * beam_params [ \"deltap_p\" ]) ** 2 ) twiss_hr [ \"envelope_y\" ] = np . sqrt ( twiss_hr . betatronic_envelope_y . values ** 2 + ( twiss_hr . dy . values * beam_params [ \"deltap_p\" ]) ** 2 ) machine = twiss_hr [ twiss_hr . apertype == \"ellipse\" ] figure = plt . figure ( figsize = figsize ) logger . debug ( \"Plotting the horizontal aperture\" ) axis1 = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) axis1 . plot ( twiss_hr . s , twiss_hr . envelope_x , color = \"b\" ) axis1 . plot ( twiss_hr . s , - twiss_hr . envelope_x , color = \"b\" ) axis1 . fill_between ( twiss_hr . s , twiss_hr . envelope_x , - twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_x , - 3 * twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( machine . s , machine . aper_1 , machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . fill_between ( machine . s , - machine . aper_1 , - machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . plot ( machine . s , machine . aper_1 , \"k.-\" ) axis1 . plot ( machine . s , - machine . aper_1 , \"k.-\" ) axis1 . set_xlim ( xlimits ) axis1 . set_ylim ( hplane_ylim ) axis1 . set_ylabel ( \"x [m]\" ) axis1 . set_xlabel ( \"s [m]\" ) axis1 . set_title ( f \"Horizontal aperture at { beam_params [ 'pc_GeV' ] } GeV/c\" ) logger . debug ( \"Plotting the vertical aperture\" ) axis2 = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis2 . plot ( twiss_hr . s , twiss_hr . envelope_y , color = \"r\" ) axis2 . plot ( twiss_hr . s , - twiss_hr . envelope_y , color = \"r\" ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( machine . s , machine . aper_2 , machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . fill_between ( machine . s , - machine . aper_2 , - machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . plot ( machine . s , machine . aper_2 , \"k.-\" ) axis2 . plot ( machine . s , - machine . aper_2 , \"k.-\" ) axis2 . set_ylim ( vplane_ylim ) axis2 . set_ylabel ( \"y [m]\" ) axis2 . set_xlabel ( \"s [m]\" ) axis2 . set_title ( f \"Vertical aperture at { beam_params [ 'pc_GeV' ] } GeV/c\" ) logger . debug ( \"Plotting the stay-clear envelope\" ) axis3 = plt . subplot2grid (( 3 , 3 ), ( 2 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis3 . plot ( machine . s , machine . aper_1 / machine . envelope_x , \".-b\" , label = \"Horizontal plane\" ) axis3 . plot ( machine . s , machine . aper_2 / machine . envelope_y , \".-r\" , label = \"Vertical plane\" ) axis3 . set_xlim ( xlimits ) axis3 . set_ylabel ( \"n1\" ) axis3 . set_xlabel ( \"s [m]\" ) axis3 . legend ( loc = \"best\" ) axis3 . set_title ( f \"Stay-clear envelope at { beam_params [ 'pc_GeV' ] } GeV/c\" ) if savefig : logger . info ( f \"Saving aperture plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure class DynamicAperturePlotter : \"\"\" A class to plot the dynamic aperture of your machine. \"\"\" @staticmethod def plot_dynamic_aperture ( vx_coords : np . ndarray , vy_coords : np . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure : \"\"\" Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Args: vx_coords (np.ndarray): numpy array of horizontal coordinates over turns. vy_coords (np.ndarray): numpy array of vertical coordinates over turns. n_particles (int): number of particles simulated. savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" figure = plt . figure ( figsize = ( 12 , 7 )) turn_lost = [] x_in_lost = [] for particle in range ( n_particles ): nb = len ( vx_coords [ particle ]) - max ( np . isnan ( vx_coords [ particle ]) . sum (), np . isnan ( vy_coords [ particle ]) . sum () ) turn_lost . append ( nb ) x_in_lost . append ( vx_coords [ particle ][ 0 ] ** 2 + vy_coords [ particle ][ 0 ] ** 2 ) turn_lost = np . array ( turn_lost ) x_in_lost = np . array ( x_in_lost ) plt . scatter ( turn_lost , x_in_lost * 1000 , linewidths = 0.7 , c = \"darkblue\" , marker = \".\" ) plt . title ( \"Amplitudes lost over turns\" , fontsize = 20 ) plt . xlabel ( \"Number of Turns Survived\" , fontsize = 17 ) plt . ylabel ( \"Initial amplitude [mm]\" , fontsize = 17 ) if savefig : logger . info ( f \"Saving dynamic aperture plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure class PhaseSpacePlotter : \"\"\" A class to plot Courant-Snyder coordinates phase space. \"\"\" @staticmethod def plot_courant_snyder_phase_space ( cpymad_instance : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ): logger . error ( f \"Plane should be either Horizontal or Vertical but ' { plane } ' was given\" ) raise ValueError ( \"Invalid plane value\" ) figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) # Getting the P matrix to compute Courant-Snyder coordinates logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = ( cpymad_instance . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . alfy [ 0 ] ) beta = ( cpymad_instance . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . bety [ 0 ] ) logger . debug ( f \"Plotting Courant-Snyder phase space for the { plane . lower () } plane\" ) for index , _ in enumerate ( u_coordinates ): logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle { index } \" ) u = np . array ([ u_coordinates [ index ], pu_coordinates [ index ]]) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0 , :] * 1e3 , u_bar [ 1 , :] * 1e3 , s = 0.1 , c = \"k\" ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$ \\\\ bar {x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$ \\\\ bar {y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving Courant-Snyder phase space plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure @staticmethod def plot_courant_snyder_phase_space_colored ( cpymad_instance : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156th color. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ): logger . error ( f \"Plane should be either Horizontal or Vertical but ' { plane } ' was given\" ) raise ValueError ( \"Invalid plane value\" ) # Getting a sufficiently long array of colors to use colors = int ( np . floor ( len ( u_coordinates ) / 100 )) * SORTED_COLORS while len ( colors ) > len ( u_coordinates ): colors . pop () figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = ( cpymad_instance . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . alfy [ 0 ] ) beta = ( cpymad_instance . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . bety [ 0 ] ) logger . debug ( f \"Plotting colored normalised phase space for the { plane . lower () } plane\" ) for index , _ in enumerate ( u_coordinates ): logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle { index } \" ) u = np . array ([ u_coordinates [ index ], pu_coordinates [ index ]]) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0 , :] * 1e3 , u_bar [ 1 , :] * 1e3 , s = 0.1 , c = colors [ index ]) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$ \\\\ bar {x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$ \\\\ bar {y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving colored Courant-Snyder phase space plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure class TuneDiagramPlotter : \"\"\" A class to plot a blank tune diagram with Farey sequences, as well as your working points. \"\"\" @staticmethod def farey_sequence ( order : int ) -> list : \"\"\" Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Args: order (int): the order up to which we want to calculate the sequence. Returns: The sequence as a list. \"\"\" seq = [[ 0 , 1 ]] a , b , c , d = 0 , 1 , 1 , order while c <= order : k = int (( order + b ) / d ) a , b , c , d = c , d , k * c - a , k * d - b seq . append ([ a , b ]) return seq @staticmethod def plot_blank_tune_diagram () -> matplotlib . figure . Figure : \"\"\" Plotting the tune diagram up to the 6th order. Original code from Rogelio Tom\u00e1s. Returns: The figure on which resonance lines from farey sequences are drawn. \"\"\" logger . debug ( \"Plotting resonance lines from Farey sequence, up to 5th order\" ) figure = plt . figure ( figsize = ( 13 , 13 )) plt . ylim (( 0 , 1 )) plt . xlim (( 0 , 1 )) x = np . linspace ( 0 , 1 , 1000 ) for i in range ( 1 , 6 ): farey_sequences = TuneDiagramPlotter . farey_sequence ( i ) for f in farey_sequences : h , k = f # Node h/k on the axes for sequence in farey_sequences : p , q = sequence a = float ( k * p ) # Resonance linea Qx + b*Qy = clinkedtop / q if a > 0 : b = float ( q - k * p ) c = float ( p * h ) plt . plot ( x , c / a - x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( x , c / a + x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , 1 - x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , 1 - x , \"b\" , alpha = 0.1 ) if q == k and p == 1 : # FN elements below 1/k break plt . title ( \"Tune Diagram\" , fontsize = 20 ) plt . axis ( \"square\" ) plt . xlim ([ 0 , 1 ]) plt . ylim ([ 0 , 1 ]) plt . xlabel ( \"$Q_ {x} }$\" , fontsize = 17 ) plt . ylabel ( \"$Q_ {y} $\" , fontsize = 17 ) return figure @staticmethod def plot_tune_diagram ( cpymad_instance : Madx , v_qx : np . ndarray = np . array ([ 0 ]), vxgood : np . ndarray = np . array ([ False ]), v_qy : np . ndarray = np . array ([ 0 ]), vygood : np . ndarray = np . array ([ False ]), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plots the evolution of particles' tunes on a Tune Diagram. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. v_qx (np.ndarray): horizontal tune value as a numpy array. vxgood (np.ndarray): ?? v_qy (np.ndarray): vertical tune value as a numpy array. vygood (np.ndarray): ?? savefig: will save the figure if this is not None, using the string value passed. Returns: The figure on which the diagram is drawn. \"\"\" figure = TuneDiagramPlotter . plot_blank_tune_diagram () logger . debug ( \"Getting Tunes from cpymad\" ) new_q1 : float = cpymad_instance . table . summ . dframe () . q1 [ 0 ] new_q2 : float = cpymad_instance . table . summ . dframe () . q2 [ 0 ] if vxgood . any () and vygood . any (): plt . plot ( v_qx [ vxgood * vygood ], v_qy [ vxgood * vygood ], \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif vxgood . any () and ~ vygood . any (): tp = np . ones ( len ( vxgood )) * ( new_q2 - np . floor ( new_q2 )) plt . plot ( v_qx [ vxgood ], tp [ vxgood ], \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif ~ vxgood . any () and vygood . any (): tp = np . ones ( len ( vygood )) * ( new_q1 - np . floor ( new_q1 )) plt . plot ( tp [ vygood ], v_qy [ vygood ], \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) if savefig : logger . info ( f \"Saving Tune diagram plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure Variables BY_HSV COLORS_DICT PLOT_PARAMS SORTED_COLORS Classes AperturePlotter class AperturePlotter ( / , * args , ** kwargs ) A class to plot the physical aperture of your machine. View Source class AperturePlotter : \"\"\" A class to plot the physical aperture of your machine. \"\"\" @staticmethod def plot_aperture ( cpymad_instance : Madx , beam_params : Dict [ str, float ] , figsize : Tuple [ int, int ] = ( 13 , 20 ), xlimits : Tuple [ float, float ] = None , hplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. beam_params (Dict[str, float]): a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. figsize (str): size of the figure, defaults to (15, 15). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. hplane_ylim (Tuple[float, float]): the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). vplane_ylim (Tuple[float, float]): the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments # We need to interpolate in order to get high resolution along the s direction logger . debug ( \"Running interpolation in cpymad\" ) cpymad_instance . input ( \"\"\" select, flag=interpolate, class=drift, slice=4, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=8, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; select, flag=interpolate, class=rbend, slice=10, range=#s/#e; twiss; \"\"\" ) logger . debug ( \"Getting Twiss dframe from cpymad\" ) twiss_hr : pd . DataFrame = cpymad_instance . table . twiss . dframe () twiss_hr [ \"betatronic_envelope_x\" ] = np . sqrt ( twiss_hr . betx . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"betatronic_envelope_y\" ] = np . sqrt ( twiss_hr . bety . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"dispersive_envelope_x\" ] = twiss_hr . dx . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"dispersive_envelope_y\" ] = twiss_hr . dy . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"envelope_x\" ] = np . sqrt ( twiss_hr . betatronic_envelope_x . values ** 2 + ( twiss_hr . dx . values * beam_params [ \"deltap_p\" ] ) ** 2 ) twiss_hr [ \"envelope_y\" ] = np . sqrt ( twiss_hr . betatronic_envelope_y . values ** 2 + ( twiss_hr . dy . values * beam_params [ \"deltap_p\" ] ) ** 2 ) machine = twiss_hr [ twiss_hr.apertype == \"ellipse\" ] figure = plt . figure ( figsize = figsize ) logger . debug ( \"Plotting the horizontal aperture\" ) axis1 = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) axis1 . plot ( twiss_hr . s , twiss_hr . envelope_x , color = \"b\" ) axis1 . plot ( twiss_hr . s , - twiss_hr . envelope_x , color = \"b\" ) axis1 . fill_between ( twiss_hr . s , twiss_hr . envelope_x , - twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_x , - 3 * twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( machine . s , machine . aper_1 , machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . fill_between ( machine . s , - machine . aper_1 , - machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . plot ( machine . s , machine . aper_1 , \"k.-\" ) axis1 . plot ( machine . s , - machine . aper_1 , \"k.-\" ) axis1 . set_xlim ( xlimits ) axis1 . set_ylim ( hplane_ylim ) axis1 . set_ylabel ( \"x [m]\" ) axis1 . set_xlabel ( \"s [m]\" ) axis1 . set_title ( f \"Horizontal aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the vertical aperture\" ) axis2 = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis2 . plot ( twiss_hr . s , twiss_hr . envelope_y , color = \"r\" ) axis2 . plot ( twiss_hr . s , - twiss_hr . envelope_y , color = \"r\" ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( machine . s , machine . aper_2 , machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . fill_between ( machine . s , - machine . aper_2 , - machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . plot ( machine . s , machine . aper_2 , \"k.-\" ) axis2 . plot ( machine . s , - machine . aper_2 , \"k.-\" ) axis2 . set_ylim ( vplane_ylim ) axis2 . set_ylabel ( \"y [m]\" ) axis2 . set_xlabel ( \"s [m]\" ) axis2 . set_title ( f \"Vertical aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the stay-clear envelope\" ) axis3 = plt . subplot2grid (( 3 , 3 ), ( 2 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis3 . plot ( machine . s , machine . aper_1 / machine . envelope_x , \".-b\" , label = \"Horizontal plane\" ) axis3 . plot ( machine . s , machine . aper_2 / machine . envelope_y , \".-r\" , label = \"Vertical plane\" ) axis3 . set_xlim ( xlimits ) axis3 . set_ylabel ( \"n1\" ) axis3 . set_xlabel ( \"s [m]\" ) axis3 . legend ( loc = \"best\" ) axis3 . set_title ( f \"Stay-clear envelope at {beam_params['pc_GeV']} GeV/c\" ) if savefig : logger . info ( f \"Saving aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure Static methods plot_aperture def plot_aperture ( cpymad_instance : cpymad . madx . Madx , beam_params : Dict [ str , float ], figsize : Tuple [ int , int ] = ( 13 , 20 ), xlimits : Tuple [ float , float ] = None , hplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), savefig : str = None ) -> matplotlib . figure . Figure Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. beam_params (Dict[str, float]): a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. figsize (str): size of the figure, defaults to (15, 15). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. hplane_ylim (Tuple[float, float]): the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). vplane_ylim (Tuple[float, float]): the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_aperture ( cpymad_instance : Madx , beam_params : Dict [ str, float ] , figsize : Tuple [ int, int ] = ( 13 , 20 ), xlimits : Tuple [ float, float ] = None , hplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. beam_params (Dict[str, float]): a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. figsize (str): size of the figure, defaults to (15, 15). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. hplane_ylim (Tuple[float, float]): the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). vplane_ylim (Tuple[float, float]): the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments # We need to interpolate in order to get high resolution along the s direction logger . debug ( \"Running interpolation in cpymad\" ) cpymad_instance . input ( \"\"\" select, flag=interpolate, class=drift, slice=4, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=8, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; select, flag=interpolate, class=rbend, slice=10, range=#s/#e; twiss; \"\"\" ) logger . debug ( \"Getting Twiss dframe from cpymad\" ) twiss_hr : pd . DataFrame = cpymad_instance . table . twiss . dframe () twiss_hr [ \"betatronic_envelope_x\" ] = np . sqrt ( twiss_hr . betx . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"betatronic_envelope_y\" ] = np . sqrt ( twiss_hr . bety . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"dispersive_envelope_x\" ] = twiss_hr . dx . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"dispersive_envelope_y\" ] = twiss_hr . dy . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"envelope_x\" ] = np . sqrt ( twiss_hr . betatronic_envelope_x . values ** 2 + ( twiss_hr . dx . values * beam_params [ \"deltap_p\" ] ) ** 2 ) twiss_hr [ \"envelope_y\" ] = np . sqrt ( twiss_hr . betatronic_envelope_y . values ** 2 + ( twiss_hr . dy . values * beam_params [ \"deltap_p\" ] ) ** 2 ) machine = twiss_hr [ twiss_hr.apertype == \"ellipse\" ] figure = plt . figure ( figsize = figsize ) logger . debug ( \"Plotting the horizontal aperture\" ) axis1 = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) axis1 . plot ( twiss_hr . s , twiss_hr . envelope_x , color = \"b\" ) axis1 . plot ( twiss_hr . s , - twiss_hr . envelope_x , color = \"b\" ) axis1 . fill_between ( twiss_hr . s , twiss_hr . envelope_x , - twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_x , - 3 * twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( machine . s , machine . aper_1 , machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . fill_between ( machine . s , - machine . aper_1 , - machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . plot ( machine . s , machine . aper_1 , \"k.-\" ) axis1 . plot ( machine . s , - machine . aper_1 , \"k.-\" ) axis1 . set_xlim ( xlimits ) axis1 . set_ylim ( hplane_ylim ) axis1 . set_ylabel ( \"x [m]\" ) axis1 . set_xlabel ( \"s [m]\" ) axis1 . set_title ( f \"Horizontal aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the vertical aperture\" ) axis2 = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis2 . plot ( twiss_hr . s , twiss_hr . envelope_y , color = \"r\" ) axis2 . plot ( twiss_hr . s , - twiss_hr . envelope_y , color = \"r\" ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( machine . s , machine . aper_2 , machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . fill_between ( machine . s , - machine . aper_2 , - machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . plot ( machine . s , machine . aper_2 , \"k.-\" ) axis2 . plot ( machine . s , - machine . aper_2 , \"k.-\" ) axis2 . set_ylim ( vplane_ylim ) axis2 . set_ylabel ( \"y [m]\" ) axis2 . set_xlabel ( \"s [m]\" ) axis2 . set_title ( f \"Vertical aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the stay-clear envelope\" ) axis3 = plt . subplot2grid (( 3 , 3 ), ( 2 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis3 . plot ( machine . s , machine . aper_1 / machine . envelope_x , \".-b\" , label = \"Horizontal plane\" ) axis3 . plot ( machine . s , machine . aper_2 / machine . envelope_y , \".-r\" , label = \"Vertical plane\" ) axis3 . set_xlim ( xlimits ) axis3 . set_ylabel ( \"n1\" ) axis3 . set_xlabel ( \"s [m]\" ) axis3 . legend ( loc = \"best\" ) axis3 . set_title ( f \"Stay-clear envelope at {beam_params['pc_GeV']} GeV/c\" ) if savefig : logger . info ( f \"Saving aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure DynamicAperturePlotter class DynamicAperturePlotter ( / , * args , ** kwargs ) A class to plot the dynamic aperture of your machine. View Source class DynamicAperturePlotter : \"\"\" A class to plot the dynamic aperture of your machine. \"\"\" @staticmethod def plot_dynamic_aperture ( vx_coords : np . ndarray , vy_coords : np . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure : \"\"\" Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Args: vx_coords (np.ndarray): numpy array of horizontal coordinates over turns. vy_coords (np.ndarray): numpy array of vertical coordinates over turns. n_particles (int): number of particles simulated. savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" figure = plt . figure ( figsize = ( 12 , 7 )) turn_lost = [] x_in_lost = [] for particle in range ( n_particles ) : nb = len ( vx_coords [ particle ] ) - max ( np . isnan ( vx_coords [ particle ] ). sum (), np . isnan ( vy_coords [ particle ] ). sum () ) turn_lost . append ( nb ) x_in_lost . append ( vx_coords [ particle ][ 0 ] ** 2 + vy_coords [ particle ][ 0 ] ** 2 ) turn_lost = np . array ( turn_lost ) x_in_lost = np . array ( x_in_lost ) plt . scatter ( turn_lost , x_in_lost * 1000 , linewidths = 0.7 , c = \"darkblue\" , marker = \".\" ) plt . title ( \"Amplitudes lost over turns\" , fontsize = 20 ) plt . xlabel ( \"Number of Turns Survived\" , fontsize = 17 ) plt . ylabel ( \"Initial amplitude [mm]\" , fontsize = 17 ) if savefig : logger . info ( f \"Saving dynamic aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure Static methods plot_dynamic_aperture def plot_dynamic_aperture ( vx_coords : numpy . ndarray , vy_coords : numpy . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Args: vx_coords (np.ndarray): numpy array of horizontal coordinates over turns. vy_coords (np.ndarray): numpy array of vertical coordinates over turns. n_particles (int): number of particles simulated. savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_dynamic_aperture ( vx_coords : np . ndarray , vy_coords : np . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure : \"\"\" Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Args: vx_coords (np.ndarray): numpy array of horizontal coordinates over turns. vy_coords (np.ndarray): numpy array of vertical coordinates over turns. n_particles (int): number of particles simulated. savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" figure = plt . figure ( figsize = ( 12 , 7 )) turn_lost = [] x_in_lost = [] for particle in range ( n_particles ) : nb = len ( vx_coords [ particle ] ) - max ( np . isnan ( vx_coords [ particle ] ). sum (), np . isnan ( vy_coords [ particle ] ). sum () ) turn_lost . append ( nb ) x_in_lost . append ( vx_coords [ particle ][ 0 ] ** 2 + vy_coords [ particle ][ 0 ] ** 2 ) turn_lost = np . array ( turn_lost ) x_in_lost = np . array ( x_in_lost ) plt . scatter ( turn_lost , x_in_lost * 1000 , linewidths = 0.7 , c = \"darkblue\" , marker = \".\" ) plt . title ( \"Amplitudes lost over turns\" , fontsize = 20 ) plt . xlabel ( \"Number of Turns Survived\" , fontsize = 17 ) plt . ylabel ( \"Initial amplitude [mm]\" , fontsize = 17 ) if savefig : logger . info ( f \"Saving dynamic aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure PhaseSpacePlotter class PhaseSpacePlotter ( / , * args , ** kwargs ) A class to plot Courant-Snyder coordinates phase space. View Source class PhaseSpacePlotter : \"\"\" A class to plot Courant-Snyder coordinates phase space. \"\"\" @staticmethod def plot_courant_snyder_phase_space ( cpymad_instance : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) # Getting the P matrix to compute Courant - Snyder coordinates logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = ( cpymad_instance . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . alfy [ 0 ] ) beta = ( cpymad_instance . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . bety [ 0 ] ) logger . debug ( f \"Plotting Courant-Snyder phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = \"k\" ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure @staticmethod def plot_courant_snyder_phase_space_colored ( cpymad_instance : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156th color. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) # Getting a sufficiently long array of colors to use colors = int ( np . floor ( len ( u_coordinates ) / 100 )) * SORTED_COLORS while len ( colors ) > len ( u_coordinates ) : colors . pop () figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = ( cpymad_instance . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . alfy [ 0 ] ) beta = ( cpymad_instance . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . bety [ 0 ] ) logger . debug ( f \"Plotting colored normalised phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = colors [ index ] ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving colored Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure Static methods plot_courant_snyder_phase_space def plot_courant_snyder_phase_space ( cpymad_instance : cpymad . madx . Madx , u_coordinates : numpy . ndarray , pu_coordinates : numpy . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = 'Horizontal' ) -> matplotlib . figure . Figure Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_courant_snyder_phase_space ( cpymad_instance : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) # Getting the P matrix to compute Courant - Snyder coordinates logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = ( cpymad_instance . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . alfy [ 0 ] ) beta = ( cpymad_instance . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . bety [ 0 ] ) logger . debug ( f \"Plotting Courant-Snyder phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = \"k\" ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure plot_courant_snyder_phase_space_colored def plot_courant_snyder_phase_space_colored ( cpymad_instance : cpymad . madx . Madx , u_coordinates : numpy . ndarray , pu_coordinates : numpy . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = 'Horizontal' ) -> matplotlib . figure . Figure Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156 th color. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_courant_snyder_phase_space_colored ( cpymad_instance : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156th color. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) # Getting a sufficiently long array of colors to use colors = int ( np . floor ( len ( u_coordinates ) / 100 )) * SORTED_COLORS while len ( colors ) > len ( u_coordinates ) : colors . pop () figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = ( cpymad_instance . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . alfy [ 0 ] ) beta = ( cpymad_instance . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . bety [ 0 ] ) logger . debug ( f \"Plotting colored normalised phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = colors [ index ] ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving colored Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure TuneDiagramPlotter class TuneDiagramPlotter ( / , * args , ** kwargs ) A class to plot a blank tune diagram with Farey sequences, as well as your working points. View Source class TuneDiagramPlotter : \"\"\" A class to plot a blank tune diagram with Farey sequences, as well as your working points. \"\"\" @staticmethod def farey_sequence ( order : int ) -> list : \"\"\" Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Args: order (int): the order up to which we want to calculate the sequence. Returns: The sequence as a list. \"\"\" seq = [ [0, 1 ] ] a , b , c , d = 0 , 1 , 1 , order while c <= order : k = int (( order + b ) / d ) a , b , c , d = c , d , k * c - a , k * d - b seq . append ( [ a, b ] ) return seq @staticmethod def plot_blank_tune_diagram () -> matplotlib . figure . Figure : \"\"\" Plotting the tune diagram up to the 6th order. Original code from Rogelio Tom\u00e1s. Returns: The figure on which resonance lines from farey sequences are drawn. \"\"\" logger . debug ( \"Plotting resonance lines from Farey sequence, up to 5th order\" ) figure = plt . figure ( figsize = ( 13 , 13 )) plt . ylim (( 0 , 1 )) plt . xlim (( 0 , 1 )) x = np . linspace ( 0 , 1 , 1000 ) for i in range ( 1 , 6 ) : farey_sequences = TuneDiagramPlotter . farey_sequence ( i ) for f in farey_sequences : h , k = f # Node h / k on the axes for sequence in farey_sequences : p , q = sequence a = float ( k * p ) # Resonance linea Qx + b * Qy = clinkedtop / q if a > 0 : b = float ( q - k * p ) c = float ( p * h ) plt . plot ( x , c / a - x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( x , c / a + x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , 1 - x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , 1 - x , \"b\" , alpha = 0.1 ) if q == k and p == 1 : # FN elements below 1 / k break plt . title ( \"Tune Diagram\" , fontsize = 20 ) plt . axis ( \"square\" ) plt . xlim ( [ 0, 1 ] ) plt . ylim ( [ 0, 1 ] ) plt . xlabel ( \"$Q_{x}}$\" , fontsize = 17 ) plt . ylabel ( \"$Q_{y}$\" , fontsize = 17 ) return figure @staticmethod def plot_tune_diagram ( cpymad_instance : Madx , v_qx : np . ndarray = np . array ( [ 0 ] ), vxgood : np . ndarray = np . array ( [ False ] ), v_qy : np . ndarray = np . array ( [ 0 ] ), vygood : np . ndarray = np . array ( [ False ] ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plots the evolution of particles' tunes on a Tune Diagram. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. v_qx (np.ndarray): horizontal tune value as a numpy array. vxgood (np.ndarray): ?? v_qy (np.ndarray): vertical tune value as a numpy array. vygood (np.ndarray): ?? savefig: will save the figure if this is not None, using the string value passed. Returns: The figure on which the diagram is drawn. \"\"\" figure = TuneDiagramPlotter . plot_blank_tune_diagram () logger . debug ( \"Getting Tunes from cpymad\" ) new_q1 : float = cpymad_instance . table . summ . dframe (). q1 [ 0 ] new_q2 : float = cpymad_instance . table . summ . dframe (). q2 [ 0 ] if vxgood . any () and vygood . any () : plt . plot ( v_qx [ vxgood * vygood ] , v_qy [ vxgood * vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif vxgood . any () and ~ vygood . any () : tp = np . ones ( len ( vxgood )) * ( new_q2 - np . floor ( new_q2 )) plt . plot ( v_qx [ vxgood ] , tp [ vxgood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif ~ vxgood . any () and vygood . any () : tp = np . ones ( len ( vygood )) * ( new_q1 - np . floor ( new_q1 )) plt . plot ( tp [ vygood ] , v_qy [ vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) if savefig : logger . info ( f \"Saving Tune diagram plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure Static methods farey_sequence def farey_sequence ( order : int ) -> list Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Args: order (int): the order up to which we want to calculate the sequence. Returns: The sequence as a list. View Source @staticmethod def farey_sequence ( order : int ) -> list : \"\"\" Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Args: order (int): the order up to which we want to calculate the sequence. Returns: The sequence as a list. \"\"\" seq = [ [0, 1 ] ] a , b , c , d = 0 , 1 , 1 , order while c <= order : k = int (( order + b ) / d ) a , b , c , d = c , d , k * c - a , k * d - b seq . append ( [ a, b ] ) return seq plot_blank_tune_diagram def plot_blank_tune_diagram ( ) -> matplotlib . figure . Figure Plotting the tune diagram up to the 6 th order. Original code from Rogelio Tom\u00e1s. Returns: The figure on which resonance lines from farey sequences are drawn. View Source @staticmethod def plot_blank_tune_diagram () -> matplotlib . figure . Figure : \"\"\" Plotting the tune diagram up to the 6th order. Original code from Rogelio Tom\u00e1s. Returns: The figure on which resonance lines from farey sequences are drawn. \"\"\" logger . debug ( \"Plotting resonance lines from Farey sequence, up to 5th order\" ) figure = plt . figure ( figsize = ( 13 , 13 )) plt . ylim (( 0 , 1 )) plt . xlim (( 0 , 1 )) x = np . linspace ( 0 , 1 , 1000 ) for i in range ( 1 , 6 ) : farey_sequences = TuneDiagramPlotter . farey_sequence ( i ) for f in farey_sequences : h , k = f # Node h / k on the axes for sequence in farey_sequences : p , q = sequence a = float ( k * p ) # Resonance linea Qx + b * Qy = clinkedtop / q if a > 0 : b = float ( q - k * p ) c = float ( p * h ) plt . plot ( x , c / a - x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( x , c / a + x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , 1 - x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , 1 - x , \"b\" , alpha = 0.1 ) if q == k and p == 1 : # FN elements below 1 / k break plt . title ( \"Tune Diagram\" , fontsize = 20 ) plt . axis ( \"square\" ) plt . xlim ( [ 0, 1 ] ) plt . ylim ( [ 0, 1 ] ) plt . xlabel ( \"$Q_{x}}$\" , fontsize = 17 ) plt . ylabel ( \"$Q_{y}$\" , fontsize = 17 ) return figure plot_tune_diagram def plot_tune_diagram ( cpymad_instance : cpymad . madx . Madx , v_qx : numpy . ndarray = array ([ 0 ]), vxgood : numpy . ndarray = array ([ False ]), v_qy : numpy . ndarray = array ([ 0 ]), vygood : numpy . ndarray = array ([ False ]), savefig : str = None ) -> matplotlib . figure . Figure Plots the evolution of particles' tunes on a Tune Diagram. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. v_qx (np.ndarray): horizontal tune value as a numpy array. vxgood (np.ndarray): ?? v_qy (np.ndarray): vertical tune value as a numpy array. vygood (np.ndarray): ?? savefig: will save the figure if this is not None, using the string value passed. Returns: The figure on which the diagram is drawn. View Source @staticmethod def plot_tune_diagram ( cpymad_instance : Madx , v_qx : np . ndarray = np . array ( [ 0 ] ), vxgood : np . ndarray = np . array ( [ False ] ), v_qy : np . ndarray = np . array ( [ 0 ] ), vygood : np . ndarray = np . array ( [ False ] ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plots the evolution of particles' tunes on a Tune Diagram. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. v_qx (np.ndarray): horizontal tune value as a numpy array. vxgood (np.ndarray): ?? v_qy (np.ndarray): vertical tune value as a numpy array. vygood (np.ndarray): ?? savefig: will save the figure if this is not None, using the string value passed. Returns: The figure on which the diagram is drawn. \"\"\" figure = TuneDiagramPlotter . plot_blank_tune_diagram () logger . debug ( \"Getting Tunes from cpymad\" ) new_q1 : float = cpymad_instance . table . summ . dframe (). q1 [ 0 ] new_q2 : float = cpymad_instance . table . summ . dframe (). q2 [ 0 ] if vxgood . any () and vygood . any () : plt . plot ( v_qx [ vxgood * vygood ] , v_qy [ vxgood * vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif vxgood . any () and ~ vygood . any () : tp = np . ones ( len ( vxgood )) * ( new_q2 - np . floor ( new_q2 )) plt . plot ( v_qx [ vxgood ] , tp [ vxgood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif ~ vxgood . any () and vygood . any () : tp = np . ones ( len ( vygood )) * ( new_q1 - np . floor ( new_q1 )) plt . plot ( tp [ vygood ] , v_qy [ vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) if savefig : logger . info ( f \"Saving Tune diagram plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure","title":"Plotters"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#module-pyhdtoolkitcpymadtoolsplotters","text":"","title":"Module pyhdtoolkit.cpymadtools.plotters"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#module-cpymadtoolsplotters","text":"Created on 2019.12.08 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A collection of functions to plot different output results from a cpymad.madx.Madx object's simulation results. View Source \"\"\" Module cpymadtools.plotters --------------------------- Created on 2019.12.08 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions to plot different output results from a cpymad.madx.Madx object's simulation results. \"\"\" from pathlib import Path from typing import Dict , Tuple import matplotlib import matplotlib.pyplot as plt import numpy as np import pandas as pd from loguru import logger from matplotlib import colors as mcolors from pyhdtoolkit.optics.twiss import courant_snyder_transform from pyhdtoolkit.plotting.settings import PLOT_PARAMS try : from cpymad.madx import Madx except ModuleNotFoundError : Madx = None plt . rcParams . update ( PLOT_PARAMS ) COLORS_DICT = dict ( mcolors . BASE_COLORS , ** mcolors . CSS4_COLORS ) BY_HSV = sorted ( ( tuple ( mcolors . rgb_to_hsv ( mcolors . to_rgba ( color )[: 3 ])), name ) for name , color in COLORS_DICT . items () ) SORTED_COLORS = [ name for hsv , name in BY_HSV ] class AperturePlotter : \"\"\" A class to plot the physical aperture of your machine. \"\"\" @staticmethod def plot_aperture ( cpymad_instance : Madx , beam_params : Dict [ str , float ], figsize : Tuple [ int , int ] = ( 13 , 20 ), xlimits : Tuple [ float , float ] = None , hplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. beam_params (Dict[str, float]): a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. figsize (str): size of the figure, defaults to (15, 15). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. hplane_ylim (Tuple[float, float]): the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). vplane_ylim (Tuple[float, float]): the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint: disable=too-many-arguments # We need to interpolate in order to get high resolution along the s direction logger . debug ( \"Running interpolation in cpymad\" ) cpymad_instance . input ( \"\"\" select, flag=interpolate, class=drift, slice=4, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=8, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; select, flag=interpolate, class=rbend, slice=10, range=#s/#e; twiss; \"\"\" ) logger . debug ( \"Getting Twiss dframe from cpymad\" ) twiss_hr : pd . DataFrame = cpymad_instance . table . twiss . dframe () twiss_hr [ \"betatronic_envelope_x\" ] = np . sqrt ( twiss_hr . betx . values * beam_params [ \"eg_y_m\" ]) twiss_hr [ \"betatronic_envelope_y\" ] = np . sqrt ( twiss_hr . bety . values * beam_params [ \"eg_y_m\" ]) twiss_hr [ \"dispersive_envelope_x\" ] = twiss_hr . dx . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"dispersive_envelope_y\" ] = twiss_hr . dy . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"envelope_x\" ] = np . sqrt ( twiss_hr . betatronic_envelope_x . values ** 2 + ( twiss_hr . dx . values * beam_params [ \"deltap_p\" ]) ** 2 ) twiss_hr [ \"envelope_y\" ] = np . sqrt ( twiss_hr . betatronic_envelope_y . values ** 2 + ( twiss_hr . dy . values * beam_params [ \"deltap_p\" ]) ** 2 ) machine = twiss_hr [ twiss_hr . apertype == \"ellipse\" ] figure = plt . figure ( figsize = figsize ) logger . debug ( \"Plotting the horizontal aperture\" ) axis1 = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) axis1 . plot ( twiss_hr . s , twiss_hr . envelope_x , color = \"b\" ) axis1 . plot ( twiss_hr . s , - twiss_hr . envelope_x , color = \"b\" ) axis1 . fill_between ( twiss_hr . s , twiss_hr . envelope_x , - twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_x , - 3 * twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( machine . s , machine . aper_1 , machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . fill_between ( machine . s , - machine . aper_1 , - machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . plot ( machine . s , machine . aper_1 , \"k.-\" ) axis1 . plot ( machine . s , - machine . aper_1 , \"k.-\" ) axis1 . set_xlim ( xlimits ) axis1 . set_ylim ( hplane_ylim ) axis1 . set_ylabel ( \"x [m]\" ) axis1 . set_xlabel ( \"s [m]\" ) axis1 . set_title ( f \"Horizontal aperture at { beam_params [ 'pc_GeV' ] } GeV/c\" ) logger . debug ( \"Plotting the vertical aperture\" ) axis2 = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis2 . plot ( twiss_hr . s , twiss_hr . envelope_y , color = \"r\" ) axis2 . plot ( twiss_hr . s , - twiss_hr . envelope_y , color = \"r\" ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( machine . s , machine . aper_2 , machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . fill_between ( machine . s , - machine . aper_2 , - machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . plot ( machine . s , machine . aper_2 , \"k.-\" ) axis2 . plot ( machine . s , - machine . aper_2 , \"k.-\" ) axis2 . set_ylim ( vplane_ylim ) axis2 . set_ylabel ( \"y [m]\" ) axis2 . set_xlabel ( \"s [m]\" ) axis2 . set_title ( f \"Vertical aperture at { beam_params [ 'pc_GeV' ] } GeV/c\" ) logger . debug ( \"Plotting the stay-clear envelope\" ) axis3 = plt . subplot2grid (( 3 , 3 ), ( 2 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis3 . plot ( machine . s , machine . aper_1 / machine . envelope_x , \".-b\" , label = \"Horizontal plane\" ) axis3 . plot ( machine . s , machine . aper_2 / machine . envelope_y , \".-r\" , label = \"Vertical plane\" ) axis3 . set_xlim ( xlimits ) axis3 . set_ylabel ( \"n1\" ) axis3 . set_xlabel ( \"s [m]\" ) axis3 . legend ( loc = \"best\" ) axis3 . set_title ( f \"Stay-clear envelope at { beam_params [ 'pc_GeV' ] } GeV/c\" ) if savefig : logger . info ( f \"Saving aperture plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure class DynamicAperturePlotter : \"\"\" A class to plot the dynamic aperture of your machine. \"\"\" @staticmethod def plot_dynamic_aperture ( vx_coords : np . ndarray , vy_coords : np . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure : \"\"\" Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Args: vx_coords (np.ndarray): numpy array of horizontal coordinates over turns. vy_coords (np.ndarray): numpy array of vertical coordinates over turns. n_particles (int): number of particles simulated. savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" figure = plt . figure ( figsize = ( 12 , 7 )) turn_lost = [] x_in_lost = [] for particle in range ( n_particles ): nb = len ( vx_coords [ particle ]) - max ( np . isnan ( vx_coords [ particle ]) . sum (), np . isnan ( vy_coords [ particle ]) . sum () ) turn_lost . append ( nb ) x_in_lost . append ( vx_coords [ particle ][ 0 ] ** 2 + vy_coords [ particle ][ 0 ] ** 2 ) turn_lost = np . array ( turn_lost ) x_in_lost = np . array ( x_in_lost ) plt . scatter ( turn_lost , x_in_lost * 1000 , linewidths = 0.7 , c = \"darkblue\" , marker = \".\" ) plt . title ( \"Amplitudes lost over turns\" , fontsize = 20 ) plt . xlabel ( \"Number of Turns Survived\" , fontsize = 17 ) plt . ylabel ( \"Initial amplitude [mm]\" , fontsize = 17 ) if savefig : logger . info ( f \"Saving dynamic aperture plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure class PhaseSpacePlotter : \"\"\" A class to plot Courant-Snyder coordinates phase space. \"\"\" @staticmethod def plot_courant_snyder_phase_space ( cpymad_instance : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ): logger . error ( f \"Plane should be either Horizontal or Vertical but ' { plane } ' was given\" ) raise ValueError ( \"Invalid plane value\" ) figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) # Getting the P matrix to compute Courant-Snyder coordinates logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = ( cpymad_instance . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . alfy [ 0 ] ) beta = ( cpymad_instance . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . bety [ 0 ] ) logger . debug ( f \"Plotting Courant-Snyder phase space for the { plane . lower () } plane\" ) for index , _ in enumerate ( u_coordinates ): logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle { index } \" ) u = np . array ([ u_coordinates [ index ], pu_coordinates [ index ]]) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0 , :] * 1e3 , u_bar [ 1 , :] * 1e3 , s = 0.1 , c = \"k\" ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$ \\\\ bar {x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$ \\\\ bar {y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving Courant-Snyder phase space plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure @staticmethod def plot_courant_snyder_phase_space_colored ( cpymad_instance : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156th color. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ): logger . error ( f \"Plane should be either Horizontal or Vertical but ' { plane } ' was given\" ) raise ValueError ( \"Invalid plane value\" ) # Getting a sufficiently long array of colors to use colors = int ( np . floor ( len ( u_coordinates ) / 100 )) * SORTED_COLORS while len ( colors ) > len ( u_coordinates ): colors . pop () figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = ( cpymad_instance . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . alfy [ 0 ] ) beta = ( cpymad_instance . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . bety [ 0 ] ) logger . debug ( f \"Plotting colored normalised phase space for the { plane . lower () } plane\" ) for index , _ in enumerate ( u_coordinates ): logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle { index } \" ) u = np . array ([ u_coordinates [ index ], pu_coordinates [ index ]]) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0 , :] * 1e3 , u_bar [ 1 , :] * 1e3 , s = 0.1 , c = colors [ index ]) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$ \\\\ bar {x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$ \\\\ bar {y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$ \\\\ bar {py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving colored Courant-Snyder phase space plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure class TuneDiagramPlotter : \"\"\" A class to plot a blank tune diagram with Farey sequences, as well as your working points. \"\"\" @staticmethod def farey_sequence ( order : int ) -> list : \"\"\" Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Args: order (int): the order up to which we want to calculate the sequence. Returns: The sequence as a list. \"\"\" seq = [[ 0 , 1 ]] a , b , c , d = 0 , 1 , 1 , order while c <= order : k = int (( order + b ) / d ) a , b , c , d = c , d , k * c - a , k * d - b seq . append ([ a , b ]) return seq @staticmethod def plot_blank_tune_diagram () -> matplotlib . figure . Figure : \"\"\" Plotting the tune diagram up to the 6th order. Original code from Rogelio Tom\u00e1s. Returns: The figure on which resonance lines from farey sequences are drawn. \"\"\" logger . debug ( \"Plotting resonance lines from Farey sequence, up to 5th order\" ) figure = plt . figure ( figsize = ( 13 , 13 )) plt . ylim (( 0 , 1 )) plt . xlim (( 0 , 1 )) x = np . linspace ( 0 , 1 , 1000 ) for i in range ( 1 , 6 ): farey_sequences = TuneDiagramPlotter . farey_sequence ( i ) for f in farey_sequences : h , k = f # Node h/k on the axes for sequence in farey_sequences : p , q = sequence a = float ( k * p ) # Resonance linea Qx + b*Qy = clinkedtop / q if a > 0 : b = float ( q - k * p ) c = float ( p * h ) plt . plot ( x , c / a - x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( x , c / a + x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , 1 - x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , 1 - x , \"b\" , alpha = 0.1 ) if q == k and p == 1 : # FN elements below 1/k break plt . title ( \"Tune Diagram\" , fontsize = 20 ) plt . axis ( \"square\" ) plt . xlim ([ 0 , 1 ]) plt . ylim ([ 0 , 1 ]) plt . xlabel ( \"$Q_ {x} }$\" , fontsize = 17 ) plt . ylabel ( \"$Q_ {y} $\" , fontsize = 17 ) return figure @staticmethod def plot_tune_diagram ( cpymad_instance : Madx , v_qx : np . ndarray = np . array ([ 0 ]), vxgood : np . ndarray = np . array ([ False ]), v_qy : np . ndarray = np . array ([ 0 ]), vygood : np . ndarray = np . array ([ False ]), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plots the evolution of particles' tunes on a Tune Diagram. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. v_qx (np.ndarray): horizontal tune value as a numpy array. vxgood (np.ndarray): ?? v_qy (np.ndarray): vertical tune value as a numpy array. vygood (np.ndarray): ?? savefig: will save the figure if this is not None, using the string value passed. Returns: The figure on which the diagram is drawn. \"\"\" figure = TuneDiagramPlotter . plot_blank_tune_diagram () logger . debug ( \"Getting Tunes from cpymad\" ) new_q1 : float = cpymad_instance . table . summ . dframe () . q1 [ 0 ] new_q2 : float = cpymad_instance . table . summ . dframe () . q2 [ 0 ] if vxgood . any () and vygood . any (): plt . plot ( v_qx [ vxgood * vygood ], v_qy [ vxgood * vygood ], \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif vxgood . any () and ~ vygood . any (): tp = np . ones ( len ( vxgood )) * ( new_q2 - np . floor ( new_q2 )) plt . plot ( v_qx [ vxgood ], tp [ vxgood ], \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif ~ vxgood . any () and vygood . any (): tp = np . ones ( len ( vygood )) * ( new_q1 - np . floor ( new_q1 )) plt . plot ( tp [ vygood ], v_qy [ vygood ], \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) if savefig : logger . info ( f \"Saving Tune diagram plot at ' { Path ( savefig ) . absolute () } '\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure","title":"Module cpymadtools.plotters"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#variables","text":"BY_HSV COLORS_DICT PLOT_PARAMS SORTED_COLORS","title":"Variables"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#apertureplotter","text":"class AperturePlotter ( / , * args , ** kwargs ) A class to plot the physical aperture of your machine. View Source class AperturePlotter : \"\"\" A class to plot the physical aperture of your machine. \"\"\" @staticmethod def plot_aperture ( cpymad_instance : Madx , beam_params : Dict [ str, float ] , figsize : Tuple [ int, int ] = ( 13 , 20 ), xlimits : Tuple [ float, float ] = None , hplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. beam_params (Dict[str, float]): a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. figsize (str): size of the figure, defaults to (15, 15). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. hplane_ylim (Tuple[float, float]): the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). vplane_ylim (Tuple[float, float]): the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments # We need to interpolate in order to get high resolution along the s direction logger . debug ( \"Running interpolation in cpymad\" ) cpymad_instance . input ( \"\"\" select, flag=interpolate, class=drift, slice=4, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=8, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; select, flag=interpolate, class=rbend, slice=10, range=#s/#e; twiss; \"\"\" ) logger . debug ( \"Getting Twiss dframe from cpymad\" ) twiss_hr : pd . DataFrame = cpymad_instance . table . twiss . dframe () twiss_hr [ \"betatronic_envelope_x\" ] = np . sqrt ( twiss_hr . betx . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"betatronic_envelope_y\" ] = np . sqrt ( twiss_hr . bety . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"dispersive_envelope_x\" ] = twiss_hr . dx . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"dispersive_envelope_y\" ] = twiss_hr . dy . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"envelope_x\" ] = np . sqrt ( twiss_hr . betatronic_envelope_x . values ** 2 + ( twiss_hr . dx . values * beam_params [ \"deltap_p\" ] ) ** 2 ) twiss_hr [ \"envelope_y\" ] = np . sqrt ( twiss_hr . betatronic_envelope_y . values ** 2 + ( twiss_hr . dy . values * beam_params [ \"deltap_p\" ] ) ** 2 ) machine = twiss_hr [ twiss_hr.apertype == \"ellipse\" ] figure = plt . figure ( figsize = figsize ) logger . debug ( \"Plotting the horizontal aperture\" ) axis1 = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) axis1 . plot ( twiss_hr . s , twiss_hr . envelope_x , color = \"b\" ) axis1 . plot ( twiss_hr . s , - twiss_hr . envelope_x , color = \"b\" ) axis1 . fill_between ( twiss_hr . s , twiss_hr . envelope_x , - twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_x , - 3 * twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( machine . s , machine . aper_1 , machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . fill_between ( machine . s , - machine . aper_1 , - machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . plot ( machine . s , machine . aper_1 , \"k.-\" ) axis1 . plot ( machine . s , - machine . aper_1 , \"k.-\" ) axis1 . set_xlim ( xlimits ) axis1 . set_ylim ( hplane_ylim ) axis1 . set_ylabel ( \"x [m]\" ) axis1 . set_xlabel ( \"s [m]\" ) axis1 . set_title ( f \"Horizontal aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the vertical aperture\" ) axis2 = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis2 . plot ( twiss_hr . s , twiss_hr . envelope_y , color = \"r\" ) axis2 . plot ( twiss_hr . s , - twiss_hr . envelope_y , color = \"r\" ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( machine . s , machine . aper_2 , machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . fill_between ( machine . s , - machine . aper_2 , - machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . plot ( machine . s , machine . aper_2 , \"k.-\" ) axis2 . plot ( machine . s , - machine . aper_2 , \"k.-\" ) axis2 . set_ylim ( vplane_ylim ) axis2 . set_ylabel ( \"y [m]\" ) axis2 . set_xlabel ( \"s [m]\" ) axis2 . set_title ( f \"Vertical aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the stay-clear envelope\" ) axis3 = plt . subplot2grid (( 3 , 3 ), ( 2 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis3 . plot ( machine . s , machine . aper_1 / machine . envelope_x , \".-b\" , label = \"Horizontal plane\" ) axis3 . plot ( machine . s , machine . aper_2 / machine . envelope_y , \".-r\" , label = \"Vertical plane\" ) axis3 . set_xlim ( xlimits ) axis3 . set_ylabel ( \"n1\" ) axis3 . set_xlabel ( \"s [m]\" ) axis3 . legend ( loc = \"best\" ) axis3 . set_title ( f \"Stay-clear envelope at {beam_params['pc_GeV']} GeV/c\" ) if savefig : logger . info ( f \"Saving aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure","title":"AperturePlotter"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#plot_aperture","text":"def plot_aperture ( cpymad_instance : cpymad . madx . Madx , beam_params : Dict [ str , float ], figsize : Tuple [ int , int ] = ( 13 , 20 ), xlimits : Tuple [ float , float ] = None , hplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float , float ] = ( - 0.12 , 0.12 ), savefig : str = None ) -> matplotlib . figure . Figure Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. beam_params (Dict[str, float]): a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. figsize (str): size of the figure, defaults to (15, 15). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. hplane_ylim (Tuple[float, float]): the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). vplane_ylim (Tuple[float, float]): the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_aperture ( cpymad_instance : Madx , beam_params : Dict [ str, float ] , figsize : Tuple [ int, int ] = ( 13 , 20 ), xlimits : Tuple [ float, float ] = None , hplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), vplane_ylim : Tuple [ float, float ] = ( - 0.12 , 0.12 ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plot the physical aperture of your machine, already defined into the provided cpymad.Madx object. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. beam_params (Dict[str, float]): a beam_parameters dictionary obtained through cpymadtools.helpers.beam_parameters. figsize (str): size of the figure, defaults to (15, 15). xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. hplane_ylim (Tuple[float, float]): the y limits for the horizontal plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). vplane_ylim (Tuple[float, float]): the y limits for the vertical plane plot (so that machine geometry doesn't make the plot look shrinked). Defaults to (-0.12, 0.12). savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments # We need to interpolate in order to get high resolution along the s direction logger . debug ( \"Running interpolation in cpymad\" ) cpymad_instance . input ( \"\"\" select, flag=interpolate, class=drift, slice=4, range=#s/#e; select, flag=interpolate, class=quadrupole, slice=8, range=#s/#e; select, flag=interpolate, class=sbend, slice=10, range=#s/#e; select, flag=interpolate, class=rbend, slice=10, range=#s/#e; twiss; \"\"\" ) logger . debug ( \"Getting Twiss dframe from cpymad\" ) twiss_hr : pd . DataFrame = cpymad_instance . table . twiss . dframe () twiss_hr [ \"betatronic_envelope_x\" ] = np . sqrt ( twiss_hr . betx . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"betatronic_envelope_y\" ] = np . sqrt ( twiss_hr . bety . values * beam_params [ \"eg_y_m\" ] ) twiss_hr [ \"dispersive_envelope_x\" ] = twiss_hr . dx . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"dispersive_envelope_y\" ] = twiss_hr . dy . values * beam_params [ \"deltap_p\" ] twiss_hr [ \"envelope_x\" ] = np . sqrt ( twiss_hr . betatronic_envelope_x . values ** 2 + ( twiss_hr . dx . values * beam_params [ \"deltap_p\" ] ) ** 2 ) twiss_hr [ \"envelope_y\" ] = np . sqrt ( twiss_hr . betatronic_envelope_y . values ** 2 + ( twiss_hr . dy . values * beam_params [ \"deltap_p\" ] ) ** 2 ) machine = twiss_hr [ twiss_hr.apertype == \"ellipse\" ] figure = plt . figure ( figsize = figsize ) logger . debug ( \"Plotting the horizontal aperture\" ) axis1 = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) axis1 . plot ( twiss_hr . s , twiss_hr . envelope_x , color = \"b\" ) axis1 . plot ( twiss_hr . s , - twiss_hr . envelope_x , color = \"b\" ) axis1 . fill_between ( twiss_hr . s , twiss_hr . envelope_x , - twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_x , - 3 * twiss_hr . envelope_x , color = \"b\" , alpha = 0.25 ) axis1 . fill_between ( machine . s , machine . aper_1 , machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . fill_between ( machine . s , - machine . aper_1 , - machine . aper_1 * 100 , color = \"k\" , alpha = 0.5 ) axis1 . plot ( machine . s , machine . aper_1 , \"k.-\" ) axis1 . plot ( machine . s , - machine . aper_1 , \"k.-\" ) axis1 . set_xlim ( xlimits ) axis1 . set_ylim ( hplane_ylim ) axis1 . set_ylabel ( \"x [m]\" ) axis1 . set_xlabel ( \"s [m]\" ) axis1 . set_title ( f \"Horizontal aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the vertical aperture\" ) axis2 = plt . subplot2grid (( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis2 . plot ( twiss_hr . s , twiss_hr . envelope_y , color = \"r\" ) axis2 . plot ( twiss_hr . s , - twiss_hr . envelope_y , color = \"r\" ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , twiss_hr . envelope_y , - twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( twiss_hr . s , 3 * twiss_hr . envelope_y , - 3 * twiss_hr . envelope_y , color = \"r\" , alpha = 0.25 ) axis2 . fill_between ( machine . s , machine . aper_2 , machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . fill_between ( machine . s , - machine . aper_2 , - machine . aper_2 * 100 , color = \"k\" , alpha = 0.5 ) axis2 . plot ( machine . s , machine . aper_2 , \"k.-\" ) axis2 . plot ( machine . s , - machine . aper_2 , \"k.-\" ) axis2 . set_ylim ( vplane_ylim ) axis2 . set_ylabel ( \"y [m]\" ) axis2 . set_xlabel ( \"s [m]\" ) axis2 . set_title ( f \"Vertical aperture at {beam_params['pc_GeV']} GeV/c\" ) logger . debug ( \"Plotting the stay-clear envelope\" ) axis3 = plt . subplot2grid (( 3 , 3 ), ( 2 , 0 ), colspan = 3 , rowspan = 1 , sharex = axis1 ) axis3 . plot ( machine . s , machine . aper_1 / machine . envelope_x , \".-b\" , label = \"Horizontal plane\" ) axis3 . plot ( machine . s , machine . aper_2 / machine . envelope_y , \".-r\" , label = \"Vertical plane\" ) axis3 . set_xlim ( xlimits ) axis3 . set_ylabel ( \"n1\" ) axis3 . set_xlabel ( \"s [m]\" ) axis3 . legend ( loc = \"best\" ) axis3 . set_title ( f \"Stay-clear envelope at {beam_params['pc_GeV']} GeV/c\" ) if savefig : logger . info ( f \"Saving aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure","title":"plot_aperture"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#dynamicapertureplotter","text":"class DynamicAperturePlotter ( / , * args , ** kwargs ) A class to plot the dynamic aperture of your machine. View Source class DynamicAperturePlotter : \"\"\" A class to plot the dynamic aperture of your machine. \"\"\" @staticmethod def plot_dynamic_aperture ( vx_coords : np . ndarray , vy_coords : np . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure : \"\"\" Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Args: vx_coords (np.ndarray): numpy array of horizontal coordinates over turns. vy_coords (np.ndarray): numpy array of vertical coordinates over turns. n_particles (int): number of particles simulated. savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" figure = plt . figure ( figsize = ( 12 , 7 )) turn_lost = [] x_in_lost = [] for particle in range ( n_particles ) : nb = len ( vx_coords [ particle ] ) - max ( np . isnan ( vx_coords [ particle ] ). sum (), np . isnan ( vy_coords [ particle ] ). sum () ) turn_lost . append ( nb ) x_in_lost . append ( vx_coords [ particle ][ 0 ] ** 2 + vy_coords [ particle ][ 0 ] ** 2 ) turn_lost = np . array ( turn_lost ) x_in_lost = np . array ( x_in_lost ) plt . scatter ( turn_lost , x_in_lost * 1000 , linewidths = 0.7 , c = \"darkblue\" , marker = \".\" ) plt . title ( \"Amplitudes lost over turns\" , fontsize = 20 ) plt . xlabel ( \"Number of Turns Survived\" , fontsize = 17 ) plt . ylabel ( \"Initial amplitude [mm]\" , fontsize = 17 ) if savefig : logger . info ( f \"Saving dynamic aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure","title":"DynamicAperturePlotter"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#plot_dynamic_aperture","text":"def plot_dynamic_aperture ( vx_coords : numpy . ndarray , vy_coords : numpy . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Args: vx_coords (np.ndarray): numpy array of horizontal coordinates over turns. vy_coords (np.ndarray): numpy array of vertical coordinates over turns. n_particles (int): number of particles simulated. savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_dynamic_aperture ( vx_coords : np . ndarray , vy_coords : np . ndarray , n_particles : int , savefig : str = None ) -> matplotlib . figure . Figure : \"\"\" Plots a visual aid for the dynamic aperture after a tracking. Initial amplitudes are on the vertical axis, and the turn at which they were lost is in the horizontal axis. Args: vx_coords (np.ndarray): numpy array of horizontal coordinates over turns. vy_coords (np.ndarray): numpy array of vertical coordinates over turns. n_particles (int): number of particles simulated. savefig (str): will save the figure if this is not None, using the string value passed. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" figure = plt . figure ( figsize = ( 12 , 7 )) turn_lost = [] x_in_lost = [] for particle in range ( n_particles ) : nb = len ( vx_coords [ particle ] ) - max ( np . isnan ( vx_coords [ particle ] ). sum (), np . isnan ( vy_coords [ particle ] ). sum () ) turn_lost . append ( nb ) x_in_lost . append ( vx_coords [ particle ][ 0 ] ** 2 + vy_coords [ particle ][ 0 ] ** 2 ) turn_lost = np . array ( turn_lost ) x_in_lost = np . array ( x_in_lost ) plt . scatter ( turn_lost , x_in_lost * 1000 , linewidths = 0.7 , c = \"darkblue\" , marker = \".\" ) plt . title ( \"Amplitudes lost over turns\" , fontsize = 20 ) plt . xlabel ( \"Number of Turns Survived\" , fontsize = 17 ) plt . ylabel ( \"Initial amplitude [mm]\" , fontsize = 17 ) if savefig : logger . info ( f \"Saving dynamic aperture plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure","title":"plot_dynamic_aperture"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#phasespaceplotter","text":"class PhaseSpacePlotter ( / , * args , ** kwargs ) A class to plot Courant-Snyder coordinates phase space. View Source class PhaseSpacePlotter : \"\"\" A class to plot Courant-Snyder coordinates phase space. \"\"\" @staticmethod def plot_courant_snyder_phase_space ( cpymad_instance : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) # Getting the P matrix to compute Courant - Snyder coordinates logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = ( cpymad_instance . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . alfy [ 0 ] ) beta = ( cpymad_instance . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . bety [ 0 ] ) logger . debug ( f \"Plotting Courant-Snyder phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = \"k\" ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure @staticmethod def plot_courant_snyder_phase_space_colored ( cpymad_instance : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156th color. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) # Getting a sufficiently long array of colors to use colors = int ( np . floor ( len ( u_coordinates ) / 100 )) * SORTED_COLORS while len ( colors ) > len ( u_coordinates ) : colors . pop () figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = ( cpymad_instance . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . alfy [ 0 ] ) beta = ( cpymad_instance . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . bety [ 0 ] ) logger . debug ( f \"Plotting colored normalised phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = colors [ index ] ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving colored Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure","title":"PhaseSpacePlotter"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#static-methods_2","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#plot_courant_snyder_phase_space","text":"def plot_courant_snyder_phase_space ( cpymad_instance : cpymad . madx . Madx , u_coordinates : numpy . ndarray , pu_coordinates : numpy . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = 'Horizontal' ) -> matplotlib . figure . Figure Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_courant_snyder_phase_space ( cpymad_instance : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) # Getting the P matrix to compute Courant - Snyder coordinates logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = ( cpymad_instance . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . alfy [ 0 ] ) beta = ( cpymad_instance . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . bety [ 0 ] ) logger . debug ( f \"Plotting Courant-Snyder phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = \"k\" ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure","title":"plot_courant_snyder_phase_space"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#plot_courant_snyder_phase_space_colored","text":"def plot_courant_snyder_phase_space_colored ( cpymad_instance : cpymad . madx . Madx , u_coordinates : numpy . ndarray , pu_coordinates : numpy . ndarray , savefig : str = None , size : Tuple [ int , int ] = ( 16 , 8 ), plane : str = 'Horizontal' ) -> matplotlib . figure . Figure Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156 th color. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_courant_snyder_phase_space_colored ( cpymad_instance : Madx , u_coordinates : np . ndarray , pu_coordinates : np . ndarray , savefig : str = None , size : Tuple [ int, int ] = ( 16 , 8 ), plane : str = \"Horizontal\" , ) -> matplotlib . figure . Figure : \"\"\" Plots the Courant-Snyder phase space of a particle distribution when provided by position and momentum coordinates for a specific plane. Each particle trajectory has its own color on the plot, within the limit of pyplot's 156 named colors. The sequence repeats after the 156th color. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. u_coordinates (np.ndarray): numpy array of particles's coordinates for the given plane. pu_coordinates (np.ndarray): numpy array of particles's momentum coordinates for the given plane. savefig (str): will save the figure if this is not None, using the string value passed. size (Tuple[int, int]): the wanted matplotlib figure size. Defaults to (16, 8). plane (str): the physical plane to plot. Defaults to 'Horizontal'. Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" if plane . upper () not in ( \"HORIZONTAL\" , \"VERTICAL\" ) : logger . error ( f \"Plane should be either Horizontal or Vertical but '{plane}' was given\" ) raise ValueError ( \"Invalid plane value\" ) # Getting a sufficiently long array of colors to use colors = int ( np . floor ( len ( u_coordinates ) / 100 )) * SORTED_COLORS while len ( colors ) > len ( u_coordinates ) : colors . pop () figure = plt . figure ( figsize = size ) plt . title ( \"Courant-Snyder Phase Space\" , fontsize = 20 ) logger . debug ( \"Getting Twiss functions from cpymad\" ) alpha = ( cpymad_instance . table . twiss . alfx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . alfy [ 0 ] ) beta = ( cpymad_instance . table . twiss . betx [ 0 ] if plane . upper () == \"HORIZONTAL\" else cpymad_instance . table . twiss . bety [ 0 ] ) logger . debug ( f \"Plotting colored normalised phase space for the {plane.lower()} plane\" ) for index , _ in enumerate ( u_coordinates ) : logger . trace ( f \"Getting and plotting Courant-Snyder coordinates for particle {index}\" ) u = np . array ( [ u_coordinates[index ] , pu_coordinates [ index ] ] ) u_bar = courant_snyder_transform ( u , alpha , beta ) plt . scatter ( u_bar [ 0, : ] * 1e3 , u_bar [ 1, : ] * 1e3 , s = 0.1 , c = colors [ index ] ) if plane . upper () == \"HORIZONTAL\" : plt . xlabel ( \"$\\\\bar{x} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{px} [mrad]$\" , fontsize = 17 ) else : plt . xlabel ( \"$\\\\bar{y} [mm]$\" , fontsize = 17 ) plt . ylabel ( \"$\\\\bar{py} [mrad]$\" , fontsize = 17 ) plt . axis ( \"Equal\" ) if savefig : logger . info ( f \"Saving colored Courant-Snyder phase space plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure","title":"plot_courant_snyder_phase_space_colored"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#tunediagramplotter","text":"class TuneDiagramPlotter ( / , * args , ** kwargs ) A class to plot a blank tune diagram with Farey sequences, as well as your working points. View Source class TuneDiagramPlotter : \"\"\" A class to plot a blank tune diagram with Farey sequences, as well as your working points. \"\"\" @staticmethod def farey_sequence ( order : int ) -> list : \"\"\" Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Args: order (int): the order up to which we want to calculate the sequence. Returns: The sequence as a list. \"\"\" seq = [ [0, 1 ] ] a , b , c , d = 0 , 1 , 1 , order while c <= order : k = int (( order + b ) / d ) a , b , c , d = c , d , k * c - a , k * d - b seq . append ( [ a, b ] ) return seq @staticmethod def plot_blank_tune_diagram () -> matplotlib . figure . Figure : \"\"\" Plotting the tune diagram up to the 6th order. Original code from Rogelio Tom\u00e1s. Returns: The figure on which resonance lines from farey sequences are drawn. \"\"\" logger . debug ( \"Plotting resonance lines from Farey sequence, up to 5th order\" ) figure = plt . figure ( figsize = ( 13 , 13 )) plt . ylim (( 0 , 1 )) plt . xlim (( 0 , 1 )) x = np . linspace ( 0 , 1 , 1000 ) for i in range ( 1 , 6 ) : farey_sequences = TuneDiagramPlotter . farey_sequence ( i ) for f in farey_sequences : h , k = f # Node h / k on the axes for sequence in farey_sequences : p , q = sequence a = float ( k * p ) # Resonance linea Qx + b * Qy = clinkedtop / q if a > 0 : b = float ( q - k * p ) c = float ( p * h ) plt . plot ( x , c / a - x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( x , c / a + x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , 1 - x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , 1 - x , \"b\" , alpha = 0.1 ) if q == k and p == 1 : # FN elements below 1 / k break plt . title ( \"Tune Diagram\" , fontsize = 20 ) plt . axis ( \"square\" ) plt . xlim ( [ 0, 1 ] ) plt . ylim ( [ 0, 1 ] ) plt . xlabel ( \"$Q_{x}}$\" , fontsize = 17 ) plt . ylabel ( \"$Q_{y}$\" , fontsize = 17 ) return figure @staticmethod def plot_tune_diagram ( cpymad_instance : Madx , v_qx : np . ndarray = np . array ( [ 0 ] ), vxgood : np . ndarray = np . array ( [ False ] ), v_qy : np . ndarray = np . array ( [ 0 ] ), vygood : np . ndarray = np . array ( [ False ] ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plots the evolution of particles' tunes on a Tune Diagram. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. v_qx (np.ndarray): horizontal tune value as a numpy array. vxgood (np.ndarray): ?? v_qy (np.ndarray): vertical tune value as a numpy array. vygood (np.ndarray): ?? savefig: will save the figure if this is not None, using the string value passed. Returns: The figure on which the diagram is drawn. \"\"\" figure = TuneDiagramPlotter . plot_blank_tune_diagram () logger . debug ( \"Getting Tunes from cpymad\" ) new_q1 : float = cpymad_instance . table . summ . dframe (). q1 [ 0 ] new_q2 : float = cpymad_instance . table . summ . dframe (). q2 [ 0 ] if vxgood . any () and vygood . any () : plt . plot ( v_qx [ vxgood * vygood ] , v_qy [ vxgood * vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif vxgood . any () and ~ vygood . any () : tp = np . ones ( len ( vxgood )) * ( new_q2 - np . floor ( new_q2 )) plt . plot ( v_qx [ vxgood ] , tp [ vxgood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif ~ vxgood . any () and vygood . any () : tp = np . ones ( len ( vygood )) * ( new_q1 - np . floor ( new_q1 )) plt . plot ( tp [ vygood ] , v_qy [ vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) if savefig : logger . info ( f \"Saving Tune diagram plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure","title":"TuneDiagramPlotter"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#static-methods_3","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#farey_sequence","text":"def farey_sequence ( order : int ) -> list Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Args: order (int): the order up to which we want to calculate the sequence. Returns: The sequence as a list. View Source @staticmethod def farey_sequence ( order : int ) -> list : \"\"\" Returns the n-th farey_sequence sequence, ascending. Original code from Rogelio Tom\u00e1s. Args: order (int): the order up to which we want to calculate the sequence. Returns: The sequence as a list. \"\"\" seq = [ [0, 1 ] ] a , b , c , d = 0 , 1 , 1 , order while c <= order : k = int (( order + b ) / d ) a , b , c , d = c , d , k * c - a , k * d - b seq . append ( [ a, b ] ) return seq","title":"farey_sequence"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#plot_blank_tune_diagram","text":"def plot_blank_tune_diagram ( ) -> matplotlib . figure . Figure Plotting the tune diagram up to the 6 th order. Original code from Rogelio Tom\u00e1s. Returns: The figure on which resonance lines from farey sequences are drawn. View Source @staticmethod def plot_blank_tune_diagram () -> matplotlib . figure . Figure : \"\"\" Plotting the tune diagram up to the 6th order. Original code from Rogelio Tom\u00e1s. Returns: The figure on which resonance lines from farey sequences are drawn. \"\"\" logger . debug ( \"Plotting resonance lines from Farey sequence, up to 5th order\" ) figure = plt . figure ( figsize = ( 13 , 13 )) plt . ylim (( 0 , 1 )) plt . xlim (( 0 , 1 )) x = np . linspace ( 0 , 1 , 1000 ) for i in range ( 1 , 6 ) : farey_sequences = TuneDiagramPlotter . farey_sequence ( i ) for f in farey_sequences : h , k = f # Node h / k on the axes for sequence in farey_sequences : p , q = sequence a = float ( k * p ) # Resonance linea Qx + b * Qy = clinkedtop / q if a > 0 : b = float ( q - k * p ) c = float ( p * h ) plt . plot ( x , c / a - x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( x , c / a + x * b / a , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , x , \"b\" , alpha = 0.1 ) plt . plot ( c / a - x * b / a , 1 - x , \"b\" , alpha = 0.1 ) plt . plot ( c / a + x * b / a , 1 - x , \"b\" , alpha = 0.1 ) if q == k and p == 1 : # FN elements below 1 / k break plt . title ( \"Tune Diagram\" , fontsize = 20 ) plt . axis ( \"square\" ) plt . xlim ( [ 0, 1 ] ) plt . ylim ( [ 0, 1 ] ) plt . xlabel ( \"$Q_{x}}$\" , fontsize = 17 ) plt . ylabel ( \"$Q_{y}$\" , fontsize = 17 ) return figure","title":"plot_blank_tune_diagram"},{"location":"reference/pyhdtoolkit/cpymadtools/plotters/#plot_tune_diagram","text":"def plot_tune_diagram ( cpymad_instance : cpymad . madx . Madx , v_qx : numpy . ndarray = array ([ 0 ]), vxgood : numpy . ndarray = array ([ False ]), v_qy : numpy . ndarray = array ([ 0 ]), vygood : numpy . ndarray = array ([ False ]), savefig : str = None ) -> matplotlib . figure . Figure Plots the evolution of particles' tunes on a Tune Diagram. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. v_qx (np.ndarray): horizontal tune value as a numpy array. vxgood (np.ndarray): ?? v_qy (np.ndarray): vertical tune value as a numpy array. vygood (np.ndarray): ?? savefig: will save the figure if this is not None, using the string value passed. Returns: The figure on which the diagram is drawn. View Source @staticmethod def plot_tune_diagram ( cpymad_instance : Madx , v_qx : np . ndarray = np . array ( [ 0 ] ), vxgood : np . ndarray = np . array ( [ False ] ), v_qy : np . ndarray = np . array ( [ 0 ] ), vygood : np . ndarray = np . array ( [ False ] ), savefig : str = None , ) -> matplotlib . figure . Figure : \"\"\" Plots the evolution of particles' tunes on a Tune Diagram. Args: cpymad_instance (cpymad.madx.Madx): an instanciated cpymad Madx object. v_qx (np.ndarray): horizontal tune value as a numpy array. vxgood (np.ndarray): ?? v_qy (np.ndarray): vertical tune value as a numpy array. vygood (np.ndarray): ?? savefig: will save the figure if this is not None, using the string value passed. Returns: The figure on which the diagram is drawn. \"\"\" figure = TuneDiagramPlotter . plot_blank_tune_diagram () logger . debug ( \"Getting Tunes from cpymad\" ) new_q1 : float = cpymad_instance . table . summ . dframe (). q1 [ 0 ] new_q2 : float = cpymad_instance . table . summ . dframe (). q2 [ 0 ] if vxgood . any () and vygood . any () : plt . plot ( v_qx [ vxgood * vygood ] , v_qy [ vxgood * vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif vxgood . any () and ~ vygood . any () : tp = np . ones ( len ( vxgood )) * ( new_q2 - np . floor ( new_q2 )) plt . plot ( v_qx [ vxgood ] , tp [ vxgood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) elif ~ vxgood . any () and vygood . any () : tp = np . ones ( len ( vygood )) * ( new_q1 - np . floor ( new_q1 )) plt . plot ( tp [ vygood ] , v_qy [ vygood ] , \".r\" ) plt . plot ( new_q1 - np . floor ( new_q1 ), new_q2 - np . floor ( new_q2 ), \".g\" ) if savefig : logger . info ( f \"Saving Tune diagram plot at '{Path(savefig).absolute()}'\" ) plt . savefig ( Path ( savefig ), format = \"png\" , dpi = 500 ) return figure","title":"plot_tune_diagram"},{"location":"reference/pyhdtoolkit/maths/","text":"Module pyhdtoolkit.maths Sub-modules pyhdtoolkit.maths.nonconvex_phase_sync pyhdtoolkit.maths.stats_fitting","title":"Index"},{"location":"reference/pyhdtoolkit/maths/#module-pyhdtoolkitmaths","text":"","title":"Module pyhdtoolkit.maths"},{"location":"reference/pyhdtoolkit/maths/#sub-modules","text":"pyhdtoolkit.maths.nonconvex_phase_sync pyhdtoolkit.maths.stats_fitting","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/","text":"Module pyhdtoolkit.maths.nonconvex_phase_sync Module maths.nonconvex_phase_sync Created on 2020.01.13 :author: Felix Soubelet ( felix.soubelet@cern.ch ) This is a Python3 implementation of the Nonconvex Phase Synchronisation method found in the following paper (DOI: 10.1137/16M105808X, the algorithm reproduced is page 8). Methodology and Use Case We consider that from measurements, we can only obtain noisy relative phase advances mu_{i} - mu_{j} and want a converging solution to reconstruct the different individual mu_{1}, ...., mu_{n} values. From measurements, we construct a hermitian matrix C in the shape of: C_{ij} = z_{i} * bar(z_{j}) = exp(i * (mu_{i} - mu_{j})) A mock one with random values (500 by 500 as we have 500 BPMs per plane in the LHC) would be: c_matrix = np.exp(1j * np.random.rand(500, 500)) Considering 4 BPMs, the measurement matrix would be: M_matrix = [[mu_{1 -> 1}, mu_{1 -> 2}, mu_{1 -> 3}, mu_{1 -> 4}], [mu_{2 -> 1}, mu_{2 -> 2}, mu_{2 -> 3}, mu_{2 -> 4}], [mu_{3 -> 1}, mu_{3 -> 2}, mu_{3 -> 3}, mu_{3 -> 4}], [mu_{4 -> 1}, mu_{4 -> 2}, mu_{4 -> 3}, mu_{4 -> 4}]] Note two particular properties here: - Because our measurements are phase differences, the M_matrix will necessarily have zeros on its diagonal (mu_{k -> k} = 0). - By definition, since mu_{a -> b} = - mu_{b -> a}, M_matrix is symmetric. - Also note that for all computations, M_matrix needs to be initialised in radians! We can very simply get our C_matrix (see page 1 of referenced paper) with numpy.exp which, applied to a numpy.ndarray applies the exponential function element-wise. See reference at https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html Then follows: C_matrix = np.exp(1j * M_matrix) Note that M_matrix being symmetric, then c_matrix will be Hermitian. Note that M_matrix having zeros in its diagonal, c_matrix will have (1 + 0j) on its diagonal. With added noise to those values (noise should be included in M_matrix in the case of measurements), we can reconstruct a good estimator of the original values through the EVM method, provided in the class below. View Source \"\"\" Module maths.nonconvex_phase_sync --------------------------------- Created on 2020.01.13 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 implementation of the Nonconvex Phase Synchronisation method found in the following paper (DOI: 10.1137/16M105808X, the algorithm reproduced is page 8). Methodology and Use Case ======================== We consider that from measurements, we can only obtain noisy relative phase advances mu_{i} - mu_{j} and want a converging solution to reconstruct the different individual mu_{1}, ...., mu_{n} values. From measurements, we construct a hermitian matrix C in the shape of: C_{ij} = z_{i} * bar(z_{j}) = exp(i * (mu_{i} - mu_{j})) A mock one with random values (500 by 500 as we have 500 BPMs per plane in the LHC) would be: c_matrix = np.exp(1j * np.random.rand(500, 500)) Considering 4 BPMs, the measurement matrix would be: M_matrix = [[mu_{1 -> 1}, mu_{1 -> 2}, mu_{1 -> 3}, mu_{1 -> 4}], [mu_{2 -> 1}, mu_{2 -> 2}, mu_{2 -> 3}, mu_{2 -> 4}], [mu_{3 -> 1}, mu_{3 -> 2}, mu_{3 -> 3}, mu_{3 -> 4}], [mu_{4 -> 1}, mu_{4 -> 2}, mu_{4 -> 3}, mu_{4 -> 4}]] Note two particular properties here: - Because our measurements are phase differences, the M_matrix will necessarily have zeros on its diagonal (mu_{k -> k} = 0). - By definition, since mu_{a -> b} = - mu_{b -> a}, M_matrix is symmetric. - Also note that for all computations, M_matrix needs to be initialised in radians! We can very simply get our C_matrix (see page 1 of referenced paper) with `numpy.exp` which, applied to a `numpy.ndarray` applies the exponential function element-wise. See reference at https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html Then follows: C_matrix = np.exp(1j * M_matrix) Note that M_matrix being symmetric, then c_matrix will be Hermitian. Note that M_matrix having zeros in its diagonal, c_matrix will have (1 + 0j) on its diagonal. With added noise to those values (noise should be included in M_matrix in the case of measurements), we can reconstruct a good estimator of the original values through the EVM method, provided in the class below. \"\"\" import numpy as np from loguru import logger class PhaseReconstructor: \"\"\" Class algorithm to reconstruct your phase values. Make sure to provide vectors as `numpy.ndarray` with shape (1, N), N being the dimension. \"\"\" __slots__ = { \"c_matrix\" : \"Hermitian square matrix from your measurements\" , \"c_matrix_eigenvalues\" : \"Eigenvalues of c_matrix\" , \"c_matrix_eigenvectors\" : \"Eigenvectors of c_matrix\" , \"space_dimension\" : \"Dimension of your measurement space\" , } def __init__ ( self , measurements_hermitian_matrix: np . ndarray ) -> None: \"\"\" Initialize your reconstructor object from measurements. Args: measurements_hermitian_matrix: a `numpy.ndarray` object built from measurements, see module docstring on how to build this matrix. \"\"\" logger . debug ( \"Checking that the provided matrix is Hermitian\" ) if np . allclose ( measurements_hermitian_matrix , np . conj ( measurements_hermitian_matrix ). T ): self . c_matrix: np . ndarray = measurements_hermitian_matrix self . c_matrix_eigenvalues: np . ndarray = np . linalg . eigvalsh ( self . c_matrix ) # Numpy gives the eigenvectors in column form, so transpose is needed there! self . c_matrix_eigenvectors: np . ndarray = np . linalg . eigh ( self . c_matrix )[- 1 ]. T self . space_dimension: int = self . c_matrix . shape [ 0 ] else: logger . exception ( \"Instantiating a PhaseReconstructor with a non hermitian matrix is \" \"not possible\" ) raise ValueError ( \"Provided matrix should be Hermitian\" ) @property def alpha ( self ) -> np . float64: \"\"\" This is a factor used to define the new reconstruction matrix. It is taken either as the operator norm of the hermitian noise matrix, or as the max value between 0 and the opposite of the min eigenvalue of c_matrix (chosen for implementation, since our noise is included in the measurements). See page 8 of the paper for reference. Returns: A real scalar value, because c_matrix is Hermitian and the eigenvalues of real symmetric or complex Hermitian matrices are always real (see G. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, pg. 222.) \"\"\" return np . float64 ( max ( 0 , np . amin ( self . c_matrix_eigenvalues ))) @property def leading_eigenvector ( self ) -> np . ndarray: \"\"\" Returns the leading eigenvector of `self.c_matrix`, which is the eigenvector corresponding to the max eigenvalue (in absolute value). Returns: A `numpy.ndarray` object, corresponding to said eigenvector. \"\"\" return self . c_matrix_eigenvectors [ np . where ( self . c_matrix_eigenvalues == np . amax ( np . absolute ( self . c_matrix_eigenvalues ))) ]. reshape (( 1 , self . space_dimension )) @property def reconstructor_matrix ( self ) -> np . ndarray: \"\"\" This is the reconstructor matrix built from `self.c_matrix` and the `alpha` property. It is the matrix denoted as \\\\widetilde{C} on page 8 of the reference paper. Returns: A `numpy.ndarray`, with same dimension as `self.c_matrix`. \"\"\" return self . c_matrix + self . alpha * np . identity ( self . c_matrix . shape [ 0 ]) def get_eigenvector_estimator ( self , eigenvector: np . ndarray ) -> np . ndarray: \"\"\" Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Args: eigenvector (np.ndarray): a numpy array representing the vector. Returns: A `numpy.ndarray` object of the same dimension as param `eigenvector`. \"\"\" try: return eigenvector / np . absolute ( eigenvector ) except RuntimeWarning: # In case of 0-division, we don't want `inf` values from numpy # Generate a random complex vector with same dimension (since `eigenvector` is of # dimension N * 1, `numpy.ndarray.size` method will give us N). # Remember to initialize a random real and imaginary part. logger . exception ( \"Encountered 0-division, trying normalization\" ) e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) while ( np . absolute ( e_vect @ eigenvector ) == 0 ): # Guarantee that we don't fall back to this edge case. e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) return ( e_vect @ eigenvector / np . absolute ( e_vect @ eigenvector )). reshape ( ( 1 , self . space_dimension ) ) def reconstruct_complex_phases_evm ( self ) -> np . ndarray: \"\"\" Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: The complex form of the result as a 'numpy.ndarray' instance. \"\"\" logger . debug ( \"Getting complex phase results\" ) return self . get_eigenvector_estimator ( self . leading_eigenvector ) @staticmethod def convert_complex_result_to_phase_values ( complex_estimator: np . ndarray , deg: bool = False ) -> np . ndarray: \"\"\" Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A `numpy.ndarray` with the real phase values of the result. \"\"\" logger . debug ( \"Casting complex phases to real values\" ) return np . apply_along_axis ( np . angle , axis = 0 , arr = complex_estimator , deg = deg ) Classes PhaseReconstructor class PhaseReconstructor ( measurements_hermitian_matrix : numpy . ndarray ) Class algorithm to reconstruct your phase values. Make sure to provide vectors as numpy.ndarray with shape (1, N), N being the dimension. View Source class PhaseReconstructor : \" \"\" Class algorithm to reconstruct your phase values. Make sure to provide vectors as `numpy.ndarray` with shape (1, N), N being the dimension. \"\" \" __slots__ = { \"c_matrix\" : \"Hermitian square matrix from your measurements\" , \"c_matrix_eigenvalues\" : \"Eigenvalues of c_matrix\" , \"c_matrix_eigenvectors\" : \"Eigenvectors of c_matrix\" , \"space_dimension\" : \"Dimension of your measurement space\" , } def __init__ ( self , measurements_hermitian_matrix : np . ndarray ) -> None : \" \"\" Initialize your reconstructor object from measurements. Args: measurements_hermitian_matrix: a `numpy.ndarray` object built from measurements, see module docstring on how to build this matrix. \"\" \" logger . debug ( \"Checking that the provided matrix is Hermitian\" ) if np . allclose ( measurements_hermitian_matrix , np . conj ( measurements_hermitian_matrix ). T ) : self . c_matrix : np . ndarray = measurements_hermitian_matrix self . c_matrix_eigenvalues : np . ndarray = np . linalg . eigvalsh ( self . c_matrix ) # Numpy gives the eigenvectors in column form, so transpose is needed there! self . c_matrix_eigenvectors : np . ndarray = np . linalg . eigh ( self . c_matrix ) [ - 1 ] . T self . space_dimension : int = self . c_matrix . shape [ 0 ] else : logger . exception ( \"Instantiating a PhaseReconstructor with a non hermitian matrix is \" \"not possible\" ) raise ValueError ( \"Provided matrix should be Hermitian\" ) @property def alpha ( self ) -> np . float64 : \" \"\" This is a factor used to define the new reconstruction matrix. It is taken either as the operator norm of the hermitian noise matrix, or as the max value between 0 and the opposite of the min eigenvalue of c_matrix (chosen for implementation, since our noise is included in the measurements). See page 8 of the paper for reference. Returns: A real scalar value, because c_matrix is Hermitian and the eigenvalues of real symmetric or complex Hermitian matrices are always real (see G. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, pg. 222.) \"\" \" return np . float64 ( max ( 0 , np . amin ( self . c_matrix_eigenvalues ))) @property def leading_eigenvector ( self ) -> np . ndarray : \" \"\" Returns the leading eigenvector of `self.c_matrix`, which is the eigenvector corresponding to the max eigenvalue (in absolute value). Returns: A `numpy.ndarray` object, corresponding to said eigenvector. \"\" \" return self . c_matrix_eigenvectors [ np . where ( self . c_matrix_eigenvalues == np . amax ( np . absolute ( self . c_matrix_eigenvalues ))) ] . reshape (( 1 , self . space_dimension )) @property def reconstructor_matrix ( self ) -> np . ndarray : \" \"\" This is the reconstructor matrix built from `self.c_matrix` and the `alpha` property. It is the matrix denoted as \\\\ widetilde{C} on page 8 of the reference paper. Returns: A `numpy.ndarray`, with same dimension as `self.c_matrix`. \"\" \" return self . c_matrix + self . alpha * np . identity ( self . c_matrix . shape [ 0 ] ) def get_eigenvector_estimator ( self , eigenvector : np . ndarray ) -> np . ndarray : \" \"\" Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Args: eigenvector (np.ndarray): a numpy array representing the vector. Returns: A `numpy.ndarray` object of the same dimension as param `eigenvector`. \"\" \" try : return eigenvector / np . absolute ( eigenvector ) except RuntimeWarning : # In case of 0-division, we don't want `inf` values from numpy # Generate a random complex vector with same dimension (since `eigenvector` is of # dimension N * 1, `numpy.ndarray.size` method will give us N). # Remember to initialize a random real and imaginary part. logger . exception ( \"Encountered 0-division, trying normalization\" ) e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) while ( np . absolute ( e_vect @ eigenvector ) == 0 ) : # Guarantee that we don't fall back to this edge case. e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) return ( e_vect @ eigenvector / np . absolute ( e_vect @ eigenvector )). reshape ( ( 1 , self . space_dimension ) ) def reconstruct_complex_phases_evm ( self ) -> np . ndarray : \" \"\" Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: The complex form of the result as a 'numpy.ndarray' instance. \"\" \" logger . debug ( \"Getting complex phase results\" ) return self . get_eigenvector_estimator ( self . leading_eigenvector ) @staticmethod def convert_complex_result_to_phase_values ( complex_estimator : np . ndarray , deg : bool = False ) -> np . ndarray : \" \"\" Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A `numpy.ndarray` with the real phase values of the result. \"\" \" logger . debug ( \"Casting complex phases to real values\" ) return np . apply_along_axis ( np . angle , axis = 0 , arr = complex_estimator , deg = deg ) Static methods convert_complex_result_to_phase_values def convert_complex_result_to_phase_values ( complex_estimator : numpy . ndarray , deg : bool = False ) -> numpy . ndarray Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A numpy.ndarray with the real phase values of the result. View Source @staticmethod def convert_complex_result_to_phase_values ( complex_estimator : np . ndarray , deg : bool = False ) -> np . ndarray : \"\"\" Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A `numpy.ndarray` with the real phase values of the result. \"\"\" logger . debug ( \"Casting complex phases to real values\" ) return np . apply_along_axis ( np . angle , axis = 0 , arr = complex_estimator , deg = deg ) Instance variables alpha This is a factor used to define the new reconstruction matrix. It is taken either as the operator norm of the hermitian noise matrix, or as the max value between 0 and the opposite of the min eigenvalue of c_matrix (chosen for implementation, since our noise is included in the measurements). See page 8 of the paper for reference. Returns: A real scalar value, because c_matrix is Hermitian and the eigenvalues of real symmetric or complex Hermitian matrices are always real (see G. Strang, Linear Algebra and Its Applications, 2 nd Ed., Orlando, FL, Academic Press, Inc., 1980, pg. 222.) c_matrix c_matrix_eigenvalues c_matrix_eigenvectors leading_eigenvector Returns the leading eigenvector of self.c_matrix , which is the eigenvector corresponding to the max eigenvalue (in absolute value). Returns: A numpy.ndarray object, corresponding to said eigenvector. reconstructor_matrix This is the reconstructor matrix built from self.c_matrix and the alpha property. It is the matrix denoted as \\widetilde{C} on page 8 of the reference paper. Returns: A numpy.ndarray , with same dimension as self.c_matrix . space_dimension Methods get_eigenvector_estimator def get_eigenvector_estimator ( self , eigenvector : numpy . ndarray ) -> numpy . ndarray Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Args: eigenvector (np.ndarray): a numpy array representing the vector. Returns: A numpy.ndarray object of the same dimension as param eigenvector . View Source def get_eigenvector_estimator ( self , eigenvector : np . ndarray ) -> np . ndarray : \" \"\" Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Args: eigenvector (np.ndarray): a numpy array representing the vector. Returns: A `numpy.ndarray` object of the same dimension as param `eigenvector`. \"\" \" try : return eigenvector / np . absolute ( eigenvector ) except RuntimeWarning : # In case of 0-division, we don't want `inf` values from numpy # Generate a random complex vector with same dimension (since `eigenvector` is of # dimension N * 1, `numpy.ndarray.size` method will give us N). # Remember to initialize a random real and imaginary part. logger . exception ( \"Encountered 0-division, trying normalization\" ) e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) while ( np . absolute ( e_vect @ eigenvector ) == 0 ) : # Guarantee that we don't fall back to this edge case. e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) return ( e_vect @ eigenvector / np . absolute ( e_vect @ eigenvector )). reshape ( ( 1 , self . space_dimension ) ) reconstruct_complex_phases_evm def reconstruct_complex_phases_evm ( self ) -> numpy . ndarray Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: The complex form of the result as a 'numpy.ndarray' instance. View Source def reconstruct_complex_phases_evm ( self ) -> np . ndarray : \"\"\" Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: The complex form of the result as a 'numpy.ndarray' instance. \"\"\" logger . debug ( \"Getting complex phase results\" ) return self . get_eigenvector_estimator ( self . leading_eigenvector )","title":"Nonconvex Phase Sync"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#module-pyhdtoolkitmathsnonconvex_phase_sync","text":"","title":"Module pyhdtoolkit.maths.nonconvex_phase_sync"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#module-mathsnonconvex_phase_sync","text":"Created on 2020.01.13 :author: Felix Soubelet ( felix.soubelet@cern.ch ) This is a Python3 implementation of the Nonconvex Phase Synchronisation method found in the following paper (DOI: 10.1137/16M105808X, the algorithm reproduced is page 8).","title":"Module maths.nonconvex_phase_sync"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#methodology-and-use-case","text":"We consider that from measurements, we can only obtain noisy relative phase advances mu_{i} - mu_{j} and want a converging solution to reconstruct the different individual mu_{1}, ...., mu_{n} values. From measurements, we construct a hermitian matrix C in the shape of: C_{ij} = z_{i} * bar(z_{j}) = exp(i * (mu_{i} - mu_{j})) A mock one with random values (500 by 500 as we have 500 BPMs per plane in the LHC) would be: c_matrix = np.exp(1j * np.random.rand(500, 500)) Considering 4 BPMs, the measurement matrix would be: M_matrix = [[mu_{1 -> 1}, mu_{1 -> 2}, mu_{1 -> 3}, mu_{1 -> 4}], [mu_{2 -> 1}, mu_{2 -> 2}, mu_{2 -> 3}, mu_{2 -> 4}], [mu_{3 -> 1}, mu_{3 -> 2}, mu_{3 -> 3}, mu_{3 -> 4}], [mu_{4 -> 1}, mu_{4 -> 2}, mu_{4 -> 3}, mu_{4 -> 4}]] Note two particular properties here: - Because our measurements are phase differences, the M_matrix will necessarily have zeros on its diagonal (mu_{k -> k} = 0). - By definition, since mu_{a -> b} = - mu_{b -> a}, M_matrix is symmetric. - Also note that for all computations, M_matrix needs to be initialised in radians! We can very simply get our C_matrix (see page 1 of referenced paper) with numpy.exp which, applied to a numpy.ndarray applies the exponential function element-wise. See reference at https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html Then follows: C_matrix = np.exp(1j * M_matrix) Note that M_matrix being symmetric, then c_matrix will be Hermitian. Note that M_matrix having zeros in its diagonal, c_matrix will have (1 + 0j) on its diagonal. With added noise to those values (noise should be included in M_matrix in the case of measurements), we can reconstruct a good estimator of the original values through the EVM method, provided in the class below. View Source \"\"\" Module maths.nonconvex_phase_sync --------------------------------- Created on 2020.01.13 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 implementation of the Nonconvex Phase Synchronisation method found in the following paper (DOI: 10.1137/16M105808X, the algorithm reproduced is page 8). Methodology and Use Case ======================== We consider that from measurements, we can only obtain noisy relative phase advances mu_{i} - mu_{j} and want a converging solution to reconstruct the different individual mu_{1}, ...., mu_{n} values. From measurements, we construct a hermitian matrix C in the shape of: C_{ij} = z_{i} * bar(z_{j}) = exp(i * (mu_{i} - mu_{j})) A mock one with random values (500 by 500 as we have 500 BPMs per plane in the LHC) would be: c_matrix = np.exp(1j * np.random.rand(500, 500)) Considering 4 BPMs, the measurement matrix would be: M_matrix = [[mu_{1 -> 1}, mu_{1 -> 2}, mu_{1 -> 3}, mu_{1 -> 4}], [mu_{2 -> 1}, mu_{2 -> 2}, mu_{2 -> 3}, mu_{2 -> 4}], [mu_{3 -> 1}, mu_{3 -> 2}, mu_{3 -> 3}, mu_{3 -> 4}], [mu_{4 -> 1}, mu_{4 -> 2}, mu_{4 -> 3}, mu_{4 -> 4}]] Note two particular properties here: - Because our measurements are phase differences, the M_matrix will necessarily have zeros on its diagonal (mu_{k -> k} = 0). - By definition, since mu_{a -> b} = - mu_{b -> a}, M_matrix is symmetric. - Also note that for all computations, M_matrix needs to be initialised in radians! We can very simply get our C_matrix (see page 1 of referenced paper) with `numpy.exp` which, applied to a `numpy.ndarray` applies the exponential function element-wise. See reference at https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html Then follows: C_matrix = np.exp(1j * M_matrix) Note that M_matrix being symmetric, then c_matrix will be Hermitian. Note that M_matrix having zeros in its diagonal, c_matrix will have (1 + 0j) on its diagonal. With added noise to those values (noise should be included in M_matrix in the case of measurements), we can reconstruct a good estimator of the original values through the EVM method, provided in the class below. \"\"\" import numpy as np from loguru import logger class PhaseReconstructor: \"\"\" Class algorithm to reconstruct your phase values. Make sure to provide vectors as `numpy.ndarray` with shape (1, N), N being the dimension. \"\"\" __slots__ = { \"c_matrix\" : \"Hermitian square matrix from your measurements\" , \"c_matrix_eigenvalues\" : \"Eigenvalues of c_matrix\" , \"c_matrix_eigenvectors\" : \"Eigenvectors of c_matrix\" , \"space_dimension\" : \"Dimension of your measurement space\" , } def __init__ ( self , measurements_hermitian_matrix: np . ndarray ) -> None: \"\"\" Initialize your reconstructor object from measurements. Args: measurements_hermitian_matrix: a `numpy.ndarray` object built from measurements, see module docstring on how to build this matrix. \"\"\" logger . debug ( \"Checking that the provided matrix is Hermitian\" ) if np . allclose ( measurements_hermitian_matrix , np . conj ( measurements_hermitian_matrix ). T ): self . c_matrix: np . ndarray = measurements_hermitian_matrix self . c_matrix_eigenvalues: np . ndarray = np . linalg . eigvalsh ( self . c_matrix ) # Numpy gives the eigenvectors in column form, so transpose is needed there! self . c_matrix_eigenvectors: np . ndarray = np . linalg . eigh ( self . c_matrix )[- 1 ]. T self . space_dimension: int = self . c_matrix . shape [ 0 ] else: logger . exception ( \"Instantiating a PhaseReconstructor with a non hermitian matrix is \" \"not possible\" ) raise ValueError ( \"Provided matrix should be Hermitian\" ) @property def alpha ( self ) -> np . float64: \"\"\" This is a factor used to define the new reconstruction matrix. It is taken either as the operator norm of the hermitian noise matrix, or as the max value between 0 and the opposite of the min eigenvalue of c_matrix (chosen for implementation, since our noise is included in the measurements). See page 8 of the paper for reference. Returns: A real scalar value, because c_matrix is Hermitian and the eigenvalues of real symmetric or complex Hermitian matrices are always real (see G. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, pg. 222.) \"\"\" return np . float64 ( max ( 0 , np . amin ( self . c_matrix_eigenvalues ))) @property def leading_eigenvector ( self ) -> np . ndarray: \"\"\" Returns the leading eigenvector of `self.c_matrix`, which is the eigenvector corresponding to the max eigenvalue (in absolute value). Returns: A `numpy.ndarray` object, corresponding to said eigenvector. \"\"\" return self . c_matrix_eigenvectors [ np . where ( self . c_matrix_eigenvalues == np . amax ( np . absolute ( self . c_matrix_eigenvalues ))) ]. reshape (( 1 , self . space_dimension )) @property def reconstructor_matrix ( self ) -> np . ndarray: \"\"\" This is the reconstructor matrix built from `self.c_matrix` and the `alpha` property. It is the matrix denoted as \\\\widetilde{C} on page 8 of the reference paper. Returns: A `numpy.ndarray`, with same dimension as `self.c_matrix`. \"\"\" return self . c_matrix + self . alpha * np . identity ( self . c_matrix . shape [ 0 ]) def get_eigenvector_estimator ( self , eigenvector: np . ndarray ) -> np . ndarray: \"\"\" Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Args: eigenvector (np.ndarray): a numpy array representing the vector. Returns: A `numpy.ndarray` object of the same dimension as param `eigenvector`. \"\"\" try: return eigenvector / np . absolute ( eigenvector ) except RuntimeWarning: # In case of 0-division, we don't want `inf` values from numpy # Generate a random complex vector with same dimension (since `eigenvector` is of # dimension N * 1, `numpy.ndarray.size` method will give us N). # Remember to initialize a random real and imaginary part. logger . exception ( \"Encountered 0-division, trying normalization\" ) e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) while ( np . absolute ( e_vect @ eigenvector ) == 0 ): # Guarantee that we don't fall back to this edge case. e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) return ( e_vect @ eigenvector / np . absolute ( e_vect @ eigenvector )). reshape ( ( 1 , self . space_dimension ) ) def reconstruct_complex_phases_evm ( self ) -> np . ndarray: \"\"\" Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: The complex form of the result as a 'numpy.ndarray' instance. \"\"\" logger . debug ( \"Getting complex phase results\" ) return self . get_eigenvector_estimator ( self . leading_eigenvector ) @staticmethod def convert_complex_result_to_phase_values ( complex_estimator: np . ndarray , deg: bool = False ) -> np . ndarray: \"\"\" Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A `numpy.ndarray` with the real phase values of the result. \"\"\" logger . debug ( \"Casting complex phases to real values\" ) return np . apply_along_axis ( np . angle , axis = 0 , arr = complex_estimator , deg = deg )","title":"Methodology and Use Case"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#phasereconstructor","text":"class PhaseReconstructor ( measurements_hermitian_matrix : numpy . ndarray ) Class algorithm to reconstruct your phase values. Make sure to provide vectors as numpy.ndarray with shape (1, N), N being the dimension. View Source class PhaseReconstructor : \" \"\" Class algorithm to reconstruct your phase values. Make sure to provide vectors as `numpy.ndarray` with shape (1, N), N being the dimension. \"\" \" __slots__ = { \"c_matrix\" : \"Hermitian square matrix from your measurements\" , \"c_matrix_eigenvalues\" : \"Eigenvalues of c_matrix\" , \"c_matrix_eigenvectors\" : \"Eigenvectors of c_matrix\" , \"space_dimension\" : \"Dimension of your measurement space\" , } def __init__ ( self , measurements_hermitian_matrix : np . ndarray ) -> None : \" \"\" Initialize your reconstructor object from measurements. Args: measurements_hermitian_matrix: a `numpy.ndarray` object built from measurements, see module docstring on how to build this matrix. \"\" \" logger . debug ( \"Checking that the provided matrix is Hermitian\" ) if np . allclose ( measurements_hermitian_matrix , np . conj ( measurements_hermitian_matrix ). T ) : self . c_matrix : np . ndarray = measurements_hermitian_matrix self . c_matrix_eigenvalues : np . ndarray = np . linalg . eigvalsh ( self . c_matrix ) # Numpy gives the eigenvectors in column form, so transpose is needed there! self . c_matrix_eigenvectors : np . ndarray = np . linalg . eigh ( self . c_matrix ) [ - 1 ] . T self . space_dimension : int = self . c_matrix . shape [ 0 ] else : logger . exception ( \"Instantiating a PhaseReconstructor with a non hermitian matrix is \" \"not possible\" ) raise ValueError ( \"Provided matrix should be Hermitian\" ) @property def alpha ( self ) -> np . float64 : \" \"\" This is a factor used to define the new reconstruction matrix. It is taken either as the operator norm of the hermitian noise matrix, or as the max value between 0 and the opposite of the min eigenvalue of c_matrix (chosen for implementation, since our noise is included in the measurements). See page 8 of the paper for reference. Returns: A real scalar value, because c_matrix is Hermitian and the eigenvalues of real symmetric or complex Hermitian matrices are always real (see G. Strang, Linear Algebra and Its Applications, 2nd Ed., Orlando, FL, Academic Press, Inc., 1980, pg. 222.) \"\" \" return np . float64 ( max ( 0 , np . amin ( self . c_matrix_eigenvalues ))) @property def leading_eigenvector ( self ) -> np . ndarray : \" \"\" Returns the leading eigenvector of `self.c_matrix`, which is the eigenvector corresponding to the max eigenvalue (in absolute value). Returns: A `numpy.ndarray` object, corresponding to said eigenvector. \"\" \" return self . c_matrix_eigenvectors [ np . where ( self . c_matrix_eigenvalues == np . amax ( np . absolute ( self . c_matrix_eigenvalues ))) ] . reshape (( 1 , self . space_dimension )) @property def reconstructor_matrix ( self ) -> np . ndarray : \" \"\" This is the reconstructor matrix built from `self.c_matrix` and the `alpha` property. It is the matrix denoted as \\\\ widetilde{C} on page 8 of the reference paper. Returns: A `numpy.ndarray`, with same dimension as `self.c_matrix`. \"\" \" return self . c_matrix + self . alpha * np . identity ( self . c_matrix . shape [ 0 ] ) def get_eigenvector_estimator ( self , eigenvector : np . ndarray ) -> np . ndarray : \" \"\" Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Args: eigenvector (np.ndarray): a numpy array representing the vector. Returns: A `numpy.ndarray` object of the same dimension as param `eigenvector`. \"\" \" try : return eigenvector / np . absolute ( eigenvector ) except RuntimeWarning : # In case of 0-division, we don't want `inf` values from numpy # Generate a random complex vector with same dimension (since `eigenvector` is of # dimension N * 1, `numpy.ndarray.size` method will give us N). # Remember to initialize a random real and imaginary part. logger . exception ( \"Encountered 0-division, trying normalization\" ) e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) while ( np . absolute ( e_vect @ eigenvector ) == 0 ) : # Guarantee that we don't fall back to this edge case. e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) return ( e_vect @ eigenvector / np . absolute ( e_vect @ eigenvector )). reshape ( ( 1 , self . space_dimension ) ) def reconstruct_complex_phases_evm ( self ) -> np . ndarray : \" \"\" Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: The complex form of the result as a 'numpy.ndarray' instance. \"\" \" logger . debug ( \"Getting complex phase results\" ) return self . get_eigenvector_estimator ( self . leading_eigenvector ) @staticmethod def convert_complex_result_to_phase_values ( complex_estimator : np . ndarray , deg : bool = False ) -> np . ndarray : \" \"\" Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A `numpy.ndarray` with the real phase values of the result. \"\" \" logger . debug ( \"Casting complex phases to real values\" ) return np . apply_along_axis ( np . angle , axis = 0 , arr = complex_estimator , deg = deg )","title":"PhaseReconstructor"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#convert_complex_result_to_phase_values","text":"def convert_complex_result_to_phase_values ( complex_estimator : numpy . ndarray , deg : bool = False ) -> numpy . ndarray Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A numpy.ndarray with the real phase values of the result. View Source @staticmethod def convert_complex_result_to_phase_values ( complex_estimator : np . ndarray , deg : bool = False ) -> np . ndarray : \"\"\" Casts back the complex form of your result to real phase values. Args: complex_estimator (np.ndarray): your result's complex form as a numpy array. deg (bool): if this is set to True, the result is cast to degrees (from radians) before being returned. Defaults to False. Returns: A `numpy.ndarray` with the real phase values of the result. \"\"\" logger . debug ( \"Casting complex phases to real values\" ) return np . apply_along_axis ( np . angle , axis = 0 , arr = complex_estimator , deg = deg )","title":"convert_complex_result_to_phase_values"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#instance-variables","text":"alpha This is a factor used to define the new reconstruction matrix. It is taken either as the operator norm of the hermitian noise matrix, or as the max value between 0 and the opposite of the min eigenvalue of c_matrix (chosen for implementation, since our noise is included in the measurements). See page 8 of the paper for reference. Returns: A real scalar value, because c_matrix is Hermitian and the eigenvalues of real symmetric or complex Hermitian matrices are always real (see G. Strang, Linear Algebra and Its Applications, 2 nd Ed., Orlando, FL, Academic Press, Inc., 1980, pg. 222.) c_matrix c_matrix_eigenvalues c_matrix_eigenvectors leading_eigenvector Returns the leading eigenvector of self.c_matrix , which is the eigenvector corresponding to the max eigenvalue (in absolute value). Returns: A numpy.ndarray object, corresponding to said eigenvector. reconstructor_matrix This is the reconstructor matrix built from self.c_matrix and the alpha property. It is the matrix denoted as \\widetilde{C} on page 8 of the reference paper. Returns: A numpy.ndarray , with same dimension as self.c_matrix . space_dimension","title":"Instance variables"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#methods","text":"","title":"Methods"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#get_eigenvector_estimator","text":"def get_eigenvector_estimator ( self , eigenvector : numpy . ndarray ) -> numpy . ndarray Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Args: eigenvector (np.ndarray): a numpy array representing the vector. Returns: A numpy.ndarray object of the same dimension as param eigenvector . View Source def get_eigenvector_estimator ( self , eigenvector : np . ndarray ) -> np . ndarray : \" \"\" Return the eigenvector estimator of a given eigenvector (id est the component-wise projection of said eigenvector onto \u2102\u02c6{n}_{1}, see reference paper at page 7 for implementation. Args: eigenvector (np.ndarray): a numpy array representing the vector. Returns: A `numpy.ndarray` object of the same dimension as param `eigenvector`. \"\" \" try : return eigenvector / np . absolute ( eigenvector ) except RuntimeWarning : # In case of 0-division, we don't want `inf` values from numpy # Generate a random complex vector with same dimension (since `eigenvector` is of # dimension N * 1, `numpy.ndarray.size` method will give us N). # Remember to initialize a random real and imaginary part. logger . exception ( \"Encountered 0-division, trying normalization\" ) e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) while ( np . absolute ( e_vect @ eigenvector ) == 0 ) : # Guarantee that we don't fall back to this edge case. e_vect = np . random . randn ( eigenvector . size ) + 1 j * np . random . randn ( eigenvector . size ) return ( e_vect @ eigenvector / np . absolute ( e_vect @ eigenvector )). reshape ( ( 1 , self . space_dimension ) )","title":"get_eigenvector_estimator"},{"location":"reference/pyhdtoolkit/maths/nonconvex_phase_sync/#reconstruct_complex_phases_evm","text":"def reconstruct_complex_phases_evm ( self ) -> numpy . ndarray Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: The complex form of the result as a 'numpy.ndarray' instance. View Source def reconstruct_complex_phases_evm ( self ) -> np . ndarray : \"\"\" Reconstruct simplest estimator fom the eigenvector method. The result is in complex form, and will be radians once cast back to real form. Returns: The complex form of the result as a 'numpy.ndarray' instance. \"\"\" logger . debug ( \"Getting complex phase results\" ) return self . get_eigenvector_estimator ( self . leading_eigenvector )","title":"reconstruct_complex_phases_evm"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/","text":"Module pyhdtoolkit.maths.stats_fitting Module maths.stats_fitting Created on 2020.02.06 :author: Felix Soubelet ( felix.soubelet@cern.ch ) This is a Python3 module implementing methods to find the best fit of statistical distributions to data. View Source \"\"\" Module maths.stats_fitting -------------------------- Created on 2020.02.06 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 module implementing methods to find the best fit of statistical distributions to data. \"\"\" import warnings from typing import Dict , Tuple , Union import matplotlib import numpy as np import pandas as pd import scipy.stats as st from loguru import logger # Distributions to check # DISTRIBUTIONS : Dict [ st . rv_continuous , str ] = { st . chi : \"Chi\" , st . chi2 : \"Chi-Square\" , st . expon : \"Exponential\" , st . laplace : \"Laplace\" , st . lognorm : \"LogNorm\" , st . norm : \"Normal\" , } def set_distributions_dict ( dist_dict : Dict [ st . rv_continuous , str ]) -> None : \"\"\" Sets DISTRIBUTIONS as the provided dict. This is useful to define only the ones you want to try out. Args: dist_dict Dict[st.rv_continuous, str]: dictionnary with the wanted distributions, in the format of DISTRIBUTIONS, aka scipy.stats generator objects as keys, and a string representation of their name as value. Returns: Nothing, but modifies the global DISTRIBUTIONS dict called by other functions. \"\"\" # pylint: disable=global-statement logger . debug ( \"Setting tested distributions\" ) global DISTRIBUTIONS DISTRIBUTIONS = dist_dict def best_fit_distribution ( data : Union [ pd . Series , np . ndarray ], bins : int = 200 , ax : matplotlib . axes . Axes = None ) -> Tuple [ st . rv_continuous , Tuple [ float , ... ]]: \"\"\" Model data by finding best fit candidate distribution among those in DISTRIBUTIONS. Args: data (Union[pd.Series, np.ndarray]): a pandas Series or numpy array with your distribution data. bins (int): the number of bins to decompose your data in before performing fittings. ax (matplotlib.axes.Axes): the matplotlib axis object on which to plot the pdf of tried functions. This should be provided as the ax on which you plotted your distribution. Returns: A tuple containing the scipy.stats generator corresponding to the best fit candidate, and the parameters to give said generator to get this fit. \"\"\" # pylint: disable=too-many-locals logger . debug ( f \"Getting histogram of original data, in { bins } bins\" ) y , x = np . histogram ( data , bins = bins , density = True ) x = ( x + np . roll ( x , - 1 ))[: - 1 ] / 2.0 logger . debug ( \"Creating initial guess\" ) best_distribution = st . norm best_params = ( 0.0 , 1.0 ) best_sse = np . inf # Estimate distribution parameters from data for distribution , distname in DISTRIBUTIONS . items (): try : with warnings . catch_warnings (): # Ignore warnings from data that can't be fit warnings . filterwarnings ( \"ignore\" ) logger . debug ( f \"Trying to fit distribution ' { distname } '\" ) params = distribution . fit ( data ) * args , loc , scale = params logger . debug ( f \"Calculating PDF goodness of fit and error for distribution ' { distname } '\" ) pdf = distribution . pdf ( x , loc = loc , scale = scale , * args ) sse = np . sum ( np . power ( y - pdf , 2.0 )) try : if ax : logger . debug ( f \"Plotting fitted PDF for distribution ' { distname } '\" ) pd . Series ( pdf , x ) . plot ( ax = ax , label = f \" { distname } fit\" , alpha = 1 , lw = 2 ) except Exception : logger . exception ( f \"Plotting distribution ' { distname } ' failed\" ) logger . debug ( f \"Identifying if distribution ' { distname } ' is a better fit than previous tries\" ) if best_sse > sse > 0 : best_distribution = distribution best_params = params best_sse = sse except Exception : logger . exception ( f \"Trying to fit distribution ' { distname } ' failed and aborted\" ) logger . info ( f \"Found a best fit: ' { DISTRIBUTIONS [ best_distribution ] } ' distribution\" ) return best_distribution , best_params def make_pdf ( distribution : st . rv_continuous , params : Tuple [ float , ... ], size : int = 25_000 ) -> pd . Series : \"\"\" Generate a pandas Series for the distributions's Probability Distribution Function. This Series will have axis values as index, and PDF values as values. Args: distribution (st.rv_continuous): a scipy.stats generator object params (Tuple[float, ...]): the parameters for this generator given back by the fit. size (int): the number of points to evaluate. Returns: A pandas Series object with the PDF as values, corresponding axis values as index. \"\"\" # Separate parts of parameters * args , loc , scale = params logger . debug ( \"Getting sane start and end points of distribution\" ) start = ( distribution . ppf ( 0.01 , * args , loc = loc , scale = scale ) if args else distribution . ppf ( 0.01 , loc = loc , scale = scale ) ) end = ( distribution . ppf ( 0.99 , * args , loc = loc , scale = scale ) if args else distribution . ppf ( 0.99 , loc = loc , scale = scale ) ) logger . debug ( \"Building PDF\" ) x = np . linspace ( start , end , size ) y = distribution . pdf ( x , loc = loc , scale = scale , * args ) return pd . Series ( y , x ) Variables DISTRIBUTIONS Functions best_fit_distribution def best_fit_distribution ( data : Union [ pandas . core . series . Series , numpy . ndarray ], bins : int = 200 , ax : matplotlib . axes . _axes . Axes = None ) -> Tuple [ scipy . stats . _distn_infrastructure . rv_continuous , Tuple [ float , ... ]] Model data by finding best fit candidate distribution among those in DISTRIBUTIONS. Args: data (Union[pd.Series, np.ndarray]): a pandas Series or numpy array with your distribution data. bins (int): the number of bins to decompose your data in before performing fittings. ax (matplotlib.axes.Axes): the matplotlib axis object on which to plot the pdf of tried functions. This should be provided as the ax on which you plotted your distribution. Returns: A tuple containing the scipy.stats generator corresponding to the best fit candidate, and the parameters to give said generator to get this fit. View Source def best_fit_distribution ( data : Union [ pd . Series , np . ndarray ], bins : int = 200 , ax : matplotlib . axes . Axes = None ) -> Tuple [ st . rv_continuous , Tuple [ float , ...]] : \"\"\" Model data by finding best fit candidate distribution among those in DISTRIBUTIONS. Args: data (Union[pd.Series, np.ndarray]): a pandas Series or numpy array with your distribution data. bins (int): the number of bins to decompose your data in before performing fittings. ax (matplotlib.axes.Axes): the matplotlib axis object on which to plot the pdf of tried functions. This should be provided as the ax on which you plotted your distribution. Returns: A tuple containing the scipy.stats generator corresponding to the best fit candidate, and the parameters to give said generator to get this fit. \"\"\" # pylint : disable = too - many - locals logger . debug ( f \"Getting histogram of original data, in {bins} bins\" ) y , x = np . histogram ( data , bins = bins , density = True ) x = ( x + np . roll ( x , - 1 ))[:- 1 ] / 2.0 logger . debug ( \"Creating initial guess\" ) best_distribution = st . norm best_params = ( 0.0 , 1.0 ) best_sse = np . inf # Estimate distribution parameters from data for distribution , distname in DISTRIBUTIONS . items () : try : with warnings . catch_warnings () : # Ignore warnings from data that can't be fit warnings.filterwarnings(\"ignore\") logger.debug(f\"Trying to fit distribution ' { distname } '\") params = distribution.fit(data) *args, loc, scale = params logger.debug( f\"Calculating PDF goodness of fit and error for distribution ' { distname } '\" ) pdf = distribution.pdf(x, loc=loc, scale=scale, *args) sse = np.sum(np.power(y - pdf, 2.0)) try: if ax: logger.debug(f\"Plotting fitted PDF for distribution ' { distname } '\") pd.Series(pdf, x).plot(ax=ax, label=f\"{distname} fit\", alpha=1, lw=2) except Exception: logger.exception(f\"Plotting distribution ' { distname } ' failed\") logger.debug( f\"Identifying if distribution ' { distname } ' is a better fit than previous tries\" ) if best_sse > sse > 0: best_distribution = distribution best_params = params best_sse = sse except Exception: logger.exception(f\"Trying to fit distribution ' { distname } ' failed and aborted\") logger.info(f\"Found a best fit: ' { DISTRIBUTIONS [ best_distribution ]} ' distribution \" ) return best_distribution , best_params make_pdf def make_pdf ( distribution : scipy . stats . _distn_infrastructure . rv_continuous , params : Tuple [ float , ... ], size : int = 25000 ) -> pandas . core . series . Series Generate a pandas Series for the distributions's Probability Distribution Function. This Series will have axis values as index, and PDF values as values. Args: distribution (st.rv_continuous): a scipy.stats generator object params (Tuple[float, ...]): the parameters for this generator given back by the fit. size (int): the number of points to evaluate. Returns: A pandas Series object with the PDF as values, corresponding axis values as index. View Source def make_pdf ( distribution : st . rv_continuous , params : Tuple [ float , ...], size : int = 25 _000 ) -> pd . Series : \"\"\" Generate a pandas Series for the distributions's Probability Distribution Function. This Series will have axis values as index, and PDF values as values. Args: distribution (st.rv_continuous): a scipy.stats generator object params (Tuple[float, ...]): the parameters for this generator given back by the fit. size (int): the number of points to evaluate. Returns: A pandas Series object with the PDF as values, corresponding axis values as index. \"\"\" # Separate parts of parameters * args , loc , scale = params logger . debug ( \"Getting sane start and end points of distribution\" ) start = ( distribution . ppf ( 0 . 01 , * args , loc = loc , scale = scale ) if args else distribution . ppf ( 0 . 01 , loc = loc , scale = scale ) ) end = ( distribution . ppf ( 0 . 99 , * args , loc = loc , scale = scale ) if args else distribution . ppf ( 0 . 99 , loc = loc , scale = scale ) ) logger . debug ( \"Building PDF\" ) x = np . linspace ( start , end , size ) y = distribution . pdf ( x , loc = loc , scale = scale , * args ) return pd . Series ( y , x ) set_distributions_dict def set_distributions_dict ( dist_dict : Dict [ scipy . stats . _distn_infrastructure . rv_continuous , str ] ) -> None Sets DISTRIBUTIONS as the provided dict. This is useful to define only the ones you want to try out. Args: dist_dict Dict[st.rv_continuous, str]: dictionnary with the wanted distributions, in the format of DISTRIBUTIONS, aka scipy.stats generator objects as keys, and a string representation of their name as value. Returns: Nothing, but modifies the global DISTRIBUTIONS dict called by other functions. View Source def set_distributions_dict ( dist_dict : Dict [ st . rv_continuous , str ]) -> None : \"\"\" Sets DISTRIBUTIONS as the provided dict. This is useful to define only the ones you want to try out. Args: dist_dict Dict[st.rv_continuous, str]: dictionnary with the wanted distributions, in the format of DISTRIBUTIONS, aka scipy.stats generator objects as keys, and a string representation of their name as value. Returns: Nothing, but modifies the global DISTRIBUTIONS dict called by other functions. \"\"\" # pylint : disable = global - statement logger . debug ( \"Setting tested distributions\" ) global DISTRIBUTIONS DISTRIBUTIONS = dist_dict","title":"Stats Fitting"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/#module-pyhdtoolkitmathsstats_fitting","text":"","title":"Module pyhdtoolkit.maths.stats_fitting"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/#module-mathsstats_fitting","text":"Created on 2020.02.06 :author: Felix Soubelet ( felix.soubelet@cern.ch ) This is a Python3 module implementing methods to find the best fit of statistical distributions to data. View Source \"\"\" Module maths.stats_fitting -------------------------- Created on 2020.02.06 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 module implementing methods to find the best fit of statistical distributions to data. \"\"\" import warnings from typing import Dict , Tuple , Union import matplotlib import numpy as np import pandas as pd import scipy.stats as st from loguru import logger # Distributions to check # DISTRIBUTIONS : Dict [ st . rv_continuous , str ] = { st . chi : \"Chi\" , st . chi2 : \"Chi-Square\" , st . expon : \"Exponential\" , st . laplace : \"Laplace\" , st . lognorm : \"LogNorm\" , st . norm : \"Normal\" , } def set_distributions_dict ( dist_dict : Dict [ st . rv_continuous , str ]) -> None : \"\"\" Sets DISTRIBUTIONS as the provided dict. This is useful to define only the ones you want to try out. Args: dist_dict Dict[st.rv_continuous, str]: dictionnary with the wanted distributions, in the format of DISTRIBUTIONS, aka scipy.stats generator objects as keys, and a string representation of their name as value. Returns: Nothing, but modifies the global DISTRIBUTIONS dict called by other functions. \"\"\" # pylint: disable=global-statement logger . debug ( \"Setting tested distributions\" ) global DISTRIBUTIONS DISTRIBUTIONS = dist_dict def best_fit_distribution ( data : Union [ pd . Series , np . ndarray ], bins : int = 200 , ax : matplotlib . axes . Axes = None ) -> Tuple [ st . rv_continuous , Tuple [ float , ... ]]: \"\"\" Model data by finding best fit candidate distribution among those in DISTRIBUTIONS. Args: data (Union[pd.Series, np.ndarray]): a pandas Series or numpy array with your distribution data. bins (int): the number of bins to decompose your data in before performing fittings. ax (matplotlib.axes.Axes): the matplotlib axis object on which to plot the pdf of tried functions. This should be provided as the ax on which you plotted your distribution. Returns: A tuple containing the scipy.stats generator corresponding to the best fit candidate, and the parameters to give said generator to get this fit. \"\"\" # pylint: disable=too-many-locals logger . debug ( f \"Getting histogram of original data, in { bins } bins\" ) y , x = np . histogram ( data , bins = bins , density = True ) x = ( x + np . roll ( x , - 1 ))[: - 1 ] / 2.0 logger . debug ( \"Creating initial guess\" ) best_distribution = st . norm best_params = ( 0.0 , 1.0 ) best_sse = np . inf # Estimate distribution parameters from data for distribution , distname in DISTRIBUTIONS . items (): try : with warnings . catch_warnings (): # Ignore warnings from data that can't be fit warnings . filterwarnings ( \"ignore\" ) logger . debug ( f \"Trying to fit distribution ' { distname } '\" ) params = distribution . fit ( data ) * args , loc , scale = params logger . debug ( f \"Calculating PDF goodness of fit and error for distribution ' { distname } '\" ) pdf = distribution . pdf ( x , loc = loc , scale = scale , * args ) sse = np . sum ( np . power ( y - pdf , 2.0 )) try : if ax : logger . debug ( f \"Plotting fitted PDF for distribution ' { distname } '\" ) pd . Series ( pdf , x ) . plot ( ax = ax , label = f \" { distname } fit\" , alpha = 1 , lw = 2 ) except Exception : logger . exception ( f \"Plotting distribution ' { distname } ' failed\" ) logger . debug ( f \"Identifying if distribution ' { distname } ' is a better fit than previous tries\" ) if best_sse > sse > 0 : best_distribution = distribution best_params = params best_sse = sse except Exception : logger . exception ( f \"Trying to fit distribution ' { distname } ' failed and aborted\" ) logger . info ( f \"Found a best fit: ' { DISTRIBUTIONS [ best_distribution ] } ' distribution\" ) return best_distribution , best_params def make_pdf ( distribution : st . rv_continuous , params : Tuple [ float , ... ], size : int = 25_000 ) -> pd . Series : \"\"\" Generate a pandas Series for the distributions's Probability Distribution Function. This Series will have axis values as index, and PDF values as values. Args: distribution (st.rv_continuous): a scipy.stats generator object params (Tuple[float, ...]): the parameters for this generator given back by the fit. size (int): the number of points to evaluate. Returns: A pandas Series object with the PDF as values, corresponding axis values as index. \"\"\" # Separate parts of parameters * args , loc , scale = params logger . debug ( \"Getting sane start and end points of distribution\" ) start = ( distribution . ppf ( 0.01 , * args , loc = loc , scale = scale ) if args else distribution . ppf ( 0.01 , loc = loc , scale = scale ) ) end = ( distribution . ppf ( 0.99 , * args , loc = loc , scale = scale ) if args else distribution . ppf ( 0.99 , loc = loc , scale = scale ) ) logger . debug ( \"Building PDF\" ) x = np . linspace ( start , end , size ) y = distribution . pdf ( x , loc = loc , scale = scale , * args ) return pd . Series ( y , x )","title":"Module maths.stats_fitting"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/#variables","text":"DISTRIBUTIONS","title":"Variables"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/#best_fit_distribution","text":"def best_fit_distribution ( data : Union [ pandas . core . series . Series , numpy . ndarray ], bins : int = 200 , ax : matplotlib . axes . _axes . Axes = None ) -> Tuple [ scipy . stats . _distn_infrastructure . rv_continuous , Tuple [ float , ... ]] Model data by finding best fit candidate distribution among those in DISTRIBUTIONS. Args: data (Union[pd.Series, np.ndarray]): a pandas Series or numpy array with your distribution data. bins (int): the number of bins to decompose your data in before performing fittings. ax (matplotlib.axes.Axes): the matplotlib axis object on which to plot the pdf of tried functions. This should be provided as the ax on which you plotted your distribution. Returns: A tuple containing the scipy.stats generator corresponding to the best fit candidate, and the parameters to give said generator to get this fit. View Source def best_fit_distribution ( data : Union [ pd . Series , np . ndarray ], bins : int = 200 , ax : matplotlib . axes . Axes = None ) -> Tuple [ st . rv_continuous , Tuple [ float , ...]] : \"\"\" Model data by finding best fit candidate distribution among those in DISTRIBUTIONS. Args: data (Union[pd.Series, np.ndarray]): a pandas Series or numpy array with your distribution data. bins (int): the number of bins to decompose your data in before performing fittings. ax (matplotlib.axes.Axes): the matplotlib axis object on which to plot the pdf of tried functions. This should be provided as the ax on which you plotted your distribution. Returns: A tuple containing the scipy.stats generator corresponding to the best fit candidate, and the parameters to give said generator to get this fit. \"\"\" # pylint : disable = too - many - locals logger . debug ( f \"Getting histogram of original data, in {bins} bins\" ) y , x = np . histogram ( data , bins = bins , density = True ) x = ( x + np . roll ( x , - 1 ))[:- 1 ] / 2.0 logger . debug ( \"Creating initial guess\" ) best_distribution = st . norm best_params = ( 0.0 , 1.0 ) best_sse = np . inf # Estimate distribution parameters from data for distribution , distname in DISTRIBUTIONS . items () : try : with warnings . catch_warnings () : # Ignore warnings from data that can't be fit warnings.filterwarnings(\"ignore\") logger.debug(f\"Trying to fit distribution ' { distname } '\") params = distribution.fit(data) *args, loc, scale = params logger.debug( f\"Calculating PDF goodness of fit and error for distribution ' { distname } '\" ) pdf = distribution.pdf(x, loc=loc, scale=scale, *args) sse = np.sum(np.power(y - pdf, 2.0)) try: if ax: logger.debug(f\"Plotting fitted PDF for distribution ' { distname } '\") pd.Series(pdf, x).plot(ax=ax, label=f\"{distname} fit\", alpha=1, lw=2) except Exception: logger.exception(f\"Plotting distribution ' { distname } ' failed\") logger.debug( f\"Identifying if distribution ' { distname } ' is a better fit than previous tries\" ) if best_sse > sse > 0: best_distribution = distribution best_params = params best_sse = sse except Exception: logger.exception(f\"Trying to fit distribution ' { distname } ' failed and aborted\") logger.info(f\"Found a best fit: ' { DISTRIBUTIONS [ best_distribution ]} ' distribution \" ) return best_distribution , best_params","title":"best_fit_distribution"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/#make_pdf","text":"def make_pdf ( distribution : scipy . stats . _distn_infrastructure . rv_continuous , params : Tuple [ float , ... ], size : int = 25000 ) -> pandas . core . series . Series Generate a pandas Series for the distributions's Probability Distribution Function. This Series will have axis values as index, and PDF values as values. Args: distribution (st.rv_continuous): a scipy.stats generator object params (Tuple[float, ...]): the parameters for this generator given back by the fit. size (int): the number of points to evaluate. Returns: A pandas Series object with the PDF as values, corresponding axis values as index. View Source def make_pdf ( distribution : st . rv_continuous , params : Tuple [ float , ...], size : int = 25 _000 ) -> pd . Series : \"\"\" Generate a pandas Series for the distributions's Probability Distribution Function. This Series will have axis values as index, and PDF values as values. Args: distribution (st.rv_continuous): a scipy.stats generator object params (Tuple[float, ...]): the parameters for this generator given back by the fit. size (int): the number of points to evaluate. Returns: A pandas Series object with the PDF as values, corresponding axis values as index. \"\"\" # Separate parts of parameters * args , loc , scale = params logger . debug ( \"Getting sane start and end points of distribution\" ) start = ( distribution . ppf ( 0 . 01 , * args , loc = loc , scale = scale ) if args else distribution . ppf ( 0 . 01 , loc = loc , scale = scale ) ) end = ( distribution . ppf ( 0 . 99 , * args , loc = loc , scale = scale ) if args else distribution . ppf ( 0 . 99 , loc = loc , scale = scale ) ) logger . debug ( \"Building PDF\" ) x = np . linspace ( start , end , size ) y = distribution . pdf ( x , loc = loc , scale = scale , * args ) return pd . Series ( y , x )","title":"make_pdf"},{"location":"reference/pyhdtoolkit/maths/stats_fitting/#set_distributions_dict","text":"def set_distributions_dict ( dist_dict : Dict [ scipy . stats . _distn_infrastructure . rv_continuous , str ] ) -> None Sets DISTRIBUTIONS as the provided dict. This is useful to define only the ones you want to try out. Args: dist_dict Dict[st.rv_continuous, str]: dictionnary with the wanted distributions, in the format of DISTRIBUTIONS, aka scipy.stats generator objects as keys, and a string representation of their name as value. Returns: Nothing, but modifies the global DISTRIBUTIONS dict called by other functions. View Source def set_distributions_dict ( dist_dict : Dict [ st . rv_continuous , str ]) -> None : \"\"\" Sets DISTRIBUTIONS as the provided dict. This is useful to define only the ones you want to try out. Args: dist_dict Dict[st.rv_continuous, str]: dictionnary with the wanted distributions, in the format of DISTRIBUTIONS, aka scipy.stats generator objects as keys, and a string representation of their name as value. Returns: Nothing, but modifies the global DISTRIBUTIONS dict called by other functions. \"\"\" # pylint : disable = global - statement logger . debug ( \"Setting tested distributions\" ) global DISTRIBUTIONS DISTRIBUTIONS = dist_dict","title":"set_distributions_dict"},{"location":"reference/pyhdtoolkit/optics/","text":"Module pyhdtoolkit.optics optics package ~ ~ ~ ~ ~~ These are miscellaneous utilities to perform optics calculation from simulation outputs. :copyright: \u00a9 2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. View Source \"\"\" optics package ~~~~~~~~~~~~~~ These are miscellaneous utilities to perform optics calculation from simulation outputs. :copyright: (c) 2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .amplitude_detuning import HorizontalAmplitudeDetuning , VerticalAmplitudeDetuning Sub-modules pyhdtoolkit.optics.amplitude_detuning pyhdtoolkit.optics.beam pyhdtoolkit.optics.twiss","title":"Index"},{"location":"reference/pyhdtoolkit/optics/#module-pyhdtoolkitoptics","text":"optics package ~ ~ ~ ~ ~~ These are miscellaneous utilities to perform optics calculation from simulation outputs. :copyright: \u00a9 2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. View Source \"\"\" optics package ~~~~~~~~~~~~~~ These are miscellaneous utilities to perform optics calculation from simulation outputs. :copyright: (c) 2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .amplitude_detuning import HorizontalAmplitudeDetuning , VerticalAmplitudeDetuning","title":"Module pyhdtoolkit.optics"},{"location":"reference/pyhdtoolkit/optics/#sub-modules","text":"pyhdtoolkit.optics.amplitude_detuning pyhdtoolkit.optics.beam pyhdtoolkit.optics.twiss","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/","text":"Module pyhdtoolkit.optics.amplitude_detuning Module optics.amplitude_detuning Created on 2020.08.13 :author: Felix Soubelet ( felix.soubelet@cern.ch ) This is a Python3 module implementing classes for amplitude detuning calculations after loading twiss output files from MAD. This module is a heavy refactor of initial code & formulas by @leonvanriesen Example usage: hor_amp_det = HorizontalAmplitudeDetuning(twiss_filename=\"mad_twiss_output.tfs\") hor_amp_det.d2qx_djx2() hor_amp_det.dqx_from_skew_quadrupoles() View Source \"\"\" Module optics.amplitude_detuning -------------------------------- Created on 2020.08.13 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 module implementing classes for amplitude detuning calculations after loading twiss output files from MAD. This module is a heavy refactor of initial code & formulas by @leonvanriesen Example usage: hor_amp_det = HorizontalAmplitudeDetuning(twiss_filename=\"mad_twiss_output.tfs\") hor_amp_det.d2qx_djx2() hor_amp_det.dqx_from_skew_quadrupoles() \"\"\" from pathlib import Path from typing import Union import numba import numpy as np import tfs from loguru import logger class HorizontalAmplitudeDetuning : \"\"\" Class to compute different orders of amplitude detuning for the horizontal plane. \"\"\" __slots__ = { \"twiss_file\" : \"PosixPath object to the twiss output tfs file\" , \"twiss_df\" : \"TfsDataFrame loaded from twiss_file\" , \"qx\" : \"Horizontal tune extracted from twiss_df\" , \"qy\" : \"Vertical tune extracted from twiss_df\" , \"quadrupoles_twiss_df\" : \"Twiss dataframe for normal quadrupoles\" , \"skew_quadrupoles_twiss_df\" : \"Twiss dataframe for skew quadrupoles\" , \"sextupoles_twiss_df\" : \"Twiss dataframe for normal sextupoles\" , \"skew_sextupoles_twiss_df\" : \"Twiss dataframe for skew sextupoles\" , \"octupoles_twiss_df\" : \"Twiss dataframe for normal octupoles\" , \"skew_octupoles_twiss_df\" : \"Twiss dataframe for skew octupoles\" , } def __init__ ( self , twiss_filename : Union [ Path , str ]) -> None : \"\"\" Load external twiss file and extract relevant values and dataframes. Args: twiss_filename (Union[Path, str]): location to the twiss file output by MAD, in the tfs format, to be read by the tfs package, which accepts either a Path or a string. \"\"\" logger . debug ( \"Loading twiss file into memory and extracting sub-dataframes\" ) self . twiss_file : Path = Path ( twiss_filename ) self . twiss_df : tfs . TfsDataFrame = tfs . read ( twiss_filename ) self . qx : float = self . twiss_df [ \"MUX\" ] . values [ - 1 ] self . qy : float = self . twiss_df [ \"MUY\" ] . values [ - 1 ] logger . trace ( \"Extracting quadrupoles dataframe\" ) self . quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1L\" ] != 0 ] logger . trace ( \"Extracting skew quadrupoles dataframe\" ) self . skew_quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1SL\" ] != 0 ] logger . trace ( \"Extracting sextupoles dataframe\" ) self . sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2L\" ] != 0 ] logger . trace ( \"Extracting skew sextupoles dataframe\" ) self . skew_sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2SL\" ] != 0 ] logger . trace ( \"Extracting octupoles dataframe\" ) self . octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3L\" ] != 0 ] logger . trace ( \"Extracting skew octupoles dataframe\" ) self . skew_octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3SL\" ] != 0 ] def __str__ ( self ): \"\"\"Simple str method indicates the name\"\"\" return f \"HorAmpDet[' { self . twiss_file . name } ']\" def __repr__ ( self ): \"\"\"The repr method indicates tunes\"\"\" return ( f \"'HorizontalAmplitudeDetuning[ { self . twiss_file . absolute () } ' | \" f \"Qx = { self . qx : .4f } | Qy = { self . qy : .4f } ]\" ) def dqx_djx_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 4 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_djx_from_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 3 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_djx ( self ) -> float : \"\"\" Returns the first order horizontal direct-term amplitude detuning. Returns: The first order horizontal direct-term amplitude detuning. \"\"\" return self . dqx_djx_from_skew_sextupoles () + self . dqx_djx_from_sextupoles () def d2qx_djx2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal direct-term amplitude detuning from skew octupoles. Returns: The second order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( 2 * 1 ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( 2 * 1 ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djx2_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal direct-term amplitude detuning from octupoles. Returns: The second order horizontal direct-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 4 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djx2 ( self ) -> float : \"\"\" Returns the second order horizontal direct-term amplitude detuning. Returns: The second order horizontal direct-term amplitude detuning. \"\"\" return self . d2qx_djx2_from_skew_octupoles () + self . d2qx_djx2_from_octupoles () def dqx_djy_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal cross-term amplitude detuning from skew sextupoles. Returns: The first order horizontal cross-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( 2 * 1 ) * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( - 2 * 1 ) * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_djy_from_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal cross-term amplitude detuning from sextupoles. Returns: The first order horizontal cross-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 2 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvx / ( 2 * np . pi ) def dqx_djy ( self ) -> float : \"\"\" Returns the first order horizontal cross-term amplitude detuning. Returns: The first order horizontal cross-term amplitude detuning. \"\"\" return self . dqx_djy_from_skew_sextupoles () + self . dqx_djy_from_sextupoles () def d2qx_djy2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal cross-term amplitude detuning from skew octupoles. Returns: The second order horizontal cross-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * ( T ( 1 , - 3 , dmux , dmuy , qx , qy ) - T ( 1 , 3 , dmux , dmuy , qx , qy )) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djy2_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal cross-term amplitude detuning from octupoles. Returns: The second order horizontal cross-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djy2 ( self ) -> float : \"\"\" Returns the second order horizontal cross-term amplitude detuning. Returns: The second order horizontal cross-term amplitude detuning. \"\"\" return self . d2qx_djy2_from_skew_octupoles () + self . d2qx_djy2_from_octupoles () def d2qx_djxdjy_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal mixed-term amplitude detuning from skew octupoles. Returns: The second order horizontal mixed-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( 6 * 1 * 1 ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( - 6 * 1 * 1 ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djxdjy_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal mixed-term amplitude detuning from octupoles. Returns: The second order horizontal mixed-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * 1 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djxdjy ( self ) -> float : \"\"\" Returns the second order horizontal mixed-term amplitude detuning. Returns: The second order horizontal mixed-term amplitude detuning. \"\"\" return self . d2qx_djxdjy_from_skew_octupoles () + self . d2qx_djxdjy_from_octupoles () def dqx_from_skew_quadrupoles ( self ) -> float : \"\"\" Get the horizontal amplitude detuning from skew quadrupoles. Returns: The horizontals amplitude detuning from skew quadrupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 betas_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUY\" ] . values a1 : np . ndarray = self . skew_quadrupoles_twiss_df [ \"K1SL\" ] . values for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a1 [ j ] * a1 [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * ( T ( 1 , - 1 , dmux , dmuy , qx , qy ) - T ( 1 , 1 , dmux , dmuy , qx , qy )) ) return dvx / ( 2 * np . pi ) def dqx_from_skew_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 4 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jx * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jy * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( jx + 2 * jy ) * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( jx - 2 * jy ) * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_from_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jx * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_x [ k ] * betas_y [ j ] * jy * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jx * T ( 3 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 2 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jy * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvx / ( 2 * np . pi ) def dqx_from_skew_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from skew octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * ( T ( 1 , - 3 , dmux , dmuy , qx , qy ) - T ( 1 , 3 , dmux , dmuy , qx , qy )) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( jx * jx + 6 * jx * jy ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( jx * jx - 6 * jx * jy ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_from_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy + jy * jy ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy - jy * jy ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jx * jx * T ( 4 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * jy * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * jx * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jx * jx * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx ( self , jx : float , jy : float ) -> float : \"\"\" Returns the horizontal amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning. \"\"\" return ( self . dqx_from_skew_quadrupoles () + self . dqx_from_skew_sextupoles ( jx , jy ) + self . dqx_from_sextupoles ( jx , jy ) + self . dqx_from_skew_octupoles ( jx , jy ) + self . dqx_from_octupoles ( jx , jy ) ) class VerticalAmplitudeDetuning : \"\"\" Class to compute different orders of amplitude detuning for the vertical plane. \"\"\" __slots__ = { \"twiss_file\" : \"PosixPath object to the twiss output tfs file\" , \"twiss_df\" : \"TfsDataFrame loaded from twiss_file\" , \"qx\" : \"Horizontal tune extracted from twiss_df\" , \"qy\" : \"Vertical tune extracted from twiss_df\" , \"quadrupoles_twiss_df\" : \"Twiss dataframe for normal quadrupoles\" , \"skew_quadrupoles_twiss_df\" : \"Twiss dataframe for skew quadrupoles\" , \"sextupoles_twiss_df\" : \"Twiss dataframe for normal sextupoles\" , \"skew_sextupoles_twiss_df\" : \"Twiss dataframe for skew sextupoles\" , \"octupoles_twiss_df\" : \"Twiss dataframe for normal octupoles\" , \"skew_octupoles_twiss_df\" : \"Twiss dataframe for skew octupoles\" , } def __init__ ( self , twiss_filename : Union [ Path , str ]) -> None : \"\"\" Load external twiss file and extract relevant values and dataframes. Args: twiss_filename (Union[Path, str]): location to the twiss file output by MAD, in the tfs format, to be read by the tfs package, which accepts either a Path or a string. \"\"\" logger . debug ( \"Loading twiss file into memory and extracting sub-dataframes\" ) self . twiss_file : Path = Path ( twiss_filename ) self . twiss_df : tfs . TfsDataFrame = tfs . read ( twiss_filename ) self . qx : float = self . twiss_df [ \"MUX\" ] . values [ - 1 ] self . qy : float = self . twiss_df [ \"MUY\" ] . values [ - 1 ] logger . trace ( \"Extracting quadrupoles dataframe\" ) self . quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1L\" ] != 0 ] logger . trace ( \"Extracting skew quadrupoles dataframe\" ) self . skew_quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1SL\" ] != 0 ] logger . trace ( \"Extracting sextupoles dataframe\" ) self . sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2L\" ] != 0 ] logger . trace ( \"Extracting skew sextupoles dataframe\" ) self . skew_sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2SL\" ] != 0 ] logger . trace ( \"Extracting octupoles dataframe\" ) self . octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3L\" ] != 0 ] logger . trace ( \"Extracting skew octupoles dataframe\" ) self . skew_octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3SL\" ] != 0 ] def __str__ ( self ): \"\"\"Simple str method indicates the name\"\"\" return f \"VertAmpDet[' { self . twiss_file . name } ']\" def __repr__ ( self ): \"\"\"The repr method indicates tunes\"\"\" return ( f \"'VerticalAmplitudeDetuning[ { self . twiss_file . absolute () } ' | \" f \"Qx = { self . qx : .4f } | Qy = { self . qy : .4f } ]\" ) def dqy_djx_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order vertical cross-term amplitude detuning from skew sextupoles. Returns: The first order vertical cross-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 2 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * ( T ( 2 , - 1 , dmux , dmuy , qx , qy ) - T ( 2 , 1 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_djx_from_sextupoles ( self ) -> float : \"\"\" Get the first order vertical cross-term amplitude detuning from sextupoles. Returns: The first order vertical cross-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * betas_x [ k ] * betas_y [ j ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * 1 ) * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * 1 ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_djx ( self ) -> float : \"\"\" Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. \"\"\" return self . dqy_djx_from_skew_sextupoles () + self . dqy_djx_from_sextupoles () def d2qy_djx2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical cross-term amplitude detuning from skew octupoles. Returns: The second order vertical cross-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETy\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * ( T ( 3 , - 1 , dmux , dmuy , qx , qy ) + T ( 3 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djx2_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical cross-term amplitude detuning from octupoles. Returns: The second order vertical cross-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_x [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_y [ j ] * betas_x [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djx2 ( self ) -> float : \"\"\" Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. \"\"\" return self . d2qy_djx2_from_skew_octupoles () + self . d2qy_djx2_from_octupoles () def dqy_djy_skew_sextupoles ( self ) -> float : \"\"\" Get the first order vertical direct-term amplitude detuning from skew sextupoles. Returns: The first order vertical direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 3 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 3 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy_djy_from_sextupoles ( self ) -> float : \"\"\" Get the first order vertical direct-term amplitude detuning from sextupoles. Returns: The first order vertical direct-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_y [ k ] * betas_y [ j ] * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( - 1 ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_djy ( self ) -> float : \"\"\" Returns the first order vertical direct-term amplitude detuning. Returns: The first order vertical direct-term amplitude detuning. \"\"\" return self . dqy_djy_skew_sextupoles () + self . dqy_djy_from_sextupoles () def d2qy_djy2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical direct-term amplitude detuning from skew octupoles. Returns: The second order vertical direct-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djy2_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical direct-term amplitude detuning from octupoles. Returns: The second order vertical direct-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 0 , 4 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_y [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djy2 ( self ) -> float : \"\"\" Returns the second order vertical direct-term amplitude detuning. Returns: The second order vertical direct-term amplitude detuning. \"\"\" return self . d2qy_djy2_from_skew_octupoles () + self . d2qy_djy2_from_octupoles () def d2qy_djxdjy_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical mixed-term amplitude detuning from skew octupoles. Returns: The second order vertical mixed-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * 1 * 1 ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * 1 * 1 ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djxdjy_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical mixed-term amplitude detuning from octupoles. Returns: The second order vertical mixed-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_y [ k ] * betas_y [ j ] * betas_y [ k ] * 1 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djxdjy ( self ) -> float : \"\"\" Returns the second order vertical mixed-term amplitude detuning. Returns: The second order vertical mixed-term amplitude detuning. \"\"\" return self . d2qy_djxdjy_from_skew_octupoles () + self . d2qy_djxdjy_from_octupoles () def dqy_from_skew_quadrupoles ( self ) -> float : \"\"\" Get the vertical amplitude detuning from skew quadrupoles. Returns: The vertical amplitude detuning from skew quadrupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUY\" ] . values a1 : np . ndarray = self . skew_quadrupoles_twiss_df [ \"K1SL\" ] . values for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a1 [ j ] * a1 [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * ( T ( 1 , - 1 , dmux , dmuy , qx , qy ) + T ( 1 , 1 , dmux , dmuy , qx , qy )) ) return dvy / ( 2 * np . pi ) def dqy_from_skew_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jx * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 3 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jy * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 2 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jx * ( T ( 2 , - 1 , dmux , dmuy , qx , qy ) - T ( 2 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jy * T ( 0 , 3 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy_from_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * betas_x [ k ] * betas_y [ j ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jx * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_y [ k ] * betas_y [ j ] * jy * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * jx + jy ) * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * jx - jy ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_from_skew_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from skew octupoles. jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * ( T ( 3 , - 1 , dmux , dmuy , qx , qy ) + T ( 3 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * jx * jy + jy * jy ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * jx * jy - jy * jy ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy_from_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy + jx * jx ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy - jx * jx ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jy * jy * T ( 0 , 4 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_y [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * jy * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_y [ k ] * betas_y [ j ] * betas_y [ k ] * jx * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_x [ k ] * jx * jx * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_y [ j ] * betas_x [ k ] * betas_y [ k ] * jx * jx * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy ( self , jx : float , jy : float ) -> float : \"\"\" Returns the vertical amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning. \"\"\" return ( self . dqy_from_skew_quadrupoles () + self . dqy_from_skew_sextupoles ( jx , jy ) + self . dqy_from_sextupoles ( jx , jy ) + self . dqy_from_skew_octupoles ( jx , jy ) + self . dqy_from_octupoles ( jx , jy ) ) # -------- Math function -------- # @numba . njit () def T ( nx , ny , dmux : float , dmuy : float , qx : float , qy : float ) -> float : \"\"\" The T-function defined in eq. 3.55 of the 'Analytical Calculations of Smear and Tune Shift' paper (https://lss.fnal.gov/archive/other/ssc/ssc-232.pdf) Args: nx (int): first element of the T function's power. ny (int): second element of the T function's power. dmux (float): horizontal phase advance. dmuy (float): vertical phase advance. qx (float): horizontal tune. qy (float): vertical tune. Returns: T parameter. \"\"\" return np . cos ( 2 * np . pi * ( nx * ( np . abs ( dmux ) - qx / 2 ) + ny * ( np . abs ( dmuy ) - qy / 2 )) ) / np . sin ( np . pi * ( nx * qx + ny * qy )) Functions T def T ( nx , ny , dmux : float , dmuy : float , qx : float , qy : float ) -> float The T-function defined in eq. 3.55 of the 'Analytical Calculations of Smear and Tune Shift' paper ( https://lss.fnal.gov/archive/other/ssc/ssc-232.pdf ) Args: nx (int): first element of the T function's power. ny (int): second element of the T function's power. dmux (float): horizontal phase advance. dmuy (float): vertical phase advance. qx (float): horizontal tune. qy (float): vertical tune. Returns: T parameter. View Source @numba . njit () def T ( nx , ny , dmux : float , dmuy : float , qx : float , qy : float ) -> float : \"\"\" The T-function defined in eq. 3.55 of the 'Analytical Calculations of Smear and Tune Shift' paper (https://lss.fnal.gov/archive/other/ssc/ssc-232.pdf) Args: nx (int): first element of the T function's power. ny (int): second element of the T function's power. dmux (float): horizontal phase advance. dmuy (float): vertical phase advance. qx (float): horizontal tune. qy (float): vertical tune. Returns: T parameter. \"\"\" return np . cos ( 2 * np . pi * ( nx * ( np . abs ( dmux ) - qx / 2 ) + ny * ( np . abs ( dmuy ) - qy / 2 )) ) / np . sin ( np . pi * ( nx * qx + ny * qy )) Classes HorizontalAmplitudeDetuning class HorizontalAmplitudeDetuning ( twiss_filename : Union [ pathlib . Path , str ] ) Class to compute different orders of amplitude detuning for the horizontal plane. View Source class HorizontalAmplitudeDetuning : \"\"\" Class to compute different orders of amplitude detuning for the horizontal plane. \"\"\" __slots__ = { \"twiss_file\" : \"PosixPath object to the twiss output tfs file\" , \"twiss_df\" : \"TfsDataFrame loaded from twiss_file\" , \"qx\" : \"Horizontal tune extracted from twiss_df\" , \"qy\" : \"Vertical tune extracted from twiss_df\" , \"quadrupoles_twiss_df\" : \"Twiss dataframe for normal quadrupoles\" , \"skew_quadrupoles_twiss_df\" : \"Twiss dataframe for skew quadrupoles\" , \"sextupoles_twiss_df\" : \"Twiss dataframe for normal sextupoles\" , \"skew_sextupoles_twiss_df\" : \"Twiss dataframe for skew sextupoles\" , \"octupoles_twiss_df\" : \"Twiss dataframe for normal octupoles\" , \"skew_octupoles_twiss_df\" : \"Twiss dataframe for skew octupoles\" , } def __init__ ( self , twiss_filename : Union [ Path , str ]) -> None : \"\"\" Load external twiss file and extract relevant values and dataframes. Args: twiss_filename (Union[Path, str]): location to the twiss file output by MAD, in the tfs format, to be read by the tfs package, which accepts either a Path or a string. \"\"\" logger . debug ( \"Loading twiss file into memory and extracting sub-dataframes\" ) self . twiss_file : Path = Path ( twiss_filename ) self . twiss_df : tfs . TfsDataFrame = tfs . read ( twiss_filename ) self . qx : float = self . twiss_df [ \"MUX\" ] . values [ - 1 ] self . qy : float = self . twiss_df [ \"MUY\" ] . values [ - 1 ] logger . trace ( \"Extracting quadrupoles dataframe\" ) self . quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1L\" ] != 0 ] logger . trace ( \"Extracting skew quadrupoles dataframe\" ) self . skew_quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1SL\" ] != 0 ] logger . trace ( \"Extracting sextupoles dataframe\" ) self . sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2L\" ] != 0 ] logger . trace ( \"Extracting skew sextupoles dataframe\" ) self . skew_sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2SL\" ] != 0 ] logger . trace ( \"Extracting octupoles dataframe\" ) self . octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3L\" ] != 0 ] logger . trace ( \"Extracting skew octupoles dataframe\" ) self . skew_octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3SL\" ] != 0 ] def __str__ ( self ): \"\"\"Simple str method indicates the name\"\"\" return f \"HorAmpDet['{self.twiss_file.name}']\" def __repr__ ( self ): \"\"\"The repr method indicates tunes\"\"\" return ( f \"'HorizontalAmplitudeDetuning[{self.twiss_file.absolute()}' | \" f \"Qx = {self.qx:.4f} | Qy = {self.qy:.4f}]\" ) def dqx_djx_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 4 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_djx_from_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 3 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_djx ( self ) -> float : \"\"\" Returns the first order horizontal direct-term amplitude detuning. Returns: The first order horizontal direct-term amplitude detuning. \"\"\" return self . dqx_djx_from_skew_sextupoles () + self . dqx_djx_from_sextupoles () def d2qx_djx2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal direct-term amplitude detuning from skew octupoles. Returns: The second order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( 2 * 1 ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( 2 * 1 ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djx2_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal direct-term amplitude detuning from octupoles. Returns: The second order horizontal direct-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 4 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djx2 ( self ) -> float : \"\"\" Returns the second order horizontal direct-term amplitude detuning. Returns: The second order horizontal direct-term amplitude detuning. \"\"\" return self . d2qx_djx2_from_skew_octupoles () + self . d2qx_djx2_from_octupoles () def dqx_djy_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal cross-term amplitude detuning from skew sextupoles. Returns: The first order horizontal cross-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( 2 * 1 ) * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( - 2 * 1 ) * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_djy_from_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal cross-term amplitude detuning from sextupoles. Returns: The first order horizontal cross-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 2 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvx / ( 2 * np . pi ) def dqx_djy ( self ) -> float : \"\"\" Returns the first order horizontal cross-term amplitude detuning. Returns: The first order horizontal cross-term amplitude detuning. \"\"\" return self . dqx_djy_from_skew_sextupoles () + self . dqx_djy_from_sextupoles () def d2qx_djy2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal cross-term amplitude detuning from skew octupoles. Returns: The second order horizontal cross-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * ( T ( 1 , - 3 , dmux , dmuy , qx , qy ) - T ( 1 , 3 , dmux , dmuy , qx , qy )) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djy2_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal cross-term amplitude detuning from octupoles. Returns: The second order horizontal cross-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djy2 ( self ) -> float : \"\"\" Returns the second order horizontal cross-term amplitude detuning. Returns: The second order horizontal cross-term amplitude detuning. \"\"\" return self . d2qx_djy2_from_skew_octupoles () + self . d2qx_djy2_from_octupoles () def d2qx_djxdjy_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal mixed-term amplitude detuning from skew octupoles. Returns: The second order horizontal mixed-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( 6 * 1 * 1 ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( - 6 * 1 * 1 ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djxdjy_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal mixed-term amplitude detuning from octupoles. Returns: The second order horizontal mixed-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * 1 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djxdjy ( self ) -> float : \"\"\" Returns the second order horizontal mixed-term amplitude detuning. Returns: The second order horizontal mixed-term amplitude detuning. \"\"\" return self . d2qx_djxdjy_from_skew_octupoles () + self . d2qx_djxdjy_from_octupoles () def dqx_from_skew_quadrupoles ( self ) -> float : \"\"\" Get the horizontal amplitude detuning from skew quadrupoles. Returns: The horizontals amplitude detuning from skew quadrupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 betas_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUY\" ] . values a1 : np . ndarray = self . skew_quadrupoles_twiss_df [ \"K1SL\" ] . values for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a1 [ j ] * a1 [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * ( T ( 1 , - 1 , dmux , dmuy , qx , qy ) - T ( 1 , 1 , dmux , dmuy , qx , qy )) ) return dvx / ( 2 * np . pi ) def dqx_from_skew_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 4 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jx * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jy * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( jx + 2 * jy ) * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( jx - 2 * jy ) * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_from_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jx * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_x [ k ] * betas_y [ j ] * jy * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jx * T ( 3 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 2 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jy * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvx / ( 2 * np . pi ) def dqx_from_skew_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from skew octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * ( T ( 1 , - 3 , dmux , dmuy , qx , qy ) - T ( 1 , 3 , dmux , dmuy , qx , qy )) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( jx * jx + 6 * jx * jy ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( jx * jx - 6 * jx * jy ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_from_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy + jy * jy ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy - jy * jy ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jx * jx * T ( 4 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * jy * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * jx * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jx * jx * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx ( self , jx : float , jy : float ) -> float : \"\"\" Returns the horizontal amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning. \"\"\" return ( self . dqx_from_skew_quadrupoles () + self . dqx_from_skew_sextupoles ( jx , jy ) + self . dqx_from_sextupoles ( jx , jy ) + self . dqx_from_skew_octupoles ( jx , jy ) + self . dqx_from_octupoles ( jx , jy ) ) Instance variables octupoles_twiss_df quadrupoles_twiss_df qx qy sextupoles_twiss_df skew_octupoles_twiss_df skew_quadrupoles_twiss_df skew_sextupoles_twiss_df twiss_df twiss_file Methods d2qx_djx2 def d2qx_djx2 ( self ) -> float Returns the second order horizontal direct-term amplitude detuning. Returns: The second order horizontal direct-term amplitude detuning. View Source def d2qx_djx2 ( self ) -> float : \"\"\" Returns the second order horizontal direct-term amplitude detuning. Returns: The second order horizontal direct-term amplitude detuning. \"\"\" return self . d2qx_djx2_from_skew_octupoles () + self . d2qx_djx2_from_octupoles () d2qx_djx2_from_octupoles def d2qx_djx2_from_octupoles ( self ) -> float Get the second order horizontal direct-term amplitude detuning from octupoles. Returns: The second order horizontal direct-term amplitude detuning from sextupoles. View Source def d2qx_djx2_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal direct-term amplitude detuning from octupoles. Returns: The second order horizontal direct-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 4 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) d2qx_djx2_from_skew_octupoles def d2qx_djx2_from_skew_octupoles ( self ) -> float Get the second order horizontal direct-term amplitude detuning from skew octupoles. Returns: The second order horizontal direct-term amplitude detuning from skew sextupoles. View Source def d2qx_djx2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal direct-term amplitude detuning from skew octupoles. Returns: The second order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * ( 2 * 1 ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * ( 2 * 1 ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) d2qx_djxdjy def d2qx_djxdjy ( self ) -> float Returns the second order horizontal mixed-term amplitude detuning. Returns: The second order horizontal mixed-term amplitude detuning. View Source def d2qx_djxdjy ( self ) -> float : \"\"\" Returns the second order horizontal mixed-term amplitude detuning. Returns: The second order horizontal mixed-term amplitude detuning. \"\"\" return self . d2qx_djxdjy_from_skew_octupoles () + self . d2qx_djxdjy_from_octupoles () d2qx_djxdjy_from_octupoles def d2qx_djxdjy_from_octupoles ( self ) -> float Get the second order horizontal mixed-term amplitude detuning from octupoles. Returns: The second order horizontal mixed-term amplitude detuning from octupoles. View Source def d2qx_djxdjy_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal mixed-term amplitude detuning from octupoles. Returns: The second order horizontal mixed-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * 1 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) d2qx_djxdjy_from_skew_octupoles def d2qx_djxdjy_from_skew_octupoles ( self ) -> float Get the second order horizontal mixed-term amplitude detuning from skew octupoles. Returns: The second order horizontal mixed-term amplitude detuning from skew octupoles. View Source def d2qx_djxdjy_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal mixed-term amplitude detuning from skew octupoles. Returns: The second order horizontal mixed-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * ( 6 * 1 * 1 ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * ( - 6 * 1 * 1 ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) d2qx_djy2 def d2qx_djy2 ( self ) -> float Returns the second order horizontal cross-term amplitude detuning. Returns: The second order horizontal cross-term amplitude detuning. View Source def d2qx_djy2 ( self ) -> float : \"\"\" Returns the second order horizontal cross-term amplitude detuning. Returns: The second order horizontal cross-term amplitude detuning. \"\"\" return self . d2qx_djy2_from_skew_octupoles () + self . d2qx_djy2_from_octupoles () d2qx_djy2_from_octupoles def d2qx_djy2_from_octupoles ( self ) -> float Get the second order horizontal cross-term amplitude detuning from octupoles. Returns: The second order horizontal cross-term amplitude detuning from octupoles. View Source def d2qx_djy2_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal cross-term amplitude detuning from octupoles. Returns: The second order horizontal cross-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) d2qx_djy2_from_skew_octupoles def d2qx_djy2_from_skew_octupoles ( self ) -> float Get the second order horizontal cross-term amplitude detuning from skew octupoles. Returns: The second order horizontal cross-term amplitude detuning from skew octupoles. View Source def d2qx_djy2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal cross-term amplitude detuning from skew octupoles. Returns: The second order horizontal cross-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * ( T ( 1 , - 3 , dmux , dmuy , qx , qy ) - T ( 1 , 3 , dmux , dmuy , qx , qy )) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) dqx def dqx ( self , jx : float , jy : float ) -> float Returns the horizontal amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning. View Source def dqx ( self , jx : float , jy : float ) -> float : \"\"\" Returns the horizontal amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning. \"\"\" return ( self . dqx_from_skew_quadrupoles () + self . dqx_from_skew_sextupoles ( jx , jy ) + self . dqx_from_sextupoles ( jx , jy ) + self . dqx_from_skew_octupoles ( jx , jy ) + self . dqx_from_octupoles ( jx , jy ) ) dqx_djx def dqx_djx ( self ) -> float Returns the first order horizontal direct-term amplitude detuning. Returns: The first order horizontal direct-term amplitude detuning. View Source def dqx_djx ( self ) -> float : \"\"\" Returns the first order horizontal direct-term amplitude detuning. Returns: The first order horizontal direct-term amplitude detuning. \"\"\" return self . dqx_djx_from_skew_sextupoles () + self . dqx_djx_from_sextupoles () dqx_djx_from_sextupoles def dqx_djx_from_sextupoles ( self ) -> float Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. View Source def dqx_djx_from_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * 1 * T ( 3 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) dqx_djx_from_skew_sextupoles def dqx_djx_from_skew_sextupoles ( self ) -> float Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. View Source def dqx_djx_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 4 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) dqx_djy def dqx_djy ( self ) -> float Returns the first order horizontal cross-term amplitude detuning. Returns: The first order horizontal cross-term amplitude detuning. View Source def dqx_djy ( self ) -> float : \"\"\" Returns the first order horizontal cross-term amplitude detuning. Returns: The first order horizontal cross-term amplitude detuning. \"\"\" return self . dqx_djy_from_skew_sextupoles () + self . dqx_djy_from_sextupoles () dqx_djy_from_sextupoles def dqx_djy_from_sextupoles ( self ) -> float Get the first order horizontal cross-term amplitude detuning from sextupoles. Returns: The first order horizontal cross-term amplitude detuning from sextupoles. View Source def dqx_djy_from_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal cross-term amplitude detuning from sextupoles. Returns: The first order horizontal cross-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * betas_x [ k ] * betas_y [ j ] * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 2 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * 1 * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvx / ( 2 * np . pi ) dqx_djy_from_skew_sextupoles def dqx_djy_from_skew_sextupoles ( self ) -> float Get the first order horizontal cross-term amplitude detuning from skew sextupoles. Returns: The first order horizontal cross-term amplitude detuning from skew sextupoles. View Source def dqx_djy_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal cross-term amplitude detuning from skew sextupoles. Returns: The first order horizontal cross-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * ( 2 * 1 ) * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * ( - 2 * 1 ) * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) dqx_from_octupoles def dqx_from_octupoles ( self , jx : float , jy : float ) -> float Get the horizontal amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from octupoles. View Source def dqx_from_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy + jy * jy ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy - jy * jy ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jx * jx * T ( 4 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * jy * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * jx * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jx * jx * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) dqx_from_sextupoles def dqx_from_sextupoles ( self , jx : float , jy : float ) -> float Get the horizontal amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from sextupoles. View Source def dqx_from_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * jx * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * betas_x [ k ] * betas_y [ j ] * jy * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * jx * T ( 3 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 2 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * jy * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvx / ( 2 * np . pi ) dqx_from_skew_octupoles def dqx_from_skew_octupoles ( self , jx : float , jy : float ) -> float Get the horizontal amplitude detuning from skew octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew octupoles. View Source def dqx_from_skew_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from skew octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * jy * jy * ( T ( 1 , - 3 , dmux , dmuy , qx , qy ) - T ( 1 , 3 , dmux , dmuy , qx , qy )) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * ( jx * jx + 6 * jx * jy ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * ( jx * jx - 6 * jx * jy ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) dqx_from_skew_quadrupoles def dqx_from_skew_quadrupoles ( self ) -> float Get the horizontal amplitude detuning from skew quadrupoles. Returns: The horizontals amplitude detuning from skew quadrupoles. View Source def dqx_from_skew_quadrupoles ( self ) -> float : \"\"\" Get the horizontal amplitude detuning from skew quadrupoles. Returns: The horizontals amplitude detuning from skew quadrupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 betas_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUY\" ] . values a1 : np . ndarray = self . skew_quadrupoles_twiss_df [ \"K1SL\" ] . values for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a1 [ j ] * a1 [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * ( T ( 1 , - 1 , dmux , dmuy , qx , qy ) - T ( 1 , 1 , dmux , dmuy , qx , qy )) ) return dvx / ( 2 * np . pi ) dqx_from_skew_sextupoles def dqx_from_skew_sextupoles ( self , jx : float , jy : float ) -> float Get the horizontal amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew sextupoles. View Source def dqx_from_skew_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 4 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * jx * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * jy * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * ( jx + 2 * jy ) * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * ( jx - 2 * jy ) * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) VerticalAmplitudeDetuning class VerticalAmplitudeDetuning ( twiss_filename : Union [ pathlib . Path , str ] ) Class to compute different orders of amplitude detuning for the vertical plane. View Source class VerticalAmplitudeDetuning : \"\"\" Class to compute different orders of amplitude detuning for the vertical plane. \"\"\" __slots__ = { \"twiss_file\" : \"PosixPath object to the twiss output tfs file\" , \"twiss_df\" : \"TfsDataFrame loaded from twiss_file\" , \"qx\" : \"Horizontal tune extracted from twiss_df\" , \"qy\" : \"Vertical tune extracted from twiss_df\" , \"quadrupoles_twiss_df\" : \"Twiss dataframe for normal quadrupoles\" , \"skew_quadrupoles_twiss_df\" : \"Twiss dataframe for skew quadrupoles\" , \"sextupoles_twiss_df\" : \"Twiss dataframe for normal sextupoles\" , \"skew_sextupoles_twiss_df\" : \"Twiss dataframe for skew sextupoles\" , \"octupoles_twiss_df\" : \"Twiss dataframe for normal octupoles\" , \"skew_octupoles_twiss_df\" : \"Twiss dataframe for skew octupoles\" , } def __init__ ( self , twiss_filename : Union [ Path , str ]) -> None : \"\"\" Load external twiss file and extract relevant values and dataframes. Args: twiss_filename (Union[Path, str]): location to the twiss file output by MAD, in the tfs format, to be read by the tfs package, which accepts either a Path or a string. \"\"\" logger . debug ( \"Loading twiss file into memory and extracting sub-dataframes\" ) self . twiss_file : Path = Path ( twiss_filename ) self . twiss_df : tfs . TfsDataFrame = tfs . read ( twiss_filename ) self . qx : float = self . twiss_df [ \"MUX\" ] . values [ - 1 ] self . qy : float = self . twiss_df [ \"MUY\" ] . values [ - 1 ] logger . trace ( \"Extracting quadrupoles dataframe\" ) self . quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1L\" ] != 0 ] logger . trace ( \"Extracting skew quadrupoles dataframe\" ) self . skew_quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1SL\" ] != 0 ] logger . trace ( \"Extracting sextupoles dataframe\" ) self . sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2L\" ] != 0 ] logger . trace ( \"Extracting skew sextupoles dataframe\" ) self . skew_sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2SL\" ] != 0 ] logger . trace ( \"Extracting octupoles dataframe\" ) self . octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3L\" ] != 0 ] logger . trace ( \"Extracting skew octupoles dataframe\" ) self . skew_octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3SL\" ] != 0 ] def __str__ ( self ): \"\"\"Simple str method indicates the name\"\"\" return f \"VertAmpDet['{self.twiss_file.name}']\" def __repr__ ( self ): \"\"\"The repr method indicates tunes\"\"\" return ( f \"'VerticalAmplitudeDetuning[{self.twiss_file.absolute()}' | \" f \"Qx = {self.qx:.4f} | Qy = {self.qy:.4f}]\" ) def dqy_djx_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order vertical cross-term amplitude detuning from skew sextupoles. Returns: The first order vertical cross-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 2 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * ( T ( 2 , - 1 , dmux , dmuy , qx , qy ) - T ( 2 , 1 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_djx_from_sextupoles ( self ) -> float : \"\"\" Get the first order vertical cross-term amplitude detuning from sextupoles. Returns: The first order vertical cross-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * betas_x [ k ] * betas_y [ j ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * 1 ) * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * 1 ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_djx ( self ) -> float : \"\"\" Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. \"\"\" return self . dqy_djx_from_skew_sextupoles () + self . dqy_djx_from_sextupoles () def d2qy_djx2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical cross-term amplitude detuning from skew octupoles. Returns: The second order vertical cross-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETy\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * ( T ( 3 , - 1 , dmux , dmuy , qx , qy ) + T ( 3 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djx2_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical cross-term amplitude detuning from octupoles. Returns: The second order vertical cross-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_x [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_y [ j ] * betas_x [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djx2 ( self ) -> float : \"\"\" Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. \"\"\" return self . d2qy_djx2_from_skew_octupoles () + self . d2qy_djx2_from_octupoles () def dqy_djy_skew_sextupoles ( self ) -> float : \"\"\" Get the first order vertical direct-term amplitude detuning from skew sextupoles. Returns: The first order vertical direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 3 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 3 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy_djy_from_sextupoles ( self ) -> float : \"\"\" Get the first order vertical direct-term amplitude detuning from sextupoles. Returns: The first order vertical direct-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_y [ k ] * betas_y [ j ] * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( - 1 ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_djy ( self ) -> float : \"\"\" Returns the first order vertical direct-term amplitude detuning. Returns: The first order vertical direct-term amplitude detuning. \"\"\" return self . dqy_djy_skew_sextupoles () + self . dqy_djy_from_sextupoles () def d2qy_djy2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical direct-term amplitude detuning from skew octupoles. Returns: The second order vertical direct-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djy2_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical direct-term amplitude detuning from octupoles. Returns: The second order vertical direct-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 0 , 4 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_y [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djy2 ( self ) -> float : \"\"\" Returns the second order vertical direct-term amplitude detuning. Returns: The second order vertical direct-term amplitude detuning. \"\"\" return self . d2qy_djy2_from_skew_octupoles () + self . d2qy_djy2_from_octupoles () def d2qy_djxdjy_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical mixed-term amplitude detuning from skew octupoles. Returns: The second order vertical mixed-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * 1 * 1 ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * 1 * 1 ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djxdjy_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical mixed-term amplitude detuning from octupoles. Returns: The second order vertical mixed-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_y [ k ] * betas_y [ j ] * betas_y [ k ] * 1 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djxdjy ( self ) -> float : \"\"\" Returns the second order vertical mixed-term amplitude detuning. Returns: The second order vertical mixed-term amplitude detuning. \"\"\" return self . d2qy_djxdjy_from_skew_octupoles () + self . d2qy_djxdjy_from_octupoles () def dqy_from_skew_quadrupoles ( self ) -> float : \"\"\" Get the vertical amplitude detuning from skew quadrupoles. Returns: The vertical amplitude detuning from skew quadrupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUY\" ] . values a1 : np . ndarray = self . skew_quadrupoles_twiss_df [ \"K1SL\" ] . values for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a1 [ j ] * a1 [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * ( T ( 1 , - 1 , dmux , dmuy , qx , qy ) + T ( 1 , 1 , dmux , dmuy , qx , qy )) ) return dvy / ( 2 * np . pi ) def dqy_from_skew_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jx * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 3 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jy * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 2 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jx * ( T ( 2 , - 1 , dmux , dmuy , qx , qy ) - T ( 2 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jy * T ( 0 , 3 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy_from_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * betas_x [ k ] * betas_y [ j ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jx * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_y [ k ] * betas_y [ j ] * jy * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * jx + jy ) * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * jx - jy ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_from_skew_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from skew octupoles. jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * ( T ( 3 , - 1 , dmux , dmuy , qx , qy ) + T ( 3 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * jx * jy + jy * jy ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * jx * jy - jy * jy ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy_from_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy + jx * jx ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy - jx * jx ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jy * jy * T ( 0 , 4 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_y [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * jy * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_y [ k ] * betas_y [ j ] * betas_y [ k ] * jx * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_x [ k ] * jx * jx * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_y [ j ] * betas_x [ k ] * betas_y [ k ] * jx * jx * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy ( self , jx : float , jy : float ) -> float : \"\"\" Returns the vertical amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning. \"\"\" return ( self . dqy_from_skew_quadrupoles () + self . dqy_from_skew_sextupoles ( jx , jy ) + self . dqy_from_sextupoles ( jx , jy ) + self . dqy_from_skew_octupoles ( jx , jy ) + self . dqy_from_octupoles ( jx , jy ) ) Instance variables octupoles_twiss_df quadrupoles_twiss_df qx qy sextupoles_twiss_df skew_octupoles_twiss_df skew_quadrupoles_twiss_df skew_sextupoles_twiss_df twiss_df twiss_file Methods d2qy_djx2 def d2qy_djx2 ( self ) -> float Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. View Source def d2qy_djx2 ( self ) -> float : \"\"\" Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. \"\"\" return self . d2qy_djx2_from_skew_octupoles () + self . d2qy_djx2_from_octupoles () d2qy_djx2_from_octupoles def d2qy_djx2_from_octupoles ( self ) -> float Get the second order vertical cross-term amplitude detuning from octupoles. Returns: The second order vertical cross-term amplitude detuning from octupoles. View Source def d2qy_djx2_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical cross-term amplitude detuning from octupoles. Returns: The second order vertical cross-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_x [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_y [ j ] * betas_x [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) d2qy_djx2_from_skew_octupoles def d2qy_djx2_from_skew_octupoles ( self ) -> float Get the second order vertical cross-term amplitude detuning from skew octupoles. Returns: The second order vertical cross-term amplitude detuning from skew octupoles. View Source def d2qy_djx2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical cross-term amplitude detuning from skew octupoles. Returns: The second order vertical cross-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETy\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * ( T ( 3 , - 1 , dmux , dmuy , qx , qy ) + T ( 3 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) d2qy_djxdjy def d2qy_djxdjy ( self ) -> float Returns the second order vertical mixed-term amplitude detuning. Returns: The second order vertical mixed-term amplitude detuning. View Source def d2qy_djxdjy ( self ) -> float : \"\"\" Returns the second order vertical mixed-term amplitude detuning. Returns: The second order vertical mixed-term amplitude detuning. \"\"\" return self . d2qy_djxdjy_from_skew_octupoles () + self . d2qy_djxdjy_from_octupoles () d2qy_djxdjy_from_octupoles def d2qy_djxdjy_from_octupoles ( self ) -> float Get the second order vertical mixed-term amplitude detuning from octupoles. Returns: The second order vertical mixed-term amplitude detuning from octupoles. View Source def d2qy_djxdjy_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical mixed-term amplitude detuning from octupoles. Returns: The second order vertical mixed-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_y [ k ] * betas_y [ j ] * betas_y [ k ] * 1 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) d2qy_djxdjy_from_skew_octupoles def d2qy_djxdjy_from_skew_octupoles ( self ) -> float Get the second order vertical mixed-term amplitude detuning from skew octupoles. Returns: The second order vertical mixed-term amplitude detuning from skew octupoles. View Source def d2qy_djxdjy_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical mixed-term amplitude detuning from skew octupoles. Returns: The second order vertical mixed-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * ( 6 * 1 * 1 ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * ( 6 * 1 * 1 ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) d2qy_djy2 def d2qy_djy2 ( self ) -> float Returns the second order vertical direct-term amplitude detuning. Returns: The second order vertical direct-term amplitude detuning. View Source def d2qy_djy2 ( self ) -> float : \"\"\" Returns the second order vertical direct-term amplitude detuning. Returns: The second order vertical direct-term amplitude detuning. \"\"\" return self . d2qy_djy2_from_skew_octupoles () + self . d2qy_djy2_from_octupoles () d2qy_djy2_from_octupoles def d2qy_djy2_from_octupoles ( self ) -> float Get the second order vertical direct-term amplitude detuning from octupoles. Returns: The second order vertical direct-term amplitude detuning from octupoles. View Source def d2qy_djy2_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical direct-term amplitude detuning from octupoles. Returns: The second order vertical direct-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 0 , 4 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_y [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) d2qy_djy2_from_skew_octupoles def d2qy_djy2_from_skew_octupoles ( self ) -> float Get the second order vertical direct-term amplitude detuning from skew octupoles. Returns: The second order vertical direct-term amplitude detuning from skew octupoles. View Source def d2qy_djy2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical direct-term amplitude detuning from skew octupoles. Returns: The second order vertical direct-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) dqy def dqy ( self , jx : float , jy : float ) -> float Returns the vertical amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning. View Source def dqy ( self , jx : float , jy : float ) -> float : \"\"\" Returns the vertical amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning. \"\"\" return ( self . dqy_from_skew_quadrupoles () + self . dqy_from_skew_sextupoles ( jx , jy ) + self . dqy_from_sextupoles ( jx , jy ) + self . dqy_from_skew_octupoles ( jx , jy ) + self . dqy_from_octupoles ( jx , jy ) ) dqy_djx def dqy_djx ( self ) -> float Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. View Source def dqy_djx ( self ) -> float : \"\"\" Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. \"\"\" return self . dqy_djx_from_skew_sextupoles () + self . dqy_djx_from_sextupoles () dqy_djx_from_sextupoles def dqy_djx_from_sextupoles ( self ) -> float Get the first order vertical cross-term amplitude detuning from sextupoles. Returns: The first order vertical cross-term amplitude detuning from sextupoles. View Source def dqy_djx_from_sextupoles ( self ) -> float : \"\"\" Get the first order vertical cross-term amplitude detuning from sextupoles. Returns: The first order vertical cross-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * betas_x [ k ] * betas_y [ j ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * ( 2 * 1 ) * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * ( 2 * 1 ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) dqy_djx_from_skew_sextupoles def dqy_djx_from_skew_sextupoles ( self ) -> float Get the first order vertical cross-term amplitude detuning from skew sextupoles. Returns: The first order vertical cross-term amplitude detuning from skew sextupoles. View Source def dqy_djx_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order vertical cross-term amplitude detuning from skew sextupoles. Returns: The first order vertical cross-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 2 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * ( T ( 2 , - 1 , dmux , dmuy , qx , qy ) - T ( 2 , 1 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) dqy_djy def dqy_djy ( self ) -> float Returns the first order vertical direct-term amplitude detuning. Returns: The first order vertical direct-term amplitude detuning. View Source def dqy_djy ( self ) -> float : \"\"\" Returns the first order vertical direct-term amplitude detuning. Returns: The first order vertical direct-term amplitude detuning. \"\"\" return self . dqy_djy_skew_sextupoles () + self . dqy_djy_from_sextupoles () dqy_djy_from_sextupoles def dqy_djy_from_sextupoles ( self ) -> float Get the first order vertical direct-term amplitude detuning from sextupoles. Returns: The first order vertical direct-term amplitude detuning from sextupoles. View Source def dqy_djy_from_sextupoles ( self ) -> float : \"\"\" Get the first order vertical direct-term amplitude detuning from sextupoles. Returns: The first order vertical direct-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * betas_y [ k ] * betas_y [ j ] * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * 1 * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * ( - 1 ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) dqy_djy_skew_sextupoles def dqy_djy_skew_sextupoles ( self ) -> float Get the first order vertical direct-term amplitude detuning from skew sextupoles. Returns: The first order vertical direct-term amplitude detuning from skew sextupoles. View Source def dqy_djy_skew_sextupoles ( self ) -> float : \"\"\" Get the first order vertical direct-term amplitude detuning from skew sextupoles. Returns: The first order vertical direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 3 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * T ( 0 , 3 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) dqy_from_octupoles def dqy_from_octupoles ( self , jx : float , jy : float ) -> float Get the vertical amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from octupoles. View Source def dqy_from_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy + jx * jx ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy - jx * jx ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jy * jy * T ( 0 , 4 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_y [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * jy * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_y [ k ] * betas_y [ j ] * betas_y [ k ] * jx * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_x [ k ] * jx * jx * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_y [ j ] * betas_x [ k ] * betas_y [ k ] * jx * jx * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) dqy_from_sextupoles def dqy_from_sextupoles ( self , jx : float , jy : float ) -> float Get the vertical amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from sextupoles. View Source def dqy_from_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * betas_x [ k ] * betas_y [ j ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * jx * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * betas_y [ k ] * betas_y [ j ] * jy * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * ( 2 * jx + jy ) * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * ( 2 * jx - jy ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) dqy_from_skew_octupoles def dqy_from_skew_octupoles ( self , jx : float , jy : float ) -> float Get the vertical amplitude detuning from skew octupoles. jx ( float ): horizontal action variable . jy ( float ): vertical action variable . Returns: The vertical amplitude detuning from skew octupoles. View Source def dqy_from_skew_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from skew octupoles. jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * jx * jx * ( T ( 3 , - 1 , dmux , dmuy , qx , qy ) + T ( 3 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * ( 6 * jx * jy + jy * jy ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * ( 6 * jx * jy - jy * jy ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) dqy_from_skew_quadrupoles def dqy_from_skew_quadrupoles ( self ) -> float Get the vertical amplitude detuning from skew quadrupoles. Returns: The vertical amplitude detuning from skew quadrupoles. View Source def dqy_from_skew_quadrupoles ( self ) -> float : \"\"\" Get the vertical amplitude detuning from skew quadrupoles. Returns: The vertical amplitude detuning from skew quadrupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUY\" ] . values a1 : np . ndarray = self . skew_quadrupoles_twiss_df [ \"K1SL\" ] . values for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a1 [ j ] * a1 [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * ( T ( 1 , - 1 , dmux , dmuy , qx , qy ) + T ( 1 , 1 , dmux , dmuy , qx , qy )) ) return dvy / ( 2 * np . pi ) dqy_from_skew_sextupoles def dqy_from_skew_sextupoles ( self , jx : float , jy : float ) -> float Get the vertical amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from skew sextupoles. View Source def dqy_from_skew_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * jx * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 3 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * jy * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 2 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * jx * ( T ( 2 , - 1 , dmux , dmuy , qx , qy ) - T ( 2 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * jy * T ( 0 , 3 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi )","title":"Amplitude Detuning"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#module-pyhdtoolkitopticsamplitude_detuning","text":"","title":"Module pyhdtoolkit.optics.amplitude_detuning"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#module-opticsamplitude_detuning","text":"Created on 2020.08.13 :author: Felix Soubelet ( felix.soubelet@cern.ch ) This is a Python3 module implementing classes for amplitude detuning calculations after loading twiss output files from MAD. This module is a heavy refactor of initial code & formulas by @leonvanriesen Example usage: hor_amp_det = HorizontalAmplitudeDetuning(twiss_filename=\"mad_twiss_output.tfs\") hor_amp_det.d2qx_djx2() hor_amp_det.dqx_from_skew_quadrupoles() View Source \"\"\" Module optics.amplitude_detuning -------------------------------- Created on 2020.08.13 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 module implementing classes for amplitude detuning calculations after loading twiss output files from MAD. This module is a heavy refactor of initial code & formulas by @leonvanriesen Example usage: hor_amp_det = HorizontalAmplitudeDetuning(twiss_filename=\"mad_twiss_output.tfs\") hor_amp_det.d2qx_djx2() hor_amp_det.dqx_from_skew_quadrupoles() \"\"\" from pathlib import Path from typing import Union import numba import numpy as np import tfs from loguru import logger class HorizontalAmplitudeDetuning : \"\"\" Class to compute different orders of amplitude detuning for the horizontal plane. \"\"\" __slots__ = { \"twiss_file\" : \"PosixPath object to the twiss output tfs file\" , \"twiss_df\" : \"TfsDataFrame loaded from twiss_file\" , \"qx\" : \"Horizontal tune extracted from twiss_df\" , \"qy\" : \"Vertical tune extracted from twiss_df\" , \"quadrupoles_twiss_df\" : \"Twiss dataframe for normal quadrupoles\" , \"skew_quadrupoles_twiss_df\" : \"Twiss dataframe for skew quadrupoles\" , \"sextupoles_twiss_df\" : \"Twiss dataframe for normal sextupoles\" , \"skew_sextupoles_twiss_df\" : \"Twiss dataframe for skew sextupoles\" , \"octupoles_twiss_df\" : \"Twiss dataframe for normal octupoles\" , \"skew_octupoles_twiss_df\" : \"Twiss dataframe for skew octupoles\" , } def __init__ ( self , twiss_filename : Union [ Path , str ]) -> None : \"\"\" Load external twiss file and extract relevant values and dataframes. Args: twiss_filename (Union[Path, str]): location to the twiss file output by MAD, in the tfs format, to be read by the tfs package, which accepts either a Path or a string. \"\"\" logger . debug ( \"Loading twiss file into memory and extracting sub-dataframes\" ) self . twiss_file : Path = Path ( twiss_filename ) self . twiss_df : tfs . TfsDataFrame = tfs . read ( twiss_filename ) self . qx : float = self . twiss_df [ \"MUX\" ] . values [ - 1 ] self . qy : float = self . twiss_df [ \"MUY\" ] . values [ - 1 ] logger . trace ( \"Extracting quadrupoles dataframe\" ) self . quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1L\" ] != 0 ] logger . trace ( \"Extracting skew quadrupoles dataframe\" ) self . skew_quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1SL\" ] != 0 ] logger . trace ( \"Extracting sextupoles dataframe\" ) self . sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2L\" ] != 0 ] logger . trace ( \"Extracting skew sextupoles dataframe\" ) self . skew_sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2SL\" ] != 0 ] logger . trace ( \"Extracting octupoles dataframe\" ) self . octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3L\" ] != 0 ] logger . trace ( \"Extracting skew octupoles dataframe\" ) self . skew_octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3SL\" ] != 0 ] def __str__ ( self ): \"\"\"Simple str method indicates the name\"\"\" return f \"HorAmpDet[' { self . twiss_file . name } ']\" def __repr__ ( self ): \"\"\"The repr method indicates tunes\"\"\" return ( f \"'HorizontalAmplitudeDetuning[ { self . twiss_file . absolute () } ' | \" f \"Qx = { self . qx : .4f } | Qy = { self . qy : .4f } ]\" ) def dqx_djx_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 4 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_djx_from_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 3 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_djx ( self ) -> float : \"\"\" Returns the first order horizontal direct-term amplitude detuning. Returns: The first order horizontal direct-term amplitude detuning. \"\"\" return self . dqx_djx_from_skew_sextupoles () + self . dqx_djx_from_sextupoles () def d2qx_djx2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal direct-term amplitude detuning from skew octupoles. Returns: The second order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( 2 * 1 ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( 2 * 1 ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djx2_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal direct-term amplitude detuning from octupoles. Returns: The second order horizontal direct-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 4 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djx2 ( self ) -> float : \"\"\" Returns the second order horizontal direct-term amplitude detuning. Returns: The second order horizontal direct-term amplitude detuning. \"\"\" return self . d2qx_djx2_from_skew_octupoles () + self . d2qx_djx2_from_octupoles () def dqx_djy_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal cross-term amplitude detuning from skew sextupoles. Returns: The first order horizontal cross-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( 2 * 1 ) * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( - 2 * 1 ) * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_djy_from_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal cross-term amplitude detuning from sextupoles. Returns: The first order horizontal cross-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 2 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvx / ( 2 * np . pi ) def dqx_djy ( self ) -> float : \"\"\" Returns the first order horizontal cross-term amplitude detuning. Returns: The first order horizontal cross-term amplitude detuning. \"\"\" return self . dqx_djy_from_skew_sextupoles () + self . dqx_djy_from_sextupoles () def d2qx_djy2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal cross-term amplitude detuning from skew octupoles. Returns: The second order horizontal cross-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * ( T ( 1 , - 3 , dmux , dmuy , qx , qy ) - T ( 1 , 3 , dmux , dmuy , qx , qy )) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djy2_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal cross-term amplitude detuning from octupoles. Returns: The second order horizontal cross-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djy2 ( self ) -> float : \"\"\" Returns the second order horizontal cross-term amplitude detuning. Returns: The second order horizontal cross-term amplitude detuning. \"\"\" return self . d2qx_djy2_from_skew_octupoles () + self . d2qx_djy2_from_octupoles () def d2qx_djxdjy_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal mixed-term amplitude detuning from skew octupoles. Returns: The second order horizontal mixed-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( 6 * 1 * 1 ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( - 6 * 1 * 1 ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djxdjy_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal mixed-term amplitude detuning from octupoles. Returns: The second order horizontal mixed-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * 1 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djxdjy ( self ) -> float : \"\"\" Returns the second order horizontal mixed-term amplitude detuning. Returns: The second order horizontal mixed-term amplitude detuning. \"\"\" return self . d2qx_djxdjy_from_skew_octupoles () + self . d2qx_djxdjy_from_octupoles () def dqx_from_skew_quadrupoles ( self ) -> float : \"\"\" Get the horizontal amplitude detuning from skew quadrupoles. Returns: The horizontals amplitude detuning from skew quadrupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 betas_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUY\" ] . values a1 : np . ndarray = self . skew_quadrupoles_twiss_df [ \"K1SL\" ] . values for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a1 [ j ] * a1 [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * ( T ( 1 , - 1 , dmux , dmuy , qx , qy ) - T ( 1 , 1 , dmux , dmuy , qx , qy )) ) return dvx / ( 2 * np . pi ) def dqx_from_skew_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 4 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jx * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jy * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( jx + 2 * jy ) * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( jx - 2 * jy ) * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_from_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jx * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_x [ k ] * betas_y [ j ] * jy * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jx * T ( 3 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 2 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jy * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvx / ( 2 * np . pi ) def dqx_from_skew_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from skew octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * ( T ( 1 , - 3 , dmux , dmuy , qx , qy ) - T ( 1 , 3 , dmux , dmuy , qx , qy )) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( jx * jx + 6 * jx * jy ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( jx * jx - 6 * jx * jy ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_from_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy + jy * jy ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy - jy * jy ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jx * jx * T ( 4 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * jy * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * jx * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jx * jx * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx ( self , jx : float , jy : float ) -> float : \"\"\" Returns the horizontal amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning. \"\"\" return ( self . dqx_from_skew_quadrupoles () + self . dqx_from_skew_sextupoles ( jx , jy ) + self . dqx_from_sextupoles ( jx , jy ) + self . dqx_from_skew_octupoles ( jx , jy ) + self . dqx_from_octupoles ( jx , jy ) ) class VerticalAmplitudeDetuning : \"\"\" Class to compute different orders of amplitude detuning for the vertical plane. \"\"\" __slots__ = { \"twiss_file\" : \"PosixPath object to the twiss output tfs file\" , \"twiss_df\" : \"TfsDataFrame loaded from twiss_file\" , \"qx\" : \"Horizontal tune extracted from twiss_df\" , \"qy\" : \"Vertical tune extracted from twiss_df\" , \"quadrupoles_twiss_df\" : \"Twiss dataframe for normal quadrupoles\" , \"skew_quadrupoles_twiss_df\" : \"Twiss dataframe for skew quadrupoles\" , \"sextupoles_twiss_df\" : \"Twiss dataframe for normal sextupoles\" , \"skew_sextupoles_twiss_df\" : \"Twiss dataframe for skew sextupoles\" , \"octupoles_twiss_df\" : \"Twiss dataframe for normal octupoles\" , \"skew_octupoles_twiss_df\" : \"Twiss dataframe for skew octupoles\" , } def __init__ ( self , twiss_filename : Union [ Path , str ]) -> None : \"\"\" Load external twiss file and extract relevant values and dataframes. Args: twiss_filename (Union[Path, str]): location to the twiss file output by MAD, in the tfs format, to be read by the tfs package, which accepts either a Path or a string. \"\"\" logger . debug ( \"Loading twiss file into memory and extracting sub-dataframes\" ) self . twiss_file : Path = Path ( twiss_filename ) self . twiss_df : tfs . TfsDataFrame = tfs . read ( twiss_filename ) self . qx : float = self . twiss_df [ \"MUX\" ] . values [ - 1 ] self . qy : float = self . twiss_df [ \"MUY\" ] . values [ - 1 ] logger . trace ( \"Extracting quadrupoles dataframe\" ) self . quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1L\" ] != 0 ] logger . trace ( \"Extracting skew quadrupoles dataframe\" ) self . skew_quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1SL\" ] != 0 ] logger . trace ( \"Extracting sextupoles dataframe\" ) self . sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2L\" ] != 0 ] logger . trace ( \"Extracting skew sextupoles dataframe\" ) self . skew_sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2SL\" ] != 0 ] logger . trace ( \"Extracting octupoles dataframe\" ) self . octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3L\" ] != 0 ] logger . trace ( \"Extracting skew octupoles dataframe\" ) self . skew_octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3SL\" ] != 0 ] def __str__ ( self ): \"\"\"Simple str method indicates the name\"\"\" return f \"VertAmpDet[' { self . twiss_file . name } ']\" def __repr__ ( self ): \"\"\"The repr method indicates tunes\"\"\" return ( f \"'VerticalAmplitudeDetuning[ { self . twiss_file . absolute () } ' | \" f \"Qx = { self . qx : .4f } | Qy = { self . qy : .4f } ]\" ) def dqy_djx_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order vertical cross-term amplitude detuning from skew sextupoles. Returns: The first order vertical cross-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 2 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * ( T ( 2 , - 1 , dmux , dmuy , qx , qy ) - T ( 2 , 1 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_djx_from_sextupoles ( self ) -> float : \"\"\" Get the first order vertical cross-term amplitude detuning from sextupoles. Returns: The first order vertical cross-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * betas_x [ k ] * betas_y [ j ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * 1 ) * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * 1 ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_djx ( self ) -> float : \"\"\" Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. \"\"\" return self . dqy_djx_from_skew_sextupoles () + self . dqy_djx_from_sextupoles () def d2qy_djx2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical cross-term amplitude detuning from skew octupoles. Returns: The second order vertical cross-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETy\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * ( T ( 3 , - 1 , dmux , dmuy , qx , qy ) + T ( 3 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djx2_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical cross-term amplitude detuning from octupoles. Returns: The second order vertical cross-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_x [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_y [ j ] * betas_x [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djx2 ( self ) -> float : \"\"\" Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. \"\"\" return self . d2qy_djx2_from_skew_octupoles () + self . d2qy_djx2_from_octupoles () def dqy_djy_skew_sextupoles ( self ) -> float : \"\"\" Get the first order vertical direct-term amplitude detuning from skew sextupoles. Returns: The first order vertical direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 3 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 3 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy_djy_from_sextupoles ( self ) -> float : \"\"\" Get the first order vertical direct-term amplitude detuning from sextupoles. Returns: The first order vertical direct-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_y [ k ] * betas_y [ j ] * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( - 1 ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_djy ( self ) -> float : \"\"\" Returns the first order vertical direct-term amplitude detuning. Returns: The first order vertical direct-term amplitude detuning. \"\"\" return self . dqy_djy_skew_sextupoles () + self . dqy_djy_from_sextupoles () def d2qy_djy2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical direct-term amplitude detuning from skew octupoles. Returns: The second order vertical direct-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djy2_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical direct-term amplitude detuning from octupoles. Returns: The second order vertical direct-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 0 , 4 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_y [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djy2 ( self ) -> float : \"\"\" Returns the second order vertical direct-term amplitude detuning. Returns: The second order vertical direct-term amplitude detuning. \"\"\" return self . d2qy_djy2_from_skew_octupoles () + self . d2qy_djy2_from_octupoles () def d2qy_djxdjy_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical mixed-term amplitude detuning from skew octupoles. Returns: The second order vertical mixed-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * 1 * 1 ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * 1 * 1 ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djxdjy_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical mixed-term amplitude detuning from octupoles. Returns: The second order vertical mixed-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_y [ k ] * betas_y [ j ] * betas_y [ k ] * 1 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djxdjy ( self ) -> float : \"\"\" Returns the second order vertical mixed-term amplitude detuning. Returns: The second order vertical mixed-term amplitude detuning. \"\"\" return self . d2qy_djxdjy_from_skew_octupoles () + self . d2qy_djxdjy_from_octupoles () def dqy_from_skew_quadrupoles ( self ) -> float : \"\"\" Get the vertical amplitude detuning from skew quadrupoles. Returns: The vertical amplitude detuning from skew quadrupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUY\" ] . values a1 : np . ndarray = self . skew_quadrupoles_twiss_df [ \"K1SL\" ] . values for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a1 [ j ] * a1 [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * ( T ( 1 , - 1 , dmux , dmuy , qx , qy ) + T ( 1 , 1 , dmux , dmuy , qx , qy )) ) return dvy / ( 2 * np . pi ) def dqy_from_skew_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jx * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 3 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jy * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 2 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jx * ( T ( 2 , - 1 , dmux , dmuy , qx , qy ) - T ( 2 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jy * T ( 0 , 3 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy_from_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * betas_x [ k ] * betas_y [ j ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jx * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_y [ k ] * betas_y [ j ] * jy * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * jx + jy ) * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * jx - jy ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_from_skew_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from skew octupoles. jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * ( T ( 3 , - 1 , dmux , dmuy , qx , qy ) + T ( 3 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * jx * jy + jy * jy ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * jx * jy - jy * jy ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy_from_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy + jx * jx ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy - jx * jx ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jy * jy * T ( 0 , 4 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_y [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * jy * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_y [ k ] * betas_y [ j ] * betas_y [ k ] * jx * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_x [ k ] * jx * jx * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_y [ j ] * betas_x [ k ] * betas_y [ k ] * jx * jx * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy ( self , jx : float , jy : float ) -> float : \"\"\" Returns the vertical amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning. \"\"\" return ( self . dqy_from_skew_quadrupoles () + self . dqy_from_skew_sextupoles ( jx , jy ) + self . dqy_from_sextupoles ( jx , jy ) + self . dqy_from_skew_octupoles ( jx , jy ) + self . dqy_from_octupoles ( jx , jy ) ) # -------- Math function -------- # @numba . njit () def T ( nx , ny , dmux : float , dmuy : float , qx : float , qy : float ) -> float : \"\"\" The T-function defined in eq. 3.55 of the 'Analytical Calculations of Smear and Tune Shift' paper (https://lss.fnal.gov/archive/other/ssc/ssc-232.pdf) Args: nx (int): first element of the T function's power. ny (int): second element of the T function's power. dmux (float): horizontal phase advance. dmuy (float): vertical phase advance. qx (float): horizontal tune. qy (float): vertical tune. Returns: T parameter. \"\"\" return np . cos ( 2 * np . pi * ( nx * ( np . abs ( dmux ) - qx / 2 ) + ny * ( np . abs ( dmuy ) - qy / 2 )) ) / np . sin ( np . pi * ( nx * qx + ny * qy ))","title":"Module optics.amplitude_detuning"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#t","text":"def T ( nx , ny , dmux : float , dmuy : float , qx : float , qy : float ) -> float The T-function defined in eq. 3.55 of the 'Analytical Calculations of Smear and Tune Shift' paper ( https://lss.fnal.gov/archive/other/ssc/ssc-232.pdf ) Args: nx (int): first element of the T function's power. ny (int): second element of the T function's power. dmux (float): horizontal phase advance. dmuy (float): vertical phase advance. qx (float): horizontal tune. qy (float): vertical tune. Returns: T parameter. View Source @numba . njit () def T ( nx , ny , dmux : float , dmuy : float , qx : float , qy : float ) -> float : \"\"\" The T-function defined in eq. 3.55 of the 'Analytical Calculations of Smear and Tune Shift' paper (https://lss.fnal.gov/archive/other/ssc/ssc-232.pdf) Args: nx (int): first element of the T function's power. ny (int): second element of the T function's power. dmux (float): horizontal phase advance. dmuy (float): vertical phase advance. qx (float): horizontal tune. qy (float): vertical tune. Returns: T parameter. \"\"\" return np . cos ( 2 * np . pi * ( nx * ( np . abs ( dmux ) - qx / 2 ) + ny * ( np . abs ( dmuy ) - qy / 2 )) ) / np . sin ( np . pi * ( nx * qx + ny * qy ))","title":"T"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#horizontalamplitudedetuning","text":"class HorizontalAmplitudeDetuning ( twiss_filename : Union [ pathlib . Path , str ] ) Class to compute different orders of amplitude detuning for the horizontal plane. View Source class HorizontalAmplitudeDetuning : \"\"\" Class to compute different orders of amplitude detuning for the horizontal plane. \"\"\" __slots__ = { \"twiss_file\" : \"PosixPath object to the twiss output tfs file\" , \"twiss_df\" : \"TfsDataFrame loaded from twiss_file\" , \"qx\" : \"Horizontal tune extracted from twiss_df\" , \"qy\" : \"Vertical tune extracted from twiss_df\" , \"quadrupoles_twiss_df\" : \"Twiss dataframe for normal quadrupoles\" , \"skew_quadrupoles_twiss_df\" : \"Twiss dataframe for skew quadrupoles\" , \"sextupoles_twiss_df\" : \"Twiss dataframe for normal sextupoles\" , \"skew_sextupoles_twiss_df\" : \"Twiss dataframe for skew sextupoles\" , \"octupoles_twiss_df\" : \"Twiss dataframe for normal octupoles\" , \"skew_octupoles_twiss_df\" : \"Twiss dataframe for skew octupoles\" , } def __init__ ( self , twiss_filename : Union [ Path , str ]) -> None : \"\"\" Load external twiss file and extract relevant values and dataframes. Args: twiss_filename (Union[Path, str]): location to the twiss file output by MAD, in the tfs format, to be read by the tfs package, which accepts either a Path or a string. \"\"\" logger . debug ( \"Loading twiss file into memory and extracting sub-dataframes\" ) self . twiss_file : Path = Path ( twiss_filename ) self . twiss_df : tfs . TfsDataFrame = tfs . read ( twiss_filename ) self . qx : float = self . twiss_df [ \"MUX\" ] . values [ - 1 ] self . qy : float = self . twiss_df [ \"MUY\" ] . values [ - 1 ] logger . trace ( \"Extracting quadrupoles dataframe\" ) self . quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1L\" ] != 0 ] logger . trace ( \"Extracting skew quadrupoles dataframe\" ) self . skew_quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1SL\" ] != 0 ] logger . trace ( \"Extracting sextupoles dataframe\" ) self . sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2L\" ] != 0 ] logger . trace ( \"Extracting skew sextupoles dataframe\" ) self . skew_sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2SL\" ] != 0 ] logger . trace ( \"Extracting octupoles dataframe\" ) self . octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3L\" ] != 0 ] logger . trace ( \"Extracting skew octupoles dataframe\" ) self . skew_octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3SL\" ] != 0 ] def __str__ ( self ): \"\"\"Simple str method indicates the name\"\"\" return f \"HorAmpDet['{self.twiss_file.name}']\" def __repr__ ( self ): \"\"\"The repr method indicates tunes\"\"\" return ( f \"'HorizontalAmplitudeDetuning[{self.twiss_file.absolute()}' | \" f \"Qx = {self.qx:.4f} | Qy = {self.qy:.4f}]\" ) def dqx_djx_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 4 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_djx_from_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 3 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_djx ( self ) -> float : \"\"\" Returns the first order horizontal direct-term amplitude detuning. Returns: The first order horizontal direct-term amplitude detuning. \"\"\" return self . dqx_djx_from_skew_sextupoles () + self . dqx_djx_from_sextupoles () def d2qx_djx2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal direct-term amplitude detuning from skew octupoles. Returns: The second order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( 2 * 1 ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( 2 * 1 ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djx2_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal direct-term amplitude detuning from octupoles. Returns: The second order horizontal direct-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 4 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djx2 ( self ) -> float : \"\"\" Returns the second order horizontal direct-term amplitude detuning. Returns: The second order horizontal direct-term amplitude detuning. \"\"\" return self . d2qx_djx2_from_skew_octupoles () + self . d2qx_djx2_from_octupoles () def dqx_djy_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal cross-term amplitude detuning from skew sextupoles. Returns: The first order horizontal cross-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( 2 * 1 ) * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( - 2 * 1 ) * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_djy_from_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal cross-term amplitude detuning from sextupoles. Returns: The first order horizontal cross-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 2 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvx / ( 2 * np . pi ) def dqx_djy ( self ) -> float : \"\"\" Returns the first order horizontal cross-term amplitude detuning. Returns: The first order horizontal cross-term amplitude detuning. \"\"\" return self . dqx_djy_from_skew_sextupoles () + self . dqx_djy_from_sextupoles () def d2qx_djy2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal cross-term amplitude detuning from skew octupoles. Returns: The second order horizontal cross-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * ( T ( 1 , - 3 , dmux , dmuy , qx , qy ) - T ( 1 , 3 , dmux , dmuy , qx , qy )) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djy2_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal cross-term amplitude detuning from octupoles. Returns: The second order horizontal cross-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djy2 ( self ) -> float : \"\"\" Returns the second order horizontal cross-term amplitude detuning. Returns: The second order horizontal cross-term amplitude detuning. \"\"\" return self . d2qx_djy2_from_skew_octupoles () + self . d2qx_djy2_from_octupoles () def d2qx_djxdjy_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal mixed-term amplitude detuning from skew octupoles. Returns: The second order horizontal mixed-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( 6 * 1 * 1 ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( - 6 * 1 * 1 ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djxdjy_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal mixed-term amplitude detuning from octupoles. Returns: The second order horizontal mixed-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * 1 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def d2qx_djxdjy ( self ) -> float : \"\"\" Returns the second order horizontal mixed-term amplitude detuning. Returns: The second order horizontal mixed-term amplitude detuning. \"\"\" return self . d2qx_djxdjy_from_skew_octupoles () + self . d2qx_djxdjy_from_octupoles () def dqx_from_skew_quadrupoles ( self ) -> float : \"\"\" Get the horizontal amplitude detuning from skew quadrupoles. Returns: The horizontals amplitude detuning from skew quadrupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 betas_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUY\" ] . values a1 : np . ndarray = self . skew_quadrupoles_twiss_df [ \"K1SL\" ] . values for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a1 [ j ] * a1 [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * ( T ( 1 , - 1 , dmux , dmuy , qx , qy ) - T ( 1 , 1 , dmux , dmuy , qx , qy )) ) return dvx / ( 2 * np . pi ) def dqx_from_skew_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 4 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jx * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jy * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( jx + 2 * jy ) * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * ( jx - 2 * jy ) * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_from_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jx * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_x [ k ] * betas_y [ j ] * jy * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jx * T ( 3 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 2 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jy * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvx / ( 2 * np . pi ) def dqx_from_skew_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from skew octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * ( T ( 1 , - 3 , dmux , dmuy , qx , qy ) - T ( 1 , 3 , dmux , dmuy , qx , qy )) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( jx * jx + 6 * jx * jy ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * ( jx * jx - 6 * jx * jy ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx_from_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy + jy * jy ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy - jy * jy ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jx * jx * T ( 4 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * jy * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * jx * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jx * jx * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi ) def dqx ( self , jx : float , jy : float ) -> float : \"\"\" Returns the horizontal amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning. \"\"\" return ( self . dqx_from_skew_quadrupoles () + self . dqx_from_skew_sextupoles ( jx , jy ) + self . dqx_from_sextupoles ( jx , jy ) + self . dqx_from_skew_octupoles ( jx , jy ) + self . dqx_from_octupoles ( jx , jy ) )","title":"HorizontalAmplitudeDetuning"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#instance-variables","text":"octupoles_twiss_df quadrupoles_twiss_df qx qy sextupoles_twiss_df skew_octupoles_twiss_df skew_quadrupoles_twiss_df skew_sextupoles_twiss_df twiss_df twiss_file","title":"Instance variables"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#methods","text":"","title":"Methods"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qx_djx2","text":"def d2qx_djx2 ( self ) -> float Returns the second order horizontal direct-term amplitude detuning. Returns: The second order horizontal direct-term amplitude detuning. View Source def d2qx_djx2 ( self ) -> float : \"\"\" Returns the second order horizontal direct-term amplitude detuning. Returns: The second order horizontal direct-term amplitude detuning. \"\"\" return self . d2qx_djx2_from_skew_octupoles () + self . d2qx_djx2_from_octupoles ()","title":"d2qx_djx2"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qx_djx2_from_octupoles","text":"def d2qx_djx2_from_octupoles ( self ) -> float Get the second order horizontal direct-term amplitude detuning from octupoles. Returns: The second order horizontal direct-term amplitude detuning from sextupoles. View Source def d2qx_djx2_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal direct-term amplitude detuning from octupoles. Returns: The second order horizontal direct-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 4 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi )","title":"d2qx_djx2_from_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qx_djx2_from_skew_octupoles","text":"def d2qx_djx2_from_skew_octupoles ( self ) -> float Get the second order horizontal direct-term amplitude detuning from skew octupoles. Returns: The second order horizontal direct-term amplitude detuning from skew sextupoles. View Source def d2qx_djx2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal direct-term amplitude detuning from skew octupoles. Returns: The second order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * ( 2 * 1 ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * ( 2 * 1 ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi )","title":"d2qx_djx2_from_skew_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qx_djxdjy","text":"def d2qx_djxdjy ( self ) -> float Returns the second order horizontal mixed-term amplitude detuning. Returns: The second order horizontal mixed-term amplitude detuning. View Source def d2qx_djxdjy ( self ) -> float : \"\"\" Returns the second order horizontal mixed-term amplitude detuning. Returns: The second order horizontal mixed-term amplitude detuning. \"\"\" return self . d2qx_djxdjy_from_skew_octupoles () + self . d2qx_djxdjy_from_octupoles ()","title":"d2qx_djxdjy"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qx_djxdjy_from_octupoles","text":"def d2qx_djxdjy_from_octupoles ( self ) -> float Get the second order horizontal mixed-term amplitude detuning from octupoles. Returns: The second order horizontal mixed-term amplitude detuning from octupoles. View Source def d2qx_djxdjy_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal mixed-term amplitude detuning from octupoles. Returns: The second order horizontal mixed-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * 1 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi )","title":"d2qx_djxdjy_from_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qx_djxdjy_from_skew_octupoles","text":"def d2qx_djxdjy_from_skew_octupoles ( self ) -> float Get the second order horizontal mixed-term amplitude detuning from skew octupoles. Returns: The second order horizontal mixed-term amplitude detuning from skew octupoles. View Source def d2qx_djxdjy_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal mixed-term amplitude detuning from skew octupoles. Returns: The second order horizontal mixed-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * ( 6 * 1 * 1 ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * ( - 6 * 1 * 1 ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi )","title":"d2qx_djxdjy_from_skew_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qx_djy2","text":"def d2qx_djy2 ( self ) -> float Returns the second order horizontal cross-term amplitude detuning. Returns: The second order horizontal cross-term amplitude detuning. View Source def d2qx_djy2 ( self ) -> float : \"\"\" Returns the second order horizontal cross-term amplitude detuning. Returns: The second order horizontal cross-term amplitude detuning. \"\"\" return self . d2qx_djy2_from_skew_octupoles () + self . d2qx_djy2_from_octupoles ()","title":"d2qx_djy2"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qx_djy2_from_octupoles","text":"def d2qx_djy2_from_octupoles ( self ) -> float Get the second order horizontal cross-term amplitude detuning from octupoles. Returns: The second order horizontal cross-term amplitude detuning from octupoles. View Source def d2qx_djy2_from_octupoles ( self ) -> float : \"\"\" Get the second order horizontal cross-term amplitude detuning from octupoles. Returns: The second order horizontal cross-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi )","title":"d2qx_djy2_from_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qx_djy2_from_skew_octupoles","text":"def d2qx_djy2_from_skew_octupoles ( self ) -> float Get the second order horizontal cross-term amplitude detuning from skew octupoles. Returns: The second order horizontal cross-term amplitude detuning from skew octupoles. View Source def d2qx_djy2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order horizontal cross-term amplitude detuning from skew octupoles. Returns: The second order horizontal cross-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * ( T ( 1 , - 3 , dmux , dmuy , qx , qy ) - T ( 1 , 3 , dmux , dmuy , qx , qy )) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi )","title":"d2qx_djy2_from_skew_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqx","text":"def dqx ( self , jx : float , jy : float ) -> float Returns the horizontal amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning. View Source def dqx ( self , jx : float , jy : float ) -> float : \"\"\" Returns the horizontal amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning. \"\"\" return ( self . dqx_from_skew_quadrupoles () + self . dqx_from_skew_sextupoles ( jx , jy ) + self . dqx_from_sextupoles ( jx , jy ) + self . dqx_from_skew_octupoles ( jx , jy ) + self . dqx_from_octupoles ( jx , jy ) )","title":"dqx"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqx_djx","text":"def dqx_djx ( self ) -> float Returns the first order horizontal direct-term amplitude detuning. Returns: The first order horizontal direct-term amplitude detuning. View Source def dqx_djx ( self ) -> float : \"\"\" Returns the first order horizontal direct-term amplitude detuning. Returns: The first order horizontal direct-term amplitude detuning. \"\"\" return self . dqx_djx_from_skew_sextupoles () + self . dqx_djx_from_sextupoles ()","title":"dqx_djx"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqx_djx_from_sextupoles","text":"def dqx_djx_from_sextupoles ( self ) -> float Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. View Source def dqx_djx_from_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * 1 * T ( 3 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi )","title":"dqx_djx_from_sextupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqx_djx_from_skew_sextupoles","text":"def dqx_djx_from_skew_sextupoles ( self ) -> float Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. View Source def dqx_djx_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal direct-term amplitude detuning from skew sextupoles. Returns: The first order horizontal direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 4 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi )","title":"dqx_djx_from_skew_sextupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqx_djy","text":"def dqx_djy ( self ) -> float Returns the first order horizontal cross-term amplitude detuning. Returns: The first order horizontal cross-term amplitude detuning. View Source def dqx_djy ( self ) -> float : \"\"\" Returns the first order horizontal cross-term amplitude detuning. Returns: The first order horizontal cross-term amplitude detuning. \"\"\" return self . dqx_djy_from_skew_sextupoles () + self . dqx_djy_from_sextupoles ()","title":"dqx_djy"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqx_djy_from_sextupoles","text":"def dqx_djy_from_sextupoles ( self ) -> float Get the first order horizontal cross-term amplitude detuning from sextupoles. Returns: The first order horizontal cross-term amplitude detuning from sextupoles. View Source def dqx_djy_from_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal cross-term amplitude detuning from sextupoles. Returns: The first order horizontal cross-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * betas_x [ k ] * betas_y [ j ] * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 2 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * 1 * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvx / ( 2 * np . pi )","title":"dqx_djy_from_sextupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqx_djy_from_skew_sextupoles","text":"def dqx_djy_from_skew_sextupoles ( self ) -> float Get the first order horizontal cross-term amplitude detuning from skew sextupoles. Returns: The first order horizontal cross-term amplitude detuning from skew sextupoles. View Source def dqx_djy_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order horizontal cross-term amplitude detuning from skew sextupoles. Returns: The first order horizontal cross-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * ( 2 * 1 ) * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * ( - 2 * 1 ) * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi )","title":"dqx_djy_from_skew_sextupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqx_from_octupoles","text":"def dqx_from_octupoles ( self , jx : float , jy : float ) -> float Get the horizontal amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from octupoles. View Source def dqx_from_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy + jy * jy ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy - jy * jy ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jx * jx * T ( 4 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * jy * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * jx * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jx * jx * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi )","title":"dqx_from_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqx_from_sextupoles","text":"def dqx_from_sextupoles ( self , jx : float , jy : float ) -> float Get the horizontal amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from sextupoles. View Source def dqx_from_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * jx * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * betas_x [ k ] * betas_y [ j ] * jy * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * jx * T ( 3 , 0 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 2 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * jy * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvx / ( 2 * np . pi )","title":"dqx_from_sextupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqx_from_skew_octupoles","text":"def dqx_from_skew_octupoles ( self , jx : float , jy : float ) -> float Get the horizontal amplitude detuning from skew octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew octupoles. View Source def dqx_from_skew_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from skew octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * jy * jy * ( T ( 1 , - 3 , dmux , dmuy , qx , qy ) - T ( 1 , 3 , dmux , dmuy , qx , qy )) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * ( jx * jx + 6 * jx * jy ) * T ( 3 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( + 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * ( jx * jx - 6 * jx * jy ) * T ( 3 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi )","title":"dqx_from_skew_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqx_from_skew_quadrupoles","text":"def dqx_from_skew_quadrupoles ( self ) -> float Get the horizontal amplitude detuning from skew quadrupoles. Returns: The horizontals amplitude detuning from skew quadrupoles. View Source def dqx_from_skew_quadrupoles ( self ) -> float : \"\"\" Get the horizontal amplitude detuning from skew quadrupoles. Returns: The horizontals amplitude detuning from skew quadrupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 betas_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUY\" ] . values a1 : np . ndarray = self . skew_quadrupoles_twiss_df [ \"K1SL\" ] . values for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a1 [ j ] * a1 [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * ( T ( 1 , - 1 , dmux , dmuy , qx , qy ) - T ( 1 , 1 , dmux , dmuy , qx , qy )) ) return dvx / ( 2 * np . pi )","title":"dqx_from_skew_quadrupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqx_from_skew_sextupoles","text":"def dqx_from_skew_sextupoles ( self , jx : float , jy : float ) -> float Get the horizontal amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew sextupoles. View Source def dqx_from_skew_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the horizontal amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The horizontal amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvx : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 4 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * jx * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * jy * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * ( jx + 2 * jy ) * T ( 2 , 1 , dmux , dmuy , qx , qy ) ) ) dvx += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * ( jx - 2 * jy ) * T ( 2 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvx / ( 2 * np . pi )","title":"dqx_from_skew_sextupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#verticalamplitudedetuning","text":"class VerticalAmplitudeDetuning ( twiss_filename : Union [ pathlib . Path , str ] ) Class to compute different orders of amplitude detuning for the vertical plane. View Source class VerticalAmplitudeDetuning : \"\"\" Class to compute different orders of amplitude detuning for the vertical plane. \"\"\" __slots__ = { \"twiss_file\" : \"PosixPath object to the twiss output tfs file\" , \"twiss_df\" : \"TfsDataFrame loaded from twiss_file\" , \"qx\" : \"Horizontal tune extracted from twiss_df\" , \"qy\" : \"Vertical tune extracted from twiss_df\" , \"quadrupoles_twiss_df\" : \"Twiss dataframe for normal quadrupoles\" , \"skew_quadrupoles_twiss_df\" : \"Twiss dataframe for skew quadrupoles\" , \"sextupoles_twiss_df\" : \"Twiss dataframe for normal sextupoles\" , \"skew_sextupoles_twiss_df\" : \"Twiss dataframe for skew sextupoles\" , \"octupoles_twiss_df\" : \"Twiss dataframe for normal octupoles\" , \"skew_octupoles_twiss_df\" : \"Twiss dataframe for skew octupoles\" , } def __init__ ( self , twiss_filename : Union [ Path , str ]) -> None : \"\"\" Load external twiss file and extract relevant values and dataframes. Args: twiss_filename (Union[Path, str]): location to the twiss file output by MAD, in the tfs format, to be read by the tfs package, which accepts either a Path or a string. \"\"\" logger . debug ( \"Loading twiss file into memory and extracting sub-dataframes\" ) self . twiss_file : Path = Path ( twiss_filename ) self . twiss_df : tfs . TfsDataFrame = tfs . read ( twiss_filename ) self . qx : float = self . twiss_df [ \"MUX\" ] . values [ - 1 ] self . qy : float = self . twiss_df [ \"MUY\" ] . values [ - 1 ] logger . trace ( \"Extracting quadrupoles dataframe\" ) self . quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1L\" ] != 0 ] logger . trace ( \"Extracting skew quadrupoles dataframe\" ) self . skew_quadrupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K1SL\" ] != 0 ] logger . trace ( \"Extracting sextupoles dataframe\" ) self . sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2L\" ] != 0 ] logger . trace ( \"Extracting skew sextupoles dataframe\" ) self . skew_sextupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K2SL\" ] != 0 ] logger . trace ( \"Extracting octupoles dataframe\" ) self . octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3L\" ] != 0 ] logger . trace ( \"Extracting skew octupoles dataframe\" ) self . skew_octupoles_twiss_df : tfs . TfsDataFrame = self . twiss_df [ self . twiss_df [ \"K3SL\" ] != 0 ] def __str__ ( self ): \"\"\"Simple str method indicates the name\"\"\" return f \"VertAmpDet['{self.twiss_file.name}']\" def __repr__ ( self ): \"\"\"The repr method indicates tunes\"\"\" return ( f \"'VerticalAmplitudeDetuning[{self.twiss_file.absolute()}' | \" f \"Qx = {self.qx:.4f} | Qy = {self.qy:.4f}]\" ) def dqy_djx_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order vertical cross-term amplitude detuning from skew sextupoles. Returns: The first order vertical cross-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 2 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * ( T ( 2 , - 1 , dmux , dmuy , qx , qy ) - T ( 2 , 1 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_djx_from_sextupoles ( self ) -> float : \"\"\" Get the first order vertical cross-term amplitude detuning from sextupoles. Returns: The first order vertical cross-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * betas_x [ k ] * betas_y [ j ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * 1 ) * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * 1 ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_djx ( self ) -> float : \"\"\" Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. \"\"\" return self . dqy_djx_from_skew_sextupoles () + self . dqy_djx_from_sextupoles () def d2qy_djx2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical cross-term amplitude detuning from skew octupoles. Returns: The second order vertical cross-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETy\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * ( T ( 3 , - 1 , dmux , dmuy , qx , qy ) + T ( 3 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djx2_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical cross-term amplitude detuning from octupoles. Returns: The second order vertical cross-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_x [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_y [ j ] * betas_x [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djx2 ( self ) -> float : \"\"\" Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. \"\"\" return self . d2qy_djx2_from_skew_octupoles () + self . d2qy_djx2_from_octupoles () def dqy_djy_skew_sextupoles ( self ) -> float : \"\"\" Get the first order vertical direct-term amplitude detuning from skew sextupoles. Returns: The first order vertical direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 3 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * 1 * T ( 0 , 3 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy_djy_from_sextupoles ( self ) -> float : \"\"\" Get the first order vertical direct-term amplitude detuning from sextupoles. Returns: The first order vertical direct-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_y [ k ] * betas_y [ j ] * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * 1 * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( - 1 ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_djy ( self ) -> float : \"\"\" Returns the first order vertical direct-term amplitude detuning. Returns: The first order vertical direct-term amplitude detuning. \"\"\" return self . dqy_djy_skew_sextupoles () + self . dqy_djy_from_sextupoles () def d2qy_djy2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical direct-term amplitude detuning from skew octupoles. Returns: The second order vertical direct-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djy2_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical direct-term amplitude detuning from octupoles. Returns: The second order vertical direct-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 0 , 4 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_y [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djy2 ( self ) -> float : \"\"\" Returns the second order vertical direct-term amplitude detuning. Returns: The second order vertical direct-term amplitude detuning. \"\"\" return self . d2qy_djy2_from_skew_octupoles () + self . d2qy_djy2_from_octupoles () def d2qy_djxdjy_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical mixed-term amplitude detuning from skew octupoles. Returns: The second order vertical mixed-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * 1 * 1 ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * 1 * 1 ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djxdjy_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical mixed-term amplitude detuning from octupoles. Returns: The second order vertical mixed-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_y [ k ] * betas_y [ j ] * betas_y [ k ] * 1 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def d2qy_djxdjy ( self ) -> float : \"\"\" Returns the second order vertical mixed-term amplitude detuning. Returns: The second order vertical mixed-term amplitude detuning. \"\"\" return self . d2qy_djxdjy_from_skew_octupoles () + self . d2qy_djxdjy_from_octupoles () def dqy_from_skew_quadrupoles ( self ) -> float : \"\"\" Get the vertical amplitude detuning from skew quadrupoles. Returns: The vertical amplitude detuning from skew quadrupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUY\" ] . values a1 : np . ndarray = self . skew_quadrupoles_twiss_df [ \"K1SL\" ] . values for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a1 [ j ] * a1 [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * ( T ( 1 , - 1 , dmux , dmuy , qx , qy ) + T ( 1 , 1 , dmux , dmuy , qx , qy )) ) return dvy / ( 2 * np . pi ) def dqy_from_skew_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jx * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 3 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jy * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 2 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jx * ( T ( 2 , - 1 , dmux , dmuy , qx , qy ) - T ( 2 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ]) * jy * T ( 0 , 3 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy_from_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * betas_x [ k ] * betas_y [ j ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * jx * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * betas_y [ k ] * betas_y [ j ] * jy * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * jx + jy ) * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ]) * ( 2 * jx - jy ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi ) def dqy_from_skew_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from skew octupoles. jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * ( T ( 3 , - 1 , dmux , dmuy , qx , qy ) + T ( 3 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * jx * jy + jy * jy ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * ( 6 * jx * jy - jy * jy ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_y [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ]) * betas_x [ k ] * betas_y [ j ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy_from_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ): for k in range ( betas_y . size ): dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy + jx * jx ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy - jx * jx ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jy * jy * T ( 0 , 4 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_y [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * jy * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_y [ k ] * betas_y [ j ] * betas_y [ k ] * jx * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_x [ k ] * jx * jx * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_y [ j ] * betas_x [ k ] * betas_y [ k ] * jx * jx * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi ) def dqy ( self , jx : float , jy : float ) -> float : \"\"\" Returns the vertical amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning. \"\"\" return ( self . dqy_from_skew_quadrupoles () + self . dqy_from_skew_sextupoles ( jx , jy ) + self . dqy_from_sextupoles ( jx , jy ) + self . dqy_from_skew_octupoles ( jx , jy ) + self . dqy_from_octupoles ( jx , jy ) )","title":"VerticalAmplitudeDetuning"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#instance-variables_1","text":"octupoles_twiss_df quadrupoles_twiss_df qx qy sextupoles_twiss_df skew_octupoles_twiss_df skew_quadrupoles_twiss_df skew_sextupoles_twiss_df twiss_df twiss_file","title":"Instance variables"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#methods_1","text":"","title":"Methods"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qy_djx2","text":"def d2qy_djx2 ( self ) -> float Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. View Source def d2qy_djx2 ( self ) -> float : \"\"\" Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. \"\"\" return self . d2qy_djx2_from_skew_octupoles () + self . d2qy_djx2_from_octupoles ()","title":"d2qy_djx2"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qy_djx2_from_octupoles","text":"def d2qy_djx2_from_octupoles ( self ) -> float Get the second order vertical cross-term amplitude detuning from octupoles. Returns: The second order vertical cross-term amplitude detuning from octupoles. View Source def d2qy_djx2_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical cross-term amplitude detuning from octupoles. Returns: The second order vertical cross-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_x [ k ] * 2 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_y [ j ] * betas_x [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi )","title":"d2qy_djx2_from_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qy_djx2_from_skew_octupoles","text":"def d2qy_djx2_from_skew_octupoles ( self ) -> float Get the second order vertical cross-term amplitude detuning from skew octupoles. Returns: The second order vertical cross-term amplitude detuning from skew octupoles. View Source def d2qy_djx2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical cross-term amplitude detuning from skew octupoles. Returns: The second order vertical cross-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETy\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * ( T ( 3 , - 1 , dmux , dmuy , qx , qy ) + T ( 3 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi )","title":"d2qy_djx2_from_skew_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qy_djxdjy","text":"def d2qy_djxdjy ( self ) -> float Returns the second order vertical mixed-term amplitude detuning. Returns: The second order vertical mixed-term amplitude detuning. View Source def d2qy_djxdjy ( self ) -> float : \"\"\" Returns the second order vertical mixed-term amplitude detuning. Returns: The second order vertical mixed-term amplitude detuning. \"\"\" return self . d2qy_djxdjy_from_skew_octupoles () + self . d2qy_djxdjy_from_octupoles ()","title":"d2qy_djxdjy"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qy_djxdjy_from_octupoles","text":"def d2qy_djxdjy_from_octupoles ( self ) -> float Get the second order vertical mixed-term amplitude detuning from octupoles. Returns: The second order vertical mixed-term amplitude detuning from octupoles. View Source def d2qy_djxdjy_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical mixed-term amplitude detuning from octupoles. Returns: The second order vertical mixed-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 * 1 ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_y [ k ] * betas_y [ j ] * betas_y [ k ] * 1 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi )","title":"d2qy_djxdjy_from_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qy_djxdjy_from_skew_octupoles","text":"def d2qy_djxdjy_from_skew_octupoles ( self ) -> float Get the second order vertical mixed-term amplitude detuning from skew octupoles. Returns: The second order vertical mixed-term amplitude detuning from skew octupoles. View Source def d2qy_djxdjy_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical mixed-term amplitude detuning from skew octupoles. Returns: The second order vertical mixed-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * ( 6 * 1 * 1 ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * ( 6 * 1 * 1 ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * 1 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi )","title":"d2qy_djxdjy_from_skew_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qy_djy2","text":"def d2qy_djy2 ( self ) -> float Returns the second order vertical direct-term amplitude detuning. Returns: The second order vertical direct-term amplitude detuning. View Source def d2qy_djy2 ( self ) -> float : \"\"\" Returns the second order vertical direct-term amplitude detuning. Returns: The second order vertical direct-term amplitude detuning. \"\"\" return self . d2qy_djy2_from_skew_octupoles () + self . d2qy_djy2_from_octupoles ()","title":"d2qy_djy2"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qy_djy2_from_octupoles","text":"def d2qy_djy2_from_octupoles ( self ) -> float Get the second order vertical direct-term amplitude detuning from octupoles. Returns: The second order vertical direct-term amplitude detuning from octupoles. View Source def d2qy_djy2_from_octupoles ( self ) -> float : \"\"\" Get the second order vertical direct-term amplitude detuning from octupoles. Returns: The second order vertical direct-term amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * 2 * 1 * T ( 0 , 4 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_y [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * 2 * 1 * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi )","title":"d2qy_djy2_from_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#d2qy_djy2_from_skew_octupoles","text":"def d2qy_djy2_from_skew_octupoles ( self ) -> float Get the second order vertical direct-term amplitude detuning from skew octupoles. Returns: The second order vertical direct-term amplitude detuning from skew octupoles. View Source def d2qy_djy2_from_skew_octupoles ( self ) -> float : \"\"\" Get the second order vertical direct-term amplitude detuning from skew octupoles. Returns: The second order vertical direct-term amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * ( 2 * 1 ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * ( - 2 * 1 ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * 2 * 1 * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi )","title":"d2qy_djy2_from_skew_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqy","text":"def dqy ( self , jx : float , jy : float ) -> float Returns the vertical amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning. View Source def dqy ( self , jx : float , jy : float ) -> float : \"\"\" Returns the vertical amplitude detuning. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning. \"\"\" return ( self . dqy_from_skew_quadrupoles () + self . dqy_from_skew_sextupoles ( jx , jy ) + self . dqy_from_sextupoles ( jx , jy ) + self . dqy_from_skew_octupoles ( jx , jy ) + self . dqy_from_octupoles ( jx , jy ) )","title":"dqy"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqy_djx","text":"def dqy_djx ( self ) -> float Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. View Source def dqy_djx ( self ) -> float : \"\"\" Returns the first order vertical cross-term amplitude detuning. Returns: The first order vertical cross-term amplitude detuning. \"\"\" return self . dqy_djx_from_skew_sextupoles () + self . dqy_djx_from_sextupoles ()","title":"dqy_djx"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqy_djx_from_sextupoles","text":"def dqy_djx_from_sextupoles ( self ) -> float Get the first order vertical cross-term amplitude detuning from sextupoles. Returns: The first order vertical cross-term amplitude detuning from sextupoles. View Source def dqy_djx_from_sextupoles ( self ) -> float : \"\"\" Get the first order vertical cross-term amplitude detuning from sextupoles. Returns: The first order vertical cross-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * betas_x [ k ] * betas_y [ j ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * ( 2 * 1 ) * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * ( 2 * 1 ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi )","title":"dqy_djx_from_sextupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqy_djx_from_skew_sextupoles","text":"def dqy_djx_from_skew_sextupoles ( self ) -> float Get the first order vertical cross-term amplitude detuning from skew sextupoles. Returns: The first order vertical cross-term amplitude detuning from skew sextupoles. View Source def dqy_djx_from_skew_sextupoles ( self ) -> float : \"\"\" Get the first order vertical cross-term amplitude detuning from skew sextupoles. Returns: The first order vertical cross-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 2 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * ( T ( 2 , - 1 , dmux , dmuy , qx , qy ) - T ( 2 , 1 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi )","title":"dqy_djx_from_skew_sextupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqy_djy","text":"def dqy_djy ( self ) -> float Returns the first order vertical direct-term amplitude detuning. Returns: The first order vertical direct-term amplitude detuning. View Source def dqy_djy ( self ) -> float : \"\"\" Returns the first order vertical direct-term amplitude detuning. Returns: The first order vertical direct-term amplitude detuning. \"\"\" return self . dqy_djy_skew_sextupoles () + self . dqy_djy_from_sextupoles ()","title":"dqy_djy"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqy_djy_from_sextupoles","text":"def dqy_djy_from_sextupoles ( self ) -> float Get the first order vertical direct-term amplitude detuning from sextupoles. Returns: The first order vertical direct-term amplitude detuning from sextupoles. View Source def dqy_djy_from_sextupoles ( self ) -> float : \"\"\" Get the first order vertical direct-term amplitude detuning from sextupoles. Returns: The first order vertical direct-term amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * betas_y [ k ] * betas_y [ j ] * 1 * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * 1 * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * ( - 1 ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi )","title":"dqy_djy_from_sextupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqy_djy_skew_sextupoles","text":"def dqy_djy_skew_sextupoles ( self ) -> float Get the first order vertical direct-term amplitude detuning from skew sextupoles. Returns: The first order vertical direct-term amplitude detuning from skew sextupoles. View Source def dqy_djy_skew_sextupoles ( self ) -> float : \"\"\" Get the first order vertical direct-term amplitude detuning from skew sextupoles. Returns: The first order vertical direct-term amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 3 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * 1 * T ( 0 , 3 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi )","title":"dqy_djy_skew_sextupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqy_from_octupoles","text":"def dqy_from_octupoles ( self , jx : float , jy : float ) -> float Get the vertical amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from octupoles. View Source def dqy_from_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from octupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . octupoles_twiss_df [ \"MUY\" ] . values b3 : np . ndarray = self . octupoles_twiss_df [ \"K3L\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy + jx * jx ) * T ( 2 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 9 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] * ( 2 * jx * jy - jx * jx ) * T ( 2 , - 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 3 * betas_x [ j ] * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * jy * jy * T ( 0 , 4 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 24 * betas_y [ j ] * betas_y [ j ] * betas_y [ k ] * betas_y [ k ] * jy * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 72 * betas_x [ j ] * betas_y [ k ] * betas_y [ j ] * betas_y [ k ] * jx * jy * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 72 * betas_x [ j ] * betas_x [ k ] * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( 36 * betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_x [ k ] * jx * jx * T ( 2 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * b3 [ j ] * b3 [ k ] * ( - 36 * betas_x [ j ] * betas_y [ j ] * betas_x [ k ] * betas_y [ k ] * jx * jx * T ( 0 , 2 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi )","title":"dqy_from_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqy_from_sextupoles","text":"def dqy_from_sextupoles ( self , jx : float , jy : float ) -> float Get the vertical amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from sextupoles. View Source def dqy_from_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . sextupoles_twiss_df [ \"MUY\" ] . values b2 : np . ndarray = self . sextupoles_twiss_df [ \"K2L\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( 4 * betas_x [ k ] * betas_y [ j ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * jx * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - 4 * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * betas_y [ k ] * betas_y [ j ] * jy * T ( 1 , 0 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * ( 2 * jx + jy ) * T ( 1 , 2 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * b2 [ j ] * b2 [ k ] * ( - betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] ) * ( 2 * jx - jy ) * ( T ( 1 , - 2 , dmux , dmuy , qx , qy ) - T ( 1 , 2 , dmux , dmuy , qx , qy )) ) ) return dvy / ( 2 * np . pi )","title":"dqy_from_sextupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqy_from_skew_octupoles","text":"def dqy_from_skew_octupoles ( self , jx : float , jy : float ) -> float Get the vertical amplitude detuning from skew octupoles. jx ( float ): horizontal action variable . jy ( float ): vertical action variable . Returns: The vertical amplitude detuning from skew octupoles. View Source def dqy_from_skew_octupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from skew octupoles. jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from skew octupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_octupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_octupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_octupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_octupoles_twiss_df [ \"MUY\" ] . values a3 : np . ndarray = self . skew_octupoles_twiss_df [ \"K3SL\" ] . values * 6 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 9 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * jx * jx * ( T ( 3 , - 1 , dmux , dmuy , qx , qy ) + T ( 3 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * ( 6 * jx * jy + jy * jy ) * T ( 1 , - 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 3 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * ( 6 * jx * jy - jy * jy ) * T ( 1 , 3 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_x [ k ] * jx * jx * T ( 1 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ j ] * betas_y [ k ] * jy * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 54 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_y [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( 72 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * jx * jy * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 27 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ j ] * betas_x [ k ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 32 ) * a3 [ j ] * a3 [ k ] * ( - 36 * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * betas_x [ k ] * betas_y [ j ] * jx * jx * T ( 1 , - 1 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi )","title":"dqy_from_skew_octupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqy_from_skew_quadrupoles","text":"def dqy_from_skew_quadrupoles ( self ) -> float Get the vertical amplitude detuning from skew quadrupoles. Returns: The vertical amplitude detuning from skew quadrupoles. View Source def dqy_from_skew_quadrupoles ( self ) -> float : \"\"\" Get the vertical amplitude detuning from skew quadrupoles. Returns: The vertical amplitude detuning from skew quadrupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_quadrupoles_twiss_df [ \"MUY\" ] . values a1 : np . ndarray = self . skew_quadrupoles_twiss_df [ \"K1SL\" ] . values for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a1 [ j ] * a1 [ k ] * np . sqrt ( betas_x [ j ] * betas_x [ k ] * betas_y [ j ] * betas_y [ k ] ) * ( T ( 1 , - 1 , dmux , dmuy , qx , qy ) + T ( 1 , 1 , dmux , dmuy , qx , qy )) ) return dvy / ( 2 * np . pi )","title":"dqy_from_skew_quadrupoles"},{"location":"reference/pyhdtoolkit/optics/amplitude_detuning/#dqy_from_skew_sextupoles","text":"def dqy_from_skew_sextupoles ( self , jx : float , jy : float ) -> float Get the vertical amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from skew sextupoles. View Source def dqy_from_skew_sextupoles ( self , jx : float , jy : float ) -> float : \"\"\" Get the vertical amplitude detuning from skew sextupoles. Args: jx (float): horizontal action variable. jy (float): vertical action variable. Returns: The vertical amplitude detuning from skew sextupoles. \"\"\" qx : float = self . qx qy : float = self . qy dvy : float = 0 # accumulator for final result betas_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETX\" ] . values betas_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"BETY\" ] . values mu_x : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUX\" ] . values mu_y : np . ndarray = self . skew_sextupoles_twiss_df [ \"MUY\" ] . values a2 : np . ndarray = self . skew_sextupoles_twiss_df [ \"K2SL\" ] . values * 2 for j in range ( betas_x . size ) : for k in range ( betas_y . size ) : dmux : float = mu_x [ j ] - mu_x [ k ] # horizontal phase advance between those indices dmuy : float = mu_y [ j ] - mu_y [ k ] # vertical phase advance between those indices dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 4 * betas_x [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * jx * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( - 3 * betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * jy * T ( 0 , 1 , dmux , dmuy , qx , qy ) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( 2 * betas_x [ j ] * betas_x [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * jx * ( T ( 2 , - 1 , dmux , dmuy , qx , qy ) - T ( 2 , 1 , dmux , dmuy , qx , qy )) ) ) dvy += ( ( 1.0 / 8 ) * a2 [ j ] * a2 [ k ] * ( betas_y [ j ] * betas_y [ k ] * np . sqrt ( betas_y [ j ] * betas_y [ k ] ) * jy * T ( 0 , 3 , dmux , dmuy , qx , qy ) ) ) return dvy / ( 2 * np . pi )","title":"dqy_from_skew_sextupoles"},{"location":"reference/pyhdtoolkit/optics/beam/","text":"Module pyhdtoolkit.optics.beam View Source import numpy as np from scipy import constants class Beam : def __init__ ( self , energy : float , emittance : float , m0 : float = constants . physical_constants [ \"proton mass energy equivalent in MeV\" ][ 0 ], ) -> None : \"\"\" Args: energy (float): energy of the particles in your beam, in [GeV]. emittance (float): beam emittance, in [m]. m0 (float): rest mass of the beam's particles in MeV. Defaults to that of a proton. \"\"\" self . energy = energy self . emittance = emittance self . rest_mass = m0 @property def gamma_rel ( self ) -> float : \"\"\"Relativistic gamma.\"\"\" return ( 1e3 * self . energy + self . rest_mass ) / self . rest_mass @property def beta_rel ( self ) -> float : \"\"\"Relativistic beta.\"\"\" return np . sqrt ( 1 + 1 / ( self . gamma_rel ** 2 )) @property def brho ( self ) -> float : \"\"\"Beam rigidity [T/m].\"\"\" return ( 1 / 0.3 ) * self . beta_rel * self . energy / constants . c @property def normalized_emittance ( self ) -> float : \"\"\" Normalized emittance [m]. \"\"\" return self . emittance * self . beta_rel * self . gamma_rel @property def rms_emittance ( self ) -> float : \"\"\" Rms emittance [m]. \"\"\" return self . emittance / ( self . beta_rel * self . gamma_rel ) def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = constants . c ) -> float : \"\"\" Revolution frequency. Args: circumference (float): the machine circumference in [m]. Defaults to that of the LHC. speed (float): the particles' speed in the machine, in [m/s]. Defaults to c. \"\"\" return self . beta_rel * speed / circumference def eta ( self , alpha_p : float ) -> float : \"\"\" Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Args: alpha_p (float): momentum compaction factor. \"\"\" return ( 1 / ( self . gamma_rel ** 2 )) - alpha_p def gamma_transition ( self , alpha_p : float ) -> float : \"\"\" Relativistic gamma corresponding to the transition energy. Args: alpha_p (float): momentum compaction factor. \"\"\" return np . sqrt ( 1 / alpha_p ) Classes Beam class Beam ( energy : float , emittance : float , m0 : float = 938.27208816 ) View Source class Beam : def __init__ ( self , energy : float , emittance : float , m0 : float = constants . physical_constants [ \"proton mass energy equivalent in MeV\" ][ 0 ] , ) -> None : \"\"\" Args: energy (float): energy of the particles in your beam, in [GeV]. emittance (float): beam emittance, in [m]. m0 (float): rest mass of the beam's particles in MeV. Defaults to that of a proton. \"\"\" self . energy = energy self . emittance = emittance self . rest_mass = m0 @property def gamma_rel ( self ) -> float : \"\"\"Relativistic gamma.\"\"\" return ( 1e3 * self . energy + self . rest_mass ) / self . rest_mass @property def beta_rel ( self ) -> float : \"\"\"Relativistic beta.\"\"\" return np . sqrt ( 1 + 1 / ( self . gamma_rel ** 2 )) @property def brho ( self ) -> float : \"\"\"Beam rigidity [T/m].\"\"\" return ( 1 / 0.3 ) * self . beta_rel * self . energy / constants . c @property def normalized_emittance ( self ) -> float : \"\"\" Normalized emittance [m]. \"\"\" return self . emittance * self . beta_rel * self . gamma_rel @property def rms_emittance ( self ) -> float : \"\"\" Rms emittance [m]. \"\"\" return self . emittance / ( self . beta_rel * self . gamma_rel ) def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = constants . c ) -> float : \"\"\" Revolution frequency. Args: circumference (float): the machine circumference in [m]. Defaults to that of the LHC. speed (float): the particles' speed in the machine, in [m/s]. Defaults to c. \"\"\" return self . beta_rel * speed / circumference def eta ( self , alpha_p : float ) -> float : \"\"\" Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Args: alpha_p (float): momentum compaction factor. \"\"\" return ( 1 / ( self . gamma_rel ** 2 )) - alpha_p def gamma_transition ( self , alpha_p : float ) -> float : \"\"\" Relativistic gamma corresponding to the transition energy. Args: alpha_p (float): momentum compaction factor. \"\"\" return np . sqrt ( 1 / alpha_p ) Instance variables beta_rel Relativistic beta. brho Beam rigidity [T/m]. gamma_rel Relativistic gamma. normalized_emittance Normalized emittance [m]. rms_emittance Rms emittance [m]. Methods eta def eta ( self , alpha_p : float ) -> float Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Args: alpha_p (float): momentum compaction factor. View Source def eta ( self , alpha_p : float ) -> float : \"\"\" Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Args: alpha_p (float): momentum compaction factor. \"\"\" return ( 1 / ( self . gamma_rel ** 2 )) - alpha_p gamma_transition def gamma_transition ( self , alpha_p : float ) -> float Relativistic gamma corresponding to the transition energy. Args: alpha_p (float): momentum compaction factor. View Source def gamma_transition ( self , alpha_p : float ) -> float : \"\"\" Relativistic gamma corresponding to the transition energy. Args: alpha_p (float): momentum compaction factor. \"\"\" return np . sqrt ( 1 / alpha_p ) revolution_frequency def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = 299792458.0 ) -> float Revolution frequency. Args: circumference (float): the machine circumference in [m]. Defaults to that of the LHC. speed (float): the particles' speed in the machine, in [m/s]. Defaults to c. View Source def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = constants . c ) -> float : \"\"\" Revolution frequency. Args: circumference (float): the machine circumference in [m]. Defaults to that of the LHC. speed (float): the particles' speed in the machine, in [m/s]. Defaults to c. \"\"\" return self . beta_rel * speed / circumference","title":"Beam"},{"location":"reference/pyhdtoolkit/optics/beam/#module-pyhdtoolkitopticsbeam","text":"View Source import numpy as np from scipy import constants class Beam : def __init__ ( self , energy : float , emittance : float , m0 : float = constants . physical_constants [ \"proton mass energy equivalent in MeV\" ][ 0 ], ) -> None : \"\"\" Args: energy (float): energy of the particles in your beam, in [GeV]. emittance (float): beam emittance, in [m]. m0 (float): rest mass of the beam's particles in MeV. Defaults to that of a proton. \"\"\" self . energy = energy self . emittance = emittance self . rest_mass = m0 @property def gamma_rel ( self ) -> float : \"\"\"Relativistic gamma.\"\"\" return ( 1e3 * self . energy + self . rest_mass ) / self . rest_mass @property def beta_rel ( self ) -> float : \"\"\"Relativistic beta.\"\"\" return np . sqrt ( 1 + 1 / ( self . gamma_rel ** 2 )) @property def brho ( self ) -> float : \"\"\"Beam rigidity [T/m].\"\"\" return ( 1 / 0.3 ) * self . beta_rel * self . energy / constants . c @property def normalized_emittance ( self ) -> float : \"\"\" Normalized emittance [m]. \"\"\" return self . emittance * self . beta_rel * self . gamma_rel @property def rms_emittance ( self ) -> float : \"\"\" Rms emittance [m]. \"\"\" return self . emittance / ( self . beta_rel * self . gamma_rel ) def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = constants . c ) -> float : \"\"\" Revolution frequency. Args: circumference (float): the machine circumference in [m]. Defaults to that of the LHC. speed (float): the particles' speed in the machine, in [m/s]. Defaults to c. \"\"\" return self . beta_rel * speed / circumference def eta ( self , alpha_p : float ) -> float : \"\"\" Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Args: alpha_p (float): momentum compaction factor. \"\"\" return ( 1 / ( self . gamma_rel ** 2 )) - alpha_p def gamma_transition ( self , alpha_p : float ) -> float : \"\"\" Relativistic gamma corresponding to the transition energy. Args: alpha_p (float): momentum compaction factor. \"\"\" return np . sqrt ( 1 / alpha_p )","title":"Module pyhdtoolkit.optics.beam"},{"location":"reference/pyhdtoolkit/optics/beam/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/optics/beam/#beam","text":"class Beam ( energy : float , emittance : float , m0 : float = 938.27208816 ) View Source class Beam : def __init__ ( self , energy : float , emittance : float , m0 : float = constants . physical_constants [ \"proton mass energy equivalent in MeV\" ][ 0 ] , ) -> None : \"\"\" Args: energy (float): energy of the particles in your beam, in [GeV]. emittance (float): beam emittance, in [m]. m0 (float): rest mass of the beam's particles in MeV. Defaults to that of a proton. \"\"\" self . energy = energy self . emittance = emittance self . rest_mass = m0 @property def gamma_rel ( self ) -> float : \"\"\"Relativistic gamma.\"\"\" return ( 1e3 * self . energy + self . rest_mass ) / self . rest_mass @property def beta_rel ( self ) -> float : \"\"\"Relativistic beta.\"\"\" return np . sqrt ( 1 + 1 / ( self . gamma_rel ** 2 )) @property def brho ( self ) -> float : \"\"\"Beam rigidity [T/m].\"\"\" return ( 1 / 0.3 ) * self . beta_rel * self . energy / constants . c @property def normalized_emittance ( self ) -> float : \"\"\" Normalized emittance [m]. \"\"\" return self . emittance * self . beta_rel * self . gamma_rel @property def rms_emittance ( self ) -> float : \"\"\" Rms emittance [m]. \"\"\" return self . emittance / ( self . beta_rel * self . gamma_rel ) def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = constants . c ) -> float : \"\"\" Revolution frequency. Args: circumference (float): the machine circumference in [m]. Defaults to that of the LHC. speed (float): the particles' speed in the machine, in [m/s]. Defaults to c. \"\"\" return self . beta_rel * speed / circumference def eta ( self , alpha_p : float ) -> float : \"\"\" Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Args: alpha_p (float): momentum compaction factor. \"\"\" return ( 1 / ( self . gamma_rel ** 2 )) - alpha_p def gamma_transition ( self , alpha_p : float ) -> float : \"\"\" Relativistic gamma corresponding to the transition energy. Args: alpha_p (float): momentum compaction factor. \"\"\" return np . sqrt ( 1 / alpha_p )","title":"Beam"},{"location":"reference/pyhdtoolkit/optics/beam/#instance-variables","text":"beta_rel Relativistic beta. brho Beam rigidity [T/m]. gamma_rel Relativistic gamma. normalized_emittance Normalized emittance [m]. rms_emittance Rms emittance [m].","title":"Instance variables"},{"location":"reference/pyhdtoolkit/optics/beam/#methods","text":"","title":"Methods"},{"location":"reference/pyhdtoolkit/optics/beam/#eta","text":"def eta ( self , alpha_p : float ) -> float Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Args: alpha_p (float): momentum compaction factor. View Source def eta ( self , alpha_p : float ) -> float : \"\"\" Slip factor parameter eta: eta = 0 at transition energy (eta < 0 above transition). Args: alpha_p (float): momentum compaction factor. \"\"\" return ( 1 / ( self . gamma_rel ** 2 )) - alpha_p","title":"eta"},{"location":"reference/pyhdtoolkit/optics/beam/#gamma_transition","text":"def gamma_transition ( self , alpha_p : float ) -> float Relativistic gamma corresponding to the transition energy. Args: alpha_p (float): momentum compaction factor. View Source def gamma_transition ( self , alpha_p : float ) -> float : \"\"\" Relativistic gamma corresponding to the transition energy. Args: alpha_p (float): momentum compaction factor. \"\"\" return np . sqrt ( 1 / alpha_p )","title":"gamma_transition"},{"location":"reference/pyhdtoolkit/optics/beam/#revolution_frequency","text":"def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = 299792458.0 ) -> float Revolution frequency. Args: circumference (float): the machine circumference in [m]. Defaults to that of the LHC. speed (float): the particles' speed in the machine, in [m/s]. Defaults to c. View Source def revolution_frequency ( self , circumference : float = 26658.8832 , speed : float = constants . c ) -> float : \"\"\" Revolution frequency. Args: circumference (float): the machine circumference in [m]. Defaults to that of the LHC. speed (float): the particles' speed in the machine, in [m/s]. Defaults to c. \"\"\" return self . beta_rel * speed / circumference","title":"revolution_frequency"},{"location":"reference/pyhdtoolkit/optics/twiss/","text":"Module pyhdtoolkit.optics.twiss Module optics.twiss Created on 2020.09.07 :author: Felix Soubelet ( felix.soubelet@cern.ch ) This is a Python3 module implementing various functionality for optics calculations from / to twiss parameters. View Source \"\"\" Module optics.twiss ------------------- Created on 2020.09.07 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 module implementing various functionality for optics calculations from / to twiss parameters. \"\"\" import numba import numpy as np @numba . njit () def courant_snyder_transform ( u_vector : np . ndarray , alpha : float , beta : float ) -> np . ndarray : \"\"\" Perform the Courant-Snyder transform on rergular (nonchaotic) phase-space coordinatess. Specifically, if considering the horizontal plane and noting U = (x, px) the phase-space vector, it returns U_bar = (x_bar, px_bar) according to the transform: U_bar = P * U, where P = [1/sqrt(beta_x) 0 ] [alpha_x/sqrt(beta_x) sqrt(beta_x)] Args: u_vector (np.ndarray): two-dimentional array of phase-space (spatial and momenta) coordinates, either horizontal or vertical. alpha (float): alpha twiss parameter in the appropriate plane. beta (float): beta twiss parameter in the appropriate plane. Returns: The normal phase-space coordinates from the Courant-Snyder transform. \"\"\" p_matrix = np . array ([[ 1 / np . sqrt ( beta ), 0 ], [ alpha / np . sqrt ( beta ), np . sqrt ( beta )]]) return p_matrix @ u_vector Functions courant_snyder_transform def courant_snyder_transform ( u_vector : numpy . ndarray , alpha : float , beta : float ) -> numpy . ndarray Perform the Courant-Snyder transform on rergular (nonchaotic) phase-space coordinatess. Specifically, if considering the horizontal plane and noting U = (x, px) the phase-space vector, it returns U_bar = (x_bar, px_bar) according to the transform: U_bar = P * U, where P = [1/sqrt(beta_x) 0 ] [alpha_x/sqrt(beta_x) sqrt(beta_x)] Args: u_vector (np.ndarray): two-dimentional array of phase-space (spatial and momenta) coordinates, either horizontal or vertical. alpha (float): alpha twiss parameter in the appropriate plane. beta (float): beta twiss parameter in the appropriate plane. Returns: The normal phase-space coordinates from the Courant-Snyder transform. View Source @numba . njit () def courant_snyder_transform ( u_vector : np . ndarray , alpha : float , beta : float ) -> np . ndarray : \"\"\" Perform the Courant-Snyder transform on rergular (nonchaotic) phase-space coordinatess. Specifically, if considering the horizontal plane and noting U = (x, px) the phase-space vector, it returns U_bar = (x_bar, px_bar) according to the transform: U_bar = P * U, where P = [1/sqrt(beta_x) 0 ] [alpha_x/sqrt(beta_x) sqrt(beta_x)] Args: u_vector (np.ndarray): two-dimentional array of phase-space (spatial and momenta) coordinates, either horizontal or vertical. alpha (float): alpha twiss parameter in the appropriate plane. beta (float): beta twiss parameter in the appropriate plane. Returns: The normal phase-space coordinates from the Courant-Snyder transform. \"\"\" p_matrix = np . array ( [ [1 / np.sqrt(beta), 0 ] , [ alpha / np.sqrt(beta), np.sqrt(beta) ] ] ) return p_matrix @ u_vector","title":"Twiss"},{"location":"reference/pyhdtoolkit/optics/twiss/#module-pyhdtoolkitopticstwiss","text":"","title":"Module pyhdtoolkit.optics.twiss"},{"location":"reference/pyhdtoolkit/optics/twiss/#module-opticstwiss","text":"Created on 2020.09.07 :author: Felix Soubelet ( felix.soubelet@cern.ch ) This is a Python3 module implementing various functionality for optics calculations from / to twiss parameters. View Source \"\"\" Module optics.twiss ------------------- Created on 2020.09.07 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 module implementing various functionality for optics calculations from / to twiss parameters. \"\"\" import numba import numpy as np @numba . njit () def courant_snyder_transform ( u_vector : np . ndarray , alpha : float , beta : float ) -> np . ndarray : \"\"\" Perform the Courant-Snyder transform on rergular (nonchaotic) phase-space coordinatess. Specifically, if considering the horizontal plane and noting U = (x, px) the phase-space vector, it returns U_bar = (x_bar, px_bar) according to the transform: U_bar = P * U, where P = [1/sqrt(beta_x) 0 ] [alpha_x/sqrt(beta_x) sqrt(beta_x)] Args: u_vector (np.ndarray): two-dimentional array of phase-space (spatial and momenta) coordinates, either horizontal or vertical. alpha (float): alpha twiss parameter in the appropriate plane. beta (float): beta twiss parameter in the appropriate plane. Returns: The normal phase-space coordinates from the Courant-Snyder transform. \"\"\" p_matrix = np . array ([[ 1 / np . sqrt ( beta ), 0 ], [ alpha / np . sqrt ( beta ), np . sqrt ( beta )]]) return p_matrix @ u_vector","title":"Module optics.twiss"},{"location":"reference/pyhdtoolkit/optics/twiss/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/optics/twiss/#courant_snyder_transform","text":"def courant_snyder_transform ( u_vector : numpy . ndarray , alpha : float , beta : float ) -> numpy . ndarray Perform the Courant-Snyder transform on rergular (nonchaotic) phase-space coordinatess. Specifically, if considering the horizontal plane and noting U = (x, px) the phase-space vector, it returns U_bar = (x_bar, px_bar) according to the transform: U_bar = P * U, where P = [1/sqrt(beta_x) 0 ] [alpha_x/sqrt(beta_x) sqrt(beta_x)] Args: u_vector (np.ndarray): two-dimentional array of phase-space (spatial and momenta) coordinates, either horizontal or vertical. alpha (float): alpha twiss parameter in the appropriate plane. beta (float): beta twiss parameter in the appropriate plane. Returns: The normal phase-space coordinates from the Courant-Snyder transform. View Source @numba . njit () def courant_snyder_transform ( u_vector : np . ndarray , alpha : float , beta : float ) -> np . ndarray : \"\"\" Perform the Courant-Snyder transform on rergular (nonchaotic) phase-space coordinatess. Specifically, if considering the horizontal plane and noting U = (x, px) the phase-space vector, it returns U_bar = (x_bar, px_bar) according to the transform: U_bar = P * U, where P = [1/sqrt(beta_x) 0 ] [alpha_x/sqrt(beta_x) sqrt(beta_x)] Args: u_vector (np.ndarray): two-dimentional array of phase-space (spatial and momenta) coordinates, either horizontal or vertical. alpha (float): alpha twiss parameter in the appropriate plane. beta (float): beta twiss parameter in the appropriate plane. Returns: The normal phase-space coordinates from the Courant-Snyder transform. \"\"\" p_matrix = np . array ( [ [1 / np.sqrt(beta), 0 ] , [ alpha / np.sqrt(beta), np.sqrt(beta) ] ] ) return p_matrix @ u_vector","title":"courant_snyder_transform"},{"location":"reference/pyhdtoolkit/plotting/","text":"Module pyhdtoolkit.plotting plotting package ~ ~ ~ ~ ~ ~ ~ These are miscellaneous utilities to integrate to my plots. :copyright: \u00a9 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. View Source \"\"\" plotting package ~~~~~~~~~~~~~~~~~~~ These are miscellaneous utilities to integrate to my plots. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .helpers import AnnotationsPlotter from .settings import PLOT_PARAMS Sub-modules pyhdtoolkit.plotting.helpers pyhdtoolkit.plotting.settings pyhdtoolkit.plotting.timedata Variables python3 PLOT_PARAMS","title":"Index"},{"location":"reference/pyhdtoolkit/plotting/#module-pyhdtoolkitplotting","text":"plotting package ~ ~ ~ ~ ~ ~ ~ These are miscellaneous utilities to integrate to my plots. :copyright: \u00a9 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. View Source \"\"\" plotting package ~~~~~~~~~~~~~~~~~~~ These are miscellaneous utilities to integrate to my plots. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .helpers import AnnotationsPlotter from .settings import PLOT_PARAMS","title":"Module pyhdtoolkit.plotting"},{"location":"reference/pyhdtoolkit/plotting/#sub-modules","text":"pyhdtoolkit.plotting.helpers pyhdtoolkit.plotting.settings pyhdtoolkit.plotting.timedata","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/plotting/#variables","text":"python3 PLOT_PARAMS","title":"Variables"},{"location":"reference/pyhdtoolkit/plotting/helpers/","text":"Module pyhdtoolkit.plotting.helpers Module plotting.helpers Created on 2019.06.15 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A collection of functions for more descriptive plots. View Source \"\"\" Module plotting.helpers ----------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions for more descriptive plots. \"\"\" from typing import Tuple import matplotlib import matplotlib.axes class AnnotationsPlotter : \"\"\" A class to encapsulate all useful plotting additional tidbits. \"\"\" @staticmethod def set_arrow_label ( axis : matplotlib . axes . Axes , label : str , arrow_position : Tuple [ float , float ], label_position : Tuple [ float , float ], color : str = \"k\" , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 , ) -> matplotlib . text . Annotation : \"\"\" Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes `Axes` instance. Original code from Guido Sterbini. Args: axis (matplotlib.axes.Axes): a matplotlib axis to plot on. label (str): label text to print on the axis. arrow_position (Tuple[float, float]): where on the plot to point the tip of the arrow. label_position (Tuple[float, float]): where on the plot the text label (and thus start of the arrow) is. color (str): color parameter for your arrow and label. Defaults to 'k'. arrow_arc_rad (float): angle value defining the upwards / downwards shape of and bending of the arrow. fontsize (int): text size in the box Returns: A matploblit text annotation object. \"\"\" return axis . annotate ( label , xy = arrow_position , xycoords = \"data\" , xytext = label_position , textcoords = \"data\" , size = fontsize , color = color , va = \"center\" , ha = \"center\" , bbox = dict ( boxstyle = \"round4\" , fc = \"w\" , color = color , lw = 2 ), arrowprops = dict ( arrowstyle = \"-|>\" , connectionstyle = \"arc3,rad=\" + str ( arrow_arc_rad ), fc = \"w\" , color = color , lw = 2 , ), ) Classes AnnotationsPlotter class AnnotationsPlotter ( / , * args , ** kwargs ) A class to encapsulate all useful plotting additional tidbits. View Source class AnnotationsPlotter : \" \"\" A class to encapsulate all useful plotting additional tidbits. \"\" \" @staticmethod def set _arrow_label ( axis : matplotlib . axes . Axes , label : str , arrow_position : Tuple [ float , float ] , label_position : Tuple [ float , float ] , color : str = \"k\" , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 , ) -> matplotlib . text . Annotation : \" \"\" Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes `Axes` instance. Original code from Guido Sterbini. Args: axis (matplotlib.axes.Axes): a matplotlib axis to plot on. label (str): label text to print on the axis. arrow_position (Tuple[float, float]): where on the plot to point the tip of the arrow. label_position (Tuple[float, float]): where on the plot the text label (and thus start of the arrow) is. color (str): color parameter for your arrow and label. Defaults to 'k'. arrow_arc_rad (float): angle value defining the upwards / downwards shape of and bending of the arrow. fontsize (int): text size in the box Returns: A matploblit text annotation object. \"\" \" return axis . annotate ( label , xy = arrow_position , xycoords = \"data\" , xytext = label_position , textcoords = \"data\" , size = fontsize , color = color , va = \"center\" , ha = \"center\" , bbox = dict ( boxstyle = \"round4\" , fc = \"w\" , color = color , lw = 2 ), arrowprops = dict ( arrowstyle = \"-|>\" , connectionstyle = \"arc3,rad=\" + str ( arrow_arc_rad ), fc = \"w\" , color = color , lw = 2 , ), ) Static methods set_arrow_label def set_arrow_label ( axis : matplotlib . axes . _axes . Axes , label : str , arrow_position : Tuple [ float , float ], label_position : Tuple [ float , float ], color : str = 'k' , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 ) -> matplotlib . text . Annotation Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes Axes instance. Original code from Guido Sterbini. Args: axis (matplotlib.axes.Axes): a matplotlib axis to plot on. label (str): label text to print on the axis. arrow_position (Tuple[float, float]): where on the plot to point the tip of the arrow. label_position (Tuple[float, float]): where on the plot the text label (and thus start of the arrow) is. color (str): color parameter for your arrow and label. Defaults to 'k'. arrow_arc_rad (float): angle value defining the upwards / downwards shape of and bending of the arrow. fontsize (int): text size in the box Returns: A matploblit text annotation object. View Source @staticmethod def set _arrow_label ( axis : matplotlib . axes . Axes , label : str , arrow_position : Tuple [ float , float ] , label_position : Tuple [ float , float ] , color : str = \"k\" , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 , ) -> matplotlib . text . Annotation : \" \"\" Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes `Axes` instance. Original code from Guido Sterbini. Args: axis (matplotlib.axes.Axes): a matplotlib axis to plot on. label (str): label text to print on the axis. arrow_position (Tuple[float, float]): where on the plot to point the tip of the arrow. label_position (Tuple[float, float]): where on the plot the text label (and thus start of the arrow) is. color (str): color parameter for your arrow and label. Defaults to 'k'. arrow_arc_rad (float): angle value defining the upwards / downwards shape of and bending of the arrow. fontsize (int): text size in the box Returns: A matploblit text annotation object. \"\" \" return axis . annotate ( label , xy = arrow_position , xycoords = \"data\" , xytext = label_position , textcoords = \"data\" , size = fontsize , color = color , va = \"center\" , ha = \"center\" , bbox = dict ( boxstyle = \"round4\" , fc = \"w\" , color = color , lw = 2 ), arrowprops = dict ( arrowstyle = \"-|>\" , connectionstyle = \"arc3,rad=\" + str ( arrow_arc_rad ), fc = \"w\" , color = color , lw = 2 , ), )","title":"Helpers"},{"location":"reference/pyhdtoolkit/plotting/helpers/#module-pyhdtoolkitplottinghelpers","text":"","title":"Module pyhdtoolkit.plotting.helpers"},{"location":"reference/pyhdtoolkit/plotting/helpers/#module-plottinghelpers","text":"Created on 2019.06.15 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A collection of functions for more descriptive plots. View Source \"\"\" Module plotting.helpers ----------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions for more descriptive plots. \"\"\" from typing import Tuple import matplotlib import matplotlib.axes class AnnotationsPlotter : \"\"\" A class to encapsulate all useful plotting additional tidbits. \"\"\" @staticmethod def set_arrow_label ( axis : matplotlib . axes . Axes , label : str , arrow_position : Tuple [ float , float ], label_position : Tuple [ float , float ], color : str = \"k\" , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 , ) -> matplotlib . text . Annotation : \"\"\" Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes `Axes` instance. Original code from Guido Sterbini. Args: axis (matplotlib.axes.Axes): a matplotlib axis to plot on. label (str): label text to print on the axis. arrow_position (Tuple[float, float]): where on the plot to point the tip of the arrow. label_position (Tuple[float, float]): where on the plot the text label (and thus start of the arrow) is. color (str): color parameter for your arrow and label. Defaults to 'k'. arrow_arc_rad (float): angle value defining the upwards / downwards shape of and bending of the arrow. fontsize (int): text size in the box Returns: A matploblit text annotation object. \"\"\" return axis . annotate ( label , xy = arrow_position , xycoords = \"data\" , xytext = label_position , textcoords = \"data\" , size = fontsize , color = color , va = \"center\" , ha = \"center\" , bbox = dict ( boxstyle = \"round4\" , fc = \"w\" , color = color , lw = 2 ), arrowprops = dict ( arrowstyle = \"-|>\" , connectionstyle = \"arc3,rad=\" + str ( arrow_arc_rad ), fc = \"w\" , color = color , lw = 2 , ), )","title":"Module plotting.helpers"},{"location":"reference/pyhdtoolkit/plotting/helpers/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/plotting/helpers/#annotationsplotter","text":"class AnnotationsPlotter ( / , * args , ** kwargs ) A class to encapsulate all useful plotting additional tidbits. View Source class AnnotationsPlotter : \" \"\" A class to encapsulate all useful plotting additional tidbits. \"\" \" @staticmethod def set _arrow_label ( axis : matplotlib . axes . Axes , label : str , arrow_position : Tuple [ float , float ] , label_position : Tuple [ float , float ] , color : str = \"k\" , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 , ) -> matplotlib . text . Annotation : \" \"\" Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes `Axes` instance. Original code from Guido Sterbini. Args: axis (matplotlib.axes.Axes): a matplotlib axis to plot on. label (str): label text to print on the axis. arrow_position (Tuple[float, float]): where on the plot to point the tip of the arrow. label_position (Tuple[float, float]): where on the plot the text label (and thus start of the arrow) is. color (str): color parameter for your arrow and label. Defaults to 'k'. arrow_arc_rad (float): angle value defining the upwards / downwards shape of and bending of the arrow. fontsize (int): text size in the box Returns: A matploblit text annotation object. \"\" \" return axis . annotate ( label , xy = arrow_position , xycoords = \"data\" , xytext = label_position , textcoords = \"data\" , size = fontsize , color = color , va = \"center\" , ha = \"center\" , bbox = dict ( boxstyle = \"round4\" , fc = \"w\" , color = color , lw = 2 ), arrowprops = dict ( arrowstyle = \"-|>\" , connectionstyle = \"arc3,rad=\" + str ( arrow_arc_rad ), fc = \"w\" , color = color , lw = 2 , ), )","title":"AnnotationsPlotter"},{"location":"reference/pyhdtoolkit/plotting/helpers/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/plotting/helpers/#set_arrow_label","text":"def set_arrow_label ( axis : matplotlib . axes . _axes . Axes , label : str , arrow_position : Tuple [ float , float ], label_position : Tuple [ float , float ], color : str = 'k' , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 ) -> matplotlib . text . Annotation Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes Axes instance. Original code from Guido Sterbini. Args: axis (matplotlib.axes.Axes): a matplotlib axis to plot on. label (str): label text to print on the axis. arrow_position (Tuple[float, float]): where on the plot to point the tip of the arrow. label_position (Tuple[float, float]): where on the plot the text label (and thus start of the arrow) is. color (str): color parameter for your arrow and label. Defaults to 'k'. arrow_arc_rad (float): angle value defining the upwards / downwards shape of and bending of the arrow. fontsize (int): text size in the box Returns: A matploblit text annotation object. View Source @staticmethod def set _arrow_label ( axis : matplotlib . axes . Axes , label : str , arrow_position : Tuple [ float , float ] , label_position : Tuple [ float , float ] , color : str = \"k\" , arrow_arc_rad : float = - 0.2 , fontsize : int = 20 , ) -> matplotlib . text . Annotation : \" \"\" Add a label box with text and an arrow from the box to a specified position to an existing provided matplotlib.axes `Axes` instance. Original code from Guido Sterbini. Args: axis (matplotlib.axes.Axes): a matplotlib axis to plot on. label (str): label text to print on the axis. arrow_position (Tuple[float, float]): where on the plot to point the tip of the arrow. label_position (Tuple[float, float]): where on the plot the text label (and thus start of the arrow) is. color (str): color parameter for your arrow and label. Defaults to 'k'. arrow_arc_rad (float): angle value defining the upwards / downwards shape of and bending of the arrow. fontsize (int): text size in the box Returns: A matploblit text annotation object. \"\" \" return axis . annotate ( label , xy = arrow_position , xycoords = \"data\" , xytext = label_position , textcoords = \"data\" , size = fontsize , color = color , va = \"center\" , ha = \"center\" , bbox = dict ( boxstyle = \"round4\" , fc = \"w\" , color = color , lw = 2 ), arrowprops = dict ( arrowstyle = \"-|>\" , connectionstyle = \"arc3,rad=\" + str ( arrow_arc_rad ), fc = \"w\" , color = color , lw = 2 , ), )","title":"set_arrow_label"},{"location":"reference/pyhdtoolkit/plotting/settings/","text":"Module pyhdtoolkit.plotting.settings Module plotting.settings Created on 2019.12.08 :author: Felix Soubelet ( felix.soubelet@cern.ch ) Some settings for better matplotlib.pyplot plots. Work in progress. View Source \"\"\" Module plotting.settings ------------------------ Created on 2019.12.08 :author: Felix Soubelet (felix.soubelet@cern.ch) Some settings for better matplotlib.pyplot plots. Work in progress. \"\"\" from typing import Dict , Union # Set those with matplotlib.pyplot.rcParams.update(PLOT_PARAMS). # Will ALWAYS be overwritten by later on definition PLOT_PARAMS : Dict [ str , Union [ float , bool , str , tuple ]] = { # ------ Axes ------ # \"axes.linewidth\" : 0.8 , # Linewidth of axes edges \"axes.grid\" : False , # Do not display grid \"axes.labelsize\" : 25 , # Fontsize of the x and y axis labels \"axes.titlesize\" : 27 , # Fontsize of the axes title # ------ Date Forrmats ------ # \"date.autoformatter.year\" : \"%Y\" , # AutoDateFormatter setting for years display \"date.autoformatter.month\" : \"%Y-%m\" , # AutoDateFormatter setting for months display \"date.autoformatter.day\" : \"%Y-%m- %d \" , # AutoDateFormatter setting for days display \"date.autoformatter.hour\" : \"%m- %d %H\" , # AutoDateFormatter setting for seconds display \"date.autoformatter.minute\" : \" %d %H:%M\" , # AutoDateFormatter setting for minutes display \"date.autoformatter.second\" : \"%H:%M:%S\" , # AutoDateFormatter setting for seconds display \"date.autoformatter.microsecond\" : \"%M:%S. %f \" , # AutoDateFormatter setting for microseconds # ------ General Figure ------ # \"figure.autolayout\" : True , # Adjust subplot params to fit the figure (tight_layout) \"figure.dpi\" : 300 , # Figure dots per inch \"figure.figsize\" : ( 18 , 11 ), # Size of the figure \"figure.max_open_warning\" : 10 , # Max number of figures to open before warning \"figure.titlesize\" : 30 , # Size of the figure title # ------ Fonts ------ # \"font.family\" : \"sans-serif\" , # Font family # \"font.sans-serif\": \"Helvetica\", # Sans-Serif font to use \"font.style\" : \"normal\" , # Style to apply to text font # ------- Legend ------ # \"legend.fancybox\" : True , # Use rounded box for legend background \"legend.fontsize\" : 22 , # Legend text font size \"legend.loc\" : \"best\" , # Default legend location # ------ Lines ------ # \"lines.linewidth\" : 1 , # Line width, in points \"lines.markersize\" : 5 , # Marker size, in points \"lines.antialiased\" : True , # Apply anti-aliasing to lines display # ------ Patches ------ # \"patch.linewidth\" : 1 , # Width of patches edge lines \"patch.antialiased\" : True , # Apply anti-aliasing to patches display # ------ Paths ------ # \"path.simplify\" : True , # Reduce file size by removing \"invisible\" points # ------ Saving ------ # \"savefig.dpi\" : 300 , # Saved figure dots per inch \"savefig.format\" : \"pdf\" , # Saved figure file format \"savefig.bbox\" : \"tight\" , # Careful: incompatible with pipe-based animation backends # ------ Text ------ # \"text.antialiased\" : True , # Apply anti-aliasing to text elements \"text.color\" : \"black\" , # Default text color \"text.usetex\" : False , # Do not use LaTeX for text handling (I don't have a local installation) # ------ Ticks ------ # \"xtick.labelsize\" : 20 , # Fontsize of the x axis tick labels \"ytick.labelsize\" : 20 , # Fontsize of the y axis tick labels } Variables PLOT_PARAMS","title":"Settings"},{"location":"reference/pyhdtoolkit/plotting/settings/#module-pyhdtoolkitplottingsettings","text":"","title":"Module pyhdtoolkit.plotting.settings"},{"location":"reference/pyhdtoolkit/plotting/settings/#module-plottingsettings","text":"Created on 2019.12.08 :author: Felix Soubelet ( felix.soubelet@cern.ch ) Some settings for better matplotlib.pyplot plots. Work in progress. View Source \"\"\" Module plotting.settings ------------------------ Created on 2019.12.08 :author: Felix Soubelet (felix.soubelet@cern.ch) Some settings for better matplotlib.pyplot plots. Work in progress. \"\"\" from typing import Dict , Union # Set those with matplotlib.pyplot.rcParams.update(PLOT_PARAMS). # Will ALWAYS be overwritten by later on definition PLOT_PARAMS : Dict [ str , Union [ float , bool , str , tuple ]] = { # ------ Axes ------ # \"axes.linewidth\" : 0.8 , # Linewidth of axes edges \"axes.grid\" : False , # Do not display grid \"axes.labelsize\" : 25 , # Fontsize of the x and y axis labels \"axes.titlesize\" : 27 , # Fontsize of the axes title # ------ Date Forrmats ------ # \"date.autoformatter.year\" : \"%Y\" , # AutoDateFormatter setting for years display \"date.autoformatter.month\" : \"%Y-%m\" , # AutoDateFormatter setting for months display \"date.autoformatter.day\" : \"%Y-%m- %d \" , # AutoDateFormatter setting for days display \"date.autoformatter.hour\" : \"%m- %d %H\" , # AutoDateFormatter setting for seconds display \"date.autoformatter.minute\" : \" %d %H:%M\" , # AutoDateFormatter setting for minutes display \"date.autoformatter.second\" : \"%H:%M:%S\" , # AutoDateFormatter setting for seconds display \"date.autoformatter.microsecond\" : \"%M:%S. %f \" , # AutoDateFormatter setting for microseconds # ------ General Figure ------ # \"figure.autolayout\" : True , # Adjust subplot params to fit the figure (tight_layout) \"figure.dpi\" : 300 , # Figure dots per inch \"figure.figsize\" : ( 18 , 11 ), # Size of the figure \"figure.max_open_warning\" : 10 , # Max number of figures to open before warning \"figure.titlesize\" : 30 , # Size of the figure title # ------ Fonts ------ # \"font.family\" : \"sans-serif\" , # Font family # \"font.sans-serif\": \"Helvetica\", # Sans-Serif font to use \"font.style\" : \"normal\" , # Style to apply to text font # ------- Legend ------ # \"legend.fancybox\" : True , # Use rounded box for legend background \"legend.fontsize\" : 22 , # Legend text font size \"legend.loc\" : \"best\" , # Default legend location # ------ Lines ------ # \"lines.linewidth\" : 1 , # Line width, in points \"lines.markersize\" : 5 , # Marker size, in points \"lines.antialiased\" : True , # Apply anti-aliasing to lines display # ------ Patches ------ # \"patch.linewidth\" : 1 , # Width of patches edge lines \"patch.antialiased\" : True , # Apply anti-aliasing to patches display # ------ Paths ------ # \"path.simplify\" : True , # Reduce file size by removing \"invisible\" points # ------ Saving ------ # \"savefig.dpi\" : 300 , # Saved figure dots per inch \"savefig.format\" : \"pdf\" , # Saved figure file format \"savefig.bbox\" : \"tight\" , # Careful: incompatible with pipe-based animation backends # ------ Text ------ # \"text.antialiased\" : True , # Apply anti-aliasing to text elements \"text.color\" : \"black\" , # Default text color \"text.usetex\" : False , # Do not use LaTeX for text handling (I don't have a local installation) # ------ Ticks ------ # \"xtick.labelsize\" : 20 , # Fontsize of the x axis tick labels \"ytick.labelsize\" : 20 , # Fontsize of the y axis tick labels }","title":"Module plotting.settings"},{"location":"reference/pyhdtoolkit/plotting/settings/#variables","text":"PLOT_PARAMS","title":"Variables"},{"location":"reference/pyhdtoolkit/plotting/timedata/","text":"Module pyhdtoolkit.plotting.timedata View Source import html.parser from datetime import date , datetime from typing import List import dateutil.parser import matplotlib import matplotlib.pyplot as plt import numpy as np import requests from dateutil.relativedelta import relativedelta from loguru import logger from matplotlib.patches import Polygon from pyhdtoolkit.plotting.settings import PLOT_PARAMS plt . rcParams . update ( PLOT_PARAMS ) WEEKDAYS : List [ str ] = [ \"Mon\" , \"Tue\" , \"Wed\" , \"Thu\" , \"Fri\" , \"Sat\" , \"Sun\" ] @logger . catch def calendar_heatmap ( axis : matplotlib . axes . Axes , data : np . ndarray , year : int , origin : str = \"upper\" , cmap : str = \"RdYlBu\" , ) -> None : \"\"\" Plots the data as a heatmap on a Github-like calendar type of plot. Args: axis (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. data (np.ndarray): the data to plot, as a number of occurences for each day. year (int): the year for which the data has to be plotted. origin (str): the bound to use to start counting weekdays, either upper or lower. Defaults to 'upper'. cmap (str): the color map to use for the heatmap. Defaults to 'RdYlBu'. \"\"\" logger . info ( \"Creating calendar heatmap\" ) logger . trace ( \"Setting axis parameters\" ) axis . tick_params ( \"x\" , length = 0 , labelsize = \"medium\" , which = \"major\" ) axis . tick_params ( \"y\" , length = 0 , labelsize = \"x-small\" , which = \"major\" ) xticks , xlabels = [], [] start = datetime ( year , 1 , 1 ) . weekday () data = _prepare_data ( start , data ) for month in range ( 1 , 13 ): first_day = datetime ( year , month , 1 ) last_day = first_day + relativedelta ( months = 1 , days =- 1 ) logger . trace ( f \"Preparing polygon area for { first_day . strftime ( '%B' ) } { year } \" ) x0 : int = ( int ( first_day . strftime ( \"%j\" )) + start - 1 ) // 7 x1 : int = ( int ( last_day . strftime ( \"%j\" )) + start - 1 ) // 7 xticks . append ( x0 + ( x1 - x0 + 1 ) / 2 ) xlabels . append ( first_day . strftime ( \"%b\" )) poly = _prepare_polygon ( first_day , last_day , origin ) axis . add_artist ( poly ) logger . trace ( \"Finishing up axis settings\" ) axis . set_xticks ( xticks ) axis . set_xticklabels ( xlabels ) axis . set_yticks ( 0.5 + np . arange ( 7 )) ylabels = WEEKDAYS if origin . lower () == \"lower\" else WEEKDAYS [:: - 1 ] axis . set_yticklabels ( ylabels ) axis . set_title ( f \" { year } \" , weight = \"semibold\" ) logger . trace ( \"Mapping data\" ) axis . imshow ( data , extent = [ 0 , 54 , 0 , 7 ], zorder = 10 , vmin = np . nanmin ( data ), vmax = np . nanmax ( data ), cmap = cmap , origin = origin , # alpha=0.75, ) @logger . catch def _prepare_data ( start : int , data : np . ndarray ) -> np . ndarray : \"\"\" Prepares a ready-to-use in `calendar_heatmap` data array from the initially provided data. The returned data array is guaranteed to have the proper shape for a full year, and includes np.nan values wherever the initial data does not provide any. Args: start (int): int value of the weekday for the first day of the year the data is for. data (np.ndarray): the data to plot, as a number of occurences for each day. Returns: A prepared numpy array for the data. \"\"\" logger . trace ( \"Preparing data for calendar heatmap\" ) print ( f \"DATA SHAPE: { data . shape } \" ) print ( f \"START: { start } \" ) _data = np . zeros ( data . shape ) * np . nan _data [ start : start + len ( data )] = data return _data . reshape ( 54 , 7 ) . T def _prepare_polygon ( first_day : datetime , last_day : datetime , origin : str ) -> matplotlib . patches . Polygon : \"\"\" Make the calculation for the coordinates of the Polygon corners, based on the first and last day of a month to plot, and the origin setting. Args: first_day (datetime): datetime object for the first day of the month. last_day(datetime): datetime object for the last day of the month. origin (str): the bound to use to start counting weekdays, either upper or lower. Returns: The Polygon object. \"\"\" start : int = datetime ( first_day . year , 1 , 1 ) . weekday () if origin . lower () not in ( \"lower\" , \"upper\" ): logger . error ( f \"The origin must be one of 'upper' or 'lower', but ' { origin } ' was given\" ) raise ValueError ( \"Invalid origin value\" ) logger . trace ( \"Preparing Polygon artist corners\" ) y0 : int = first_day . weekday () if origin . lower () == \"lower\" else 6 - first_day . weekday () y1 : int = last_day . weekday () if origin . lower () == \"lower\" else 6 - last_day . weekday () x0 : int = ( int ( first_day . strftime ( \"%j\" )) + start - 1 ) // 7 x1 : int = ( int ( last_day . strftime ( \"%j\" )) + start - 1 ) // 7 if origin . lower () == \"lower\" : polygon_corners = [ ( x0 , y0 ), ( x0 , 7 ), ( x1 , 7 ), ( x1 , y1 + 1 ), ( x1 + 1 , y1 + 1 ), ( x1 + 1 , 0 ), ( x0 + 1 , 0 ), ( x0 + 1 , y0 ), ] else : polygon_corners = [ ( x0 , y0 + 1 ), ( x0 , 0 ), ( x1 , 0 ), ( x1 , y1 ), ( x1 + 1 , y1 ), ( x1 + 1 , 7 ), ( x0 + 1 , 7 ), ( x0 + 1 , y0 + 1 ), ] logger . trace ( \"Creating polygon\" ) return Polygon ( polygon_corners , edgecolor = \"black\" , facecolor = \"None\" , linewidth = 1 , zorder = 20 , clip_on = False , ) def _github_contributions ( year : int , user : str = \"fsoubelet\" ) -> np . ndarray : \"\"\" Fetch the Github contribution data for the given user in the given year. See how contributions are counted here: https://docs.github.com/en/free-pro-team@latest/github/setting-up-and-managing-your-github-profile/why-are-my-contributions-not-showing-up-on-my-profile Args: year (int): the year to request the data for. user (str): the github username to get the contribution data for. Defaults to mine. Returns: A numpy array with the number of contributions for each day in the year. \"\"\" url : str = f \"https://github.com/users/ { user } /contributions?to= { year } -12-31\" contents = str ( requests . get ( url ) . content ) n = 1 + ( date ( year , 12 , 31 ) - date ( year , 1 , 1 )) . days data = - np . zeros ( n , dtype = int ) class HTMLParser ( html . parser . HTMLParser ): def handle_starttag ( self , tag , attrs ): if tag == \"rect\" : data_ = { key : value for ( key , value ) in attrs } date_ = dateutil . parser . parse ( data_ [ \"data-date\" ]) count = int ( data_ [ \"data-count\" ]) day = date_ . timetuple () . tm_yday - 1 if count > 0 : data [ day ] = count parser = HTMLParser () parser . feed ( contents ) return data Variables PLOT_PARAMS WEEKDAYS Functions calendar_heatmap def calendar_heatmap ( axis : matplotlib . axes . _axes . Axes , data : numpy . ndarray , year : int , origin : str = 'upper' , cmap : str = 'RdYlBu' ) -> None Plots the data as a heatmap on a Github-like calendar type of plot. Args: axis (matplotlib.axes.Axes): an existing matplotlib.axis Axes object to act on. data (np.ndarray): the data to plot, as a number of occurences for each day. year (int): the year for which the data has to be plotted. origin (str): the bound to use to start counting weekdays, either upper or lower. Defaults to 'upper'. cmap (str): the color map to use for the heatmap. Defaults to 'RdYlBu'. View Source @logger . catch def calendar_heatmap ( axis : matplotlib . axes . Axes , data : np . ndarray , year : int , origin : str = \"upper\" , cmap : str = \"RdYlBu\" , ) -> None : \"\"\" Plots the data as a heatmap on a Github-like calendar type of plot. Args: axis (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. data (np.ndarray): the data to plot, as a number of occurences for each day. year (int): the year for which the data has to be plotted. origin (str): the bound to use to start counting weekdays, either upper or lower. Defaults to 'upper'. cmap (str): the color map to use for the heatmap. Defaults to 'RdYlBu'. \"\"\" logger . info ( \"Creating calendar heatmap\" ) logger . trace ( \"Setting axis parameters\" ) axis . tick_params ( \"x\" , length = 0 , labelsize= \"medium\" , which= \"major\" ) axis . tick_params ( \"y\" , length = 0 , labelsize= \"x-small\" , which= \"major\" ) xticks , xlabels = [], [] start = datetime ( year , 1 , 1 ). weekday () data = _ prepare_data ( start , data ) for month in range ( 1 , 13 ) : first_day = datetime ( year , month , 1 ) last_day = first_day + relativedelta ( months = 1 , days=- 1 ) logger . trace ( f \"Preparing polygon area for {first_day.strftime('%B')} {year}\" ) x0: int = ( int ( first_day . strftime ( \"%j\" )) + start - 1 ) // 7 x1: int = ( int ( last_day . strftime ( \"%j\" )) + start - 1 ) // 7 xticks . append ( x0 + ( x1 - x0 + 1 ) / 2 ) xlabels . append ( first_day . strftime ( \"%b\" )) poly = _ prepare_polygon ( first_day , last_day , origin ) axis . add_artist ( poly ) logger . trace ( \"Finishing up axis settings\" ) axis . set_xticks ( xticks ) axis . set_xticklabels ( xlabels ) axis . set_yticks ( 0.5 + np . arange ( 7 )) ylabels = WEEKDAYS if origin . lower () == \"lower\" else WEEKDAYS [ ::- 1 ] axis . set_yticklabels ( ylabels ) axis . set_title ( f \"{year}\" , weight= \"semibold\" ) logger . trace ( \"Mapping data\" ) axis . imshow ( data , extent = [ 0 , 54 , 0 , 7 ], zorder = 10 , vmin = np . nanmin ( data ), vmax = np . nanmax ( data ), cmap = cmap , origin = origin , # alpha = 0.75 , )","title":"Timedata"},{"location":"reference/pyhdtoolkit/plotting/timedata/#module-pyhdtoolkitplottingtimedata","text":"View Source import html.parser from datetime import date , datetime from typing import List import dateutil.parser import matplotlib import matplotlib.pyplot as plt import numpy as np import requests from dateutil.relativedelta import relativedelta from loguru import logger from matplotlib.patches import Polygon from pyhdtoolkit.plotting.settings import PLOT_PARAMS plt . rcParams . update ( PLOT_PARAMS ) WEEKDAYS : List [ str ] = [ \"Mon\" , \"Tue\" , \"Wed\" , \"Thu\" , \"Fri\" , \"Sat\" , \"Sun\" ] @logger . catch def calendar_heatmap ( axis : matplotlib . axes . Axes , data : np . ndarray , year : int , origin : str = \"upper\" , cmap : str = \"RdYlBu\" , ) -> None : \"\"\" Plots the data as a heatmap on a Github-like calendar type of plot. Args: axis (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. data (np.ndarray): the data to plot, as a number of occurences for each day. year (int): the year for which the data has to be plotted. origin (str): the bound to use to start counting weekdays, either upper or lower. Defaults to 'upper'. cmap (str): the color map to use for the heatmap. Defaults to 'RdYlBu'. \"\"\" logger . info ( \"Creating calendar heatmap\" ) logger . trace ( \"Setting axis parameters\" ) axis . tick_params ( \"x\" , length = 0 , labelsize = \"medium\" , which = \"major\" ) axis . tick_params ( \"y\" , length = 0 , labelsize = \"x-small\" , which = \"major\" ) xticks , xlabels = [], [] start = datetime ( year , 1 , 1 ) . weekday () data = _prepare_data ( start , data ) for month in range ( 1 , 13 ): first_day = datetime ( year , month , 1 ) last_day = first_day + relativedelta ( months = 1 , days =- 1 ) logger . trace ( f \"Preparing polygon area for { first_day . strftime ( '%B' ) } { year } \" ) x0 : int = ( int ( first_day . strftime ( \"%j\" )) + start - 1 ) // 7 x1 : int = ( int ( last_day . strftime ( \"%j\" )) + start - 1 ) // 7 xticks . append ( x0 + ( x1 - x0 + 1 ) / 2 ) xlabels . append ( first_day . strftime ( \"%b\" )) poly = _prepare_polygon ( first_day , last_day , origin ) axis . add_artist ( poly ) logger . trace ( \"Finishing up axis settings\" ) axis . set_xticks ( xticks ) axis . set_xticklabels ( xlabels ) axis . set_yticks ( 0.5 + np . arange ( 7 )) ylabels = WEEKDAYS if origin . lower () == \"lower\" else WEEKDAYS [:: - 1 ] axis . set_yticklabels ( ylabels ) axis . set_title ( f \" { year } \" , weight = \"semibold\" ) logger . trace ( \"Mapping data\" ) axis . imshow ( data , extent = [ 0 , 54 , 0 , 7 ], zorder = 10 , vmin = np . nanmin ( data ), vmax = np . nanmax ( data ), cmap = cmap , origin = origin , # alpha=0.75, ) @logger . catch def _prepare_data ( start : int , data : np . ndarray ) -> np . ndarray : \"\"\" Prepares a ready-to-use in `calendar_heatmap` data array from the initially provided data. The returned data array is guaranteed to have the proper shape for a full year, and includes np.nan values wherever the initial data does not provide any. Args: start (int): int value of the weekday for the first day of the year the data is for. data (np.ndarray): the data to plot, as a number of occurences for each day. Returns: A prepared numpy array for the data. \"\"\" logger . trace ( \"Preparing data for calendar heatmap\" ) print ( f \"DATA SHAPE: { data . shape } \" ) print ( f \"START: { start } \" ) _data = np . zeros ( data . shape ) * np . nan _data [ start : start + len ( data )] = data return _data . reshape ( 54 , 7 ) . T def _prepare_polygon ( first_day : datetime , last_day : datetime , origin : str ) -> matplotlib . patches . Polygon : \"\"\" Make the calculation for the coordinates of the Polygon corners, based on the first and last day of a month to plot, and the origin setting. Args: first_day (datetime): datetime object for the first day of the month. last_day(datetime): datetime object for the last day of the month. origin (str): the bound to use to start counting weekdays, either upper or lower. Returns: The Polygon object. \"\"\" start : int = datetime ( first_day . year , 1 , 1 ) . weekday () if origin . lower () not in ( \"lower\" , \"upper\" ): logger . error ( f \"The origin must be one of 'upper' or 'lower', but ' { origin } ' was given\" ) raise ValueError ( \"Invalid origin value\" ) logger . trace ( \"Preparing Polygon artist corners\" ) y0 : int = first_day . weekday () if origin . lower () == \"lower\" else 6 - first_day . weekday () y1 : int = last_day . weekday () if origin . lower () == \"lower\" else 6 - last_day . weekday () x0 : int = ( int ( first_day . strftime ( \"%j\" )) + start - 1 ) // 7 x1 : int = ( int ( last_day . strftime ( \"%j\" )) + start - 1 ) // 7 if origin . lower () == \"lower\" : polygon_corners = [ ( x0 , y0 ), ( x0 , 7 ), ( x1 , 7 ), ( x1 , y1 + 1 ), ( x1 + 1 , y1 + 1 ), ( x1 + 1 , 0 ), ( x0 + 1 , 0 ), ( x0 + 1 , y0 ), ] else : polygon_corners = [ ( x0 , y0 + 1 ), ( x0 , 0 ), ( x1 , 0 ), ( x1 , y1 ), ( x1 + 1 , y1 ), ( x1 + 1 , 7 ), ( x0 + 1 , 7 ), ( x0 + 1 , y0 + 1 ), ] logger . trace ( \"Creating polygon\" ) return Polygon ( polygon_corners , edgecolor = \"black\" , facecolor = \"None\" , linewidth = 1 , zorder = 20 , clip_on = False , ) def _github_contributions ( year : int , user : str = \"fsoubelet\" ) -> np . ndarray : \"\"\" Fetch the Github contribution data for the given user in the given year. See how contributions are counted here: https://docs.github.com/en/free-pro-team@latest/github/setting-up-and-managing-your-github-profile/why-are-my-contributions-not-showing-up-on-my-profile Args: year (int): the year to request the data for. user (str): the github username to get the contribution data for. Defaults to mine. Returns: A numpy array with the number of contributions for each day in the year. \"\"\" url : str = f \"https://github.com/users/ { user } /contributions?to= { year } -12-31\" contents = str ( requests . get ( url ) . content ) n = 1 + ( date ( year , 12 , 31 ) - date ( year , 1 , 1 )) . days data = - np . zeros ( n , dtype = int ) class HTMLParser ( html . parser . HTMLParser ): def handle_starttag ( self , tag , attrs ): if tag == \"rect\" : data_ = { key : value for ( key , value ) in attrs } date_ = dateutil . parser . parse ( data_ [ \"data-date\" ]) count = int ( data_ [ \"data-count\" ]) day = date_ . timetuple () . tm_yday - 1 if count > 0 : data [ day ] = count parser = HTMLParser () parser . feed ( contents ) return data","title":"Module pyhdtoolkit.plotting.timedata"},{"location":"reference/pyhdtoolkit/plotting/timedata/#variables","text":"PLOT_PARAMS WEEKDAYS","title":"Variables"},{"location":"reference/pyhdtoolkit/plotting/timedata/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/plotting/timedata/#calendar_heatmap","text":"def calendar_heatmap ( axis : matplotlib . axes . _axes . Axes , data : numpy . ndarray , year : int , origin : str = 'upper' , cmap : str = 'RdYlBu' ) -> None Plots the data as a heatmap on a Github-like calendar type of plot. Args: axis (matplotlib.axes.Axes): an existing matplotlib.axis Axes object to act on. data (np.ndarray): the data to plot, as a number of occurences for each day. year (int): the year for which the data has to be plotted. origin (str): the bound to use to start counting weekdays, either upper or lower. Defaults to 'upper'. cmap (str): the color map to use for the heatmap. Defaults to 'RdYlBu'. View Source @logger . catch def calendar_heatmap ( axis : matplotlib . axes . Axes , data : np . ndarray , year : int , origin : str = \"upper\" , cmap : str = \"RdYlBu\" , ) -> None : \"\"\" Plots the data as a heatmap on a Github-like calendar type of plot. Args: axis (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. data (np.ndarray): the data to plot, as a number of occurences for each day. year (int): the year for which the data has to be plotted. origin (str): the bound to use to start counting weekdays, either upper or lower. Defaults to 'upper'. cmap (str): the color map to use for the heatmap. Defaults to 'RdYlBu'. \"\"\" logger . info ( \"Creating calendar heatmap\" ) logger . trace ( \"Setting axis parameters\" ) axis . tick_params ( \"x\" , length = 0 , labelsize= \"medium\" , which= \"major\" ) axis . tick_params ( \"y\" , length = 0 , labelsize= \"x-small\" , which= \"major\" ) xticks , xlabels = [], [] start = datetime ( year , 1 , 1 ). weekday () data = _ prepare_data ( start , data ) for month in range ( 1 , 13 ) : first_day = datetime ( year , month , 1 ) last_day = first_day + relativedelta ( months = 1 , days=- 1 ) logger . trace ( f \"Preparing polygon area for {first_day.strftime('%B')} {year}\" ) x0: int = ( int ( first_day . strftime ( \"%j\" )) + start - 1 ) // 7 x1: int = ( int ( last_day . strftime ( \"%j\" )) + start - 1 ) // 7 xticks . append ( x0 + ( x1 - x0 + 1 ) / 2 ) xlabels . append ( first_day . strftime ( \"%b\" )) poly = _ prepare_polygon ( first_day , last_day , origin ) axis . add_artist ( poly ) logger . trace ( \"Finishing up axis settings\" ) axis . set_xticks ( xticks ) axis . set_xticklabels ( xlabels ) axis . set_yticks ( 0.5 + np . arange ( 7 )) ylabels = WEEKDAYS if origin . lower () == \"lower\" else WEEKDAYS [ ::- 1 ] axis . set_yticklabels ( ylabels ) axis . set_title ( f \"{year}\" , weight= \"semibold\" ) logger . trace ( \"Mapping data\" ) axis . imshow ( data , extent = [ 0 , 54 , 0 , 7 ], zorder = 10 , vmin = np . nanmin ( data ), vmax = np . nanmax ( data ), cmap = cmap , origin = origin , # alpha = 0.75 , )","title":"calendar_heatmap"},{"location":"reference/pyhdtoolkit/scripts/","text":"Module pyhdtoolkit.scripts scripts module ~ ~ ~ ~ ~ Various scripts to run, that will help manipulate data or run different flow of programs and simulations. This is helpful in my work. :copyright: \u00a9 2019-2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. View Source \"\"\" scripts module ~~~~~~~~~~~~~~~ Various scripts to run, that will help manipulate data or run different flow of programs and simulations. This is helpful in my work. :copyright: (c) 2019-2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" Sub-modules pyhdtoolkit.scripts.ac_dipole pyhdtoolkit.scripts.triplet_errors","title":"Index"},{"location":"reference/pyhdtoolkit/scripts/#module-pyhdtoolkitscripts","text":"scripts module ~ ~ ~ ~ ~ Various scripts to run, that will help manipulate data or run different flow of programs and simulations. This is helpful in my work. :copyright: \u00a9 2019-2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. View Source \"\"\" scripts module ~~~~~~~~~~~~~~~ Various scripts to run, that will help manipulate data or run different flow of programs and simulations. This is helpful in my work. :copyright: (c) 2019-2020 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\"","title":"Module pyhdtoolkit.scripts"},{"location":"reference/pyhdtoolkit/scripts/#sub-modules","text":"pyhdtoolkit.scripts.ac_dipole pyhdtoolkit.scripts.triplet_errors","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/","text":"Module pyhdtoolkit.scripts.ac_dipole Sub-modules pyhdtoolkit.scripts.ac_dipole.sext_ac_dipole_tracking","title":"Index"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/#module-pyhdtoolkitscriptsac_dipole","text":"","title":"Module pyhdtoolkit.scripts.ac_dipole"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/#sub-modules","text":"pyhdtoolkit.scripts.ac_dipole.sext_ac_dipole_tracking","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/","text":"Module pyhdtoolkit.scripts.ac_dipole.sext_ac_dipole_tracking Script scripts.ac_dipole.sext_ac_dipole_tracking Created on 2020.02.27 :author: Felix Soubelet ( felix.soubelet@cern.ch ) This is a Python3 utility to launch a series of MAD-X simlations with the proper parameters, call the appropriate python scripts on the outputs and organise the results. Made to be ran with the OMC conda environment, and ran directly for the commandline. A pair of examples Running with kicks in the horizontal plane only, for two sigma values: python path/to/sext_ac_dipole_tracking.py --planes horizontal --mask /path/to/kick/mask.mask --type kick --sigmas 5 10 Running with free oscillations in both planes succesively, for many offset values: python path/to/sext_ac_dipole_tracking.py --planes horizontal vertical --mask /path/to/offset/mask.mask --type amp -- sigmas 5 10 15 20 View Source \"\"\" Script scripts.ac_dipole.sext_ac_dipole_tracking ------------------------------------------------ Created on 2020.02.27 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 utility to launch a series of MAD-X simlations with the proper parameters, call the appropriate python scripts on the outputs and organise the results. Made to be ran with the OMC conda environment, and ran directly for the commandline. A pair of examples ================== Running with kicks in the horizontal plane only, for two sigma values: python path/to/sext_ac_dipole_tracking.py --planes horizontal --mask /path/to/kick/mask.mask \\ --type kick --sigmas 5 10 Running with free oscillations in both planes succesively, for many offset values: python path/to/sext_ac_dipole_tracking.py --planes horizontal vertical \\ --mask /path/to/offset/mask.mask --type amp -- sigmas 5 10 15 20 \"\"\" import argparse import shutil import sys from pathlib import Path from typing import Dict , List , Union from loguru import logger from pyhdtoolkit.utils.cmdline import CommandLine from pyhdtoolkit.utils.contexts import timeit from pyhdtoolkit.utils.defaults import LOGURU_FORMAT , OMC_PYTHON , TBT_CONVERTER_SCRIPT class ACDipoleGrid : \"\"\" Algorithm as a class to run the simulations and organize the outputs. \"\"\" __slots__ = { \"grid_output_dir\" : \"PosixPath object to the directory for all outputs\" , \"mask_files_dir\" : \"PosixPath object to the directory for simulations' masks\" , \"outputdata_dir\" : \"PosixPath object to the directory for simulation data\" , \"trackfiles_dir\" : \"PosixPath object to the directory for trackone files\" , \"trackfiles_planes\" : \"PosixPath objects to the planes' trackone files\" , \"run_planes\" : \"List of planes for which to run simulations\" , \"sigmas\" : \"List of amplitudes for AC dipole to kick to (in bunch sigma)\" , \"template_file\" : \"PosixPath object to the location of the mask template\" , \"template_str\" : \"Text in the template_file\" , } def __init__ ( self ) -> None : self . grid_output_dir : Path = Path ( \"grid_outputs\" ) self . mask_files_dir : Path = self . grid_output_dir / \"mask_files\" self . outputdata_dir : Path = self . grid_output_dir / \"outputdata_dirs\" self . trackfiles_dir : Path = self . grid_output_dir / \"trackfiles\" self . trackfiles_planes : Dict [ str , Path ] = { \"horizontal\" : self . grid_output_dir / \"trackfiles\" / \"X\" , \"vertical\" : self . grid_output_dir / \"trackfiles\" / \"Y\" , } self . run_planes : List [ str ] = _parse_arguments () . planes self . sigmas : List [ float ] = sorted ( _parse_arguments () . sigmas ) self . template_file : Path = Path ( _parse_arguments () . template ) self . template_str : str = self . template_file . read_text () def _check_input_sanity ( self ) -> None : \"\"\" Makes sure there are no duplicates in the provided sigma values, because that will mess up a long time after launch and you will cry. \"\"\" if len ( self . sigmas ) != len ( set ( self . sigmas )): logger . error ( \"There is a duplicate in the sigma values, which would cause a failure later.\" ) sys . exit () def _create_output_dirs ( self ) -> None : \"\"\" Will create the proper output dirs if they don't exist already. \"\"\" if not self . grid_output_dir . is_dir (): logger . debug ( f \"Creating directory '{self.grid_output_dir}'\" ) self . grid_output_dir . mkdir () if not self . mask_files_dir . is_dir (): logger . debug ( f \"Creating directory '{self.mask_files_dir}'\" ) self . mask_files_dir . mkdir () if not self . outputdata_dir . is_dir (): logger . debug ( f \"Creating directory '{self.outputdata_dir}'\" ) self . outputdata_dir . mkdir () if not self . trackfiles_dir . is_dir (): logger . debug ( f \"Creating directory '{self.trackfiles_dir}'\" ) self . trackfiles_dir . mkdir () if not self . trackfiles_planes [ \"horizontal\" ] . is_dir (): logger . debug ( f \"Creating directory '{self.trackfiles_planes['horizontal']}'\" ) self . trackfiles_planes [ \"horizontal\" ] . mkdir () if not self . trackfiles_planes [ \"vertical\" ] . is_dir (): logger . debug ( f \"Creating directory '{self.trackfiles_planes['vertical']}'\" ) self . trackfiles_planes [ \"vertical\" ] . mkdir () else : logger . error ( \"Output directories already present, you may want to move those.\" ) sys . exit () def track_forced_oscillations_for_plane ( self , kick_plane : str = None ) -> None : \"\"\" Run MAD-X simulations with AC dipole tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply a kick, either 'horizontal' or 'vertical'. \"\"\" if kick_plane not in ( \"horizontal\" , \"vertical\" ): logger . error ( f \"Plane parameter {kick_plane} is not a valid value\" ) raise ValueError ( \"Plane parameter should be one of 'horizontal' or 'vertical'\" ) with timeit ( lambda spanned : logger . info ( f \"Tracked all amplitudes for {kick_plane} kicks in {spanned:.4f} seconds\" ) ): for kick_in_sigma in self . sigmas : print ( \"\" ) # Set the wanted kick value (in sigmas) in the given plane, and a small initial # offset in the other (small offset so that harpy doesn't cry and we get tune). # Do NOT kick both planes: cross-terms influence the detuning. plane_letter = \"x\" if kick_plane == \"horizontal\" else \"y\" replace_dict = ( { \" %(SIGMAX_VALUE)s \" : kick_in_sigma , \" %(SIGMAY_VALUE)s \" : 0 , \" %(AMPLX_VALUE)s \" : 0 , \" %(AMPLY_VALUE)s \" : 0.5 , } if kick_plane == \"horizontal\" else { \" %(SIGMAX_VALUE)s \" : 0 , \" %(SIGMAY_VALUE)s \" : kick_in_sigma , \" %(AMPLX_VALUE)s \" : 0.5 , \" %(AMPLY_VALUE)s \" : 0 , } ) filename_to_write = Path ( f \"sext_ac_dipole_tracking_{kick_in_sigma}_sigma_{plane_letter}_kick\" ) mask_file = create_script_file ( self . template_str , values_replacing_dict = replace_dict , filename = Path ( str ( filename_to_write )), ) run_madx_mask ( mask_file ) _move_mask_file_after_running ( mask_file_path = mask_file , mask_files_dir = self . mask_files_dir ) _rename_madx_outputs ( kick_in_sigma = kick_in_sigma , outputdata_dir = self . outputdata_dir , plane = plane_letter , ) _convert_trackone_to_sdds () _move_trackone_sdds ( kick_in_sigma = kick_in_sigma , trackfiles_dir = self . trackfiles_planes [ kick_plane ], plane = plane_letter , ) def track_free_oscillations_for_plane ( self , kick_plane : str = None ) -> None : \"\"\" Run MAD-X simulations with amplitude offset tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply an offset, either 'horizontal' or 'vertical'. \"\"\" if kick_plane not in ( \"horizontal\" , \"vertical\" ): logger . error ( f \"Plane parameter {kick_plane} is not a valid value\" ) raise ValueError ( \"Plane parameter should be one of 'horizontal' or 'vertical'\" ) with timeit ( lambda spanned : logger . info ( f \"Tracked all amplitudes for {kick_plane} offsets in {spanned:.4f} seconds\" ) ): for kick_in_sigma in self . sigmas : print ( \"\" ) plane_letter = \"x\" if kick_plane == \"horizontal\" else \"y\" action_var_value = kick_in_sigma amplitudes_dict = ( { \" %(AMPLX_VALUE)s \" : action_var_value , \" %(AMPLY_VALUE)s \" : 0.5 } if kick_plane == \"horizontal\" else { \" %(AMPLX_VALUE)s \" : 0.5 , \" %(AMPLY_VALUE)s \" : action_var_value } ) filename_to_write = Path ( f \"initial_amplitude_tracking_{kick_in_sigma}_sigma_{plane_letter}_kick\" ) mask_file = create_script_file ( self . template_str , values_replacing_dict = amplitudes_dict , filename = Path ( str ( filename_to_write )), ) run_madx_mask ( mask_file ) _move_mask_file_after_running ( mask_file_path = mask_file , mask_files_dir = self . mask_files_dir ) _rename_madx_outputs ( kick_in_sigma = kick_in_sigma , outputdata_dir = self . outputdata_dir , plane = plane_letter , ) _convert_trackone_to_sdds () _move_trackone_sdds ( kick_in_sigma = kick_in_sigma , trackfiles_dir = self . trackfiles_planes [ kick_plane ], plane = plane_letter , ) @logger.catch def main () -> None : \"\"\" Run the whole process: create a class instance, simulate for horizontal and vertical kicks, exit. \"\"\" command_line_args = _parse_arguments () _set_logger_level ( command_line_args . log_level ) simulations = ACDipoleGrid () simulations . _check_input_sanity () simulations . _create_output_dirs () sim_type = command_line_args . simulation_type try : if sim_type == \"kick\" : logger . info ( f \"Planes to kick then track on are: {simulations.run_planes}\" ) logger . info ( f \"Kick values to compute are (in bunch sigmas): {simulations.sigmas}\" ) for plane in simulations . run_planes : simulations . track_forced_oscillations_for_plane ( kick_plane = plane ) elif sim_type == \"amp\" : logger . info ( f \"Planes to offset then track on are: {simulations.run_planes}\" ) logger . info ( f \"Registered initial tracking amplitudes (in bunch sigmas): {simulations.sigmas}\" ) for plane in simulations . run_planes : simulations . track_free_oscillations_for_plane ( kick_plane = plane ) else : logger . error ( f \"Simulation type {sim_type} is not a valid value\" ) raise ValueError ( \"Simulation type should be one of 'kick' or 'amp'\" ) except KeyboardInterrupt : logger . info ( \"Manual interruption, ending processes\" ) _cleanup_madx_residuals () logger . warning ( \"The 'grid_outputs' folder was left untouched, check for unexpected MADX residuals\" ) # ---------------------- Public Utilities ---------------------- # def run_madx_mask ( mask_file : Path ) -> None : \"\"\" Run madx on the provided file. Args: mask_file (Path): Path object with the mask file location. \"\"\" logger . debug ( f \"Running madx on script: '{mask_file.absolute()}'\" ) exit_code , std_out = CommandLine . run ( f \"madx {mask_file.absolute()}\" ) if exit_code != 0 : # Dump madx log in case of failure so we can see where it went wrong. logger . warning ( f \"MAD-X command self-killed with exit code: {exit_code}\" ) log_dump = Path ( f \"failed_madx_returnedcode_{exit_code}.log\" ) with log_dump . open ( \"w\" ) as logfile : logfile . write ( std_out . decode ()) # Default 'utf-8' encoding, depends on your system. logger . warning ( f \"The standard output has been dumped to file 'failed_command_{exit_code}.logfile'\" ) def create_script_file ( template_as_str : str , values_replacing_dict : Dict [ str , float ], filename : Path , ) -> Path : \"\"\" Create new script file from template with the appropriate values. Args: template_as_str (str): string content of your template mask file. values_replacing_dict (Dict[str, float]): keys to find and values to replace them with in the template. filename (Path): Path object for the file in which to write the script. \"\"\" string_mask = _create_script_string ( template_as_str , values_replacing_dict ) return _write_script_to_file ( string_mask , filename ) # ---------------------- Private Utilities ---------------------- # def _convert_trackone_to_sdds () -> None : \"\"\" Run the omc3 tbt_converter script on trackone output of MAD-X. Will also cleanup the `converter` and 'stats' files left by tbt_converter afterwards. \"\"\" if not Path ( \"trackone\" ) . is_file (): logger . error ( \"Tried to call 'tbt_converter' without a 'trackone' file present, aborting\" ) sys . exit () logger . debug ( f \"Running '{TBT_CONVERTER_SCRIPT}' on 'trackone' file\" ) CommandLine . run ( f \"{OMC_PYTHON.absolute()} {TBT_CONVERTER_SCRIPT.absolute()} \" \"--files trackone --outputdir . --tbt_datatype trackone\" ) logger . debug ( \"Removing trackone file 'trackone'\" ) Path ( \"trackone\" ) . unlink () logger . debug ( \"Removing outputs of 'tbt_converter'\" ) if Path ( \"stats.txt\" ) . exists (): Path ( \"stats.txt\" ) . unlink () for tbt_output_file in list ( Path ( \".\" ) . glob ( \"converter_*\" )): tbt_output_file . unlink () def _create_script_string ( template_as_string : str , values_replacing_dict : Dict [ str , float ]) -> str : \"\"\" For each key in the provided dict, will replace it in the template scripts with the corresponding dict value. Args: template_as_string (str): the string content of your template mask file. values_replacing_dict (Dict[str, float]): pairs of key, value to find and replace in the template string. Returns: The new script string. \"\"\" script_string : str = template_as_string for key , value in values_replacing_dict . items (): script_string = script_string . replace ( str ( key ), str ( value )) return script_string def _move_mask_file_after_running ( mask_file_path : Path , mask_files_dir : Path ) -> None : \"\"\" Move the mask file after being done running it with MAD-X. Args: mask_file_path (Path): Path object with the file location. mask_files_dir (Path): Path object with the directory to move mask to' location. \"\"\" logger . debug ( f \"Moving mask file '{mask_file_path}' to directory '{mask_files_dir}'\" ) mask_file_path . rename ( f \"{mask_files_dir}/{mask_file_path}\" ) def _move_trackone_sdds ( kick_in_sigma : Union [ str , float ], trackfiles_dir : Path , plane : str ) -> None : \"\"\" Call after running omc3's `tbt_converter` on the `trackone` output by MAD-X, will move the resulting `trackone.sdds` file to the `trackfiles_dir`, with a naming reflecting the ac dipole kick strength. Args: kick_in_sigma (Union[str, float]): the AC dipole kick value (in sigma) for which you ran your simulation. trackfiles_dir (Path): PosixPath to the folder in which to store all sdds trackone files. plane (str): the plane on which ac dipole provided the kick, should be `x` or `y`. \"\"\" if str ( plane ) not in ( \"x\" , \"y\" ): logger . error ( f \"Plane parameter {plane} is not a valid value\" ) raise ValueError ( \"Plane parameter should be one of 'x' or 'y'\" ) logger . debug ( f \"Moving trackone sdds file to directory '{trackfiles_dir}'\" ) track_sdds_file = Path ( \"trackone.sdds\" ) if not track_sdds_file . is_file (): logger . error ( \"Conversion to trackone sdds file must have failed, check the omc3 script\" ) sys . exit () track_sdds_file . rename ( f \"{trackfiles_dir}/trackone_{kick_in_sigma}_sigma_{plane}.sdds\" ) def _parse_arguments () -> argparse . Namespace : \"\"\" Simple argument parser to make life easier in the command-line. Returns a NameSpace with arguments as attributes. \"\"\" parser = argparse . ArgumentParser ( description = \"Running MAD-X AC dipole trackings for you.\" ) parser . add_argument ( \"-s\" , \"--sigmas\" , dest = \"sigmas\" , nargs = \"+\" , default = [ 1 , 2 ], type = float , help = \"Different amplitude values (in bunch sigma) for the AC dipole kicks.\" \"Defaults to [1, 2].\" , ) parser . add_argument ( \"-p\" , \"--planes\" , dest = \"planes\" , nargs = \"+\" , default = [ \"horizontal\" ], type = str , help = \"Planes for which to kick, possible values are 'horizontal' and 'vertical',\" \"Defaults to 'horizontal'.\" , ) parser . add_argument ( \"-m\" , \"--mask\" , dest = \"template\" , default = \"/afs/cern.ch/work/f/fesoubel/public/MADX_scripts/AC_dipole_tracking/ac_kick_tracking_template.mask\" , type = str , help = \"Location of your MAD-X template mask file to use, defaults to \" \"'/afs/cern.ch/work/f/fesoubel/public/MADX_scripts/AC_dipole_tracking/ac_kick_track_template.mask'.\" , ) parser . add_argument ( \"-t\" , \"--type\" , dest = \"simulation_type\" , default = \"kick\" , type = str , help = \"Type of simulations to run, either 'kick' for AC dipole kick or 'amp' for free \" \"oscillations. Defaults to 'kick'.\" , ) parser . add_argument ( \"-l\" , \"--logs\" , dest = \"log_level\" , default = \"info\" , type = str , help = \"The base console logging level. Can be 'debug', 'info', 'warning' and 'error'.\" \"Defaults to 'info'.\" , ) return parser . parse_args () def _rename_madx_outputs ( kick_in_sigma : Union [ str , float ], outputdata_dir : Path , plane : str ) -> None : \"\"\" Call after running MAD-X on your mask, will move the 'Outpudata' created by MAD-X to the proper place. Args: kick_in_sigma (Union[str, float]): the AC dipole kick value (in sigma) for which you ran your simulation. outputdata_dir (Path): PosixPath to the folder in which to store all successive `Outputdata`'s location. plane (str): the plane on which ac dipole provided the kick, should be `x` or `y`. \"\"\" if str ( plane ) not in ( \"x\" , \"y\" ): raise ValueError ( f \"Plane parameter should be one of 'x', 'y' but {plane} was provided.\" ) madx_outputs = Path ( \"Outputdata\" ) logger . debug ( f \"Moving MAD-X outputs to directory '{outputdata_dir}'\" ) madx_outputs . rename ( f \"{outputdata_dir}/Outputdata_{kick_in_sigma}_sigma_{plane}\" ) def _set_logger_level ( log_level : str = \"info\" ) -> None : \"\"\" Sets the logger level to the one provided at the commandline. Default loguru handler will have DEBUG level and ID 0. We need to first remove this default handler and add ours with the wanted level. Args: log_level (str): the default logging level to print out. \"\"\" logger . remove ( 0 ) logger . add ( sys . stderr , format = LOGURU_FORMAT , level = log_level . upper ()) def _write_script_to_file ( script_as_string : str , filename : Union [ str , Path ]) -> Path : \"\"\" Create a new file with the provided script, and return the location. Args: script_as_string (str): the script string to write to file. filename (Union[str, Path]): the file name to use. Returns: The `pathlib.Path` object to the created file. \"\"\" file_path = Path ( str ( filename ) + \".mask\" ) logger . debug ( f \"Creating new mask file '{file_path}'\" ) with file_path . open ( \"w\" ) as script : script . write ( script_as_string ) return file_path def _cleanup_madx_residuals () -> None : \"\"\" Will look for specific madx artifacts and remove them. Meant to be called in case of interuption. \"\"\" expected_residuals : Dict [ str , List [ str ]] = { \"symlinks\" : [ \"db5\" , \"slhc\" , \"fidel\" , \"wise\" , \"optics2016\" , \"optics2017\" , \"optics2018\" , \"scripts\" , ], \"directories\" : [ \"temp\" , \"Outputdata\" ], \"files\" : [ \"fort.18\" ], } logger . debug ( \"Cleaning up expected MADX residuals\" ) for residual_type , residual_values in expected_residuals . items (): logger . trace ( f \"Cleaning up MADX residual {residual_type}\" ) for residual in residual_values : if Path ( residual ) . is_symlink () or Path ( residual ) . is_file (): Path ( residual ) . unlink () elif Path ( residual ) . is_dir (): shutil . rmtree ( Path ( residual )) logger . debug ( \"Cleaning up potential residual mask files\" ) for suspect_mask in list ( Path ( \".\" ) . glob ( \"*.mask\" )): if ( suspect_mask . stem . startswith ( \"initial_\" ) or suspect_mask . stem . startswith ( \"sext_\" ) ) and suspect_mask . stem . endswith ( \"_kick\" ): suspect_mask . unlink () if __name__ == \"__main__\" : main () Variables LOGURU_FORMAT Functions create_script_file def create_script_file ( template_as_str : str , values_replacing_dict : Dict [ str , float ], filename : pathlib . Path ) -> pathlib . Path Create new script file from template with the appropriate values. Args: template_as_str (str): string content of your template mask file. values_replacing_dict (Dict[str, float]): keys to find and values to replace them with in the template. filename (Path): Path object for the file in which to write the script. View Source def create_script_file ( template_as_str : str , values_replacing_dict : Dict [ str , float ], filename : Path , ) -> Path : \"\"\" Create new script file from template with the appropriate values. Args: template_as_str (str): string content of your template mask file. values_replacing_dict (Dict[str, float]): keys to find and values to replace them with in the template. filename (Path): Path object for the file in which to write the script. \"\"\" string_mask = _create_script_string ( template_as_str , values_replacing_dict ) return _write_script_to_file ( string_mask , filename ) main def main ( ) -> None Run the whole process: create a class instance, simulate for horizontal and vertical kicks, exit. View Source @logger . catch def main () -> None : \"\"\" Run the whole process: create a class instance, simulate for horizontal and vertical kicks, exit. \"\"\" command_line_args = _parse_arguments () _set_logger_level ( command_line_args . log_level ) simulations = ACDipoleGrid () simulations . _check_input_sanity () simulations . _create_output_dirs () sim_type = command_line_args . simulation_type try : if sim_type == \"kick\" : logger . info ( f \"Planes to kick then track on are: {simulations.run_planes}\" ) logger . info ( f \"Kick values to compute are (in bunch sigmas): {simulations.sigmas}\" ) for plane in simulations . run_planes : simulations . track_forced_oscillations_for_plane ( kick_plane = plane ) elif sim_type == \"amp\" : logger . info ( f \"Planes to offset then track on are: {simulations.run_planes}\" ) logger . info ( f \"Registered initial tracking amplitudes (in bunch sigmas): {simulations.sigmas}\" ) for plane in simulations . run_planes : simulations . track_free_oscillations_for_plane ( kick_plane = plane ) else : logger . error ( f \"Simulation type {sim_type} is not a valid value\" ) raise ValueError ( \"Simulation type should be one of 'kick' or 'amp'\" ) except KeyboardInterrupt : logger . info ( \"Manual interruption, ending processes\" ) _cleanup_madx_residuals () logger . warning ( \"The 'grid_outputs' folder was left untouched, check for unexpected MADX residuals\" ) run_madx_mask def run_madx_mask ( mask_file : pathlib . Path ) -> None Run madx on the provided file. Args: mask_file (Path): Path object with the mask file location. View Source def run_madx_mask ( mask_file : Path ) -> None : \"\"\" Run madx on the provided file. Args: mask_file (Path): Path object with the mask file location. \"\"\" logger . debug ( f \"Running madx on script: '{mask_file.absolute()}'\" ) exit_code , std_out = CommandLine . run ( f \"madx {mask_file.absolute()}\" ) if exit_code != 0 : # Dump madx log in case of failure so we can see where it went wrong . logger . warning ( f \"MAD-X command self-killed with exit code: {exit_code}\" ) log_dump = Path ( f \"failed_madx_returnedcode_{exit_code}.log\" ) with log_dump . open ( \"w\" ) as logfile : logfile . write ( std_out . decode ()) # Default 'utf-8' encoding , depends on your system . logger . warning ( f \"The standard output has been dumped to file 'failed_command_{exit_code}.logfile'\" ) Classes ACDipoleGrid class ACDipoleGrid ( ) Algorithm as a class to run the simulations and organize the outputs. View Source class ACDipoleGrid : \"\"\" Algorithm as a class to run the simulations and organize the outputs. \"\"\" __slots__ = { \"grid_output_dir\" : \"PosixPath object to the directory for all outputs\" , \"mask_files_dir\" : \"PosixPath object to the directory for simulations' masks\" , \"outputdata_dir\" : \"PosixPath object to the directory for simulation data\" , \"trackfiles_dir\" : \"PosixPath object to the directory for trackone files\" , \"trackfiles_planes\" : \"PosixPath objects to the planes' trackone files\" , \"run_planes\" : \"List of planes for which to run simulations\" , \"sigmas\" : \"List of amplitudes for AC dipole to kick to (in bunch sigma)\" , \"template_file\" : \"PosixPath object to the location of the mask template\" , \"template_str\" : \"Text in the template_file\" , } def __init__ ( self ) -> None : self . grid_output_dir : Path = Path ( \"grid_outputs\" ) self . mask_files_dir : Path = self . grid_output_dir / \"mask_files\" self . outputdata_dir : Path = self . grid_output_dir / \"outputdata_dirs\" self . trackfiles_dir : Path = self . grid_output_dir / \"trackfiles\" self . trackfiles_planes : Dict [ str, Path ] = { \"horizontal\" : self . grid_output_dir / \"trackfiles\" / \"X\" , \"vertical\" : self . grid_output_dir / \"trackfiles\" / \"Y\" , } self . run_planes : List [ str ] = _parse_arguments (). planes self . sigmas : List [ float ] = sorted ( _parse_arguments (). sigmas ) self . template_file : Path = Path ( _parse_arguments (). template ) self . template_str : str = self . template_file . read_text () def _check_input_sanity ( self ) -> None : \"\"\" Makes sure there are no duplicates in the provided sigma values, because that will mess up a long time after launch and you will cry. \"\"\" if len ( self . sigmas ) != len ( set ( self . sigmas )) : logger . error ( \"There is a duplicate in the sigma values, which would cause a failure later.\" ) sys . exit () def _create_output_dirs ( self ) -> None : \"\"\" Will create the proper output dirs if they don't exist already. \"\"\" if not self . grid_output_dir . is_dir () : logger . debug ( f \"Creating directory '{self.grid_output_dir}'\" ) self . grid_output_dir . mkdir () if not self . mask_files_dir . is_dir () : logger . debug ( f \"Creating directory '{self.mask_files_dir}'\" ) self . mask_files_dir . mkdir () if not self . outputdata_dir . is_dir () : logger . debug ( f \"Creating directory '{self.outputdata_dir}'\" ) self . outputdata_dir . mkdir () if not self . trackfiles_dir . is_dir () : logger . debug ( f \"Creating directory '{self.trackfiles_dir}'\" ) self . trackfiles_dir . mkdir () if not self . trackfiles_planes [ \"horizontal\" ] . is_dir () : logger . debug ( f \"Creating directory '{self.trackfiles_planes['horizontal']}'\" ) self . trackfiles_planes [ \"horizontal\" ] . mkdir () if not self . trackfiles_planes [ \"vertical\" ] . is_dir () : logger . debug ( f \"Creating directory '{self.trackfiles_planes['vertical']}'\" ) self . trackfiles_planes [ \"vertical\" ] . mkdir () else : logger . error ( \"Output directories already present, you may want to move those.\" ) sys . exit () def track_forced_oscillations_for_plane ( self , kick_plane : str = None ) -> None : \"\"\" Run MAD-X simulations with AC dipole tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply a kick, either 'horizontal' or 'vertical'. \"\"\" if kick_plane not in ( \"horizontal\" , \"vertical\" ) : logger . error ( f \"Plane parameter {kick_plane} is not a valid value\" ) raise ValueError ( \"Plane parameter should be one of 'horizontal' or 'vertical'\" ) with timeit ( lambda spanned : logger . info ( f \"Tracked all amplitudes for {kick_plane} kicks in {spanned:.4f} seconds\" ) ) : for kick_in_sigma in self . sigmas : print ( \"\" ) # Set the wanted kick value ( in sigmas ) in the given plane , and a small initial # offset in the other ( small offset so that harpy doesn 't cry and we get tune). # Do NOT kick both planes: cross-terms influence the detuning. plane_letter = \"x\" if kick_plane == \"horizontal\" else \"y\" replace_dict = ( { \"%(SIGMAX_VALUE)s\": kick_in_sigma, \"%(SIGMAY_VALUE)s\": 0, \"%(AMPLX_VALUE)s\": 0, \"%(AMPLY_VALUE)s\": 0.5, } if kick_plane == \"horizontal\" else { \"%(SIGMAX_VALUE)s\": 0, \"%(SIGMAY_VALUE)s\": kick_in_sigma, \"%(AMPLX_VALUE)s\": 0.5, \"%(AMPLY_VALUE)s\": 0, } ) filename_to_write = Path( f\"sext_ac_dipole_tracking_{kick_in_sigma}_sigma_{plane_letter}_kick\" ) mask_file = create_script_file( self.template_str, values_replacing_dict=replace_dict, filename=Path(str(filename_to_write)), ) run_madx_mask(mask_file) _move_mask_file_after_running( mask_file_path=mask_file, mask_files_dir=self.mask_files_dir ) _rename_madx_outputs( kick_in_sigma=kick_in_sigma, outputdata_dir=self.outputdata_dir, plane=plane_letter, ) _convert_trackone_to_sdds() _move_trackone_sdds( kick_in_sigma=kick_in_sigma, trackfiles_dir=self.trackfiles_planes[kick_plane], plane=plane_letter, ) def track_free_oscillations_for_plane(self, kick_plane: str = None) -> None: \"\"\" Run MAD-X simulations with amplitude offset tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply an offset, either ' horizontal ' or ' vertical '. \"\"\" if kick_plane not in (\"horizontal\", \"vertical\"): logger.error(f\"Plane parameter {kick_plane} is not a valid value\") raise ValueError(\"Plane parameter should be one of ' horizontal ' or ' vertical ' \") with timeit( lambda spanned: logger.info( f\" Tracked all amplitudes for { kick_plane } offsets in { spanned : .4 f } seconds \" ) ): for kick_in_sigma in self.sigmas: print(\"\") plane_letter = \" x \" if kick_plane == \" horizontal \" else \" y \" action_var_value = kick_in_sigma amplitudes_dict = ( {\" % ( AMPLX_VALUE ) s \": action_var_value, \" % ( AMPLY_VALUE ) s \": 0.5} if kick_plane == \" horizontal \" else {\" % ( AMPLX_VALUE ) s \": 0.5, \" % ( AMPLY_VALUE ) s \": action_var_value} ) filename_to_write = Path( f\" initial_amplitude_tracking_ { kick_in_sigma } _sigma_ { plane_letter } _kick \" ) mask_file = create_script_file ( self . template_str , values_replacing_dict = amplitudes_dict , filename = Path ( str ( filename_to_write )), ) run_madx_mask ( mask_file ) _move_mask_file_after_running ( mask_file_path = mask_file , mask_files_dir = self . mask_files_dir ) _rename_madx_outputs ( kick_in_sigma = kick_in_sigma , outputdata_dir = self . outputdata_dir , plane = plane_letter , ) _convert_trackone_to_sdds () _move_trackone_sdds ( kick_in_sigma = kick_in_sigma , trackfiles_dir = self . trackfiles_planes [ kick_plane ] , plane = plane_letter , ) Instance variables grid_output_dir mask_files_dir outputdata_dir run_planes sigmas template_file template_str trackfiles_dir trackfiles_planes Methods track_forced_oscillations_for_plane def track_forced_oscillations_for_plane ( self , kick_plane : str = None ) -> None Run MAD-X simulations with AC dipole tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply a kick, either 'horizontal' or 'vertical'. View Source def track_forced_oscillations_for_plane ( self , kick_plane : str = None ) -> None : \"\"\" Run MAD-X simulations with AC dipole tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply a kick, either 'horizontal' or 'vertical'. \"\"\" if kick_plane not in ( \"horizontal\" , \"vertical\" ) : logger . error ( f \"Plane parameter {kick_plane} is not a valid value\" ) raise ValueError ( \"Plane parameter should be one of 'horizontal' or 'vertical'\" ) with timeit ( lambda spanned : logger . info ( f \"Tracked all amplitudes for {kick_plane} kicks in {spanned:.4f} seconds\" ) ) : for kick_in_sigma in self . sigmas : print ( \"\" ) # Set the wanted kick value ( in sigmas ) in the given plane , and a small initial # offset in the other ( small offset so that harpy doesn ' t cry and we get tune ). # Do NOT kick both planes : cross - terms influence the detuning . plane_letter = \"x\" if kick_plane == \"horizontal\" else \"y\" replace_dict = ( { \"%(SIGMAX_VALUE)s\" : kick_in_sigma , \"%(SIGMAY_VALUE)s\" : 0 , \"%(AMPLX_VALUE)s\" : 0 , \"%(AMPLY_VALUE)s\" : 0.5 , } if kick_plane == \"horizontal\" else { \"%(SIGMAX_VALUE)s\" : 0 , \"%(SIGMAY_VALUE)s\" : kick_in_sigma , \"%(AMPLX_VALUE)s\" : 0.5 , \"%(AMPLY_VALUE)s\" : 0 , } ) filename_to_write = Path ( f \"sext_ac_dipole_tracking_{kick_in_sigma}_sigma_{plane_letter}_kick\" ) mask_file = create_script_file ( self . template_str , values_replacing_dict = replace_dict , filename = Path ( str ( filename_to_write )), ) run_madx_mask ( mask_file ) _move_mask_file_after_running ( mask_file_path = mask_file , mask_files_dir = self . mask_files_dir ) _rename_madx_outputs ( kick_in_sigma = kick_in_sigma , outputdata_dir = self . outputdata_dir , plane = plane_letter , ) _convert_trackone_to_sdds () _move_trackone_sdds ( kick_in_sigma = kick_in_sigma , trackfiles_dir = self . trackfiles_planes [ kick_plane ] , plane = plane_letter , ) track_free_oscillations_for_plane def track_free_oscillations_for_plane ( self , kick_plane : str = None ) -> None Run MAD-X simulations with amplitude offset tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply an offset, either 'horizontal' or 'vertical'. View Source def track_free_oscillations_for_plane ( self , kick_plane : str = None ) -> None : \"\"\" Run MAD-X simulations with amplitude offset tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply an offset, either 'horizontal' or 'vertical'. \"\"\" if kick_plane not in ( \"horizontal\" , \"vertical\" ) : logger . error ( f \"Plane parameter {kick_plane} is not a valid value\" ) raise ValueError ( \"Plane parameter should be one of 'horizontal' or 'vertical'\" ) with timeit ( lambda spanned : logger . info ( f \"Tracked all amplitudes for {kick_plane} offsets in {spanned:.4f} seconds\" ) ) : for kick_in_sigma in self . sigmas : print ( \"\" ) plane_letter = \"x\" if kick_plane == \"horizontal\" else \"y\" action_var_value = kick_in_sigma amplitudes_dict = ( { \"%(AMPLX_VALUE)s\" : action_var_value , \"%(AMPLY_VALUE)s\" : 0.5 } if kick_plane == \"horizontal\" else { \"%(AMPLX_VALUE)s\" : 0.5 , \"%(AMPLY_VALUE)s\" : action_var_value } ) filename_to_write = Path ( f \"initial_amplitude_tracking_{kick_in_sigma}_sigma_{plane_letter}_kick\" ) mask_file = create_script_file ( self . template_str , values_replacing_dict = amplitudes_dict , filename = Path ( str ( filename_to_write )), ) run_madx_mask ( mask_file ) _move_mask_file_after_running ( mask_file_path = mask_file , mask_files_dir = self . mask_files_dir ) _rename_madx_outputs ( kick_in_sigma = kick_in_sigma , outputdata_dir = self . outputdata_dir , plane = plane_letter , ) _convert_trackone_to_sdds () _move_trackone_sdds ( kick_in_sigma = kick_in_sigma , trackfiles_dir = self . trackfiles_planes [ kick_plane ] , plane = plane_letter , )","title":"Sext Ac Dipole Tracking"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/#module-pyhdtoolkitscriptsac_dipolesext_ac_dipole_tracking","text":"","title":"Module pyhdtoolkit.scripts.ac_dipole.sext_ac_dipole_tracking"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/#script-scriptsac_dipolesext_ac_dipole_tracking","text":"Created on 2020.02.27 :author: Felix Soubelet ( felix.soubelet@cern.ch ) This is a Python3 utility to launch a series of MAD-X simlations with the proper parameters, call the appropriate python scripts on the outputs and organise the results. Made to be ran with the OMC conda environment, and ran directly for the commandline.","title":"Script scripts.ac_dipole.sext_ac_dipole_tracking"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/#a-pair-of-examples","text":"Running with kicks in the horizontal plane only, for two sigma values: python path/to/sext_ac_dipole_tracking.py --planes horizontal --mask /path/to/kick/mask.mask --type kick --sigmas 5 10 Running with free oscillations in both planes succesively, for many offset values: python path/to/sext_ac_dipole_tracking.py --planes horizontal vertical --mask /path/to/offset/mask.mask --type amp -- sigmas 5 10 15 20 View Source \"\"\" Script scripts.ac_dipole.sext_ac_dipole_tracking ------------------------------------------------ Created on 2020.02.27 :author: Felix Soubelet (felix.soubelet@cern.ch) This is a Python3 utility to launch a series of MAD-X simlations with the proper parameters, call the appropriate python scripts on the outputs and organise the results. Made to be ran with the OMC conda environment, and ran directly for the commandline. A pair of examples ================== Running with kicks in the horizontal plane only, for two sigma values: python path/to/sext_ac_dipole_tracking.py --planes horizontal --mask /path/to/kick/mask.mask \\ --type kick --sigmas 5 10 Running with free oscillations in both planes succesively, for many offset values: python path/to/sext_ac_dipole_tracking.py --planes horizontal vertical \\ --mask /path/to/offset/mask.mask --type amp -- sigmas 5 10 15 20 \"\"\" import argparse import shutil import sys from pathlib import Path from typing import Dict , List , Union from loguru import logger from pyhdtoolkit.utils.cmdline import CommandLine from pyhdtoolkit.utils.contexts import timeit from pyhdtoolkit.utils.defaults import LOGURU_FORMAT , OMC_PYTHON , TBT_CONVERTER_SCRIPT class ACDipoleGrid : \"\"\" Algorithm as a class to run the simulations and organize the outputs. \"\"\" __slots__ = { \"grid_output_dir\" : \"PosixPath object to the directory for all outputs\" , \"mask_files_dir\" : \"PosixPath object to the directory for simulations' masks\" , \"outputdata_dir\" : \"PosixPath object to the directory for simulation data\" , \"trackfiles_dir\" : \"PosixPath object to the directory for trackone files\" , \"trackfiles_planes\" : \"PosixPath objects to the planes' trackone files\" , \"run_planes\" : \"List of planes for which to run simulations\" , \"sigmas\" : \"List of amplitudes for AC dipole to kick to (in bunch sigma)\" , \"template_file\" : \"PosixPath object to the location of the mask template\" , \"template_str\" : \"Text in the template_file\" , } def __init__ ( self ) -> None : self . grid_output_dir : Path = Path ( \"grid_outputs\" ) self . mask_files_dir : Path = self . grid_output_dir / \"mask_files\" self . outputdata_dir : Path = self . grid_output_dir / \"outputdata_dirs\" self . trackfiles_dir : Path = self . grid_output_dir / \"trackfiles\" self . trackfiles_planes : Dict [ str , Path ] = { \"horizontal\" : self . grid_output_dir / \"trackfiles\" / \"X\" , \"vertical\" : self . grid_output_dir / \"trackfiles\" / \"Y\" , } self . run_planes : List [ str ] = _parse_arguments () . planes self . sigmas : List [ float ] = sorted ( _parse_arguments () . sigmas ) self . template_file : Path = Path ( _parse_arguments () . template ) self . template_str : str = self . template_file . read_text () def _check_input_sanity ( self ) -> None : \"\"\" Makes sure there are no duplicates in the provided sigma values, because that will mess up a long time after launch and you will cry. \"\"\" if len ( self . sigmas ) != len ( set ( self . sigmas )): logger . error ( \"There is a duplicate in the sigma values, which would cause a failure later.\" ) sys . exit () def _create_output_dirs ( self ) -> None : \"\"\" Will create the proper output dirs if they don't exist already. \"\"\" if not self . grid_output_dir . is_dir (): logger . debug ( f \"Creating directory '{self.grid_output_dir}'\" ) self . grid_output_dir . mkdir () if not self . mask_files_dir . is_dir (): logger . debug ( f \"Creating directory '{self.mask_files_dir}'\" ) self . mask_files_dir . mkdir () if not self . outputdata_dir . is_dir (): logger . debug ( f \"Creating directory '{self.outputdata_dir}'\" ) self . outputdata_dir . mkdir () if not self . trackfiles_dir . is_dir (): logger . debug ( f \"Creating directory '{self.trackfiles_dir}'\" ) self . trackfiles_dir . mkdir () if not self . trackfiles_planes [ \"horizontal\" ] . is_dir (): logger . debug ( f \"Creating directory '{self.trackfiles_planes['horizontal']}'\" ) self . trackfiles_planes [ \"horizontal\" ] . mkdir () if not self . trackfiles_planes [ \"vertical\" ] . is_dir (): logger . debug ( f \"Creating directory '{self.trackfiles_planes['vertical']}'\" ) self . trackfiles_planes [ \"vertical\" ] . mkdir () else : logger . error ( \"Output directories already present, you may want to move those.\" ) sys . exit () def track_forced_oscillations_for_plane ( self , kick_plane : str = None ) -> None : \"\"\" Run MAD-X simulations with AC dipole tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply a kick, either 'horizontal' or 'vertical'. \"\"\" if kick_plane not in ( \"horizontal\" , \"vertical\" ): logger . error ( f \"Plane parameter {kick_plane} is not a valid value\" ) raise ValueError ( \"Plane parameter should be one of 'horizontal' or 'vertical'\" ) with timeit ( lambda spanned : logger . info ( f \"Tracked all amplitudes for {kick_plane} kicks in {spanned:.4f} seconds\" ) ): for kick_in_sigma in self . sigmas : print ( \"\" ) # Set the wanted kick value (in sigmas) in the given plane, and a small initial # offset in the other (small offset so that harpy doesn't cry and we get tune). # Do NOT kick both planes: cross-terms influence the detuning. plane_letter = \"x\" if kick_plane == \"horizontal\" else \"y\" replace_dict = ( { \" %(SIGMAX_VALUE)s \" : kick_in_sigma , \" %(SIGMAY_VALUE)s \" : 0 , \" %(AMPLX_VALUE)s \" : 0 , \" %(AMPLY_VALUE)s \" : 0.5 , } if kick_plane == \"horizontal\" else { \" %(SIGMAX_VALUE)s \" : 0 , \" %(SIGMAY_VALUE)s \" : kick_in_sigma , \" %(AMPLX_VALUE)s \" : 0.5 , \" %(AMPLY_VALUE)s \" : 0 , } ) filename_to_write = Path ( f \"sext_ac_dipole_tracking_{kick_in_sigma}_sigma_{plane_letter}_kick\" ) mask_file = create_script_file ( self . template_str , values_replacing_dict = replace_dict , filename = Path ( str ( filename_to_write )), ) run_madx_mask ( mask_file ) _move_mask_file_after_running ( mask_file_path = mask_file , mask_files_dir = self . mask_files_dir ) _rename_madx_outputs ( kick_in_sigma = kick_in_sigma , outputdata_dir = self . outputdata_dir , plane = plane_letter , ) _convert_trackone_to_sdds () _move_trackone_sdds ( kick_in_sigma = kick_in_sigma , trackfiles_dir = self . trackfiles_planes [ kick_plane ], plane = plane_letter , ) def track_free_oscillations_for_plane ( self , kick_plane : str = None ) -> None : \"\"\" Run MAD-X simulations with amplitude offset tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply an offset, either 'horizontal' or 'vertical'. \"\"\" if kick_plane not in ( \"horizontal\" , \"vertical\" ): logger . error ( f \"Plane parameter {kick_plane} is not a valid value\" ) raise ValueError ( \"Plane parameter should be one of 'horizontal' or 'vertical'\" ) with timeit ( lambda spanned : logger . info ( f \"Tracked all amplitudes for {kick_plane} offsets in {spanned:.4f} seconds\" ) ): for kick_in_sigma in self . sigmas : print ( \"\" ) plane_letter = \"x\" if kick_plane == \"horizontal\" else \"y\" action_var_value = kick_in_sigma amplitudes_dict = ( { \" %(AMPLX_VALUE)s \" : action_var_value , \" %(AMPLY_VALUE)s \" : 0.5 } if kick_plane == \"horizontal\" else { \" %(AMPLX_VALUE)s \" : 0.5 , \" %(AMPLY_VALUE)s \" : action_var_value } ) filename_to_write = Path ( f \"initial_amplitude_tracking_{kick_in_sigma}_sigma_{plane_letter}_kick\" ) mask_file = create_script_file ( self . template_str , values_replacing_dict = amplitudes_dict , filename = Path ( str ( filename_to_write )), ) run_madx_mask ( mask_file ) _move_mask_file_after_running ( mask_file_path = mask_file , mask_files_dir = self . mask_files_dir ) _rename_madx_outputs ( kick_in_sigma = kick_in_sigma , outputdata_dir = self . outputdata_dir , plane = plane_letter , ) _convert_trackone_to_sdds () _move_trackone_sdds ( kick_in_sigma = kick_in_sigma , trackfiles_dir = self . trackfiles_planes [ kick_plane ], plane = plane_letter , ) @logger.catch def main () -> None : \"\"\" Run the whole process: create a class instance, simulate for horizontal and vertical kicks, exit. \"\"\" command_line_args = _parse_arguments () _set_logger_level ( command_line_args . log_level ) simulations = ACDipoleGrid () simulations . _check_input_sanity () simulations . _create_output_dirs () sim_type = command_line_args . simulation_type try : if sim_type == \"kick\" : logger . info ( f \"Planes to kick then track on are: {simulations.run_planes}\" ) logger . info ( f \"Kick values to compute are (in bunch sigmas): {simulations.sigmas}\" ) for plane in simulations . run_planes : simulations . track_forced_oscillations_for_plane ( kick_plane = plane ) elif sim_type == \"amp\" : logger . info ( f \"Planes to offset then track on are: {simulations.run_planes}\" ) logger . info ( f \"Registered initial tracking amplitudes (in bunch sigmas): {simulations.sigmas}\" ) for plane in simulations . run_planes : simulations . track_free_oscillations_for_plane ( kick_plane = plane ) else : logger . error ( f \"Simulation type {sim_type} is not a valid value\" ) raise ValueError ( \"Simulation type should be one of 'kick' or 'amp'\" ) except KeyboardInterrupt : logger . info ( \"Manual interruption, ending processes\" ) _cleanup_madx_residuals () logger . warning ( \"The 'grid_outputs' folder was left untouched, check for unexpected MADX residuals\" ) # ---------------------- Public Utilities ---------------------- # def run_madx_mask ( mask_file : Path ) -> None : \"\"\" Run madx on the provided file. Args: mask_file (Path): Path object with the mask file location. \"\"\" logger . debug ( f \"Running madx on script: '{mask_file.absolute()}'\" ) exit_code , std_out = CommandLine . run ( f \"madx {mask_file.absolute()}\" ) if exit_code != 0 : # Dump madx log in case of failure so we can see where it went wrong. logger . warning ( f \"MAD-X command self-killed with exit code: {exit_code}\" ) log_dump = Path ( f \"failed_madx_returnedcode_{exit_code}.log\" ) with log_dump . open ( \"w\" ) as logfile : logfile . write ( std_out . decode ()) # Default 'utf-8' encoding, depends on your system. logger . warning ( f \"The standard output has been dumped to file 'failed_command_{exit_code}.logfile'\" ) def create_script_file ( template_as_str : str , values_replacing_dict : Dict [ str , float ], filename : Path , ) -> Path : \"\"\" Create new script file from template with the appropriate values. Args: template_as_str (str): string content of your template mask file. values_replacing_dict (Dict[str, float]): keys to find and values to replace them with in the template. filename (Path): Path object for the file in which to write the script. \"\"\" string_mask = _create_script_string ( template_as_str , values_replacing_dict ) return _write_script_to_file ( string_mask , filename ) # ---------------------- Private Utilities ---------------------- # def _convert_trackone_to_sdds () -> None : \"\"\" Run the omc3 tbt_converter script on trackone output of MAD-X. Will also cleanup the `converter` and 'stats' files left by tbt_converter afterwards. \"\"\" if not Path ( \"trackone\" ) . is_file (): logger . error ( \"Tried to call 'tbt_converter' without a 'trackone' file present, aborting\" ) sys . exit () logger . debug ( f \"Running '{TBT_CONVERTER_SCRIPT}' on 'trackone' file\" ) CommandLine . run ( f \"{OMC_PYTHON.absolute()} {TBT_CONVERTER_SCRIPT.absolute()} \" \"--files trackone --outputdir . --tbt_datatype trackone\" ) logger . debug ( \"Removing trackone file 'trackone'\" ) Path ( \"trackone\" ) . unlink () logger . debug ( \"Removing outputs of 'tbt_converter'\" ) if Path ( \"stats.txt\" ) . exists (): Path ( \"stats.txt\" ) . unlink () for tbt_output_file in list ( Path ( \".\" ) . glob ( \"converter_*\" )): tbt_output_file . unlink () def _create_script_string ( template_as_string : str , values_replacing_dict : Dict [ str , float ]) -> str : \"\"\" For each key in the provided dict, will replace it in the template scripts with the corresponding dict value. Args: template_as_string (str): the string content of your template mask file. values_replacing_dict (Dict[str, float]): pairs of key, value to find and replace in the template string. Returns: The new script string. \"\"\" script_string : str = template_as_string for key , value in values_replacing_dict . items (): script_string = script_string . replace ( str ( key ), str ( value )) return script_string def _move_mask_file_after_running ( mask_file_path : Path , mask_files_dir : Path ) -> None : \"\"\" Move the mask file after being done running it with MAD-X. Args: mask_file_path (Path): Path object with the file location. mask_files_dir (Path): Path object with the directory to move mask to' location. \"\"\" logger . debug ( f \"Moving mask file '{mask_file_path}' to directory '{mask_files_dir}'\" ) mask_file_path . rename ( f \"{mask_files_dir}/{mask_file_path}\" ) def _move_trackone_sdds ( kick_in_sigma : Union [ str , float ], trackfiles_dir : Path , plane : str ) -> None : \"\"\" Call after running omc3's `tbt_converter` on the `trackone` output by MAD-X, will move the resulting `trackone.sdds` file to the `trackfiles_dir`, with a naming reflecting the ac dipole kick strength. Args: kick_in_sigma (Union[str, float]): the AC dipole kick value (in sigma) for which you ran your simulation. trackfiles_dir (Path): PosixPath to the folder in which to store all sdds trackone files. plane (str): the plane on which ac dipole provided the kick, should be `x` or `y`. \"\"\" if str ( plane ) not in ( \"x\" , \"y\" ): logger . error ( f \"Plane parameter {plane} is not a valid value\" ) raise ValueError ( \"Plane parameter should be one of 'x' or 'y'\" ) logger . debug ( f \"Moving trackone sdds file to directory '{trackfiles_dir}'\" ) track_sdds_file = Path ( \"trackone.sdds\" ) if not track_sdds_file . is_file (): logger . error ( \"Conversion to trackone sdds file must have failed, check the omc3 script\" ) sys . exit () track_sdds_file . rename ( f \"{trackfiles_dir}/trackone_{kick_in_sigma}_sigma_{plane}.sdds\" ) def _parse_arguments () -> argparse . Namespace : \"\"\" Simple argument parser to make life easier in the command-line. Returns a NameSpace with arguments as attributes. \"\"\" parser = argparse . ArgumentParser ( description = \"Running MAD-X AC dipole trackings for you.\" ) parser . add_argument ( \"-s\" , \"--sigmas\" , dest = \"sigmas\" , nargs = \"+\" , default = [ 1 , 2 ], type = float , help = \"Different amplitude values (in bunch sigma) for the AC dipole kicks.\" \"Defaults to [1, 2].\" , ) parser . add_argument ( \"-p\" , \"--planes\" , dest = \"planes\" , nargs = \"+\" , default = [ \"horizontal\" ], type = str , help = \"Planes for which to kick, possible values are 'horizontal' and 'vertical',\" \"Defaults to 'horizontal'.\" , ) parser . add_argument ( \"-m\" , \"--mask\" , dest = \"template\" , default = \"/afs/cern.ch/work/f/fesoubel/public/MADX_scripts/AC_dipole_tracking/ac_kick_tracking_template.mask\" , type = str , help = \"Location of your MAD-X template mask file to use, defaults to \" \"'/afs/cern.ch/work/f/fesoubel/public/MADX_scripts/AC_dipole_tracking/ac_kick_track_template.mask'.\" , ) parser . add_argument ( \"-t\" , \"--type\" , dest = \"simulation_type\" , default = \"kick\" , type = str , help = \"Type of simulations to run, either 'kick' for AC dipole kick or 'amp' for free \" \"oscillations. Defaults to 'kick'.\" , ) parser . add_argument ( \"-l\" , \"--logs\" , dest = \"log_level\" , default = \"info\" , type = str , help = \"The base console logging level. Can be 'debug', 'info', 'warning' and 'error'.\" \"Defaults to 'info'.\" , ) return parser . parse_args () def _rename_madx_outputs ( kick_in_sigma : Union [ str , float ], outputdata_dir : Path , plane : str ) -> None : \"\"\" Call after running MAD-X on your mask, will move the 'Outpudata' created by MAD-X to the proper place. Args: kick_in_sigma (Union[str, float]): the AC dipole kick value (in sigma) for which you ran your simulation. outputdata_dir (Path): PosixPath to the folder in which to store all successive `Outputdata`'s location. plane (str): the plane on which ac dipole provided the kick, should be `x` or `y`. \"\"\" if str ( plane ) not in ( \"x\" , \"y\" ): raise ValueError ( f \"Plane parameter should be one of 'x', 'y' but {plane} was provided.\" ) madx_outputs = Path ( \"Outputdata\" ) logger . debug ( f \"Moving MAD-X outputs to directory '{outputdata_dir}'\" ) madx_outputs . rename ( f \"{outputdata_dir}/Outputdata_{kick_in_sigma}_sigma_{plane}\" ) def _set_logger_level ( log_level : str = \"info\" ) -> None : \"\"\" Sets the logger level to the one provided at the commandline. Default loguru handler will have DEBUG level and ID 0. We need to first remove this default handler and add ours with the wanted level. Args: log_level (str): the default logging level to print out. \"\"\" logger . remove ( 0 ) logger . add ( sys . stderr , format = LOGURU_FORMAT , level = log_level . upper ()) def _write_script_to_file ( script_as_string : str , filename : Union [ str , Path ]) -> Path : \"\"\" Create a new file with the provided script, and return the location. Args: script_as_string (str): the script string to write to file. filename (Union[str, Path]): the file name to use. Returns: The `pathlib.Path` object to the created file. \"\"\" file_path = Path ( str ( filename ) + \".mask\" ) logger . debug ( f \"Creating new mask file '{file_path}'\" ) with file_path . open ( \"w\" ) as script : script . write ( script_as_string ) return file_path def _cleanup_madx_residuals () -> None : \"\"\" Will look for specific madx artifacts and remove them. Meant to be called in case of interuption. \"\"\" expected_residuals : Dict [ str , List [ str ]] = { \"symlinks\" : [ \"db5\" , \"slhc\" , \"fidel\" , \"wise\" , \"optics2016\" , \"optics2017\" , \"optics2018\" , \"scripts\" , ], \"directories\" : [ \"temp\" , \"Outputdata\" ], \"files\" : [ \"fort.18\" ], } logger . debug ( \"Cleaning up expected MADX residuals\" ) for residual_type , residual_values in expected_residuals . items (): logger . trace ( f \"Cleaning up MADX residual {residual_type}\" ) for residual in residual_values : if Path ( residual ) . is_symlink () or Path ( residual ) . is_file (): Path ( residual ) . unlink () elif Path ( residual ) . is_dir (): shutil . rmtree ( Path ( residual )) logger . debug ( \"Cleaning up potential residual mask files\" ) for suspect_mask in list ( Path ( \".\" ) . glob ( \"*.mask\" )): if ( suspect_mask . stem . startswith ( \"initial_\" ) or suspect_mask . stem . startswith ( \"sext_\" ) ) and suspect_mask . stem . endswith ( \"_kick\" ): suspect_mask . unlink () if __name__ == \"__main__\" : main ()","title":"A pair of examples"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/#variables","text":"LOGURU_FORMAT","title":"Variables"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/#create_script_file","text":"def create_script_file ( template_as_str : str , values_replacing_dict : Dict [ str , float ], filename : pathlib . Path ) -> pathlib . Path Create new script file from template with the appropriate values. Args: template_as_str (str): string content of your template mask file. values_replacing_dict (Dict[str, float]): keys to find and values to replace them with in the template. filename (Path): Path object for the file in which to write the script. View Source def create_script_file ( template_as_str : str , values_replacing_dict : Dict [ str , float ], filename : Path , ) -> Path : \"\"\" Create new script file from template with the appropriate values. Args: template_as_str (str): string content of your template mask file. values_replacing_dict (Dict[str, float]): keys to find and values to replace them with in the template. filename (Path): Path object for the file in which to write the script. \"\"\" string_mask = _create_script_string ( template_as_str , values_replacing_dict ) return _write_script_to_file ( string_mask , filename )","title":"create_script_file"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/#main","text":"def main ( ) -> None Run the whole process: create a class instance, simulate for horizontal and vertical kicks, exit. View Source @logger . catch def main () -> None : \"\"\" Run the whole process: create a class instance, simulate for horizontal and vertical kicks, exit. \"\"\" command_line_args = _parse_arguments () _set_logger_level ( command_line_args . log_level ) simulations = ACDipoleGrid () simulations . _check_input_sanity () simulations . _create_output_dirs () sim_type = command_line_args . simulation_type try : if sim_type == \"kick\" : logger . info ( f \"Planes to kick then track on are: {simulations.run_planes}\" ) logger . info ( f \"Kick values to compute are (in bunch sigmas): {simulations.sigmas}\" ) for plane in simulations . run_planes : simulations . track_forced_oscillations_for_plane ( kick_plane = plane ) elif sim_type == \"amp\" : logger . info ( f \"Planes to offset then track on are: {simulations.run_planes}\" ) logger . info ( f \"Registered initial tracking amplitudes (in bunch sigmas): {simulations.sigmas}\" ) for plane in simulations . run_planes : simulations . track_free_oscillations_for_plane ( kick_plane = plane ) else : logger . error ( f \"Simulation type {sim_type} is not a valid value\" ) raise ValueError ( \"Simulation type should be one of 'kick' or 'amp'\" ) except KeyboardInterrupt : logger . info ( \"Manual interruption, ending processes\" ) _cleanup_madx_residuals () logger . warning ( \"The 'grid_outputs' folder was left untouched, check for unexpected MADX residuals\" )","title":"main"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/#run_madx_mask","text":"def run_madx_mask ( mask_file : pathlib . Path ) -> None Run madx on the provided file. Args: mask_file (Path): Path object with the mask file location. View Source def run_madx_mask ( mask_file : Path ) -> None : \"\"\" Run madx on the provided file. Args: mask_file (Path): Path object with the mask file location. \"\"\" logger . debug ( f \"Running madx on script: '{mask_file.absolute()}'\" ) exit_code , std_out = CommandLine . run ( f \"madx {mask_file.absolute()}\" ) if exit_code != 0 : # Dump madx log in case of failure so we can see where it went wrong . logger . warning ( f \"MAD-X command self-killed with exit code: {exit_code}\" ) log_dump = Path ( f \"failed_madx_returnedcode_{exit_code}.log\" ) with log_dump . open ( \"w\" ) as logfile : logfile . write ( std_out . decode ()) # Default 'utf-8' encoding , depends on your system . logger . warning ( f \"The standard output has been dumped to file 'failed_command_{exit_code}.logfile'\" )","title":"run_madx_mask"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/#acdipolegrid","text":"class ACDipoleGrid ( ) Algorithm as a class to run the simulations and organize the outputs. View Source class ACDipoleGrid : \"\"\" Algorithm as a class to run the simulations and organize the outputs. \"\"\" __slots__ = { \"grid_output_dir\" : \"PosixPath object to the directory for all outputs\" , \"mask_files_dir\" : \"PosixPath object to the directory for simulations' masks\" , \"outputdata_dir\" : \"PosixPath object to the directory for simulation data\" , \"trackfiles_dir\" : \"PosixPath object to the directory for trackone files\" , \"trackfiles_planes\" : \"PosixPath objects to the planes' trackone files\" , \"run_planes\" : \"List of planes for which to run simulations\" , \"sigmas\" : \"List of amplitudes for AC dipole to kick to (in bunch sigma)\" , \"template_file\" : \"PosixPath object to the location of the mask template\" , \"template_str\" : \"Text in the template_file\" , } def __init__ ( self ) -> None : self . grid_output_dir : Path = Path ( \"grid_outputs\" ) self . mask_files_dir : Path = self . grid_output_dir / \"mask_files\" self . outputdata_dir : Path = self . grid_output_dir / \"outputdata_dirs\" self . trackfiles_dir : Path = self . grid_output_dir / \"trackfiles\" self . trackfiles_planes : Dict [ str, Path ] = { \"horizontal\" : self . grid_output_dir / \"trackfiles\" / \"X\" , \"vertical\" : self . grid_output_dir / \"trackfiles\" / \"Y\" , } self . run_planes : List [ str ] = _parse_arguments (). planes self . sigmas : List [ float ] = sorted ( _parse_arguments (). sigmas ) self . template_file : Path = Path ( _parse_arguments (). template ) self . template_str : str = self . template_file . read_text () def _check_input_sanity ( self ) -> None : \"\"\" Makes sure there are no duplicates in the provided sigma values, because that will mess up a long time after launch and you will cry. \"\"\" if len ( self . sigmas ) != len ( set ( self . sigmas )) : logger . error ( \"There is a duplicate in the sigma values, which would cause a failure later.\" ) sys . exit () def _create_output_dirs ( self ) -> None : \"\"\" Will create the proper output dirs if they don't exist already. \"\"\" if not self . grid_output_dir . is_dir () : logger . debug ( f \"Creating directory '{self.grid_output_dir}'\" ) self . grid_output_dir . mkdir () if not self . mask_files_dir . is_dir () : logger . debug ( f \"Creating directory '{self.mask_files_dir}'\" ) self . mask_files_dir . mkdir () if not self . outputdata_dir . is_dir () : logger . debug ( f \"Creating directory '{self.outputdata_dir}'\" ) self . outputdata_dir . mkdir () if not self . trackfiles_dir . is_dir () : logger . debug ( f \"Creating directory '{self.trackfiles_dir}'\" ) self . trackfiles_dir . mkdir () if not self . trackfiles_planes [ \"horizontal\" ] . is_dir () : logger . debug ( f \"Creating directory '{self.trackfiles_planes['horizontal']}'\" ) self . trackfiles_planes [ \"horizontal\" ] . mkdir () if not self . trackfiles_planes [ \"vertical\" ] . is_dir () : logger . debug ( f \"Creating directory '{self.trackfiles_planes['vertical']}'\" ) self . trackfiles_planes [ \"vertical\" ] . mkdir () else : logger . error ( \"Output directories already present, you may want to move those.\" ) sys . exit () def track_forced_oscillations_for_plane ( self , kick_plane : str = None ) -> None : \"\"\" Run MAD-X simulations with AC dipole tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply a kick, either 'horizontal' or 'vertical'. \"\"\" if kick_plane not in ( \"horizontal\" , \"vertical\" ) : logger . error ( f \"Plane parameter {kick_plane} is not a valid value\" ) raise ValueError ( \"Plane parameter should be one of 'horizontal' or 'vertical'\" ) with timeit ( lambda spanned : logger . info ( f \"Tracked all amplitudes for {kick_plane} kicks in {spanned:.4f} seconds\" ) ) : for kick_in_sigma in self . sigmas : print ( \"\" ) # Set the wanted kick value ( in sigmas ) in the given plane , and a small initial # offset in the other ( small offset so that harpy doesn 't cry and we get tune). # Do NOT kick both planes: cross-terms influence the detuning. plane_letter = \"x\" if kick_plane == \"horizontal\" else \"y\" replace_dict = ( { \"%(SIGMAX_VALUE)s\": kick_in_sigma, \"%(SIGMAY_VALUE)s\": 0, \"%(AMPLX_VALUE)s\": 0, \"%(AMPLY_VALUE)s\": 0.5, } if kick_plane == \"horizontal\" else { \"%(SIGMAX_VALUE)s\": 0, \"%(SIGMAY_VALUE)s\": kick_in_sigma, \"%(AMPLX_VALUE)s\": 0.5, \"%(AMPLY_VALUE)s\": 0, } ) filename_to_write = Path( f\"sext_ac_dipole_tracking_{kick_in_sigma}_sigma_{plane_letter}_kick\" ) mask_file = create_script_file( self.template_str, values_replacing_dict=replace_dict, filename=Path(str(filename_to_write)), ) run_madx_mask(mask_file) _move_mask_file_after_running( mask_file_path=mask_file, mask_files_dir=self.mask_files_dir ) _rename_madx_outputs( kick_in_sigma=kick_in_sigma, outputdata_dir=self.outputdata_dir, plane=plane_letter, ) _convert_trackone_to_sdds() _move_trackone_sdds( kick_in_sigma=kick_in_sigma, trackfiles_dir=self.trackfiles_planes[kick_plane], plane=plane_letter, ) def track_free_oscillations_for_plane(self, kick_plane: str = None) -> None: \"\"\" Run MAD-X simulations with amplitude offset tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply an offset, either ' horizontal ' or ' vertical '. \"\"\" if kick_plane not in (\"horizontal\", \"vertical\"): logger.error(f\"Plane parameter {kick_plane} is not a valid value\") raise ValueError(\"Plane parameter should be one of ' horizontal ' or ' vertical ' \") with timeit( lambda spanned: logger.info( f\" Tracked all amplitudes for { kick_plane } offsets in { spanned : .4 f } seconds \" ) ): for kick_in_sigma in self.sigmas: print(\"\") plane_letter = \" x \" if kick_plane == \" horizontal \" else \" y \" action_var_value = kick_in_sigma amplitudes_dict = ( {\" % ( AMPLX_VALUE ) s \": action_var_value, \" % ( AMPLY_VALUE ) s \": 0.5} if kick_plane == \" horizontal \" else {\" % ( AMPLX_VALUE ) s \": 0.5, \" % ( AMPLY_VALUE ) s \": action_var_value} ) filename_to_write = Path( f\" initial_amplitude_tracking_ { kick_in_sigma } _sigma_ { plane_letter } _kick \" ) mask_file = create_script_file ( self . template_str , values_replacing_dict = amplitudes_dict , filename = Path ( str ( filename_to_write )), ) run_madx_mask ( mask_file ) _move_mask_file_after_running ( mask_file_path = mask_file , mask_files_dir = self . mask_files_dir ) _rename_madx_outputs ( kick_in_sigma = kick_in_sigma , outputdata_dir = self . outputdata_dir , plane = plane_letter , ) _convert_trackone_to_sdds () _move_trackone_sdds ( kick_in_sigma = kick_in_sigma , trackfiles_dir = self . trackfiles_planes [ kick_plane ] , plane = plane_letter , )","title":"ACDipoleGrid"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/#instance-variables","text":"grid_output_dir mask_files_dir outputdata_dir run_planes sigmas template_file template_str trackfiles_dir trackfiles_planes","title":"Instance variables"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/#methods","text":"","title":"Methods"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/#track_forced_oscillations_for_plane","text":"def track_forced_oscillations_for_plane ( self , kick_plane : str = None ) -> None Run MAD-X simulations with AC dipole tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply a kick, either 'horizontal' or 'vertical'. View Source def track_forced_oscillations_for_plane ( self , kick_plane : str = None ) -> None : \"\"\" Run MAD-X simulations with AC dipole tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply a kick, either 'horizontal' or 'vertical'. \"\"\" if kick_plane not in ( \"horizontal\" , \"vertical\" ) : logger . error ( f \"Plane parameter {kick_plane} is not a valid value\" ) raise ValueError ( \"Plane parameter should be one of 'horizontal' or 'vertical'\" ) with timeit ( lambda spanned : logger . info ( f \"Tracked all amplitudes for {kick_plane} kicks in {spanned:.4f} seconds\" ) ) : for kick_in_sigma in self . sigmas : print ( \"\" ) # Set the wanted kick value ( in sigmas ) in the given plane , and a small initial # offset in the other ( small offset so that harpy doesn ' t cry and we get tune ). # Do NOT kick both planes : cross - terms influence the detuning . plane_letter = \"x\" if kick_plane == \"horizontal\" else \"y\" replace_dict = ( { \"%(SIGMAX_VALUE)s\" : kick_in_sigma , \"%(SIGMAY_VALUE)s\" : 0 , \"%(AMPLX_VALUE)s\" : 0 , \"%(AMPLY_VALUE)s\" : 0.5 , } if kick_plane == \"horizontal\" else { \"%(SIGMAX_VALUE)s\" : 0 , \"%(SIGMAY_VALUE)s\" : kick_in_sigma , \"%(AMPLX_VALUE)s\" : 0.5 , \"%(AMPLY_VALUE)s\" : 0 , } ) filename_to_write = Path ( f \"sext_ac_dipole_tracking_{kick_in_sigma}_sigma_{plane_letter}_kick\" ) mask_file = create_script_file ( self . template_str , values_replacing_dict = replace_dict , filename = Path ( str ( filename_to_write )), ) run_madx_mask ( mask_file ) _move_mask_file_after_running ( mask_file_path = mask_file , mask_files_dir = self . mask_files_dir ) _rename_madx_outputs ( kick_in_sigma = kick_in_sigma , outputdata_dir = self . outputdata_dir , plane = plane_letter , ) _convert_trackone_to_sdds () _move_trackone_sdds ( kick_in_sigma = kick_in_sigma , trackfiles_dir = self . trackfiles_planes [ kick_plane ] , plane = plane_letter , )","title":"track_forced_oscillations_for_plane"},{"location":"reference/pyhdtoolkit/scripts/ac_dipole/sext_ac_dipole_tracking/#track_free_oscillations_for_plane","text":"def track_free_oscillations_for_plane ( self , kick_plane : str = None ) -> None Run MAD-X simulations with amplitude offset tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply an offset, either 'horizontal' or 'vertical'. View Source def track_free_oscillations_for_plane ( self , kick_plane : str = None ) -> None : \"\"\" Run MAD-X simulations with amplitude offset tracking for the given plane, and handle outputs. Args: kick_plane: the name of the plane on which to apply an offset, either 'horizontal' or 'vertical'. \"\"\" if kick_plane not in ( \"horizontal\" , \"vertical\" ) : logger . error ( f \"Plane parameter {kick_plane} is not a valid value\" ) raise ValueError ( \"Plane parameter should be one of 'horizontal' or 'vertical'\" ) with timeit ( lambda spanned : logger . info ( f \"Tracked all amplitudes for {kick_plane} offsets in {spanned:.4f} seconds\" ) ) : for kick_in_sigma in self . sigmas : print ( \"\" ) plane_letter = \"x\" if kick_plane == \"horizontal\" else \"y\" action_var_value = kick_in_sigma amplitudes_dict = ( { \"%(AMPLX_VALUE)s\" : action_var_value , \"%(AMPLY_VALUE)s\" : 0.5 } if kick_plane == \"horizontal\" else { \"%(AMPLX_VALUE)s\" : 0.5 , \"%(AMPLY_VALUE)s\" : action_var_value } ) filename_to_write = Path ( f \"initial_amplitude_tracking_{kick_in_sigma}_sigma_{plane_letter}_kick\" ) mask_file = create_script_file ( self . template_str , values_replacing_dict = amplitudes_dict , filename = Path ( str ( filename_to_write )), ) run_madx_mask ( mask_file ) _move_mask_file_after_running ( mask_file_path = mask_file , mask_files_dir = self . mask_files_dir ) _rename_madx_outputs ( kick_in_sigma = kick_in_sigma , outputdata_dir = self . outputdata_dir , plane = plane_letter , ) _convert_trackone_to_sdds () _move_trackone_sdds ( kick_in_sigma = kick_in_sigma , trackfiles_dir = self . trackfiles_planes [ kick_plane ] , plane = plane_letter , )","title":"track_free_oscillations_for_plane"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/","text":"Module pyhdtoolkit.scripts.triplet_errors Sub-modules pyhdtoolkit.scripts.triplet_errors.algo pyhdtoolkit.scripts.triplet_errors.data_classes pyhdtoolkit.scripts.triplet_errors.plotting_functions","title":"Index"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/#module-pyhdtoolkitscriptstriplet_errors","text":"","title":"Module pyhdtoolkit.scripts.triplet_errors"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/#sub-modules","text":"pyhdtoolkit.scripts.triplet_errors.algo pyhdtoolkit.scripts.triplet_errors.data_classes pyhdtoolkit.scripts.triplet_errors.plotting_functions","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/algo/","text":"Module pyhdtoolkit.scripts.triplet_errors.algo Script scripts.triplets_errors.algo Created on 2019.06.15 :author: Felix Soubelet ( felix.soubelet@cern.ch ) Command-line utility script, which will launch a series of MAD-X simulations, perform analysis of the outputs and hand out a plot. Arguments should be given as options at launch in the command-line. See README for instructions. View Source \"\"\" Script scripts.triplets_errors.algo ---------------------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) Command-line utility script, which will launch a series of MAD-X simulations, perform analysis of the outputs and hand out a plot. Arguments should be given as options at launch in the command-line. See README for instructions. \"\"\" import argparse import sys from copy import deepcopy from typing import List import cpymad import numpy as np import pandas as pd from loguru import logger from rich.progress import track from pyhdtoolkit.cpymadtools.lattice_generators import LatticeGenerator from pyhdtoolkit.scripts.triplet_errors.data_classes import BetaBeatValues , StdevValues from pyhdtoolkit.scripts.triplet_errors.plotting_functions import ( plot_bbing_max_errorbar , plot_bbing_with_ips_errorbar , ) from pyhdtoolkit.utils.contexts import timeit from pyhdtoolkit.utils.defaults import LOGURU_FORMAT class GridCompute : \"\"\" Algorithm as a class to run the simulations and analyze the outputs. Will prompt error values for confirmation, run MAD-X simulations through a `cpymad.madx.Madx` object, get beta-beating values from the outputs and return the appropriate structures. \"\"\" __slots__ = { \"reference_mad\" : \"cpymad Madx object to run the nominal configuration\" , \"errors_mad\" : \"cpymad Madx object to run errored simulations\" , \"rms_betabeatings\" : \"BetaBeatValues class to hold rms beta-beatings from simulations\" , \"standard_deviations\" : \"StdevValues class to hold standard deviations from simulations\" , \"lost_seeds_tf\" : \"List of field error values leading to loss of closed orbit\" , \"lost_seeds_miss\" : \"List of misalignment values leading to loss of closed orbit\" , \"nominal_twiss\" : \"Twiss dataframe from the nominal simulation\" , } def __init__ ( self ) -> None : \"\"\" Initializing will take some time since the reference script is being ran, to store the reference dframe. Unless you go into PTC it should be a matter of seconds. \"\"\" self . reference_mad = cpymad . madx . Madx ( stdout = False ) self . errors_mad = cpymad . madx . Madx ( stdout = False ) self . rms_betabeatings = BetaBeatValues () self . standard_deviations = StdevValues () self . lost_seeds_tf : List [ int ] = [] self . lost_seeds_miss : List [ int ] = [] self . nominal_twiss = self . _get_nominal_twiss () def _get_nominal_twiss ( self ) -> pd . DataFrame : \"\"\" Run a MAD-X simulation without errors, and extract the nominal Twiss from the results. This will be stored in the `nominal_twiss` instance attribute. Returns: Nothing, directly updates the instance's `nominal_twiss` attribute inplace. \"\"\" logger . info ( \"Running simulation for reference nominal run\" ) ref_script = LatticeGenerator . generate_tripleterrors_study_reference () self . reference_mad . input ( ref_script ) logger . debug ( \"Extracting reference Twiss dframe from cpymad\" ) return deepcopy ( self . reference_mad . table . twiss . dframe ()) def run_tf_errors ( self , error_values : List [ float ], n_seeds : int ) -> None : \"\"\" Run simulations for field errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's `rms_betabeatings` and `standard_deviations` attributes. \"\"\" with timeit ( lambda spanned : logger . info ( f \"Simulated field errors in: { spanned : .4f } seconds\" ) ): for error in error_values : logger . debug ( f \"Running simulation for Relative Field Error: { error } E-4\" ) temp_data = BetaBeatValues () for _ in track ( range ( n_seeds ), description = \"Simulating Field Errors Seeds\" , transient = True ): # Getting beta-beatings & appending to temporary BetaBeatValues tferrors_twiss : pd . DataFrame = self . _track_tf_error ( error ) betabeatings : pd . DataFrame = _get_betabeatings ( self . nominal_twiss , tferrors_twiss ) temp_data . update_tf_from_cpymad ( betabeatings ) # Append computed seeds' RMS for this error value in `rms_betabeatings` attribute. self . rms_betabeatings . update_tf_from_seeds ( temp_data ) # Getting stdev of all values for the N computed seeds self . standard_deviations . update_tf ( temp_data ) # Getting the lost seeds if any self . lost_seeds_tf . append ( n_seeds - len ( temp_data . tferror_bbx )) def _track_tf_error ( self , error : float ) -> pd . DataFrame : \"\"\" Run tferror tracking for a given seed, which is randomly assigned at function call. Args: error (float): the error value to input in the madx script. Returns: The twiss dframe from cpymad. \"\"\" seed = str ( np . random . randint ( 1e6 , 5e6 )) tferror_script = LatticeGenerator . generate_tripleterrors_study_tferror_job ( seed , str ( error )) self . errors_mad . input ( tferror_script ) return self . errors_mad . table . twiss . dframe () def run_miss_errors ( self , error_values : List [ float ], n_seeds : int ) -> None : \"\"\" Run the simulations for misalignment errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for. n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's `rms_betabeatings` and `standard_deviations` attributes. \"\"\" with timeit ( lambda spanned : logger . info ( f \"Simulated misalignment errors in: { spanned : .4f } seconds\" ) ): for error in error_values : logger . debug ( f \"Running for Longitudinal Misalignment Error: { float ( error ) } mm\" ) temp_data = ( BetaBeatValues () ) # this will hold the beta-beats for all seeds with this error value. for _ in track ( range ( n_seeds ), description = \"Simulating Misalignment Seeds\" , transient = True ): # Getting beta-beatings & appending to temporary BetaBeatValues mserrors_twiss : pd . DataFrame = self . _track_miss_error ( error ) betabeatings : pd . DataFrame = _get_betabeatings ( self . nominal_twiss , mserrors_twiss ) temp_data . update_miss_from_cpymad ( betabeatings ) # Append computed seeds' RMS for this error value in `rms_betabeatings` attribute. self . rms_betabeatings . update_miss_from_seeds ( temp_data ) # Getting stdev of all values for the N computed seeds self . standard_deviations . update_miss ( temp_data ) # Getting the lost seeds if any self . lost_seeds_miss . append ( n_seeds - len ( temp_data . misserror_bbx )) def _track_miss_error ( self , error : float ) -> pd . DataFrame : \"\"\" Run misserror tracking for a given seed, which is randomly assigned at function call. Args: error (float): the error value to input in the madx script. Returns: The twiss dframe from cpymad. \"\"\" seed = str ( np . random . randint ( 1e6 , 5e6 )) mserror_script = LatticeGenerator . generate_tripleterrors_study_mserror_job ( seed , str ( error )) self . errors_mad . input ( mserror_script ) return self . errors_mad . table . twiss . dframe () def _get_betabeatings ( nominal_twiss : pd . DataFrame , errors_twiss : pd . DataFrame ) -> pd . DataFrame : \"\"\" Simple function to get beta-beatings from a `cpymad.madx.Madx`'s Twiss output. Args: nominal_twiss (pd.DataFrame): a twiss.dframe() results from a reference scenario. errors_twiss (pd.DataFrame): a twiss.dframe() results from the perturbed scenario. Returns: A `pd.DataFrame` with the beta-beat values, in percentage. \"\"\" betabeat = pd . DataFrame () betabeat [ \"NAME\" ] = nominal_twiss . name betabeat [ \"s\" ] = nominal_twiss . s betabeat [ \"BETX\" ] = 100 * ( errors_twiss . betx - nominal_twiss . betx ) / nominal_twiss . betx betabeat [ \"BETY\" ] = 100 * ( errors_twiss . bety - nominal_twiss . bety ) / nominal_twiss . bety return betabeat def _parse_arguments () -> argparse . Namespace : \"\"\" Simple argument parser to make life easier in the command-line. Returns a NameSpace with arguments as attributes. \"\"\" parser = argparse . ArgumentParser ( description = \"Running the beta-beating script.\" ) parser . add_argument ( \"-e\" , \"--errors\" , dest = \"errors\" , nargs = \"+\" , default = [ 1 , 3 , 5 ], type = int , help = \"Error values to simulate\" , ) parser . add_argument ( \"-s\" , \"--seeds\" , dest = \"seeds\" , default = 50 , type = int , help = \"Number of seeds to simulate per error.\" , ) parser . add_argument ( \"-p\" , \"--plotbetas\" , dest = \"plotbetas\" , default = False , help = \"Option for plotting betas at each error.\" , ) parser . add_argument ( \"-l\" , \"--logs\" , dest = \"log_level\" , default = \"info\" , type = str , help = \"The base console logging level. Can be 'debug', 'info', 'warning' and 'error'.\" \"Defaults to 'info'.\" , ) return parser . parse_args () def _set_logger_level ( log_level : str = \"info\" ) -> None : \"\"\" Sets the logger level to the one provided at the commandline. Default loguru handler will have DEBUG level and ID 0. We need to first remove this default handler and add ours with the wanted level. Args: log_level (str): string, the default logging level to print out. \"\"\" logger . remove ( 0 ) logger . add ( sys . stderr , format = LOGURU_FORMAT , level = log_level . upper ()) @logger . catch def main () -> None : \"\"\" Run the whole process. Will prompt for error grid values for confirmation. Instantiates a GridCompute object and runs for each type of errors. The results are stored in the class itself, to be accessed for plotting. \"\"\" command_line_args = _parse_arguments () _set_logger_level ( command_line_args . log_level ) simulations = GridCompute () logger . info ( f \"Here are the error values that will be ran: { command_line_args . errors } \" ) # Running simulations simulations . run_tf_errors ( command_line_args . errors , command_line_args . seeds ) simulations . run_miss_errors ( command_line_args . errors , command_line_args . seeds ) # Getting the results in dataframes and exporting to csv logger . info ( \"Exporting results to csv\" ) bbing_df : pd . DataFrame = simulations . rms_betabeatings . to_pandas () std_df : pd . DataFrame = simulations . standard_deviations . to_pandas () bbing_df . to_csv ( \"beta_beatings.csv\" , index = False ) std_df . to_csv ( \"standard_deviations.csv\" , index = False ) # Plotting the results plot_bbing_max_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Horizontal\" , figname = \"miss_vs_tf_max_hor.png\" , ) plot_bbing_max_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Vertical\" , figname = \"miss_vs_tf_max_ver.png\" , ) plot_bbing_with_ips_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Horizontal\" , figname = \"miss_vs_tf_ips_hor.png\" , ) plot_bbing_with_ips_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Vertical\" , figname = \"miss_vs_tf_ips_ver.png\" , ) if __name__ == \"__main__\" : main () Variables LOGURU_FORMAT Functions main def main ( ) -> None Run the whole process. Will prompt for error grid values for confirmation. Instantiates a GridCompute object and runs for each type of errors. The results are stored in the class itself, to be accessed for plotting. View Source @ logger . catch def main () -> None : \"\"\" Run the whole process. Will prompt for error grid values for confirmation. Instantiates a GridCompute object and runs for each type of errors. The results are stored in the class itself, to be accessed for plotting. \"\"\" command_line_args = _parse_arguments () _set_logger_level ( command_line_args . log_level ) simulations = GridCompute () logger . info ( f \"Here are the error values that will be ran: {command_line_args.errors}\" ) # Running simulations simulations . run_tf_errors ( command_line_args . errors , command_line_args . seeds ) simulations . run_miss_errors ( command_line_args . errors , command_line_args . seeds ) # Getting the results in dataframes and exporting to csv logger . info ( \"Exporting results to csv\" ) bbing_df : pd . DataFrame = simulations . rms_betabeatings . to_pandas () std_df : pd . DataFrame = simulations . standard_deviations . to_pandas () bbing_df . to_csv ( \"beta_beatings.csv\" , index = False ) std_df . to_csv ( \"standard_deviations.csv\" , index = False ) # Plotting the results plot_bbing_max_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Horizontal\" , figname = \"miss_vs_tf_max_hor.png\" , ) plot_bbing_max_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Vertical\" , figname = \"miss_vs_tf_max_ver.png\" , ) plot_bbing_with_ips_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Horizontal\" , figname = \"miss_vs_tf_ips_hor.png\" , ) plot_bbing_with_ips_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Vertical\" , figname = \"miss_vs_tf_ips_ver.png\" , ) Classes GridCompute class GridCompute ( ) Algorithm as a class to run the simulations and analyze the outputs. Will prompt error values for confirmation, run MAD-X simulations through a cpymad.madx.Madx object, get beta-beating values from the outputs and return the appropriate structures. View Source class GridCompute : \" \"\" Algorithm as a class to run the simulations and analyze the outputs. Will prompt error values for confirmation, run MAD-X simulations through a `cpymad.madx.Madx` object, get beta-beating values from the outputs and return the appropriate structures. \"\" \" __slots__ = { \"reference_mad\" : \"cpymad Madx object to run the nominal configuration\" , \"errors_mad\" : \"cpymad Madx object to run errored simulations\" , \"rms_betabeatings\" : \"BetaBeatValues class to hold rms beta-beatings from simulations\" , \"standard_deviations\" : \"StdevValues class to hold standard deviations from simulations\" , \"lost_seeds_tf\" : \"List of field error values leading to loss of closed orbit\" , \"lost_seeds_miss\" : \"List of misalignment values leading to loss of closed orbit\" , \"nominal_twiss\" : \"Twiss dataframe from the nominal simulation\" , } def __init__ ( self ) -> None : \" \"\" Initializing will take some time since the reference script is being ran, to store the reference dframe. Unless you go into PTC it should be a matter of seconds. \"\" \" self . reference_mad = cpymad . madx . Madx ( stdout = False ) self . errors_mad = cpymad . madx . Madx ( stdout = False ) self . rms_betabeatings = BetaBeatValues () self . standard_deviations = StdevValues () self . lost_seeds_tf : List [ int ] = [] self . lost_seeds_miss : List [ int ] = [] self . nominal_twiss = self . _get_nominal_twiss () def _get_nominal_twiss ( self ) -> pd . DataFrame : \" \"\" Run a MAD-X simulation without errors, and extract the nominal Twiss from the results. This will be stored in the `nominal_twiss` instance attribute. Returns: Nothing, directly updates the instance's `nominal_twiss` attribute inplace. \"\" \" logger . info ( \"Running simulation for reference nominal run\" ) ref_script = LatticeGenerator . generate_tripleterrors_study_reference () self . reference_mad . input ( ref_script ) logger . debug ( \"Extracting reference Twiss dframe from cpymad\" ) return deepcopy ( self . reference_mad . table . twiss . dframe ()) def run_tf_errors ( self , error_values : List [ float ] , n_seeds : int ) -> None : \" \"\" Run simulations for field errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's `rms_betabeatings` and `standard_deviations` attributes. \"\" \" with timeit ( lambda spanned : logger . info ( f \"Simulated field errors in: {spanned:.4f} seconds\" ) ) : for error in error_values : logger . debug ( f \"Running simulation for Relative Field Error: {error}E-4\" ) temp_data = BetaBeatValues () for _ in track ( range ( n_seeds ), description = \"Simulating Field Errors Seeds\" , transient = True ) : # Getting beta-beatings & appending to temporary BetaBeatValues tferrors_twiss : pd . DataFrame = self . _track_tf_error ( error ) betabeatings : pd . DataFrame = _get_betabeatings ( self . nominal_twiss , tferrors_twiss ) temp_data . update_tf_from_cpymad ( betabeatings ) # Append computed seeds' RMS for this error value in `rms_betabeatings` attribute. self . rms_betabeatings . update_tf_from_seeds ( temp_data ) # Getting stdev of all values for the N computed seeds self . standard_deviations . update_tf ( temp_data ) # Getting the lost seeds if any self . lost_seeds_tf . append ( n_seeds - len ( temp_data . tferror_bbx )) def _track_tf_error ( self , error : float ) -> pd . DataFrame : \" \"\" Run tferror tracking for a given seed, which is randomly assigned at function call. Args: error (float): the error value to input in the madx script. Returns: The twiss dframe from cpymad. \"\" \" seed = str ( np . random . randint ( 1e6 , 5e6 )) tferror_script = LatticeGenerator . generate_tripleterrors_study_tferror_job ( seed , str ( error )) self . errors_mad . input ( tferror_script ) return self . errors_mad . table . twiss . dframe () def run_miss_errors ( self , error_values : List [ float ] , n_seeds : int ) -> None : \" \"\" Run the simulations for misalignment errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for. n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's `rms_betabeatings` and `standard_deviations` attributes. \"\" \" with timeit ( lambda spanned : logger . info ( f \"Simulated misalignment errors in: {spanned:.4f} seconds\" ) ) : for error in error_values : logger . debug ( f \"Running for Longitudinal Misalignment Error: {float(error)}mm\" ) temp_data = ( BetaBeatValues () ) # this will hold the beta-beats for all seeds with this error value. for _ in track ( range ( n_seeds ), description = \"Simulating Misalignment Seeds\" , transient = True ) : # Getting beta-beatings & appending to temporary BetaBeatValues mserrors_twiss : pd . DataFrame = self . _track_miss_error ( error ) betabeatings : pd . DataFrame = _get_betabeatings ( self . nominal_twiss , mserrors_twiss ) temp_data . update_miss_from_cpymad ( betabeatings ) # Append computed seeds' RMS for this error value in `rms_betabeatings` attribute. self . rms_betabeatings . update_miss_from_seeds ( temp_data ) # Getting stdev of all values for the N computed seeds self . standard_deviations . update_miss ( temp_data ) # Getting the lost seeds if any self . lost_seeds_miss . append ( n_seeds - len ( temp_data . misserror_bbx )) def _track_miss_error ( self , error : float ) -> pd . DataFrame : \" \"\" Run misserror tracking for a given seed, which is randomly assigned at function call. Args: error (float): the error value to input in the madx script. Returns: The twiss dframe from cpymad. \"\" \" seed = str ( np . random . randint ( 1e6 , 5e6 )) mserror_script = LatticeGenerator . generate_tripleterrors_study_mserror_job ( seed , str ( error )) self . errors_mad . input ( mserror_script ) return self . errors_mad . table . twiss . dframe () Instance variables errors_mad lost_seeds_miss lost_seeds_tf nominal_twiss reference_mad rms_betabeatings standard_deviations Methods run_miss_errors def run_miss_errors ( self , error_values : List [ float ], n_seeds : int ) -> None Run the simulations for misalignment errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for. n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's rms_betabeatings and standard_deviations attributes. View Source def run_miss_errors ( self , error_values : List [ float ] , n_seeds : int ) -> None : \" \"\" Run the simulations for misalignment errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for. n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's `rms_betabeatings` and `standard_deviations` attributes. \"\" \" with timeit ( lambda spanned : logger . info ( f \"Simulated misalignment errors in: {spanned:.4f} seconds\" ) ) : for error in error_values : logger . debug ( f \"Running for Longitudinal Misalignment Error: {float(error)}mm\" ) temp_data = ( BetaBeatValues () ) # this will hold the beta-beats for all seeds with this error value. for _ in track ( range ( n_seeds ), description = \"Simulating Misalignment Seeds\" , transient = True ) : # Getting beta-beatings & appending to temporary BetaBeatValues mserrors_twiss : pd . DataFrame = self . _track_miss_error ( error ) betabeatings : pd . DataFrame = _get_betabeatings ( self . nominal_twiss , mserrors_twiss ) temp_data . update_miss_from_cpymad ( betabeatings ) # Append computed seeds' RMS for this error value in `rms_betabeatings` attribute. self . rms_betabeatings . update_miss_from_seeds ( temp_data ) # Getting stdev of all values for the N computed seeds self . standard_deviations . update_miss ( temp_data ) # Getting the lost seeds if any self . lost_seeds_miss . append ( n_seeds - len ( temp_data . misserror_bbx )) run_tf_errors def run_tf_errors ( self , error_values : List [ float ], n_seeds : int ) -> None Run simulations for field errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's rms_betabeatings and standard_deviations attributes. View Source def run_tf_errors ( self , error_values : List [ float ] , n_seeds : int ) -> None : \" \"\" Run simulations for field errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's `rms_betabeatings` and `standard_deviations` attributes. \"\" \" with timeit ( lambda spanned : logger . info ( f \"Simulated field errors in: {spanned:.4f} seconds\" ) ) : for error in error_values : logger . debug ( f \"Running simulation for Relative Field Error: {error}E-4\" ) temp_data = BetaBeatValues () for _ in track ( range ( n_seeds ), description = \"Simulating Field Errors Seeds\" , transient = True ) : # Getting beta-beatings & appending to temporary BetaBeatValues tferrors_twiss : pd . DataFrame = self . _track_tf_error ( error ) betabeatings : pd . DataFrame = _get_betabeatings ( self . nominal_twiss , tferrors_twiss ) temp_data . update_tf_from_cpymad ( betabeatings ) # Append computed seeds' RMS for this error value in `rms_betabeatings` attribute. self . rms_betabeatings . update_tf_from_seeds ( temp_data ) # Getting stdev of all values for the N computed seeds self . standard_deviations . update_tf ( temp_data ) # Getting the lost seeds if any self . lost_seeds_tf . append ( n_seeds - len ( temp_data . tferror_bbx ))","title":"Algo"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/algo/#module-pyhdtoolkitscriptstriplet_errorsalgo","text":"","title":"Module pyhdtoolkit.scripts.triplet_errors.algo"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/algo/#script-scriptstriplets_errorsalgo","text":"Created on 2019.06.15 :author: Felix Soubelet ( felix.soubelet@cern.ch ) Command-line utility script, which will launch a series of MAD-X simulations, perform analysis of the outputs and hand out a plot. Arguments should be given as options at launch in the command-line. See README for instructions. View Source \"\"\" Script scripts.triplets_errors.algo ---------------------------------- Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) Command-line utility script, which will launch a series of MAD-X simulations, perform analysis of the outputs and hand out a plot. Arguments should be given as options at launch in the command-line. See README for instructions. \"\"\" import argparse import sys from copy import deepcopy from typing import List import cpymad import numpy as np import pandas as pd from loguru import logger from rich.progress import track from pyhdtoolkit.cpymadtools.lattice_generators import LatticeGenerator from pyhdtoolkit.scripts.triplet_errors.data_classes import BetaBeatValues , StdevValues from pyhdtoolkit.scripts.triplet_errors.plotting_functions import ( plot_bbing_max_errorbar , plot_bbing_with_ips_errorbar , ) from pyhdtoolkit.utils.contexts import timeit from pyhdtoolkit.utils.defaults import LOGURU_FORMAT class GridCompute : \"\"\" Algorithm as a class to run the simulations and analyze the outputs. Will prompt error values for confirmation, run MAD-X simulations through a `cpymad.madx.Madx` object, get beta-beating values from the outputs and return the appropriate structures. \"\"\" __slots__ = { \"reference_mad\" : \"cpymad Madx object to run the nominal configuration\" , \"errors_mad\" : \"cpymad Madx object to run errored simulations\" , \"rms_betabeatings\" : \"BetaBeatValues class to hold rms beta-beatings from simulations\" , \"standard_deviations\" : \"StdevValues class to hold standard deviations from simulations\" , \"lost_seeds_tf\" : \"List of field error values leading to loss of closed orbit\" , \"lost_seeds_miss\" : \"List of misalignment values leading to loss of closed orbit\" , \"nominal_twiss\" : \"Twiss dataframe from the nominal simulation\" , } def __init__ ( self ) -> None : \"\"\" Initializing will take some time since the reference script is being ran, to store the reference dframe. Unless you go into PTC it should be a matter of seconds. \"\"\" self . reference_mad = cpymad . madx . Madx ( stdout = False ) self . errors_mad = cpymad . madx . Madx ( stdout = False ) self . rms_betabeatings = BetaBeatValues () self . standard_deviations = StdevValues () self . lost_seeds_tf : List [ int ] = [] self . lost_seeds_miss : List [ int ] = [] self . nominal_twiss = self . _get_nominal_twiss () def _get_nominal_twiss ( self ) -> pd . DataFrame : \"\"\" Run a MAD-X simulation without errors, and extract the nominal Twiss from the results. This will be stored in the `nominal_twiss` instance attribute. Returns: Nothing, directly updates the instance's `nominal_twiss` attribute inplace. \"\"\" logger . info ( \"Running simulation for reference nominal run\" ) ref_script = LatticeGenerator . generate_tripleterrors_study_reference () self . reference_mad . input ( ref_script ) logger . debug ( \"Extracting reference Twiss dframe from cpymad\" ) return deepcopy ( self . reference_mad . table . twiss . dframe ()) def run_tf_errors ( self , error_values : List [ float ], n_seeds : int ) -> None : \"\"\" Run simulations for field errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's `rms_betabeatings` and `standard_deviations` attributes. \"\"\" with timeit ( lambda spanned : logger . info ( f \"Simulated field errors in: { spanned : .4f } seconds\" ) ): for error in error_values : logger . debug ( f \"Running simulation for Relative Field Error: { error } E-4\" ) temp_data = BetaBeatValues () for _ in track ( range ( n_seeds ), description = \"Simulating Field Errors Seeds\" , transient = True ): # Getting beta-beatings & appending to temporary BetaBeatValues tferrors_twiss : pd . DataFrame = self . _track_tf_error ( error ) betabeatings : pd . DataFrame = _get_betabeatings ( self . nominal_twiss , tferrors_twiss ) temp_data . update_tf_from_cpymad ( betabeatings ) # Append computed seeds' RMS for this error value in `rms_betabeatings` attribute. self . rms_betabeatings . update_tf_from_seeds ( temp_data ) # Getting stdev of all values for the N computed seeds self . standard_deviations . update_tf ( temp_data ) # Getting the lost seeds if any self . lost_seeds_tf . append ( n_seeds - len ( temp_data . tferror_bbx )) def _track_tf_error ( self , error : float ) -> pd . DataFrame : \"\"\" Run tferror tracking for a given seed, which is randomly assigned at function call. Args: error (float): the error value to input in the madx script. Returns: The twiss dframe from cpymad. \"\"\" seed = str ( np . random . randint ( 1e6 , 5e6 )) tferror_script = LatticeGenerator . generate_tripleterrors_study_tferror_job ( seed , str ( error )) self . errors_mad . input ( tferror_script ) return self . errors_mad . table . twiss . dframe () def run_miss_errors ( self , error_values : List [ float ], n_seeds : int ) -> None : \"\"\" Run the simulations for misalignment errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for. n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's `rms_betabeatings` and `standard_deviations` attributes. \"\"\" with timeit ( lambda spanned : logger . info ( f \"Simulated misalignment errors in: { spanned : .4f } seconds\" ) ): for error in error_values : logger . debug ( f \"Running for Longitudinal Misalignment Error: { float ( error ) } mm\" ) temp_data = ( BetaBeatValues () ) # this will hold the beta-beats for all seeds with this error value. for _ in track ( range ( n_seeds ), description = \"Simulating Misalignment Seeds\" , transient = True ): # Getting beta-beatings & appending to temporary BetaBeatValues mserrors_twiss : pd . DataFrame = self . _track_miss_error ( error ) betabeatings : pd . DataFrame = _get_betabeatings ( self . nominal_twiss , mserrors_twiss ) temp_data . update_miss_from_cpymad ( betabeatings ) # Append computed seeds' RMS for this error value in `rms_betabeatings` attribute. self . rms_betabeatings . update_miss_from_seeds ( temp_data ) # Getting stdev of all values for the N computed seeds self . standard_deviations . update_miss ( temp_data ) # Getting the lost seeds if any self . lost_seeds_miss . append ( n_seeds - len ( temp_data . misserror_bbx )) def _track_miss_error ( self , error : float ) -> pd . DataFrame : \"\"\" Run misserror tracking for a given seed, which is randomly assigned at function call. Args: error (float): the error value to input in the madx script. Returns: The twiss dframe from cpymad. \"\"\" seed = str ( np . random . randint ( 1e6 , 5e6 )) mserror_script = LatticeGenerator . generate_tripleterrors_study_mserror_job ( seed , str ( error )) self . errors_mad . input ( mserror_script ) return self . errors_mad . table . twiss . dframe () def _get_betabeatings ( nominal_twiss : pd . DataFrame , errors_twiss : pd . DataFrame ) -> pd . DataFrame : \"\"\" Simple function to get beta-beatings from a `cpymad.madx.Madx`'s Twiss output. Args: nominal_twiss (pd.DataFrame): a twiss.dframe() results from a reference scenario. errors_twiss (pd.DataFrame): a twiss.dframe() results from the perturbed scenario. Returns: A `pd.DataFrame` with the beta-beat values, in percentage. \"\"\" betabeat = pd . DataFrame () betabeat [ \"NAME\" ] = nominal_twiss . name betabeat [ \"s\" ] = nominal_twiss . s betabeat [ \"BETX\" ] = 100 * ( errors_twiss . betx - nominal_twiss . betx ) / nominal_twiss . betx betabeat [ \"BETY\" ] = 100 * ( errors_twiss . bety - nominal_twiss . bety ) / nominal_twiss . bety return betabeat def _parse_arguments () -> argparse . Namespace : \"\"\" Simple argument parser to make life easier in the command-line. Returns a NameSpace with arguments as attributes. \"\"\" parser = argparse . ArgumentParser ( description = \"Running the beta-beating script.\" ) parser . add_argument ( \"-e\" , \"--errors\" , dest = \"errors\" , nargs = \"+\" , default = [ 1 , 3 , 5 ], type = int , help = \"Error values to simulate\" , ) parser . add_argument ( \"-s\" , \"--seeds\" , dest = \"seeds\" , default = 50 , type = int , help = \"Number of seeds to simulate per error.\" , ) parser . add_argument ( \"-p\" , \"--plotbetas\" , dest = \"plotbetas\" , default = False , help = \"Option for plotting betas at each error.\" , ) parser . add_argument ( \"-l\" , \"--logs\" , dest = \"log_level\" , default = \"info\" , type = str , help = \"The base console logging level. Can be 'debug', 'info', 'warning' and 'error'.\" \"Defaults to 'info'.\" , ) return parser . parse_args () def _set_logger_level ( log_level : str = \"info\" ) -> None : \"\"\" Sets the logger level to the one provided at the commandline. Default loguru handler will have DEBUG level and ID 0. We need to first remove this default handler and add ours with the wanted level. Args: log_level (str): string, the default logging level to print out. \"\"\" logger . remove ( 0 ) logger . add ( sys . stderr , format = LOGURU_FORMAT , level = log_level . upper ()) @logger . catch def main () -> None : \"\"\" Run the whole process. Will prompt for error grid values for confirmation. Instantiates a GridCompute object and runs for each type of errors. The results are stored in the class itself, to be accessed for plotting. \"\"\" command_line_args = _parse_arguments () _set_logger_level ( command_line_args . log_level ) simulations = GridCompute () logger . info ( f \"Here are the error values that will be ran: { command_line_args . errors } \" ) # Running simulations simulations . run_tf_errors ( command_line_args . errors , command_line_args . seeds ) simulations . run_miss_errors ( command_line_args . errors , command_line_args . seeds ) # Getting the results in dataframes and exporting to csv logger . info ( \"Exporting results to csv\" ) bbing_df : pd . DataFrame = simulations . rms_betabeatings . to_pandas () std_df : pd . DataFrame = simulations . standard_deviations . to_pandas () bbing_df . to_csv ( \"beta_beatings.csv\" , index = False ) std_df . to_csv ( \"standard_deviations.csv\" , index = False ) # Plotting the results plot_bbing_max_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Horizontal\" , figname = \"miss_vs_tf_max_hor.png\" , ) plot_bbing_max_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Vertical\" , figname = \"miss_vs_tf_max_ver.png\" , ) plot_bbing_with_ips_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Horizontal\" , figname = \"miss_vs_tf_ips_hor.png\" , ) plot_bbing_with_ips_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Vertical\" , figname = \"miss_vs_tf_ips_ver.png\" , ) if __name__ == \"__main__\" : main ()","title":"Script scripts.triplets_errors.algo"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/algo/#variables","text":"LOGURU_FORMAT","title":"Variables"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/algo/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/algo/#main","text":"def main ( ) -> None Run the whole process. Will prompt for error grid values for confirmation. Instantiates a GridCompute object and runs for each type of errors. The results are stored in the class itself, to be accessed for plotting. View Source @ logger . catch def main () -> None : \"\"\" Run the whole process. Will prompt for error grid values for confirmation. Instantiates a GridCompute object and runs for each type of errors. The results are stored in the class itself, to be accessed for plotting. \"\"\" command_line_args = _parse_arguments () _set_logger_level ( command_line_args . log_level ) simulations = GridCompute () logger . info ( f \"Here are the error values that will be ran: {command_line_args.errors}\" ) # Running simulations simulations . run_tf_errors ( command_line_args . errors , command_line_args . seeds ) simulations . run_miss_errors ( command_line_args . errors , command_line_args . seeds ) # Getting the results in dataframes and exporting to csv logger . info ( \"Exporting results to csv\" ) bbing_df : pd . DataFrame = simulations . rms_betabeatings . to_pandas () std_df : pd . DataFrame = simulations . standard_deviations . to_pandas () bbing_df . to_csv ( \"beta_beatings.csv\" , index = False ) std_df . to_csv ( \"standard_deviations.csv\" , index = False ) # Plotting the results plot_bbing_max_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Horizontal\" , figname = \"miss_vs_tf_max_hor.png\" , ) plot_bbing_max_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Vertical\" , figname = \"miss_vs_tf_max_ver.png\" , ) plot_bbing_with_ips_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Horizontal\" , figname = \"miss_vs_tf_ips_hor.png\" , ) plot_bbing_with_ips_errorbar ( command_line_args . errors , beta_beatings_df = bbing_df , stdev_df = std_df , plane = \"Vertical\" , figname = \"miss_vs_tf_ips_ver.png\" , )","title":"main"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/algo/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/algo/#gridcompute","text":"class GridCompute ( ) Algorithm as a class to run the simulations and analyze the outputs. Will prompt error values for confirmation, run MAD-X simulations through a cpymad.madx.Madx object, get beta-beating values from the outputs and return the appropriate structures. View Source class GridCompute : \" \"\" Algorithm as a class to run the simulations and analyze the outputs. Will prompt error values for confirmation, run MAD-X simulations through a `cpymad.madx.Madx` object, get beta-beating values from the outputs and return the appropriate structures. \"\" \" __slots__ = { \"reference_mad\" : \"cpymad Madx object to run the nominal configuration\" , \"errors_mad\" : \"cpymad Madx object to run errored simulations\" , \"rms_betabeatings\" : \"BetaBeatValues class to hold rms beta-beatings from simulations\" , \"standard_deviations\" : \"StdevValues class to hold standard deviations from simulations\" , \"lost_seeds_tf\" : \"List of field error values leading to loss of closed orbit\" , \"lost_seeds_miss\" : \"List of misalignment values leading to loss of closed orbit\" , \"nominal_twiss\" : \"Twiss dataframe from the nominal simulation\" , } def __init__ ( self ) -> None : \" \"\" Initializing will take some time since the reference script is being ran, to store the reference dframe. Unless you go into PTC it should be a matter of seconds. \"\" \" self . reference_mad = cpymad . madx . Madx ( stdout = False ) self . errors_mad = cpymad . madx . Madx ( stdout = False ) self . rms_betabeatings = BetaBeatValues () self . standard_deviations = StdevValues () self . lost_seeds_tf : List [ int ] = [] self . lost_seeds_miss : List [ int ] = [] self . nominal_twiss = self . _get_nominal_twiss () def _get_nominal_twiss ( self ) -> pd . DataFrame : \" \"\" Run a MAD-X simulation without errors, and extract the nominal Twiss from the results. This will be stored in the `nominal_twiss` instance attribute. Returns: Nothing, directly updates the instance's `nominal_twiss` attribute inplace. \"\" \" logger . info ( \"Running simulation for reference nominal run\" ) ref_script = LatticeGenerator . generate_tripleterrors_study_reference () self . reference_mad . input ( ref_script ) logger . debug ( \"Extracting reference Twiss dframe from cpymad\" ) return deepcopy ( self . reference_mad . table . twiss . dframe ()) def run_tf_errors ( self , error_values : List [ float ] , n_seeds : int ) -> None : \" \"\" Run simulations for field errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's `rms_betabeatings` and `standard_deviations` attributes. \"\" \" with timeit ( lambda spanned : logger . info ( f \"Simulated field errors in: {spanned:.4f} seconds\" ) ) : for error in error_values : logger . debug ( f \"Running simulation for Relative Field Error: {error}E-4\" ) temp_data = BetaBeatValues () for _ in track ( range ( n_seeds ), description = \"Simulating Field Errors Seeds\" , transient = True ) : # Getting beta-beatings & appending to temporary BetaBeatValues tferrors_twiss : pd . DataFrame = self . _track_tf_error ( error ) betabeatings : pd . DataFrame = _get_betabeatings ( self . nominal_twiss , tferrors_twiss ) temp_data . update_tf_from_cpymad ( betabeatings ) # Append computed seeds' RMS for this error value in `rms_betabeatings` attribute. self . rms_betabeatings . update_tf_from_seeds ( temp_data ) # Getting stdev of all values for the N computed seeds self . standard_deviations . update_tf ( temp_data ) # Getting the lost seeds if any self . lost_seeds_tf . append ( n_seeds - len ( temp_data . tferror_bbx )) def _track_tf_error ( self , error : float ) -> pd . DataFrame : \" \"\" Run tferror tracking for a given seed, which is randomly assigned at function call. Args: error (float): the error value to input in the madx script. Returns: The twiss dframe from cpymad. \"\" \" seed = str ( np . random . randint ( 1e6 , 5e6 )) tferror_script = LatticeGenerator . generate_tripleterrors_study_tferror_job ( seed , str ( error )) self . errors_mad . input ( tferror_script ) return self . errors_mad . table . twiss . dframe () def run_miss_errors ( self , error_values : List [ float ] , n_seeds : int ) -> None : \" \"\" Run the simulations for misalignment errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for. n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's `rms_betabeatings` and `standard_deviations` attributes. \"\" \" with timeit ( lambda spanned : logger . info ( f \"Simulated misalignment errors in: {spanned:.4f} seconds\" ) ) : for error in error_values : logger . debug ( f \"Running for Longitudinal Misalignment Error: {float(error)}mm\" ) temp_data = ( BetaBeatValues () ) # this will hold the beta-beats for all seeds with this error value. for _ in track ( range ( n_seeds ), description = \"Simulating Misalignment Seeds\" , transient = True ) : # Getting beta-beatings & appending to temporary BetaBeatValues mserrors_twiss : pd . DataFrame = self . _track_miss_error ( error ) betabeatings : pd . DataFrame = _get_betabeatings ( self . nominal_twiss , mserrors_twiss ) temp_data . update_miss_from_cpymad ( betabeatings ) # Append computed seeds' RMS for this error value in `rms_betabeatings` attribute. self . rms_betabeatings . update_miss_from_seeds ( temp_data ) # Getting stdev of all values for the N computed seeds self . standard_deviations . update_miss ( temp_data ) # Getting the lost seeds if any self . lost_seeds_miss . append ( n_seeds - len ( temp_data . misserror_bbx )) def _track_miss_error ( self , error : float ) -> pd . DataFrame : \" \"\" Run misserror tracking for a given seed, which is randomly assigned at function call. Args: error (float): the error value to input in the madx script. Returns: The twiss dframe from cpymad. \"\" \" seed = str ( np . random . randint ( 1e6 , 5e6 )) mserror_script = LatticeGenerator . generate_tripleterrors_study_mserror_job ( seed , str ( error )) self . errors_mad . input ( mserror_script ) return self . errors_mad . table . twiss . dframe ()","title":"GridCompute"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/algo/#instance-variables","text":"errors_mad lost_seeds_miss lost_seeds_tf nominal_twiss reference_mad rms_betabeatings standard_deviations","title":"Instance variables"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/algo/#methods","text":"","title":"Methods"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/algo/#run_miss_errors","text":"def run_miss_errors ( self , error_values : List [ float ], n_seeds : int ) -> None Run the simulations for misalignment errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for. n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's rms_betabeatings and standard_deviations attributes. View Source def run_miss_errors ( self , error_values : List [ float ] , n_seeds : int ) -> None : \" \"\" Run the simulations for misalignment errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for. n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's `rms_betabeatings` and `standard_deviations` attributes. \"\" \" with timeit ( lambda spanned : logger . info ( f \"Simulated misalignment errors in: {spanned:.4f} seconds\" ) ) : for error in error_values : logger . debug ( f \"Running for Longitudinal Misalignment Error: {float(error)}mm\" ) temp_data = ( BetaBeatValues () ) # this will hold the beta-beats for all seeds with this error value. for _ in track ( range ( n_seeds ), description = \"Simulating Misalignment Seeds\" , transient = True ) : # Getting beta-beatings & appending to temporary BetaBeatValues mserrors_twiss : pd . DataFrame = self . _track_miss_error ( error ) betabeatings : pd . DataFrame = _get_betabeatings ( self . nominal_twiss , mserrors_twiss ) temp_data . update_miss_from_cpymad ( betabeatings ) # Append computed seeds' RMS for this error value in `rms_betabeatings` attribute. self . rms_betabeatings . update_miss_from_seeds ( temp_data ) # Getting stdev of all values for the N computed seeds self . standard_deviations . update_miss ( temp_data ) # Getting the lost seeds if any self . lost_seeds_miss . append ( n_seeds - len ( temp_data . misserror_bbx ))","title":"run_miss_errors"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/algo/#run_tf_errors","text":"def run_tf_errors ( self , error_values : List [ float ], n_seeds : int ) -> None Run simulations for field errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's rms_betabeatings and standard_deviations attributes. View Source def run_tf_errors ( self , error_values : List [ float ] , n_seeds : int ) -> None : \" \"\" Run simulations for field errors, compute the values from the outputs, and store the final results in the class's data structures. Args: error_values (List[float]): the different error values to run simulations for n_seeds (int): number of simulations to run for each error values. Returns: Nothing, directly updates the instance's `rms_betabeatings` and `standard_deviations` attributes. \"\" \" with timeit ( lambda spanned : logger . info ( f \"Simulated field errors in: {spanned:.4f} seconds\" ) ) : for error in error_values : logger . debug ( f \"Running simulation for Relative Field Error: {error}E-4\" ) temp_data = BetaBeatValues () for _ in track ( range ( n_seeds ), description = \"Simulating Field Errors Seeds\" , transient = True ) : # Getting beta-beatings & appending to temporary BetaBeatValues tferrors_twiss : pd . DataFrame = self . _track_tf_error ( error ) betabeatings : pd . DataFrame = _get_betabeatings ( self . nominal_twiss , tferrors_twiss ) temp_data . update_tf_from_cpymad ( betabeatings ) # Append computed seeds' RMS for this error value in `rms_betabeatings` attribute. self . rms_betabeatings . update_tf_from_seeds ( temp_data ) # Getting stdev of all values for the N computed seeds self . standard_deviations . update_tf ( temp_data ) # Getting the lost seeds if any self . lost_seeds_tf . append ( n_seeds - len ( temp_data . tferror_bbx ))","title":"run_tf_errors"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/","text":"Module pyhdtoolkit.scripts.triplet_errors.data_classes Module scripts.triplet_errors.data_classes Created on 2019.06.15 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A few classes that will be useful to store values calculated from the results of the GridCompute Algorithm. View Source \"\"\" Module scripts.triplet_errors.data_classes ------------------------------------------ Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A few classes that will be useful to store values calculated from the results of the GridCompute Algorithm. \"\"\" from typing import List import numpy as np import pandas as pd from loguru import logger from pydantic import BaseModel class BetaBeatValues ( BaseModel ): \"\"\" Simple class to store and transfer beta-beating values. Class attributes are as follows: \"tferror_bbx\": \"Horizontal beta-beating values from field errors\", \"tferror_bby\": \"Vertical beta-beating values from field errors\", \"ip1_tferror_bbx\": \"Horizontal beta-beating values from field errors at IP1\", \"ip1_tferror_bby\": \"Vertical beta-beating values from field errors at IP1\", \"ip5_tferror_bbx\": \"Horizontal beta-beating values from field errors at IP5\", \"ip5_tferror_bby\": \"Vertical beta-beating values from field errors at IP5\", \"max_tferror_bbx\": \"Maximal horizontal beta-beating values from field errors\", \"max_tferror_bby\": \"Maximal vertical beta-beating values from field errors\", \"misserror_bbx\": \"Horizontal beta-beating values from misalignment errors\", \"misserror_bby\": \"Horizontal beta-beating values from misalignment errors\", \"ip1_misserror_bbx\": \"Horizontal beta-beating values from misalignment errors at IP1\", \"ip1_misserror_bby\": \"Vertical beta-beating values from misalignment errors at IP1\", \"ip5_misserror_bbx\": \"Horizontal beta-beating values from misalignment errors at IP5\", \"ip5_misserror_bby\": \"Vertical beta-beating values from misalignment errors at IP5\", \"max_misserror_bbx\": \"Maximal horizontal beta-beating values from misalignment errors\", \"max_misserror_bby\": \"Maximal vertical beta-beating values from misalignment errors\", \"\"\" tferror_bbx : List [ float ] = [] tferror_bby : List [ float ] = [] ip1_tferror_bbx : List [ float ] = [] ip1_tferror_bby : List [ float ] = [] ip5_tferror_bbx : List [ float ] = [] ip5_tferror_bby : List [ float ] = [] max_tferror_bbx : List [ float ] = [] max_tferror_bby : List [ float ] = [] misserror_bbx : List [ float ] = [] misserror_bby : List [ float ] = [] ip1_misserror_bbx : List [ float ] = [] ip1_misserror_bby : List [ float ] = [] ip5_misserror_bbx : List [ float ] = [] ip5_misserror_bby : List [ float ] = [] max_misserror_bbx : List [ float ] = [] max_misserror_bby : List [ float ] = [] def describe ( self ) -> None : \"\"\" Simple print statement of instance attributes. \"\"\" for attribute , value in self . dict () . items (): print ( f \" { attribute : <20 } { value } \" ) def update_tf_from_cpymad ( self , cpymad_betabeatings : pd . DataFrame ) -> None : \"\"\" This is to update a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. \"\"\" logger . trace ( \"Getting rms and max values for betatron functions of provided run\" ) self . tferror_bbx . append ( _get_rms ( cpymad_betabeatings [ \"BETX\" ])) self . tferror_bby . append ( _get_rms ( cpymad_betabeatings [ \"BETY\" ])) self . max_tferror_bbx . append ( cpymad_betabeatings [ \"BETX\" ] . max ()) self . max_tferror_bby . append ( cpymad_betabeatings [ \"BETY\" ] . max ()) logger . trace ( \"Getting betatron functions at IP1 and IP5\" ) # cpymad naming: lowercase and appended with :beam_number self . ip1_tferror_bbx . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip1_tferror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip5_tferror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] ) self . ip5_tferror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] ) def update_tf_from_seeds ( self , temp_data ) -> None : \"\"\" Updates the error's beta-beatings values after having ran simulations for all seeds. Append computed rms values for a group of seeds, to field errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. \"\"\" self . tferror_bbx . append ( _get_rms ( temp_data . tferror_bbx )) self . tferror_bby . append ( _get_rms ( temp_data . tferror_bby )) self . max_tferror_bbx . append ( _get_rms ( temp_data . max_tferror_bbx )) self . max_tferror_bby . append ( _get_rms ( temp_data . max_tferror_bby )) self . ip1_tferror_bbx . append ( _get_rms ( temp_data . ip1_tferror_bbx )) self . ip1_tferror_bby . append ( _get_rms ( temp_data . ip1_tferror_bby )) self . ip5_tferror_bbx . append ( _get_rms ( temp_data . ip5_tferror_bbx )) self . ip5_tferror_bby . append ( _get_rms ( temp_data . ip5_tferror_bby )) def update_miss_from_cpymad ( self , cpymad_betabeatings : pd . DataFrame ) -> None : \"\"\" Updates a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. \"\"\" logger . trace ( \"Getting rms and max values for betatron functions of provided run\" ) self . misserror_bbx . append ( _get_rms ( cpymad_betabeatings [ \"BETX\" ])) self . misserror_bby . append ( _get_rms ( cpymad_betabeatings [ \"BETY\" ])) self . max_misserror_bbx . append ( cpymad_betabeatings [ \"BETX\" ] . max ()) self . max_misserror_bby . append ( cpymad_betabeatings [ \"BETY\" ] . max ()) logger . trace ( \"Getting betatron functions at IP1 and IP5\" ) # cpymad naming: lowercase and appended with :beam_number self . ip1_misserror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip1_misserror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip5_misserror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] ) self . ip5_misserror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] ) def update_miss_from_seeds ( self , temp_data ) -> None : \"\"\" Append computed rms values for a group of seeds, to misalignment result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. \"\"\" self . misserror_bbx . append ( _get_rms ( temp_data . misserror_bbx )) self . misserror_bby . append ( _get_rms ( temp_data . misserror_bby )) self . max_misserror_bbx . append ( _get_rms ( temp_data . max_misserror_bbx )) self . max_misserror_bby . append ( _get_rms ( temp_data . max_misserror_bby )) self . ip1_misserror_bbx . append ( _get_rms ( temp_data . ip1_misserror_bbx )) self . ip1_misserror_bby . append ( _get_rms ( temp_data . ip1_misserror_bby )) self . ip5_misserror_bbx . append ( _get_rms ( temp_data . ip5_misserror_bbx )) self . ip5_misserror_bby . append ( _get_rms ( temp_data . ip5_misserror_bby )) def to_pandas ( self , * args , ** kwargs ) -> pd . DataFrame : \"\"\" Exports stored values as a pandas DataFrame. Returns: A `pandas.DataFrame` object with the instance's attributes as columns. \"\"\" return pd . DataFrame ( self . dict ( * args , ** kwargs )) class StdevValues ( BaseModel ): \"\"\" Simple class to store and transfer standard deviation values. Class attributes are as follows: \"stdev_tf_x\": \"Horizontal standard deviation values from field errors\", \"stdev_tf_y\": \"Vertical standard deviation values from field errors\", \"ip1_stdev_tf_x\": \"Horizontal standard deviation values from field errors at IP1\", \"ip1_stdev_tf_y\": \"Vertical standard deviation values from field errors at IP1\", \"ip5_stdev_tf_x\": \"Horizontal standard deviation values from field errors at IP5\", \"ip5_stdev_tf_y\": \"Vertical standard deviation values from field errors at IP5\", \"max_stdev_tf_x\": \"Maximal horizontal standard deviation values from field errors\", \"max_stdev_tf_y\": \"Maximal vertical standard deviation values from field errors\", \"stdev_miss_x\": \"Horizontal standard deviation values from misalignment errors\", \"stdev_miss_y\": \"Horizontal standard deviation values from misalignment errors\", \"ip1_stdev_miss_x\": \"Horizontal standard deviation values from misalignment errors at IP1\", \"ip1_stdev_miss_y\": \"Vertical standard deviation values from misalignment errors at IP1\", \"ip5_stdev_miss_x\": \"Horizontal standard deviation values from misalignment errors at IP5\", \"ip5_stdev_miss_y\": \"Vertical standard deviation values from misalignment errors at IP5\", \"max_stdev_miss_x\": \"Maximal horizontal standard deviation values from misalignment errors\", \"max_stdev_miss_y\": \"Maximal vertical standard deviation values from misalignment errors\", \"\"\" stdev_tf_x : List [ float ] = [] stdev_tf_y : List [ float ] = [] ip1_stdev_tf_x : List [ float ] = [] ip1_stdev_tf_y : List [ float ] = [] ip5_stdev_tf_x : List [ float ] = [] ip5_stdev_tf_y : List [ float ] = [] max_stdev_tf_x : List [ float ] = [] max_stdev_tf_y : List [ float ] = [] stdev_miss_x : List [ float ] = [] stdev_miss_y : List [ float ] = [] ip1_stdev_miss_x : List [ float ] = [] ip1_stdev_miss_y : List [ float ] = [] ip5_stdev_miss_x : List [ float ] = [] ip5_stdev_miss_y : List [ float ] = [] max_stdev_miss_x : List [ float ] = [] max_stdev_miss_y : List [ float ] = [] def describe ( self ) -> None : \"\"\" Simple print statement of instance attributes. \"\"\" for attribute , value in self . dict () . items (): print ( f \" { attribute : <20 } { value } \" ) def update_tf ( self , temp_data ) -> None : \"\"\" Append computed stdev values for a group of seeds, to field errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. Returns: Nothing, updates inplace. \"\"\" self . stdev_tf_x . append ( np . std ( temp_data . tferror_bbx )) self . stdev_tf_y . append ( np . std ( temp_data . tferror_bby )) self . max_stdev_tf_x . append ( np . std ( temp_data . max_tferror_bbx )) self . max_stdev_tf_y . append ( np . std ( temp_data . max_tferror_bby )) self . ip1_stdev_tf_x . append ( np . std ( temp_data . ip1_tferror_bbx )) self . ip1_stdev_tf_y . append ( np . std ( temp_data . ip1_tferror_bby )) self . ip5_stdev_tf_x . append ( np . std ( temp_data . ip5_tferror_bbx )) self . ip5_stdev_tf_y . append ( np . std ( temp_data . ip5_tferror_bby )) def update_miss ( self , temp_data ) -> None : \"\"\" Append computed rms values for a group of seeds, to misalignment errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. Returns: Nothing, updates inplace. \"\"\" self . stdev_miss_x . append ( np . std ( temp_data . misserror_bbx )) self . stdev_miss_y . append ( np . std ( temp_data . misserror_bby )) self . max_stdev_miss_x . append ( np . std ( temp_data . max_misserror_bbx )) self . max_stdev_miss_y . append ( np . std ( temp_data . max_misserror_bby )) self . ip1_stdev_miss_x . append ( np . std ( temp_data . ip1_misserror_bbx )) self . ip1_stdev_miss_y . append ( np . std ( temp_data . ip1_misserror_bby )) self . ip5_stdev_miss_x . append ( np . std ( temp_data . ip5_misserror_bbx )) self . ip5_stdev_miss_y . append ( np . std ( temp_data . ip5_misserror_bby )) def to_pandas ( self , * args , ** kwargs ) -> pd . DataFrame : \"\"\" Simple function to export stored values as a pandas dataframe. Returns: A `pandas.DataFrame` object with the instance's attributes as columns. \"\"\" return pd . DataFrame ( self . dict ( * args , ** kwargs )) def _get_rms ( values_list : List [ float ]) -> float : \"\"\" Get the root mean square of a list of values. Args: values_list (List[float]): a distribution of values. Returns: The root mean square of said distribution. \"\"\" try : return np . sqrt ( np . sum ( i ** 2 for i in values_list ) / len ( values_list )) except ZeroDivisionError as issue : logger . exception ( \"An empty list was provided, check the simulation logs to understand why.\" ) raise ZeroDivisionError ( \"No values were provided\" ) from issue Classes BetaBeatValues class BetaBeatValues ( __pydantic_self__ , ** data : Any ) Simple class to store and transfer beta-beating values. Class attributes are as follows: \"tferror_bbx\": \"Horizontal beta-beating values from field errors\", \"tferror_bby\": \"Vertical beta-beating values from field errors\", \"ip1_tferror_bbx\": \"Horizontal beta-beating values from field errors at IP1\", \"ip1_tferror_bby\": \"Vertical beta-beating values from field errors at IP1\", \"ip5_tferror_bbx\": \"Horizontal beta-beating values from field errors at IP5\", \"ip5_tferror_bby\": \"Vertical beta-beating values from field errors at IP5\", \"max_tferror_bbx\": \"Maximal horizontal beta-beating values from field errors\", \"max_tferror_bby\": \"Maximal vertical beta-beating values from field errors\", \"misserror_bbx\": \"Horizontal beta-beating values from misalignment errors\", \"misserror_bby\": \"Horizontal beta-beating values from misalignment errors\", \"ip1_misserror_bbx\": \"Horizontal beta-beating values from misalignment errors at IP1\", \"ip1_misserror_bby\": \"Vertical beta-beating values from misalignment errors at IP1\", \"ip5_misserror_bbx\": \"Horizontal beta-beating values from misalignment errors at IP5\", \"ip5_misserror_bby\": \"Vertical beta-beating values from misalignment errors at IP5\", \"max_misserror_bbx\": \"Maximal horizontal beta-beating values from misalignment errors\", \"max_misserror_bby\": \"Maximal vertical beta-beating values from misalignment errors\", View Source class BetaBeatValues ( BaseModel ) : \"\"\" Simple class to store and transfer beta-beating values. Class attributes are as follows: \" tferror_bbx \": \" Horizontal beta - beating values from field errors \", \" tferror_bby \": \" Vertical beta - beating values from field errors \", \" ip1_tferror_bbx \": \" Horizontal beta - beating values from field errors at IP1 \", \" ip1_tferror_bby \": \" Vertical beta - beating values from field errors at IP1 \", \" ip5_tferror_bbx \": \" Horizontal beta - beating values from field errors at IP5 \", \" ip5_tferror_bby \": \" Vertical beta - beating values from field errors at IP5 \", \" max_tferror_bbx \": \" Maximal horizontal beta - beating values from field errors \", \" max_tferror_bby \": \" Maximal vertical beta - beating values from field errors \", \" misserror_bbx \": \" Horizontal beta - beating values from misalignment errors \", \" misserror_bby \": \" Horizontal beta - beating values from misalignment errors \", \" ip1_misserror_bbx \": \" Horizontal beta - beating values from misalignment errors at IP1 \", \" ip1_misserror_bby \": \" Vertical beta - beating values from misalignment errors at IP1 \", \" ip5_misserror_bbx \": \" Horizontal beta - beating values from misalignment errors at IP5 \", \" ip5_misserror_bby \": \" Vertical beta - beating values from misalignment errors at IP5 \", \" max_misserror_bbx \": \" Maximal horizontal beta - beating values from misalignment errors \", \" max_misserror_bby \": \" Maximal vertical beta - beating values from misalignment errors \", \"\"\" tferror_bbx : List [ float ] = [] tferror_bby : List [ float ] = [] ip1_tferror_bbx : List [ float ] = [] ip1_tferror_bby : List [ float ] = [] ip5_tferror_bbx : List [ float ] = [] ip5_tferror_bby : List [ float ] = [] max_tferror_bbx : List [ float ] = [] max_tferror_bby : List [ float ] = [] misserror_bbx : List [ float ] = [] misserror_bby : List [ float ] = [] ip1_misserror_bbx : List [ float ] = [] ip1_misserror_bby : List [ float ] = [] ip5_misserror_bbx : List [ float ] = [] ip5_misserror_bby : List [ float ] = [] max_misserror_bbx : List [ float ] = [] max_misserror_bby : List [ float ] = [] def describe ( self ) -> None : \"\"\" Simple print statement of instance attributes. \"\"\" for attribute , value in self . dict (). items () : print ( f \"{attribute:<20} {value}\" ) def update_tf_from_cpymad ( self , cpymad_betabeatings : pd . DataFrame ) -> None : \"\"\" This is to update a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. \"\"\" logger . trace ( \"Getting rms and max values for betatron functions of provided run\" ) self . tferror_bbx . append ( _get_rms ( cpymad_betabeatings [ \"BETX\" ] )) self . tferror_bby . append ( _get_rms ( cpymad_betabeatings [ \"BETY\" ] )) self . max_tferror_bbx . append ( cpymad_betabeatings [ \"BETX\" ] . max ()) self . max_tferror_bby . append ( cpymad_betabeatings [ \"BETY\" ] . max ()) logger . trace ( \"Getting betatron functions at IP1 and IP5\" ) # cpymad naming : lowercase and appended with : beam_number self . ip1_tferror_bbx . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings.NAME == \"ip1:1\" ][ 0 ] ) self . ip1_tferror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings.NAME == \"ip1:1\" ][ 0 ] ) self . ip5_tferror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings.NAME == \"ip5:1\" ][ 0 ] ) self . ip5_tferror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings.NAME == \"ip5:1\" ][ 0 ] ) def update_tf_from_seeds ( self , temp_data ) -> None : \"\"\" Updates the error's beta-beatings values after having ran simulations for all seeds. Append computed rms values for a group of seeds, to field errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. \"\"\" self . tferror_bbx . append ( _get_rms ( temp_data . tferror_bbx )) self . tferror_bby . append ( _get_rms ( temp_data . tferror_bby )) self . max_tferror_bbx . append ( _get_rms ( temp_data . max_tferror_bbx )) self . max_tferror_bby . append ( _get_rms ( temp_data . max_tferror_bby )) self . ip1_tferror_bbx . append ( _get_rms ( temp_data . ip1_tferror_bbx )) self . ip1_tferror_bby . append ( _get_rms ( temp_data . ip1_tferror_bby )) self . ip5_tferror_bbx . append ( _get_rms ( temp_data . ip5_tferror_bbx )) self . ip5_tferror_bby . append ( _get_rms ( temp_data . ip5_tferror_bby )) def update_miss_from_cpymad ( self , cpymad_betabeatings : pd . DataFrame ) -> None : \"\"\" Updates a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. \"\"\" logger . trace ( \"Getting rms and max values for betatron functions of provided run\" ) self . misserror_bbx . append ( _get_rms ( cpymad_betabeatings [ \"BETX\" ] )) self . misserror_bby . append ( _get_rms ( cpymad_betabeatings [ \"BETY\" ] )) self . max_misserror_bbx . append ( cpymad_betabeatings [ \"BETX\" ] . max ()) self . max_misserror_bby . append ( cpymad_betabeatings [ \"BETY\" ] . max ()) logger . trace ( \"Getting betatron functions at IP1 and IP5\" ) # cpymad naming : lowercase and appended with : beam_number self . ip1_misserror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings.NAME == \"ip1:1\" ][ 0 ] ) self . ip1_misserror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings.NAME == \"ip1:1\" ][ 0 ] ) self . ip5_misserror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings.NAME == \"ip5:1\" ][ 0 ] ) self . ip5_misserror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings.NAME == \"ip5:1\" ][ 0 ] ) def update_miss_from_seeds ( self , temp_data ) -> None : \"\"\" Append computed rms values for a group of seeds, to misalignment result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. \"\"\" self . misserror_bbx . append ( _get_rms ( temp_data . misserror_bbx )) self . misserror_bby . append ( _get_rms ( temp_data . misserror_bby )) self . max_misserror_bbx . append ( _get_rms ( temp_data . max_misserror_bbx )) self . max_misserror_bby . append ( _get_rms ( temp_data . max_misserror_bby )) self . ip1_misserror_bbx . append ( _get_rms ( temp_data . ip1_misserror_bbx )) self . ip1_misserror_bby . append ( _get_rms ( temp_data . ip1_misserror_bby )) self . ip5_misserror_bbx . append ( _get_rms ( temp_data . ip5_misserror_bbx )) self . ip5_misserror_bby . append ( _get_rms ( temp_data . ip5_misserror_bby )) def to_pandas ( self , * args , ** kwargs ) -> pd . DataFrame : \"\"\" Exports stored values as a pandas DataFrame. Returns: A `pandas.DataFrame` object with the instance's attributes as columns. \"\"\" return pd . DataFrame ( self . dict ( * args , ** kwargs )) Ancestors (in MRO) pydantic.main.BaseModel pydantic.utils.Representation Class variables Config Static methods construct def construct ( _fields_set : Union [ ForwardRef ( 'SetStr' ), NoneType ] = None , ** values : Any ) -> 'Model' Creates a new model setting dict and fields_set from trusted or pre-validated data. Default values are respected, but no other validation is performed. from_orm def from_orm ( obj : Any ) -> 'Model' parse_file def parse_file ( path : Union [ str , pathlib . Path ], * , content_type : 'unicode' = None , encoding : 'unicode' = 'utf8' , proto : pydantic . parse . Protocol = None , allow_pickle : bool = False ) -> 'Model' parse_obj def parse_obj ( obj : Any ) -> 'Model' parse_raw def parse_raw ( b : Union [ str , bytes ], * , content_type : 'unicode' = None , encoding : 'unicode' = 'utf8' , proto : pydantic . parse . Protocol = None , allow_pickle : bool = False ) -> 'Model' schema def schema ( by_alias : bool = True , ref_template : 'unicode' = '#/definitions/ {model} ' ) -> 'DictStrAny' schema_json def schema_json ( * , by_alias : bool = True , ref_template : 'unicode' = '#/definitions/ {model} ' , ** dumps_kwargs : Any ) -> 'unicode' update_forward_refs def update_forward_refs ( ** localns : Any ) -> None Try to update ForwardRefs on fields based on this Model, globalns and localns. validate def validate ( value : Any ) -> 'Model' Instance variables fields Methods copy def copy ( self : 'Model' , * , include : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , exclude : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , update : 'DictStrAny' = None , deep : bool = False ) -> 'Model' Duplicate a model, optionally choose which fields to include, exclude and change. :param include: fields to include in new model :param exclude: fields to exclude from new model, as with values this takes precedence over include :param update: values to change/add in the new model. Note: the data is not validated before creating the new model: you should trust this data :param deep: set to True to make a deep copy of the model :return: new model instance describe def describe ( self ) -> None Simple print statement of instance attributes. View Source def describe ( self ) -> None : \"\"\" Simple print statement of instance attributes. \"\"\" for attribute , value in self . dict (). items (): print ( f \"{attribute:<20} {value}\" ) dict def dict ( self , * , include : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , exclude : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , by_alias : bool = False , skip_defaults : bool = None , exclude_unset : bool = False , exclude_defaults : bool = False , exclude_none : bool = False ) -> 'DictStrAny' Generate a dictionary representation of the model, optionally specifying which fields to include or exclude. json def json ( self , * , include : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , exclude : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , by_alias : bool = False , skip_defaults : bool = None , exclude_unset : bool = False , exclude_defaults : bool = False , exclude_none : bool = False , encoder : Union [ Callable [[ Any ], Any ], NoneType ] = None , ** dumps_kwargs : Any ) -> 'unicode' Generate a JSON representation of the model, include and exclude arguments as per dict() . encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps() . to_pandas def to_pandas ( self , * args , ** kwargs ) -> pandas . core . frame . DataFrame Exports stored values as a pandas DataFrame. Returns: A pandas.DataFrame object with the instance's attributes as columns. View Source def to_pandas ( self , * args , ** kwargs ) -> pd . DataFrame : \"\"\" Exports stored values as a pandas DataFrame. Returns: A `pandas.DataFrame` object with the instance's attributes as columns. \"\"\" return pd . DataFrame ( self . dict ( * args , ** kwargs )) to_string def to_string ( self , pretty : bool = False ) -> 'unicode' update_miss_from_cpymad def update_miss_from_cpymad ( self , cpymad_betabeatings : pandas . core . frame . DataFrame ) -> None Updates a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. View Source def update_miss_from_cpymad ( self , cpymad_betabeatings : pd . DataFrame ) -> None : \"\"\" Updates a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. \"\"\" logger . trace ( \"Getting rms and max values for betatron functions of provided run\" ) self . misserror_bbx . append ( _get_rms ( cpymad_betabeatings [ \"BETX\" ])) self . misserror_bby . append ( _get_rms ( cpymad_betabeatings [ \"BETY\" ])) self . max_misserror_bbx . append ( cpymad_betabeatings [ \"BETX\" ]. max ()) self . max_misserror_bby . append ( cpymad_betabeatings [ \"BETY\" ]. max ()) logger . trace ( \"Getting betatron functions at IP1 and IP5\" ) # cpymad naming : lowercase and appended with : beam_number self . ip1_misserror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip1_misserror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip5_misserror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] ) self . ip5_misserror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] ) update_miss_from_seeds def update_miss_from_seeds ( self , temp_data ) -> None Append computed rms values for a group of seeds, to misalignment result values. Args: temp_data: a BetaBeatValues object with the seeds' results. View Source def update_miss_from_seeds ( self , temp_data ) -> None : \" \"\" Append computed rms values for a group of seeds, to misalignment result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. \"\" \" self . misserror_bbx . append ( _get_rms ( temp_data . misserror_bbx )) self . misserror_bby . append ( _get_rms ( temp_data . misserror_bby )) self . max_misserror_bbx . append ( _get_rms ( temp_data . max_misserror_bbx )) self . max_misserror_bby . append ( _get_rms ( temp_data . max_misserror_bby )) self . ip1_misserror_bbx . append ( _get_rms ( temp_data . ip1_misserror_bbx )) self . ip1_misserror_bby . append ( _get_rms ( temp_data . ip1_misserror_bby )) self . ip5_misserror_bbx . append ( _get_rms ( temp_data . ip5_misserror_bbx )) self . ip5_misserror_bby . append ( _get_rms ( temp_data . ip5_misserror_bby )) update_tf_from_cpymad def update_tf_from_cpymad ( self , cpymad_betabeatings : pandas . core . frame . DataFrame ) -> None This is to update a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. View Source def update_tf_from_cpymad ( self , cpymad_betabeatings : pd . DataFrame ) -> None : \"\"\" This is to update a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. \"\"\" logger . trace ( \"Getting rms and max values for betatron functions of provided run\" ) self . tferror_bbx . append ( _get_rms ( cpymad_betabeatings [ \"BETX\" ])) self . tferror_bby . append ( _get_rms ( cpymad_betabeatings [ \"BETY\" ])) self . max_tferror_bbx . append ( cpymad_betabeatings [ \"BETX\" ]. max ()) self . max_tferror_bby . append ( cpymad_betabeatings [ \"BETY\" ]. max ()) logger . trace ( \"Getting betatron functions at IP1 and IP5\" ) # cpymad naming : lowercase and appended with : beam_number self . ip1_tferror_bbx . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip1_tferror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip5_tferror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] ) self . ip5_tferror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] ) update_tf_from_seeds def update_tf_from_seeds ( self , temp_data ) -> None Updates the error's beta-beatings values after having ran simulations for all seeds. Append computed rms values for a group of seeds, to field errors result values. Args: temp_data: a BetaBeatValues object with the seeds' results. View Source def update_tf_from_seeds ( self , temp_data ) -> None : \" \"\" Updates the error's beta-beatings values after having ran simulations for all seeds. Append computed rms values for a group of seeds, to field errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. \"\" \" self . tferror_bbx . append ( _get_rms ( temp_data . tferror_bbx )) self . tferror_bby . append ( _get_rms ( temp_data . tferror_bby )) self . max_tferror_bbx . append ( _get_rms ( temp_data . max_tferror_bbx )) self . max_tferror_bby . append ( _get_rms ( temp_data . max_tferror_bby )) self . ip1_tferror_bbx . append ( _get_rms ( temp_data . ip1_tferror_bbx )) self . ip1_tferror_bby . append ( _get_rms ( temp_data . ip1_tferror_bby )) self . ip5_tferror_bbx . append ( _get_rms ( temp_data . ip5_tferror_bbx )) self . ip5_tferror_bby . append ( _get_rms ( temp_data . ip5_tferror_bby )) StdevValues class StdevValues ( __pydantic_self__ , ** data : Any ) Simple class to store and transfer standard deviation values. Class attributes are as follows: \"stdev_tf_x\": \"Horizontal standard deviation values from field errors\", \"stdev_tf_y\": \"Vertical standard deviation values from field errors\", \"ip1_stdev_tf_x\": \"Horizontal standard deviation values from field errors at IP1\", \"ip1_stdev_tf_y\": \"Vertical standard deviation values from field errors at IP1\", \"ip5_stdev_tf_x\": \"Horizontal standard deviation values from field errors at IP5\", \"ip5_stdev_tf_y\": \"Vertical standard deviation values from field errors at IP5\", \"max_stdev_tf_x\": \"Maximal horizontal standard deviation values from field errors\", \"max_stdev_tf_y\": \"Maximal vertical standard deviation values from field errors\", \"stdev_miss_x\": \"Horizontal standard deviation values from misalignment errors\", \"stdev_miss_y\": \"Horizontal standard deviation values from misalignment errors\", \"ip1_stdev_miss_x\": \"Horizontal standard deviation values from misalignment errors at IP1\", \"ip1_stdev_miss_y\": \"Vertical standard deviation values from misalignment errors at IP1\", \"ip5_stdev_miss_x\": \"Horizontal standard deviation values from misalignment errors at IP5\", \"ip5_stdev_miss_y\": \"Vertical standard deviation values from misalignment errors at IP5\", \"max_stdev_miss_x\": \"Maximal horizontal standard deviation values from misalignment errors\", \"max_stdev_miss_y\": \"Maximal vertical standard deviation values from misalignment errors\", View Source class StdevValues ( BaseModel ) : \"\"\" Simple class to store and transfer standard deviation values. Class attributes are as follows: \" stdev_tf_x \": \" Horizontal standard deviation values from field errors \", \" stdev_tf_y \": \" Vertical standard deviation values from field errors \", \" ip1_stdev_tf_x \": \" Horizontal standard deviation values from field errors at IP1 \", \" ip1_stdev_tf_y \": \" Vertical standard deviation values from field errors at IP1 \", \" ip5_stdev_tf_x \": \" Horizontal standard deviation values from field errors at IP5 \", \" ip5_stdev_tf_y \": \" Vertical standard deviation values from field errors at IP5 \", \" max_stdev_tf_x \": \" Maximal horizontal standard deviation values from field errors \", \" max_stdev_tf_y \": \" Maximal vertical standard deviation values from field errors \", \" stdev_miss_x \": \" Horizontal standard deviation values from misalignment errors \", \" stdev_miss_y \": \" Horizontal standard deviation values from misalignment errors \", \" ip1_stdev_miss_x \": \" Horizontal standard deviation values from misalignment errors at IP1 \", \" ip1_stdev_miss_y \": \" Vertical standard deviation values from misalignment errors at IP1 \", \" ip5_stdev_miss_x \": \" Horizontal standard deviation values from misalignment errors at IP5 \", \" ip5_stdev_miss_y \": \" Vertical standard deviation values from misalignment errors at IP5 \", \" max_stdev_miss_x \": \" Maximal horizontal standard deviation values from misalignment errors \", \" max_stdev_miss_y \": \" Maximal vertical standard deviation values from misalignment errors \", \"\"\" stdev_tf_x : List [ float ] = [] stdev_tf_y : List [ float ] = [] ip1_stdev_tf_x : List [ float ] = [] ip1_stdev_tf_y : List [ float ] = [] ip5_stdev_tf_x : List [ float ] = [] ip5_stdev_tf_y : List [ float ] = [] max_stdev_tf_x : List [ float ] = [] max_stdev_tf_y : List [ float ] = [] stdev_miss_x : List [ float ] = [] stdev_miss_y : List [ float ] = [] ip1_stdev_miss_x : List [ float ] = [] ip1_stdev_miss_y : List [ float ] = [] ip5_stdev_miss_x : List [ float ] = [] ip5_stdev_miss_y : List [ float ] = [] max_stdev_miss_x : List [ float ] = [] max_stdev_miss_y : List [ float ] = [] def describe ( self ) -> None : \"\"\" Simple print statement of instance attributes. \"\"\" for attribute , value in self . dict (). items () : print ( f \"{attribute:<20} {value}\" ) def update_tf ( self , temp_data ) -> None : \"\"\" Append computed stdev values for a group of seeds, to field errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. Returns: Nothing, updates inplace. \"\"\" self . stdev_tf_x . append ( np . std ( temp_data . tferror_bbx )) self . stdev_tf_y . append ( np . std ( temp_data . tferror_bby )) self . max_stdev_tf_x . append ( np . std ( temp_data . max_tferror_bbx )) self . max_stdev_tf_y . append ( np . std ( temp_data . max_tferror_bby )) self . ip1_stdev_tf_x . append ( np . std ( temp_data . ip1_tferror_bbx )) self . ip1_stdev_tf_y . append ( np . std ( temp_data . ip1_tferror_bby )) self . ip5_stdev_tf_x . append ( np . std ( temp_data . ip5_tferror_bbx )) self . ip5_stdev_tf_y . append ( np . std ( temp_data . ip5_tferror_bby )) def update_miss ( self , temp_data ) -> None : \"\"\" Append computed rms values for a group of seeds, to misalignment errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. Returns: Nothing, updates inplace. \"\"\" self . stdev_miss_x . append ( np . std ( temp_data . misserror_bbx )) self . stdev_miss_y . append ( np . std ( temp_data . misserror_bby )) self . max_stdev_miss_x . append ( np . std ( temp_data . max_misserror_bbx )) self . max_stdev_miss_y . append ( np . std ( temp_data . max_misserror_bby )) self . ip1_stdev_miss_x . append ( np . std ( temp_data . ip1_misserror_bbx )) self . ip1_stdev_miss_y . append ( np . std ( temp_data . ip1_misserror_bby )) self . ip5_stdev_miss_x . append ( np . std ( temp_data . ip5_misserror_bbx )) self . ip5_stdev_miss_y . append ( np . std ( temp_data . ip5_misserror_bby )) def to_pandas ( self , * args , ** kwargs ) -> pd . DataFrame : \"\"\" Simple function to export stored values as a pandas dataframe. Returns: A `pandas.DataFrame` object with the instance's attributes as columns. \"\"\" return pd . DataFrame ( self . dict ( * args , ** kwargs )) Ancestors (in MRO) pydantic.main.BaseModel pydantic.utils.Representation Class variables Config Static methods construct def construct ( _fields_set : Union [ ForwardRef ( 'SetStr' ), NoneType ] = None , ** values : Any ) -> 'Model' Creates a new model setting dict and fields_set from trusted or pre-validated data. Default values are respected, but no other validation is performed. from_orm def from_orm ( obj : Any ) -> 'Model' parse_file def parse_file ( path : Union [ str , pathlib . Path ], * , content_type : 'unicode' = None , encoding : 'unicode' = 'utf8' , proto : pydantic . parse . Protocol = None , allow_pickle : bool = False ) -> 'Model' parse_obj def parse_obj ( obj : Any ) -> 'Model' parse_raw def parse_raw ( b : Union [ str , bytes ], * , content_type : 'unicode' = None , encoding : 'unicode' = 'utf8' , proto : pydantic . parse . Protocol = None , allow_pickle : bool = False ) -> 'Model' schema def schema ( by_alias : bool = True , ref_template : 'unicode' = '#/definitions/ {model} ' ) -> 'DictStrAny' schema_json def schema_json ( * , by_alias : bool = True , ref_template : 'unicode' = '#/definitions/ {model} ' , ** dumps_kwargs : Any ) -> 'unicode' update_forward_refs def update_forward_refs ( ** localns : Any ) -> None Try to update ForwardRefs on fields based on this Model, globalns and localns. validate def validate ( value : Any ) -> 'Model' Instance variables fields Methods copy def copy ( self : 'Model' , * , include : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , exclude : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , update : 'DictStrAny' = None , deep : bool = False ) -> 'Model' Duplicate a model, optionally choose which fields to include, exclude and change. :param include: fields to include in new model :param exclude: fields to exclude from new model, as with values this takes precedence over include :param update: values to change/add in the new model. Note: the data is not validated before creating the new model: you should trust this data :param deep: set to True to make a deep copy of the model :return: new model instance describe def describe ( self ) -> None Simple print statement of instance attributes. View Source def describe ( self ) -> None : \"\"\" Simple print statement of instance attributes. \"\"\" for attribute , value in self . dict (). items (): print ( f \"{attribute:<20} {value}\" ) dict def dict ( self , * , include : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , exclude : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , by_alias : bool = False , skip_defaults : bool = None , exclude_unset : bool = False , exclude_defaults : bool = False , exclude_none : bool = False ) -> 'DictStrAny' Generate a dictionary representation of the model, optionally specifying which fields to include or exclude. json def json ( self , * , include : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , exclude : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , by_alias : bool = False , skip_defaults : bool = None , exclude_unset : bool = False , exclude_defaults : bool = False , exclude_none : bool = False , encoder : Union [ Callable [[ Any ], Any ], NoneType ] = None , ** dumps_kwargs : Any ) -> 'unicode' Generate a JSON representation of the model, include and exclude arguments as per dict() . encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps() . to_pandas def to_pandas ( self , * args , ** kwargs ) -> pandas . core . frame . DataFrame Simple function to export stored values as a pandas dataframe. Returns: A pandas.DataFrame object with the instance's attributes as columns. View Source def to_pandas ( self , * args , ** kwargs ) -> pd . DataFrame : \"\"\" Simple function to export stored values as a pandas dataframe. Returns: A `pandas.DataFrame` object with the instance's attributes as columns. \"\"\" return pd . DataFrame ( self . dict ( * args , ** kwargs )) to_string def to_string ( self , pretty : bool = False ) -> 'unicode' update_miss def update_miss ( self , temp_data ) -> None Append computed rms values for a group of seeds, to misalignment errors result values. Args: temp_data: a BetaBeatValues object with the seeds' results. Returns: Nothing, updates inplace. View Source def update_miss ( self , temp_data ) -> None : \" \"\" Append computed rms values for a group of seeds, to misalignment errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. Returns: Nothing, updates inplace. \"\" \" self . stdev_miss_x . append ( np . std ( temp_data . misserror_bbx )) self . stdev_miss_y . append ( np . std ( temp_data . misserror_bby )) self . max_stdev_miss_x . append ( np . std ( temp_data . max_misserror_bbx )) self . max_stdev_miss_y . append ( np . std ( temp_data . max_misserror_bby )) self . ip1_stdev_miss_x . append ( np . std ( temp_data . ip1_misserror_bbx )) self . ip1_stdev_miss_y . append ( np . std ( temp_data . ip1_misserror_bby )) self . ip5_stdev_miss_x . append ( np . std ( temp_data . ip5_misserror_bbx )) self . ip5_stdev_miss_y . append ( np . std ( temp_data . ip5_misserror_bby )) update_tf def update_tf ( self , temp_data ) -> None Append computed stdev values for a group of seeds, to field errors result values. Args: temp_data: a BetaBeatValues object with the seeds' results. Returns: Nothing, updates inplace. View Source def update_tf ( self , temp_data ) -> None : \" \"\" Append computed stdev values for a group of seeds, to field errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. Returns: Nothing, updates inplace. \"\" \" self . stdev_tf_x . append ( np . std ( temp_data . tferror_bbx )) self . stdev_tf_y . append ( np . std ( temp_data . tferror_bby )) self . max_stdev_tf_x . append ( np . std ( temp_data . max_tferror_bbx )) self . max_stdev_tf_y . append ( np . std ( temp_data . max_tferror_bby )) self . ip1_stdev_tf_x . append ( np . std ( temp_data . ip1_tferror_bbx )) self . ip1_stdev_tf_y . append ( np . std ( temp_data . ip1_tferror_bby )) self . ip5_stdev_tf_x . append ( np . std ( temp_data . ip5_tferror_bbx )) self . ip5_stdev_tf_y . append ( np . std ( temp_data . ip5_tferror_bby ))","title":"Data Classes"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#module-pyhdtoolkitscriptstriplet_errorsdata_classes","text":"","title":"Module pyhdtoolkit.scripts.triplet_errors.data_classes"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#module-scriptstriplet_errorsdata_classes","text":"Created on 2019.06.15 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A few classes that will be useful to store values calculated from the results of the GridCompute Algorithm. View Source \"\"\" Module scripts.triplet_errors.data_classes ------------------------------------------ Created on 2019.06.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A few classes that will be useful to store values calculated from the results of the GridCompute Algorithm. \"\"\" from typing import List import numpy as np import pandas as pd from loguru import logger from pydantic import BaseModel class BetaBeatValues ( BaseModel ): \"\"\" Simple class to store and transfer beta-beating values. Class attributes are as follows: \"tferror_bbx\": \"Horizontal beta-beating values from field errors\", \"tferror_bby\": \"Vertical beta-beating values from field errors\", \"ip1_tferror_bbx\": \"Horizontal beta-beating values from field errors at IP1\", \"ip1_tferror_bby\": \"Vertical beta-beating values from field errors at IP1\", \"ip5_tferror_bbx\": \"Horizontal beta-beating values from field errors at IP5\", \"ip5_tferror_bby\": \"Vertical beta-beating values from field errors at IP5\", \"max_tferror_bbx\": \"Maximal horizontal beta-beating values from field errors\", \"max_tferror_bby\": \"Maximal vertical beta-beating values from field errors\", \"misserror_bbx\": \"Horizontal beta-beating values from misalignment errors\", \"misserror_bby\": \"Horizontal beta-beating values from misalignment errors\", \"ip1_misserror_bbx\": \"Horizontal beta-beating values from misalignment errors at IP1\", \"ip1_misserror_bby\": \"Vertical beta-beating values from misalignment errors at IP1\", \"ip5_misserror_bbx\": \"Horizontal beta-beating values from misalignment errors at IP5\", \"ip5_misserror_bby\": \"Vertical beta-beating values from misalignment errors at IP5\", \"max_misserror_bbx\": \"Maximal horizontal beta-beating values from misalignment errors\", \"max_misserror_bby\": \"Maximal vertical beta-beating values from misalignment errors\", \"\"\" tferror_bbx : List [ float ] = [] tferror_bby : List [ float ] = [] ip1_tferror_bbx : List [ float ] = [] ip1_tferror_bby : List [ float ] = [] ip5_tferror_bbx : List [ float ] = [] ip5_tferror_bby : List [ float ] = [] max_tferror_bbx : List [ float ] = [] max_tferror_bby : List [ float ] = [] misserror_bbx : List [ float ] = [] misserror_bby : List [ float ] = [] ip1_misserror_bbx : List [ float ] = [] ip1_misserror_bby : List [ float ] = [] ip5_misserror_bbx : List [ float ] = [] ip5_misserror_bby : List [ float ] = [] max_misserror_bbx : List [ float ] = [] max_misserror_bby : List [ float ] = [] def describe ( self ) -> None : \"\"\" Simple print statement of instance attributes. \"\"\" for attribute , value in self . dict () . items (): print ( f \" { attribute : <20 } { value } \" ) def update_tf_from_cpymad ( self , cpymad_betabeatings : pd . DataFrame ) -> None : \"\"\" This is to update a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. \"\"\" logger . trace ( \"Getting rms and max values for betatron functions of provided run\" ) self . tferror_bbx . append ( _get_rms ( cpymad_betabeatings [ \"BETX\" ])) self . tferror_bby . append ( _get_rms ( cpymad_betabeatings [ \"BETY\" ])) self . max_tferror_bbx . append ( cpymad_betabeatings [ \"BETX\" ] . max ()) self . max_tferror_bby . append ( cpymad_betabeatings [ \"BETY\" ] . max ()) logger . trace ( \"Getting betatron functions at IP1 and IP5\" ) # cpymad naming: lowercase and appended with :beam_number self . ip1_tferror_bbx . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip1_tferror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip5_tferror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] ) self . ip5_tferror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] ) def update_tf_from_seeds ( self , temp_data ) -> None : \"\"\" Updates the error's beta-beatings values after having ran simulations for all seeds. Append computed rms values for a group of seeds, to field errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. \"\"\" self . tferror_bbx . append ( _get_rms ( temp_data . tferror_bbx )) self . tferror_bby . append ( _get_rms ( temp_data . tferror_bby )) self . max_tferror_bbx . append ( _get_rms ( temp_data . max_tferror_bbx )) self . max_tferror_bby . append ( _get_rms ( temp_data . max_tferror_bby )) self . ip1_tferror_bbx . append ( _get_rms ( temp_data . ip1_tferror_bbx )) self . ip1_tferror_bby . append ( _get_rms ( temp_data . ip1_tferror_bby )) self . ip5_tferror_bbx . append ( _get_rms ( temp_data . ip5_tferror_bbx )) self . ip5_tferror_bby . append ( _get_rms ( temp_data . ip5_tferror_bby )) def update_miss_from_cpymad ( self , cpymad_betabeatings : pd . DataFrame ) -> None : \"\"\" Updates a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. \"\"\" logger . trace ( \"Getting rms and max values for betatron functions of provided run\" ) self . misserror_bbx . append ( _get_rms ( cpymad_betabeatings [ \"BETX\" ])) self . misserror_bby . append ( _get_rms ( cpymad_betabeatings [ \"BETY\" ])) self . max_misserror_bbx . append ( cpymad_betabeatings [ \"BETX\" ] . max ()) self . max_misserror_bby . append ( cpymad_betabeatings [ \"BETY\" ] . max ()) logger . trace ( \"Getting betatron functions at IP1 and IP5\" ) # cpymad naming: lowercase and appended with :beam_number self . ip1_misserror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip1_misserror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip5_misserror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] ) self . ip5_misserror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] ) def update_miss_from_seeds ( self , temp_data ) -> None : \"\"\" Append computed rms values for a group of seeds, to misalignment result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. \"\"\" self . misserror_bbx . append ( _get_rms ( temp_data . misserror_bbx )) self . misserror_bby . append ( _get_rms ( temp_data . misserror_bby )) self . max_misserror_bbx . append ( _get_rms ( temp_data . max_misserror_bbx )) self . max_misserror_bby . append ( _get_rms ( temp_data . max_misserror_bby )) self . ip1_misserror_bbx . append ( _get_rms ( temp_data . ip1_misserror_bbx )) self . ip1_misserror_bby . append ( _get_rms ( temp_data . ip1_misserror_bby )) self . ip5_misserror_bbx . append ( _get_rms ( temp_data . ip5_misserror_bbx )) self . ip5_misserror_bby . append ( _get_rms ( temp_data . ip5_misserror_bby )) def to_pandas ( self , * args , ** kwargs ) -> pd . DataFrame : \"\"\" Exports stored values as a pandas DataFrame. Returns: A `pandas.DataFrame` object with the instance's attributes as columns. \"\"\" return pd . DataFrame ( self . dict ( * args , ** kwargs )) class StdevValues ( BaseModel ): \"\"\" Simple class to store and transfer standard deviation values. Class attributes are as follows: \"stdev_tf_x\": \"Horizontal standard deviation values from field errors\", \"stdev_tf_y\": \"Vertical standard deviation values from field errors\", \"ip1_stdev_tf_x\": \"Horizontal standard deviation values from field errors at IP1\", \"ip1_stdev_tf_y\": \"Vertical standard deviation values from field errors at IP1\", \"ip5_stdev_tf_x\": \"Horizontal standard deviation values from field errors at IP5\", \"ip5_stdev_tf_y\": \"Vertical standard deviation values from field errors at IP5\", \"max_stdev_tf_x\": \"Maximal horizontal standard deviation values from field errors\", \"max_stdev_tf_y\": \"Maximal vertical standard deviation values from field errors\", \"stdev_miss_x\": \"Horizontal standard deviation values from misalignment errors\", \"stdev_miss_y\": \"Horizontal standard deviation values from misalignment errors\", \"ip1_stdev_miss_x\": \"Horizontal standard deviation values from misalignment errors at IP1\", \"ip1_stdev_miss_y\": \"Vertical standard deviation values from misalignment errors at IP1\", \"ip5_stdev_miss_x\": \"Horizontal standard deviation values from misalignment errors at IP5\", \"ip5_stdev_miss_y\": \"Vertical standard deviation values from misalignment errors at IP5\", \"max_stdev_miss_x\": \"Maximal horizontal standard deviation values from misalignment errors\", \"max_stdev_miss_y\": \"Maximal vertical standard deviation values from misalignment errors\", \"\"\" stdev_tf_x : List [ float ] = [] stdev_tf_y : List [ float ] = [] ip1_stdev_tf_x : List [ float ] = [] ip1_stdev_tf_y : List [ float ] = [] ip5_stdev_tf_x : List [ float ] = [] ip5_stdev_tf_y : List [ float ] = [] max_stdev_tf_x : List [ float ] = [] max_stdev_tf_y : List [ float ] = [] stdev_miss_x : List [ float ] = [] stdev_miss_y : List [ float ] = [] ip1_stdev_miss_x : List [ float ] = [] ip1_stdev_miss_y : List [ float ] = [] ip5_stdev_miss_x : List [ float ] = [] ip5_stdev_miss_y : List [ float ] = [] max_stdev_miss_x : List [ float ] = [] max_stdev_miss_y : List [ float ] = [] def describe ( self ) -> None : \"\"\" Simple print statement of instance attributes. \"\"\" for attribute , value in self . dict () . items (): print ( f \" { attribute : <20 } { value } \" ) def update_tf ( self , temp_data ) -> None : \"\"\" Append computed stdev values for a group of seeds, to field errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. Returns: Nothing, updates inplace. \"\"\" self . stdev_tf_x . append ( np . std ( temp_data . tferror_bbx )) self . stdev_tf_y . append ( np . std ( temp_data . tferror_bby )) self . max_stdev_tf_x . append ( np . std ( temp_data . max_tferror_bbx )) self . max_stdev_tf_y . append ( np . std ( temp_data . max_tferror_bby )) self . ip1_stdev_tf_x . append ( np . std ( temp_data . ip1_tferror_bbx )) self . ip1_stdev_tf_y . append ( np . std ( temp_data . ip1_tferror_bby )) self . ip5_stdev_tf_x . append ( np . std ( temp_data . ip5_tferror_bbx )) self . ip5_stdev_tf_y . append ( np . std ( temp_data . ip5_tferror_bby )) def update_miss ( self , temp_data ) -> None : \"\"\" Append computed rms values for a group of seeds, to misalignment errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. Returns: Nothing, updates inplace. \"\"\" self . stdev_miss_x . append ( np . std ( temp_data . misserror_bbx )) self . stdev_miss_y . append ( np . std ( temp_data . misserror_bby )) self . max_stdev_miss_x . append ( np . std ( temp_data . max_misserror_bbx )) self . max_stdev_miss_y . append ( np . std ( temp_data . max_misserror_bby )) self . ip1_stdev_miss_x . append ( np . std ( temp_data . ip1_misserror_bbx )) self . ip1_stdev_miss_y . append ( np . std ( temp_data . ip1_misserror_bby )) self . ip5_stdev_miss_x . append ( np . std ( temp_data . ip5_misserror_bbx )) self . ip5_stdev_miss_y . append ( np . std ( temp_data . ip5_misserror_bby )) def to_pandas ( self , * args , ** kwargs ) -> pd . DataFrame : \"\"\" Simple function to export stored values as a pandas dataframe. Returns: A `pandas.DataFrame` object with the instance's attributes as columns. \"\"\" return pd . DataFrame ( self . dict ( * args , ** kwargs )) def _get_rms ( values_list : List [ float ]) -> float : \"\"\" Get the root mean square of a list of values. Args: values_list (List[float]): a distribution of values. Returns: The root mean square of said distribution. \"\"\" try : return np . sqrt ( np . sum ( i ** 2 for i in values_list ) / len ( values_list )) except ZeroDivisionError as issue : logger . exception ( \"An empty list was provided, check the simulation logs to understand why.\" ) raise ZeroDivisionError ( \"No values were provided\" ) from issue","title":"Module scripts.triplet_errors.data_classes"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#betabeatvalues","text":"class BetaBeatValues ( __pydantic_self__ , ** data : Any ) Simple class to store and transfer beta-beating values. Class attributes are as follows: \"tferror_bbx\": \"Horizontal beta-beating values from field errors\", \"tferror_bby\": \"Vertical beta-beating values from field errors\", \"ip1_tferror_bbx\": \"Horizontal beta-beating values from field errors at IP1\", \"ip1_tferror_bby\": \"Vertical beta-beating values from field errors at IP1\", \"ip5_tferror_bbx\": \"Horizontal beta-beating values from field errors at IP5\", \"ip5_tferror_bby\": \"Vertical beta-beating values from field errors at IP5\", \"max_tferror_bbx\": \"Maximal horizontal beta-beating values from field errors\", \"max_tferror_bby\": \"Maximal vertical beta-beating values from field errors\", \"misserror_bbx\": \"Horizontal beta-beating values from misalignment errors\", \"misserror_bby\": \"Horizontal beta-beating values from misalignment errors\", \"ip1_misserror_bbx\": \"Horizontal beta-beating values from misalignment errors at IP1\", \"ip1_misserror_bby\": \"Vertical beta-beating values from misalignment errors at IP1\", \"ip5_misserror_bbx\": \"Horizontal beta-beating values from misalignment errors at IP5\", \"ip5_misserror_bby\": \"Vertical beta-beating values from misalignment errors at IP5\", \"max_misserror_bbx\": \"Maximal horizontal beta-beating values from misalignment errors\", \"max_misserror_bby\": \"Maximal vertical beta-beating values from misalignment errors\", View Source class BetaBeatValues ( BaseModel ) : \"\"\" Simple class to store and transfer beta-beating values. Class attributes are as follows: \" tferror_bbx \": \" Horizontal beta - beating values from field errors \", \" tferror_bby \": \" Vertical beta - beating values from field errors \", \" ip1_tferror_bbx \": \" Horizontal beta - beating values from field errors at IP1 \", \" ip1_tferror_bby \": \" Vertical beta - beating values from field errors at IP1 \", \" ip5_tferror_bbx \": \" Horizontal beta - beating values from field errors at IP5 \", \" ip5_tferror_bby \": \" Vertical beta - beating values from field errors at IP5 \", \" max_tferror_bbx \": \" Maximal horizontal beta - beating values from field errors \", \" max_tferror_bby \": \" Maximal vertical beta - beating values from field errors \", \" misserror_bbx \": \" Horizontal beta - beating values from misalignment errors \", \" misserror_bby \": \" Horizontal beta - beating values from misalignment errors \", \" ip1_misserror_bbx \": \" Horizontal beta - beating values from misalignment errors at IP1 \", \" ip1_misserror_bby \": \" Vertical beta - beating values from misalignment errors at IP1 \", \" ip5_misserror_bbx \": \" Horizontal beta - beating values from misalignment errors at IP5 \", \" ip5_misserror_bby \": \" Vertical beta - beating values from misalignment errors at IP5 \", \" max_misserror_bbx \": \" Maximal horizontal beta - beating values from misalignment errors \", \" max_misserror_bby \": \" Maximal vertical beta - beating values from misalignment errors \", \"\"\" tferror_bbx : List [ float ] = [] tferror_bby : List [ float ] = [] ip1_tferror_bbx : List [ float ] = [] ip1_tferror_bby : List [ float ] = [] ip5_tferror_bbx : List [ float ] = [] ip5_tferror_bby : List [ float ] = [] max_tferror_bbx : List [ float ] = [] max_tferror_bby : List [ float ] = [] misserror_bbx : List [ float ] = [] misserror_bby : List [ float ] = [] ip1_misserror_bbx : List [ float ] = [] ip1_misserror_bby : List [ float ] = [] ip5_misserror_bbx : List [ float ] = [] ip5_misserror_bby : List [ float ] = [] max_misserror_bbx : List [ float ] = [] max_misserror_bby : List [ float ] = [] def describe ( self ) -> None : \"\"\" Simple print statement of instance attributes. \"\"\" for attribute , value in self . dict (). items () : print ( f \"{attribute:<20} {value}\" ) def update_tf_from_cpymad ( self , cpymad_betabeatings : pd . DataFrame ) -> None : \"\"\" This is to update a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. \"\"\" logger . trace ( \"Getting rms and max values for betatron functions of provided run\" ) self . tferror_bbx . append ( _get_rms ( cpymad_betabeatings [ \"BETX\" ] )) self . tferror_bby . append ( _get_rms ( cpymad_betabeatings [ \"BETY\" ] )) self . max_tferror_bbx . append ( cpymad_betabeatings [ \"BETX\" ] . max ()) self . max_tferror_bby . append ( cpymad_betabeatings [ \"BETY\" ] . max ()) logger . trace ( \"Getting betatron functions at IP1 and IP5\" ) # cpymad naming : lowercase and appended with : beam_number self . ip1_tferror_bbx . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings.NAME == \"ip1:1\" ][ 0 ] ) self . ip1_tferror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings.NAME == \"ip1:1\" ][ 0 ] ) self . ip5_tferror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings.NAME == \"ip5:1\" ][ 0 ] ) self . ip5_tferror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings.NAME == \"ip5:1\" ][ 0 ] ) def update_tf_from_seeds ( self , temp_data ) -> None : \"\"\" Updates the error's beta-beatings values after having ran simulations for all seeds. Append computed rms values for a group of seeds, to field errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. \"\"\" self . tferror_bbx . append ( _get_rms ( temp_data . tferror_bbx )) self . tferror_bby . append ( _get_rms ( temp_data . tferror_bby )) self . max_tferror_bbx . append ( _get_rms ( temp_data . max_tferror_bbx )) self . max_tferror_bby . append ( _get_rms ( temp_data . max_tferror_bby )) self . ip1_tferror_bbx . append ( _get_rms ( temp_data . ip1_tferror_bbx )) self . ip1_tferror_bby . append ( _get_rms ( temp_data . ip1_tferror_bby )) self . ip5_tferror_bbx . append ( _get_rms ( temp_data . ip5_tferror_bbx )) self . ip5_tferror_bby . append ( _get_rms ( temp_data . ip5_tferror_bby )) def update_miss_from_cpymad ( self , cpymad_betabeatings : pd . DataFrame ) -> None : \"\"\" Updates a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. \"\"\" logger . trace ( \"Getting rms and max values for betatron functions of provided run\" ) self . misserror_bbx . append ( _get_rms ( cpymad_betabeatings [ \"BETX\" ] )) self . misserror_bby . append ( _get_rms ( cpymad_betabeatings [ \"BETY\" ] )) self . max_misserror_bbx . append ( cpymad_betabeatings [ \"BETX\" ] . max ()) self . max_misserror_bby . append ( cpymad_betabeatings [ \"BETY\" ] . max ()) logger . trace ( \"Getting betatron functions at IP1 and IP5\" ) # cpymad naming : lowercase and appended with : beam_number self . ip1_misserror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings.NAME == \"ip1:1\" ][ 0 ] ) self . ip1_misserror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings.NAME == \"ip1:1\" ][ 0 ] ) self . ip5_misserror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings.NAME == \"ip5:1\" ][ 0 ] ) self . ip5_misserror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings.NAME == \"ip5:1\" ][ 0 ] ) def update_miss_from_seeds ( self , temp_data ) -> None : \"\"\" Append computed rms values for a group of seeds, to misalignment result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. \"\"\" self . misserror_bbx . append ( _get_rms ( temp_data . misserror_bbx )) self . misserror_bby . append ( _get_rms ( temp_data . misserror_bby )) self . max_misserror_bbx . append ( _get_rms ( temp_data . max_misserror_bbx )) self . max_misserror_bby . append ( _get_rms ( temp_data . max_misserror_bby )) self . ip1_misserror_bbx . append ( _get_rms ( temp_data . ip1_misserror_bbx )) self . ip1_misserror_bby . append ( _get_rms ( temp_data . ip1_misserror_bby )) self . ip5_misserror_bbx . append ( _get_rms ( temp_data . ip5_misserror_bbx )) self . ip5_misserror_bby . append ( _get_rms ( temp_data . ip5_misserror_bby )) def to_pandas ( self , * args , ** kwargs ) -> pd . DataFrame : \"\"\" Exports stored values as a pandas DataFrame. Returns: A `pandas.DataFrame` object with the instance's attributes as columns. \"\"\" return pd . DataFrame ( self . dict ( * args , ** kwargs ))","title":"BetaBeatValues"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#ancestors-in-mro","text":"pydantic.main.BaseModel pydantic.utils.Representation","title":"Ancestors (in MRO)"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#class-variables","text":"Config","title":"Class variables"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#construct","text":"def construct ( _fields_set : Union [ ForwardRef ( 'SetStr' ), NoneType ] = None , ** values : Any ) -> 'Model' Creates a new model setting dict and fields_set from trusted or pre-validated data. Default values are respected, but no other validation is performed.","title":"construct"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#from_orm","text":"def from_orm ( obj : Any ) -> 'Model'","title":"from_orm"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#parse_file","text":"def parse_file ( path : Union [ str , pathlib . Path ], * , content_type : 'unicode' = None , encoding : 'unicode' = 'utf8' , proto : pydantic . parse . Protocol = None , allow_pickle : bool = False ) -> 'Model'","title":"parse_file"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#parse_obj","text":"def parse_obj ( obj : Any ) -> 'Model'","title":"parse_obj"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#parse_raw","text":"def parse_raw ( b : Union [ str , bytes ], * , content_type : 'unicode' = None , encoding : 'unicode' = 'utf8' , proto : pydantic . parse . Protocol = None , allow_pickle : bool = False ) -> 'Model'","title":"parse_raw"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#schema","text":"def schema ( by_alias : bool = True , ref_template : 'unicode' = '#/definitions/ {model} ' ) -> 'DictStrAny'","title":"schema"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#schema_json","text":"def schema_json ( * , by_alias : bool = True , ref_template : 'unicode' = '#/definitions/ {model} ' , ** dumps_kwargs : Any ) -> 'unicode'","title":"schema_json"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#update_forward_refs","text":"def update_forward_refs ( ** localns : Any ) -> None Try to update ForwardRefs on fields based on this Model, globalns and localns.","title":"update_forward_refs"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#validate","text":"def validate ( value : Any ) -> 'Model'","title":"validate"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#instance-variables","text":"fields","title":"Instance variables"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#methods","text":"","title":"Methods"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#copy","text":"def copy ( self : 'Model' , * , include : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , exclude : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , update : 'DictStrAny' = None , deep : bool = False ) -> 'Model' Duplicate a model, optionally choose which fields to include, exclude and change. :param include: fields to include in new model :param exclude: fields to exclude from new model, as with values this takes precedence over include :param update: values to change/add in the new model. Note: the data is not validated before creating the new model: you should trust this data :param deep: set to True to make a deep copy of the model :return: new model instance","title":"copy"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#describe","text":"def describe ( self ) -> None Simple print statement of instance attributes. View Source def describe ( self ) -> None : \"\"\" Simple print statement of instance attributes. \"\"\" for attribute , value in self . dict (). items (): print ( f \"{attribute:<20} {value}\" )","title":"describe"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#dict","text":"def dict ( self , * , include : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , exclude : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , by_alias : bool = False , skip_defaults : bool = None , exclude_unset : bool = False , exclude_defaults : bool = False , exclude_none : bool = False ) -> 'DictStrAny' Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.","title":"dict"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#json","text":"def json ( self , * , include : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , exclude : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , by_alias : bool = False , skip_defaults : bool = None , exclude_unset : bool = False , exclude_defaults : bool = False , exclude_none : bool = False , encoder : Union [ Callable [[ Any ], Any ], NoneType ] = None , ** dumps_kwargs : Any ) -> 'unicode' Generate a JSON representation of the model, include and exclude arguments as per dict() . encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps() .","title":"json"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#to_pandas","text":"def to_pandas ( self , * args , ** kwargs ) -> pandas . core . frame . DataFrame Exports stored values as a pandas DataFrame. Returns: A pandas.DataFrame object with the instance's attributes as columns. View Source def to_pandas ( self , * args , ** kwargs ) -> pd . DataFrame : \"\"\" Exports stored values as a pandas DataFrame. Returns: A `pandas.DataFrame` object with the instance's attributes as columns. \"\"\" return pd . DataFrame ( self . dict ( * args , ** kwargs ))","title":"to_pandas"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#to_string","text":"def to_string ( self , pretty : bool = False ) -> 'unicode'","title":"to_string"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#update_miss_from_cpymad","text":"def update_miss_from_cpymad ( self , cpymad_betabeatings : pandas . core . frame . DataFrame ) -> None Updates a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. View Source def update_miss_from_cpymad ( self , cpymad_betabeatings : pd . DataFrame ) -> None : \"\"\" Updates a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. \"\"\" logger . trace ( \"Getting rms and max values for betatron functions of provided run\" ) self . misserror_bbx . append ( _get_rms ( cpymad_betabeatings [ \"BETX\" ])) self . misserror_bby . append ( _get_rms ( cpymad_betabeatings [ \"BETY\" ])) self . max_misserror_bbx . append ( cpymad_betabeatings [ \"BETX\" ]. max ()) self . max_misserror_bby . append ( cpymad_betabeatings [ \"BETY\" ]. max ()) logger . trace ( \"Getting betatron functions at IP1 and IP5\" ) # cpymad naming : lowercase and appended with : beam_number self . ip1_misserror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip1_misserror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip5_misserror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] ) self . ip5_misserror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] )","title":"update_miss_from_cpymad"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#update_miss_from_seeds","text":"def update_miss_from_seeds ( self , temp_data ) -> None Append computed rms values for a group of seeds, to misalignment result values. Args: temp_data: a BetaBeatValues object with the seeds' results. View Source def update_miss_from_seeds ( self , temp_data ) -> None : \" \"\" Append computed rms values for a group of seeds, to misalignment result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. \"\" \" self . misserror_bbx . append ( _get_rms ( temp_data . misserror_bbx )) self . misserror_bby . append ( _get_rms ( temp_data . misserror_bby )) self . max_misserror_bbx . append ( _get_rms ( temp_data . max_misserror_bbx )) self . max_misserror_bby . append ( _get_rms ( temp_data . max_misserror_bby )) self . ip1_misserror_bbx . append ( _get_rms ( temp_data . ip1_misserror_bbx )) self . ip1_misserror_bby . append ( _get_rms ( temp_data . ip1_misserror_bby )) self . ip5_misserror_bbx . append ( _get_rms ( temp_data . ip5_misserror_bbx )) self . ip5_misserror_bby . append ( _get_rms ( temp_data . ip5_misserror_bby ))","title":"update_miss_from_seeds"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#update_tf_from_cpymad","text":"def update_tf_from_cpymad ( self , cpymad_betabeatings : pandas . core . frame . DataFrame ) -> None This is to update a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. View Source def update_tf_from_cpymad ( self , cpymad_betabeatings : pd . DataFrame ) -> None : \"\"\" This is to update a temporary BetaBeatValues after having ran a simulation for a specific seed. Appends relevant values to the instance's attributes. Args: cpymad_betabeatings (pd.DataFrame): the beta-beatings from the simulation, compared to the nominal twiss from a reference run. \"\"\" logger . trace ( \"Getting rms and max values for betatron functions of provided run\" ) self . tferror_bbx . append ( _get_rms ( cpymad_betabeatings [ \"BETX\" ])) self . tferror_bby . append ( _get_rms ( cpymad_betabeatings [ \"BETY\" ])) self . max_tferror_bbx . append ( cpymad_betabeatings [ \"BETX\" ]. max ()) self . max_tferror_bby . append ( cpymad_betabeatings [ \"BETY\" ]. max ()) logger . trace ( \"Getting betatron functions at IP1 and IP5\" ) # cpymad naming : lowercase and appended with : beam_number self . ip1_tferror_bbx . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip1_tferror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip1:1\" ][ 0 ] ) self . ip5_tferror_bbx . append ( cpymad_betabeatings . BETX [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] ) self . ip5_tferror_bby . append ( cpymad_betabeatings . BETY [ cpymad_betabeatings . NAME == \"ip5:1\" ][ 0 ] )","title":"update_tf_from_cpymad"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#update_tf_from_seeds","text":"def update_tf_from_seeds ( self , temp_data ) -> None Updates the error's beta-beatings values after having ran simulations for all seeds. Append computed rms values for a group of seeds, to field errors result values. Args: temp_data: a BetaBeatValues object with the seeds' results. View Source def update_tf_from_seeds ( self , temp_data ) -> None : \" \"\" Updates the error's beta-beatings values after having ran simulations for all seeds. Append computed rms values for a group of seeds, to field errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. \"\" \" self . tferror_bbx . append ( _get_rms ( temp_data . tferror_bbx )) self . tferror_bby . append ( _get_rms ( temp_data . tferror_bby )) self . max_tferror_bbx . append ( _get_rms ( temp_data . max_tferror_bbx )) self . max_tferror_bby . append ( _get_rms ( temp_data . max_tferror_bby )) self . ip1_tferror_bbx . append ( _get_rms ( temp_data . ip1_tferror_bbx )) self . ip1_tferror_bby . append ( _get_rms ( temp_data . ip1_tferror_bby )) self . ip5_tferror_bbx . append ( _get_rms ( temp_data . ip5_tferror_bbx )) self . ip5_tferror_bby . append ( _get_rms ( temp_data . ip5_tferror_bby ))","title":"update_tf_from_seeds"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#stdevvalues","text":"class StdevValues ( __pydantic_self__ , ** data : Any ) Simple class to store and transfer standard deviation values. Class attributes are as follows: \"stdev_tf_x\": \"Horizontal standard deviation values from field errors\", \"stdev_tf_y\": \"Vertical standard deviation values from field errors\", \"ip1_stdev_tf_x\": \"Horizontal standard deviation values from field errors at IP1\", \"ip1_stdev_tf_y\": \"Vertical standard deviation values from field errors at IP1\", \"ip5_stdev_tf_x\": \"Horizontal standard deviation values from field errors at IP5\", \"ip5_stdev_tf_y\": \"Vertical standard deviation values from field errors at IP5\", \"max_stdev_tf_x\": \"Maximal horizontal standard deviation values from field errors\", \"max_stdev_tf_y\": \"Maximal vertical standard deviation values from field errors\", \"stdev_miss_x\": \"Horizontal standard deviation values from misalignment errors\", \"stdev_miss_y\": \"Horizontal standard deviation values from misalignment errors\", \"ip1_stdev_miss_x\": \"Horizontal standard deviation values from misalignment errors at IP1\", \"ip1_stdev_miss_y\": \"Vertical standard deviation values from misalignment errors at IP1\", \"ip5_stdev_miss_x\": \"Horizontal standard deviation values from misalignment errors at IP5\", \"ip5_stdev_miss_y\": \"Vertical standard deviation values from misalignment errors at IP5\", \"max_stdev_miss_x\": \"Maximal horizontal standard deviation values from misalignment errors\", \"max_stdev_miss_y\": \"Maximal vertical standard deviation values from misalignment errors\", View Source class StdevValues ( BaseModel ) : \"\"\" Simple class to store and transfer standard deviation values. Class attributes are as follows: \" stdev_tf_x \": \" Horizontal standard deviation values from field errors \", \" stdev_tf_y \": \" Vertical standard deviation values from field errors \", \" ip1_stdev_tf_x \": \" Horizontal standard deviation values from field errors at IP1 \", \" ip1_stdev_tf_y \": \" Vertical standard deviation values from field errors at IP1 \", \" ip5_stdev_tf_x \": \" Horizontal standard deviation values from field errors at IP5 \", \" ip5_stdev_tf_y \": \" Vertical standard deviation values from field errors at IP5 \", \" max_stdev_tf_x \": \" Maximal horizontal standard deviation values from field errors \", \" max_stdev_tf_y \": \" Maximal vertical standard deviation values from field errors \", \" stdev_miss_x \": \" Horizontal standard deviation values from misalignment errors \", \" stdev_miss_y \": \" Horizontal standard deviation values from misalignment errors \", \" ip1_stdev_miss_x \": \" Horizontal standard deviation values from misalignment errors at IP1 \", \" ip1_stdev_miss_y \": \" Vertical standard deviation values from misalignment errors at IP1 \", \" ip5_stdev_miss_x \": \" Horizontal standard deviation values from misalignment errors at IP5 \", \" ip5_stdev_miss_y \": \" Vertical standard deviation values from misalignment errors at IP5 \", \" max_stdev_miss_x \": \" Maximal horizontal standard deviation values from misalignment errors \", \" max_stdev_miss_y \": \" Maximal vertical standard deviation values from misalignment errors \", \"\"\" stdev_tf_x : List [ float ] = [] stdev_tf_y : List [ float ] = [] ip1_stdev_tf_x : List [ float ] = [] ip1_stdev_tf_y : List [ float ] = [] ip5_stdev_tf_x : List [ float ] = [] ip5_stdev_tf_y : List [ float ] = [] max_stdev_tf_x : List [ float ] = [] max_stdev_tf_y : List [ float ] = [] stdev_miss_x : List [ float ] = [] stdev_miss_y : List [ float ] = [] ip1_stdev_miss_x : List [ float ] = [] ip1_stdev_miss_y : List [ float ] = [] ip5_stdev_miss_x : List [ float ] = [] ip5_stdev_miss_y : List [ float ] = [] max_stdev_miss_x : List [ float ] = [] max_stdev_miss_y : List [ float ] = [] def describe ( self ) -> None : \"\"\" Simple print statement of instance attributes. \"\"\" for attribute , value in self . dict (). items () : print ( f \"{attribute:<20} {value}\" ) def update_tf ( self , temp_data ) -> None : \"\"\" Append computed stdev values for a group of seeds, to field errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. Returns: Nothing, updates inplace. \"\"\" self . stdev_tf_x . append ( np . std ( temp_data . tferror_bbx )) self . stdev_tf_y . append ( np . std ( temp_data . tferror_bby )) self . max_stdev_tf_x . append ( np . std ( temp_data . max_tferror_bbx )) self . max_stdev_tf_y . append ( np . std ( temp_data . max_tferror_bby )) self . ip1_stdev_tf_x . append ( np . std ( temp_data . ip1_tferror_bbx )) self . ip1_stdev_tf_y . append ( np . std ( temp_data . ip1_tferror_bby )) self . ip5_stdev_tf_x . append ( np . std ( temp_data . ip5_tferror_bbx )) self . ip5_stdev_tf_y . append ( np . std ( temp_data . ip5_tferror_bby )) def update_miss ( self , temp_data ) -> None : \"\"\" Append computed rms values for a group of seeds, to misalignment errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. Returns: Nothing, updates inplace. \"\"\" self . stdev_miss_x . append ( np . std ( temp_data . misserror_bbx )) self . stdev_miss_y . append ( np . std ( temp_data . misserror_bby )) self . max_stdev_miss_x . append ( np . std ( temp_data . max_misserror_bbx )) self . max_stdev_miss_y . append ( np . std ( temp_data . max_misserror_bby )) self . ip1_stdev_miss_x . append ( np . std ( temp_data . ip1_misserror_bbx )) self . ip1_stdev_miss_y . append ( np . std ( temp_data . ip1_misserror_bby )) self . ip5_stdev_miss_x . append ( np . std ( temp_data . ip5_misserror_bbx )) self . ip5_stdev_miss_y . append ( np . std ( temp_data . ip5_misserror_bby )) def to_pandas ( self , * args , ** kwargs ) -> pd . DataFrame : \"\"\" Simple function to export stored values as a pandas dataframe. Returns: A `pandas.DataFrame` object with the instance's attributes as columns. \"\"\" return pd . DataFrame ( self . dict ( * args , ** kwargs ))","title":"StdevValues"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#ancestors-in-mro_1","text":"pydantic.main.BaseModel pydantic.utils.Representation","title":"Ancestors (in MRO)"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#class-variables_1","text":"Config","title":"Class variables"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#construct_1","text":"def construct ( _fields_set : Union [ ForwardRef ( 'SetStr' ), NoneType ] = None , ** values : Any ) -> 'Model' Creates a new model setting dict and fields_set from trusted or pre-validated data. Default values are respected, but no other validation is performed.","title":"construct"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#from_orm_1","text":"def from_orm ( obj : Any ) -> 'Model'","title":"from_orm"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#parse_file_1","text":"def parse_file ( path : Union [ str , pathlib . Path ], * , content_type : 'unicode' = None , encoding : 'unicode' = 'utf8' , proto : pydantic . parse . Protocol = None , allow_pickle : bool = False ) -> 'Model'","title":"parse_file"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#parse_obj_1","text":"def parse_obj ( obj : Any ) -> 'Model'","title":"parse_obj"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#parse_raw_1","text":"def parse_raw ( b : Union [ str , bytes ], * , content_type : 'unicode' = None , encoding : 'unicode' = 'utf8' , proto : pydantic . parse . Protocol = None , allow_pickle : bool = False ) -> 'Model'","title":"parse_raw"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#schema_1","text":"def schema ( by_alias : bool = True , ref_template : 'unicode' = '#/definitions/ {model} ' ) -> 'DictStrAny'","title":"schema"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#schema_json_1","text":"def schema_json ( * , by_alias : bool = True , ref_template : 'unicode' = '#/definitions/ {model} ' , ** dumps_kwargs : Any ) -> 'unicode'","title":"schema_json"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#update_forward_refs_1","text":"def update_forward_refs ( ** localns : Any ) -> None Try to update ForwardRefs on fields based on this Model, globalns and localns.","title":"update_forward_refs"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#validate_1","text":"def validate ( value : Any ) -> 'Model'","title":"validate"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#instance-variables_1","text":"fields","title":"Instance variables"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#methods_1","text":"","title":"Methods"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#copy_1","text":"def copy ( self : 'Model' , * , include : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , exclude : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , update : 'DictStrAny' = None , deep : bool = False ) -> 'Model' Duplicate a model, optionally choose which fields to include, exclude and change. :param include: fields to include in new model :param exclude: fields to exclude from new model, as with values this takes precedence over include :param update: values to change/add in the new model. Note: the data is not validated before creating the new model: you should trust this data :param deep: set to True to make a deep copy of the model :return: new model instance","title":"copy"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#describe_1","text":"def describe ( self ) -> None Simple print statement of instance attributes. View Source def describe ( self ) -> None : \"\"\" Simple print statement of instance attributes. \"\"\" for attribute , value in self . dict (). items (): print ( f \"{attribute:<20} {value}\" )","title":"describe"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#dict_1","text":"def dict ( self , * , include : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , exclude : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , by_alias : bool = False , skip_defaults : bool = None , exclude_unset : bool = False , exclude_defaults : bool = False , exclude_none : bool = False ) -> 'DictStrAny' Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.","title":"dict"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#json_1","text":"def json ( self , * , include : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , exclude : Union [ ForwardRef ( 'AbstractSetIntStr' ), ForwardRef ( 'MappingIntStrAny' )] = None , by_alias : bool = False , skip_defaults : bool = None , exclude_unset : bool = False , exclude_defaults : bool = False , exclude_none : bool = False , encoder : Union [ Callable [[ Any ], Any ], NoneType ] = None , ** dumps_kwargs : Any ) -> 'unicode' Generate a JSON representation of the model, include and exclude arguments as per dict() . encoder is an optional function to supply as default to json.dumps(), other arguments as per json.dumps() .","title":"json"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#to_pandas_1","text":"def to_pandas ( self , * args , ** kwargs ) -> pandas . core . frame . DataFrame Simple function to export stored values as a pandas dataframe. Returns: A pandas.DataFrame object with the instance's attributes as columns. View Source def to_pandas ( self , * args , ** kwargs ) -> pd . DataFrame : \"\"\" Simple function to export stored values as a pandas dataframe. Returns: A `pandas.DataFrame` object with the instance's attributes as columns. \"\"\" return pd . DataFrame ( self . dict ( * args , ** kwargs ))","title":"to_pandas"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#to_string_1","text":"def to_string ( self , pretty : bool = False ) -> 'unicode'","title":"to_string"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#update_miss","text":"def update_miss ( self , temp_data ) -> None Append computed rms values for a group of seeds, to misalignment errors result values. Args: temp_data: a BetaBeatValues object with the seeds' results. Returns: Nothing, updates inplace. View Source def update_miss ( self , temp_data ) -> None : \" \"\" Append computed rms values for a group of seeds, to misalignment errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. Returns: Nothing, updates inplace. \"\" \" self . stdev_miss_x . append ( np . std ( temp_data . misserror_bbx )) self . stdev_miss_y . append ( np . std ( temp_data . misserror_bby )) self . max_stdev_miss_x . append ( np . std ( temp_data . max_misserror_bbx )) self . max_stdev_miss_y . append ( np . std ( temp_data . max_misserror_bby )) self . ip1_stdev_miss_x . append ( np . std ( temp_data . ip1_misserror_bbx )) self . ip1_stdev_miss_y . append ( np . std ( temp_data . ip1_misserror_bby )) self . ip5_stdev_miss_x . append ( np . std ( temp_data . ip5_misserror_bbx )) self . ip5_stdev_miss_y . append ( np . std ( temp_data . ip5_misserror_bby ))","title":"update_miss"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/data_classes/#update_tf","text":"def update_tf ( self , temp_data ) -> None Append computed stdev values for a group of seeds, to field errors result values. Args: temp_data: a BetaBeatValues object with the seeds' results. Returns: Nothing, updates inplace. View Source def update_tf ( self , temp_data ) -> None : \" \"\" Append computed stdev values for a group of seeds, to field errors result values. Args: temp_data: a `BetaBeatValues` object with the seeds' results. Returns: Nothing, updates inplace. \"\" \" self . stdev_tf_x . append ( np . std ( temp_data . tferror_bbx )) self . stdev_tf_y . append ( np . std ( temp_data . tferror_bby )) self . max_stdev_tf_x . append ( np . std ( temp_data . max_tferror_bbx )) self . max_stdev_tf_y . append ( np . std ( temp_data . max_tferror_bby )) self . ip1_stdev_tf_x . append ( np . std ( temp_data . ip1_tferror_bbx )) self . ip1_stdev_tf_y . append ( np . std ( temp_data . ip1_tferror_bby )) self . ip5_stdev_tf_x . append ( np . std ( temp_data . ip5_tferror_bbx )) self . ip5_stdev_tf_y . append ( np . std ( temp_data . ip5_tferror_bby ))","title":"update_tf"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/plotting_functions/","text":"Module pyhdtoolkit.scripts.triplet_errors.plotting_functions Script scripts.triplet_errors.plotting_functions Created on 2019.06.15 :author: Felix Soubelet A collection of functions that will be useful to plot the results from GridCompute Algorithm. View Source \"\"\" Script scripts.triplet_errors.plotting_functions ------------------------------------------------ Created on 2019.06.15 :author: Felix Soubelet A collection of functions that will be useful to plot the results from GridCompute Algorithm. \"\"\" import os import pathlib from typing import List import matplotlib import matplotlib.pyplot as plt import pandas as pd from loguru import logger if os . environ . get ( \"Display\" , \"\" ) == \"\" : logger . warning ( \"Display configuration error found. Using non-interactive Agg backend\" ) matplotlib . use ( \"Agg\" ) def plot_betas_across_machine ( s_values : List [ float ], betx_values : List [ float ], bety_values : List [ float ], error_type : str , error_value : str , ) -> None : \"\"\" Plot beta functions across the machine. Save according to simulation scenario. Creates a plot of the horizontal and vertical beta functions across the whole machine. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: s_values (List[float]): the values of the s axis. betx_values (List[float]): horizontal betatron function values accross the machine. bety_values (List[float]): vertical betatron function values accross the machine. error_type (str): which error you have simulated too get those results. error_value (str): the value of the error you used in your simulations. \"\"\" if error_type == \"TFERROR\" : title = ( f \"r'Beta values, hllhc1.3, 15cm optics, relative field error: {error_value}[$10^{-4}$]'\" ) elif error_type == \"MISERROR\" : title = f \"r'Beta values, hllhc1.3 15cm optics, misalignment: {error_value}[mm]'\" else : logger . warning ( f \"Invalid error parameter {error_type} provided, aborting plot\" ) raise ValueError ( \"Error parameter should be either `TFERROR` or `MISERROR`.\" ) output_dir = pathlib . Path ( \"beta_plots\" ) / f \"{error_type}\" / f \"{error_value}\" if not output_dir . is_dir (): logger . info ( f \"Creating directory {output_dir}\" ) output_dir . mkdir () plt . figure ( figsize = ( 18 , 10 )) plt . title ( title , fontsize = 21 ) plt . xlabel ( \"Position alongside s axis [m]\" , fontsize = 17 ) plt . ylabel ( r \"$\\beta$ value [m]\" , fontsize = 17 ) plt . xticks ( fontsize = 12 ) plt . yticks ( fontsize = 12 ) plt . xlim ( 6500 , max ( s_values )) plt . plot ( s_values , betx_values , label = \"BETX\" ) plt . plot ( s_values , bety_values , label = \"BETY\" ) plt . legend ( loc = \"best\" , fontsize = \"xx-large\" ) plt . savefig ( f \"beta_plots/{error_type}/{error_value}/betas_across_machine.png\" , format = \"png\" , dpi = 300 ) logger . info ( f \"Plotted betas for {error_type} {error_value}\" ) def plot_bbing_max_errorbar ( errors : List [ float ], beta_beatings_df : pd . DataFrame , stdev_df : pd . DataFrame , plane : str , figname : str , ) -> None : \"\"\" Plot beta-beating values, with error bars, as a function of the error values. Save according to plotted plane. Creates a plot of the horizontal or vertical beta-beatings across the range of simulated error values. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: errors (List[float]): the different error values simulated. beta_beatings_df (pd.DataFrame): the resulting beta-beating values. stdev_df (pd.DataFrame): the standard deviations for those values. plane (str): the name of the plane to plot. figname (str): how to name the file when exporting the plot. \"\"\" if plane . lower () == \"horizontal\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bbx , yerr = stdev_df . stdev_tf_x , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bbx , yerr = stdev_df . stdev_miss_x , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . max_tferror_bbx , \"^\" , color = \"C0\" , label = \"Max Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . max_misserror_bbx , \"^\" , color = \"C1\" , label = \"Max Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"Relative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-Beating Against Triplet Errors, {plane} Plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) elif plane . lower () == \"vertical\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bby , yerr = stdev_df . stdev_tf_y , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bby , yerr = stdev_df . stdev_miss_y , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . max_tferror_bby , \"^\" , color = \"C0\" , label = \"Max Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . max_misserror_bby , \"^\" , color = \"C1\" , label = \"Max Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"Relative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-beating against triplet errors, {plane} plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) else : logger . warning ( f \"Invalid plane parameter {plane} provided, aborting plot\" ) raise ValueError ( \"Plane parameter should be either `Horizontal` or `Vertical`\" ) logger . info ( f \"Plotted beta-beatings with error bars for {plane.lower()} plane\" ) def plot_bbing_with_ips_errorbar ( errors : List [ float ], beta_beatings_df : pd . DataFrame , stdev_df : pd . DataFrame , plane : str , figname : str , ) -> None : \"\"\" Plot beta-beating values, with error bars, as a function of the error values. Save according to plotted plane. Creates a plot of the horizontal or vertical beta-beatings across the range of simulated error values, with the addition of the beta-beating value at IPs. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: errors (List[float]): list with different error values simulated. beta_beatings_df (pd.DataFrame): the resulting beta-beating values. stdev_df (pd.DataFrame): the standard deviations for those values. plane (str): the name of the plane to plot. figname (str): how to name the file when exporting the plot. \"\"\" if plane . lower () == \"horizontal\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bbx , yerr = stdev_df . stdev_tf_x , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bbx , yerr = stdev_df . stdev_miss_x , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_tferror_bbx , \"^\" , color = \"C0\" , label = \"IP1 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_misserror_bbx , \"^\" , color = \"C1\" , label = \"IP1 Beta-Beating Value from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_tferror_bbx , \"x\" , color = \"C0\" , label = \"IP5 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_misserror_bbx , \"x\" , color = \"C1\" , label = \"IP5 Beta-Beating Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"Relative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-Beating Against Triplet Errors, {plane} Plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) elif plane . lower () == \"vertical\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bby , yerr = stdev_df . stdev_tf_y , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bby , yerr = stdev_df . stdev_miss_y , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_tferror_bby , \"^\" , color = \"C0\" , label = \"IP1 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_misserror_bby , \"^\" , color = \"C1\" , label = \"IP1 Beta-Beating Value from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_tferror_bby , \"x\" , color = \"C0\" , label = \"IP5 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_misserror_bby , \"x\" , color = \"C1\" , label = \"IP5 Beta-Beating Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"TRelative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-Beating Against Triplet Errors, {plane} Plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) else : logger . warning ( f \"Invalid plane parameter {plane} provided, aborting plot\" ) raise ValueError ( \"Plane parameter should be either `Horizontal` or `Vertical`\" ) logger . info ( f \"Plotted beta-beatings (including IPs) with error bars for {plane.lower()} plane\" ) def plot_intermediate_beta_histograms ( betasx : List [ float ], betasy : List [ float ], error_val : float , title : str , outputname : str ) -> None : \"\"\" Plot histogram distribution for betas at seeds. Args: betasx (List[float]): horizontal beta values for all seeds for a specific error value. betasy (List[float]): vertical beta values for all seeds for a specific error value. error_val (float): the error value. title (str): the title to give the figure. outputname (str): the name to give the file saving the figure. \"\"\" plt . hist ( betasx , bins = 50 , label = f \"{error_val}, horizontal\" , alpha = 0.6 , density = True ) plt . hist ( betasy , bins = 50 , label = f \"{error_val}, vertical\" , alpha = 0.6 , density = True ) plt . legend ( loc = \"best\" ) plt . title ( title ) plt . savefig ( outputname , format = \"png\" , dpi = 300 ) logger . info ( f \"Plotted intermediate beta histogram, saved as {outputname}\" ) Functions plot_bbing_max_errorbar def plot_bbing_max_errorbar ( errors : List [ float ], beta_beatings_df : pandas . core . frame . DataFrame , stdev_df : pandas . core . frame . DataFrame , plane : str , figname : str ) -> None Plot beta-beating values, with error bars, as a function of the error values. Save according to plotted plane. Creates a plot of the horizontal or vertical beta-beatings across the range of simulated error values. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: errors (List[float]): the different error values simulated. beta_beatings_df (pd.DataFrame): the resulting beta-beating values. stdev_df (pd.DataFrame): the standard deviations for those values. plane (str): the name of the plane to plot. figname (str): how to name the file when exporting the plot. View Source def plot_bbing_max_errorbar ( errors : List [ float ] , beta_beatings_df : pd . DataFrame , stdev_df : pd . DataFrame , plane : str , figname : str , ) -> None : \"\"\" Plot beta-beating values, with error bars, as a function of the error values. Save according to plotted plane. Creates a plot of the horizontal or vertical beta-beatings across the range of simulated error values. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: errors (List[float]): the different error values simulated. beta_beatings_df (pd.DataFrame): the resulting beta-beating values. stdev_df (pd.DataFrame): the standard deviations for those values. plane (str): the name of the plane to plot. figname (str): how to name the file when exporting the plot. \"\"\" if plane . lower () == \"horizontal\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bbx , yerr = stdev_df . stdev_tf_x , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bbx , yerr = stdev_df . stdev_miss_x , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . max_tferror_bbx , \"^\" , color = \"C0\" , label = \"Max Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . max_misserror_bbx , \"^\" , color = \"C1\" , label = \"Max Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"Relative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-Beating Against Triplet Errors, {plane} Plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) elif plane . lower () == \"vertical\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bby , yerr = stdev_df . stdev_tf_y , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bby , yerr = stdev_df . stdev_miss_y , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . max_tferror_bby , \"^\" , color = \"C0\" , label = \"Max Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . max_misserror_bby , \"^\" , color = \"C1\" , label = \"Max Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"Relative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-beating against triplet errors, {plane} plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) else : logger . warning ( f \"Invalid plane parameter {plane} provided, aborting plot\" ) raise ValueError ( \"Plane parameter should be either `Horizontal` or `Vertical`\" ) logger . info ( f \"Plotted beta-beatings with error bars for {plane.lower()} plane\" ) plot_bbing_with_ips_errorbar def plot_bbing_with_ips_errorbar ( errors : List [ float ], beta_beatings_df : pandas . core . frame . DataFrame , stdev_df : pandas . core . frame . DataFrame , plane : str , figname : str ) -> None Plot beta-beating values, with error bars, as a function of the error values. Save according to plotted plane. Creates a plot of the horizontal or vertical beta-beatings across the range of simulated error values, with the addition of the beta-beating value at IPs. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: errors (List[float]): list with different error values simulated. beta_beatings_df (pd.DataFrame): the resulting beta-beating values. stdev_df (pd.DataFrame): the standard deviations for those values. plane (str): the name of the plane to plot. figname (str): how to name the file when exporting the plot. View Source def plot_bbing_with_ips_errorbar ( errors : List [ float ] , beta_beatings_df : pd . DataFrame , stdev_df : pd . DataFrame , plane : str , figname : str , ) -> None : \"\"\" Plot beta-beating values, with error bars, as a function of the error values. Save according to plotted plane. Creates a plot of the horizontal or vertical beta-beatings across the range of simulated error values, with the addition of the beta-beating value at IPs. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: errors (List[float]): list with different error values simulated. beta_beatings_df (pd.DataFrame): the resulting beta-beating values. stdev_df (pd.DataFrame): the standard deviations for those values. plane (str): the name of the plane to plot. figname (str): how to name the file when exporting the plot. \"\"\" if plane . lower () == \"horizontal\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bbx , yerr = stdev_df . stdev_tf_x , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bbx , yerr = stdev_df . stdev_miss_x , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_tferror_bbx , \"^\" , color = \"C0\" , label = \"IP1 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_misserror_bbx , \"^\" , color = \"C1\" , label = \"IP1 Beta-Beating Value from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_tferror_bbx , \"x\" , color = \"C0\" , label = \"IP5 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_misserror_bbx , \"x\" , color = \"C1\" , label = \"IP5 Beta-Beating Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"Relative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-Beating Against Triplet Errors, {plane} Plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) elif plane . lower () == \"vertical\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bby , yerr = stdev_df . stdev_tf_y , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bby , yerr = stdev_df . stdev_miss_y , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_tferror_bby , \"^\" , color = \"C0\" , label = \"IP1 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_misserror_bby , \"^\" , color = \"C1\" , label = \"IP1 Beta-Beating Value from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_tferror_bby , \"x\" , color = \"C0\" , label = \"IP5 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_misserror_bby , \"x\" , color = \"C1\" , label = \"IP5 Beta-Beating Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"TRelative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-Beating Against Triplet Errors, {plane} Plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) else : logger . warning ( f \"Invalid plane parameter {plane} provided, aborting plot\" ) raise ValueError ( \"Plane parameter should be either `Horizontal` or `Vertical`\" ) logger . info ( f \"Plotted beta-beatings (including IPs) with error bars for {plane.lower()} plane\" ) plot_betas_across_machine def plot_betas_across_machine ( s_values : List [ float ], betx_values : List [ float ], bety_values : List [ float ], error_type : str , error_value : str ) -> None Plot beta functions across the machine. Save according to simulation scenario. Creates a plot of the horizontal and vertical beta functions across the whole machine. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: s_values (List[float]): the values of the s axis. betx_values (List[float]): horizontal betatron function values accross the machine. bety_values (List[float]): vertical betatron function values accross the machine. error_type (str): which error you have simulated too get those results. error_value (str): the value of the error you used in your simulations. View Source def plot_betas_across_machine ( s_values : List [ float ] , betx_values : List [ float ] , bety_values : List [ float ] , error_type : str , error_value : str , ) -> None : \"\"\" Plot beta functions across the machine. Save according to simulation scenario. Creates a plot of the horizontal and vertical beta functions across the whole machine. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: s_values (List[float]): the values of the s axis. betx_values (List[float]): horizontal betatron function values accross the machine. bety_values (List[float]): vertical betatron function values accross the machine. error_type (str): which error you have simulated too get those results. error_value (str): the value of the error you used in your simulations. \"\"\" if error_type == \"TFERROR\" : title = ( f \"r'Beta values, hllhc1.3, 15cm optics, relative field error: {error_value}[$10^{-4}$]'\" ) elif error_type == \"MISERROR\" : title = f \"r'Beta values, hllhc1.3 15cm optics, misalignment: {error_value}[mm]'\" else : logger . warning ( f \"Invalid error parameter {error_type} provided, aborting plot\" ) raise ValueError ( \"Error parameter should be either `TFERROR` or `MISERROR`.\" ) output_dir = pathlib . Path ( \"beta_plots\" ) / f \"{error_type}\" / f \"{error_value}\" if not output_dir . is_dir () : logger . info ( f \"Creating directory {output_dir}\" ) output_dir . mkdir () plt . figure ( figsize = ( 18 , 10 )) plt . title ( title , fontsize = 21 ) plt . xlabel ( \"Position alongside s axis [m]\" , fontsize = 17 ) plt . ylabel ( r \"$\\beta$ value [m]\" , fontsize = 17 ) plt . xticks ( fontsize = 12 ) plt . yticks ( fontsize = 12 ) plt . xlim ( 6500 , max ( s_values )) plt . plot ( s_values , betx_values , label = \"BETX\" ) plt . plot ( s_values , bety_values , label = \"BETY\" ) plt . legend ( loc = \"best\" , fontsize = \"xx-large\" ) plt . savefig ( f \"beta_plots/{error_type}/{error_value}/betas_across_machine.png\" , format = \"png\" , dpi = 300 ) logger . info ( f \"Plotted betas for {error_type} {error_value}\" ) plot_intermediate_beta_histograms def plot_intermediate_beta_histograms ( betasx : List [ float ], betasy : List [ float ], error_val : float , title : str , outputname : str ) -> None Plot histogram distribution for betas at seeds. Args: betasx (List[float]): horizontal beta values for all seeds for a specific error value. betasy (List[float]): vertical beta values for all seeds for a specific error value. error_val (float): the error value. title (str): the title to give the figure. outputname (str): the name to give the file saving the figure. View Source def plot_intermediate_beta_histograms ( betasx : List [ float ] , betasy : List [ float ] , error_val : float , title : str , outputname : str ) -> None : \"\"\" Plot histogram distribution for betas at seeds. Args: betasx (List[float]): horizontal beta values for all seeds for a specific error value. betasy (List[float]): vertical beta values for all seeds for a specific error value. error_val (float): the error value. title (str): the title to give the figure. outputname (str): the name to give the file saving the figure. \"\"\" plt . hist ( betasx , bins = 50 , label = f \"{error_val}, horizontal\" , alpha = 0.6 , density = True ) plt . hist ( betasy , bins = 50 , label = f \"{error_val}, vertical\" , alpha = 0.6 , density = True ) plt . legend ( loc = \"best\" ) plt . title ( title ) plt . savefig ( outputname , format = \"png\" , dpi = 300 ) logger . info ( f \"Plotted intermediate beta histogram, saved as {outputname}\" )","title":"Plotting Functions"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/plotting_functions/#module-pyhdtoolkitscriptstriplet_errorsplotting_functions","text":"","title":"Module pyhdtoolkit.scripts.triplet_errors.plotting_functions"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/plotting_functions/#script-scriptstriplet_errorsplotting_functions","text":"Created on 2019.06.15 :author: Felix Soubelet A collection of functions that will be useful to plot the results from GridCompute Algorithm. View Source \"\"\" Script scripts.triplet_errors.plotting_functions ------------------------------------------------ Created on 2019.06.15 :author: Felix Soubelet A collection of functions that will be useful to plot the results from GridCompute Algorithm. \"\"\" import os import pathlib from typing import List import matplotlib import matplotlib.pyplot as plt import pandas as pd from loguru import logger if os . environ . get ( \"Display\" , \"\" ) == \"\" : logger . warning ( \"Display configuration error found. Using non-interactive Agg backend\" ) matplotlib . use ( \"Agg\" ) def plot_betas_across_machine ( s_values : List [ float ], betx_values : List [ float ], bety_values : List [ float ], error_type : str , error_value : str , ) -> None : \"\"\" Plot beta functions across the machine. Save according to simulation scenario. Creates a plot of the horizontal and vertical beta functions across the whole machine. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: s_values (List[float]): the values of the s axis. betx_values (List[float]): horizontal betatron function values accross the machine. bety_values (List[float]): vertical betatron function values accross the machine. error_type (str): which error you have simulated too get those results. error_value (str): the value of the error you used in your simulations. \"\"\" if error_type == \"TFERROR\" : title = ( f \"r'Beta values, hllhc1.3, 15cm optics, relative field error: {error_value}[$10^{-4}$]'\" ) elif error_type == \"MISERROR\" : title = f \"r'Beta values, hllhc1.3 15cm optics, misalignment: {error_value}[mm]'\" else : logger . warning ( f \"Invalid error parameter {error_type} provided, aborting plot\" ) raise ValueError ( \"Error parameter should be either `TFERROR` or `MISERROR`.\" ) output_dir = pathlib . Path ( \"beta_plots\" ) / f \"{error_type}\" / f \"{error_value}\" if not output_dir . is_dir (): logger . info ( f \"Creating directory {output_dir}\" ) output_dir . mkdir () plt . figure ( figsize = ( 18 , 10 )) plt . title ( title , fontsize = 21 ) plt . xlabel ( \"Position alongside s axis [m]\" , fontsize = 17 ) plt . ylabel ( r \"$\\beta$ value [m]\" , fontsize = 17 ) plt . xticks ( fontsize = 12 ) plt . yticks ( fontsize = 12 ) plt . xlim ( 6500 , max ( s_values )) plt . plot ( s_values , betx_values , label = \"BETX\" ) plt . plot ( s_values , bety_values , label = \"BETY\" ) plt . legend ( loc = \"best\" , fontsize = \"xx-large\" ) plt . savefig ( f \"beta_plots/{error_type}/{error_value}/betas_across_machine.png\" , format = \"png\" , dpi = 300 ) logger . info ( f \"Plotted betas for {error_type} {error_value}\" ) def plot_bbing_max_errorbar ( errors : List [ float ], beta_beatings_df : pd . DataFrame , stdev_df : pd . DataFrame , plane : str , figname : str , ) -> None : \"\"\" Plot beta-beating values, with error bars, as a function of the error values. Save according to plotted plane. Creates a plot of the horizontal or vertical beta-beatings across the range of simulated error values. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: errors (List[float]): the different error values simulated. beta_beatings_df (pd.DataFrame): the resulting beta-beating values. stdev_df (pd.DataFrame): the standard deviations for those values. plane (str): the name of the plane to plot. figname (str): how to name the file when exporting the plot. \"\"\" if plane . lower () == \"horizontal\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bbx , yerr = stdev_df . stdev_tf_x , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bbx , yerr = stdev_df . stdev_miss_x , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . max_tferror_bbx , \"^\" , color = \"C0\" , label = \"Max Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . max_misserror_bbx , \"^\" , color = \"C1\" , label = \"Max Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"Relative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-Beating Against Triplet Errors, {plane} Plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) elif plane . lower () == \"vertical\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bby , yerr = stdev_df . stdev_tf_y , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bby , yerr = stdev_df . stdev_miss_y , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . max_tferror_bby , \"^\" , color = \"C0\" , label = \"Max Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . max_misserror_bby , \"^\" , color = \"C1\" , label = \"Max Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"Relative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-beating against triplet errors, {plane} plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) else : logger . warning ( f \"Invalid plane parameter {plane} provided, aborting plot\" ) raise ValueError ( \"Plane parameter should be either `Horizontal` or `Vertical`\" ) logger . info ( f \"Plotted beta-beatings with error bars for {plane.lower()} plane\" ) def plot_bbing_with_ips_errorbar ( errors : List [ float ], beta_beatings_df : pd . DataFrame , stdev_df : pd . DataFrame , plane : str , figname : str , ) -> None : \"\"\" Plot beta-beating values, with error bars, as a function of the error values. Save according to plotted plane. Creates a plot of the horizontal or vertical beta-beatings across the range of simulated error values, with the addition of the beta-beating value at IPs. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: errors (List[float]): list with different error values simulated. beta_beatings_df (pd.DataFrame): the resulting beta-beating values. stdev_df (pd.DataFrame): the standard deviations for those values. plane (str): the name of the plane to plot. figname (str): how to name the file when exporting the plot. \"\"\" if plane . lower () == \"horizontal\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bbx , yerr = stdev_df . stdev_tf_x , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bbx , yerr = stdev_df . stdev_miss_x , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_tferror_bbx , \"^\" , color = \"C0\" , label = \"IP1 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_misserror_bbx , \"^\" , color = \"C1\" , label = \"IP1 Beta-Beating Value from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_tferror_bbx , \"x\" , color = \"C0\" , label = \"IP5 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_misserror_bbx , \"x\" , color = \"C1\" , label = \"IP5 Beta-Beating Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"Relative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-Beating Against Triplet Errors, {plane} Plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) elif plane . lower () == \"vertical\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bby , yerr = stdev_df . stdev_tf_y , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bby , yerr = stdev_df . stdev_miss_y , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_tferror_bby , \"^\" , color = \"C0\" , label = \"IP1 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_misserror_bby , \"^\" , color = \"C1\" , label = \"IP1 Beta-Beating Value from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_tferror_bby , \"x\" , color = \"C0\" , label = \"IP5 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_misserror_bby , \"x\" , color = \"C1\" , label = \"IP5 Beta-Beating Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"TRelative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-Beating Against Triplet Errors, {plane} Plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) else : logger . warning ( f \"Invalid plane parameter {plane} provided, aborting plot\" ) raise ValueError ( \"Plane parameter should be either `Horizontal` or `Vertical`\" ) logger . info ( f \"Plotted beta-beatings (including IPs) with error bars for {plane.lower()} plane\" ) def plot_intermediate_beta_histograms ( betasx : List [ float ], betasy : List [ float ], error_val : float , title : str , outputname : str ) -> None : \"\"\" Plot histogram distribution for betas at seeds. Args: betasx (List[float]): horizontal beta values for all seeds for a specific error value. betasy (List[float]): vertical beta values for all seeds for a specific error value. error_val (float): the error value. title (str): the title to give the figure. outputname (str): the name to give the file saving the figure. \"\"\" plt . hist ( betasx , bins = 50 , label = f \"{error_val}, horizontal\" , alpha = 0.6 , density = True ) plt . hist ( betasy , bins = 50 , label = f \"{error_val}, vertical\" , alpha = 0.6 , density = True ) plt . legend ( loc = \"best\" ) plt . title ( title ) plt . savefig ( outputname , format = \"png\" , dpi = 300 ) logger . info ( f \"Plotted intermediate beta histogram, saved as {outputname}\" )","title":"Script scripts.triplet_errors.plotting_functions"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/plotting_functions/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/plotting_functions/#plot_bbing_max_errorbar","text":"def plot_bbing_max_errorbar ( errors : List [ float ], beta_beatings_df : pandas . core . frame . DataFrame , stdev_df : pandas . core . frame . DataFrame , plane : str , figname : str ) -> None Plot beta-beating values, with error bars, as a function of the error values. Save according to plotted plane. Creates a plot of the horizontal or vertical beta-beatings across the range of simulated error values. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: errors (List[float]): the different error values simulated. beta_beatings_df (pd.DataFrame): the resulting beta-beating values. stdev_df (pd.DataFrame): the standard deviations for those values. plane (str): the name of the plane to plot. figname (str): how to name the file when exporting the plot. View Source def plot_bbing_max_errorbar ( errors : List [ float ] , beta_beatings_df : pd . DataFrame , stdev_df : pd . DataFrame , plane : str , figname : str , ) -> None : \"\"\" Plot beta-beating values, with error bars, as a function of the error values. Save according to plotted plane. Creates a plot of the horizontal or vertical beta-beatings across the range of simulated error values. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: errors (List[float]): the different error values simulated. beta_beatings_df (pd.DataFrame): the resulting beta-beating values. stdev_df (pd.DataFrame): the standard deviations for those values. plane (str): the name of the plane to plot. figname (str): how to name the file when exporting the plot. \"\"\" if plane . lower () == \"horizontal\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bbx , yerr = stdev_df . stdev_tf_x , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bbx , yerr = stdev_df . stdev_miss_x , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . max_tferror_bbx , \"^\" , color = \"C0\" , label = \"Max Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . max_misserror_bbx , \"^\" , color = \"C1\" , label = \"Max Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"Relative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-Beating Against Triplet Errors, {plane} Plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) elif plane . lower () == \"vertical\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bby , yerr = stdev_df . stdev_tf_y , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bby , yerr = stdev_df . stdev_miss_y , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . max_tferror_bby , \"^\" , color = \"C0\" , label = \"Max Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . max_misserror_bby , \"^\" , color = \"C1\" , label = \"Max Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"Relative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-beating against triplet errors, {plane} plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) else : logger . warning ( f \"Invalid plane parameter {plane} provided, aborting plot\" ) raise ValueError ( \"Plane parameter should be either `Horizontal` or `Vertical`\" ) logger . info ( f \"Plotted beta-beatings with error bars for {plane.lower()} plane\" )","title":"plot_bbing_max_errorbar"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/plotting_functions/#plot_bbing_with_ips_errorbar","text":"def plot_bbing_with_ips_errorbar ( errors : List [ float ], beta_beatings_df : pandas . core . frame . DataFrame , stdev_df : pandas . core . frame . DataFrame , plane : str , figname : str ) -> None Plot beta-beating values, with error bars, as a function of the error values. Save according to plotted plane. Creates a plot of the horizontal or vertical beta-beatings across the range of simulated error values, with the addition of the beta-beating value at IPs. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: errors (List[float]): list with different error values simulated. beta_beatings_df (pd.DataFrame): the resulting beta-beating values. stdev_df (pd.DataFrame): the standard deviations for those values. plane (str): the name of the plane to plot. figname (str): how to name the file when exporting the plot. View Source def plot_bbing_with_ips_errorbar ( errors : List [ float ] , beta_beatings_df : pd . DataFrame , stdev_df : pd . DataFrame , plane : str , figname : str , ) -> None : \"\"\" Plot beta-beating values, with error bars, as a function of the error values. Save according to plotted plane. Creates a plot of the horizontal or vertical beta-beatings across the range of simulated error values, with the addition of the beta-beating value at IPs. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: errors (List[float]): list with different error values simulated. beta_beatings_df (pd.DataFrame): the resulting beta-beating values. stdev_df (pd.DataFrame): the standard deviations for those values. plane (str): the name of the plane to plot. figname (str): how to name the file when exporting the plot. \"\"\" if plane . lower () == \"horizontal\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bbx , yerr = stdev_df . stdev_tf_x , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bbx , yerr = stdev_df . stdev_miss_x , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_tferror_bbx , \"^\" , color = \"C0\" , label = \"IP1 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_misserror_bbx , \"^\" , color = \"C1\" , label = \"IP1 Beta-Beating Value from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_tferror_bbx , \"x\" , color = \"C0\" , label = \"IP5 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_misserror_bbx , \"x\" , color = \"C1\" , label = \"IP5 Beta-Beating Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"Relative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-Beating Against Triplet Errors, {plane} Plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) elif plane . lower () == \"vertical\" : _ , axes = plt . subplots ( 1 , 1 , figsize = ( 8 , 6 )) axes . errorbar ( errors , beta_beatings_df . tferror_bby , yerr = stdev_df . stdev_tf_y , color = \"C0\" , label = \"Global Beta-Beating from Field Errors\" , ) axes . errorbar ( errors , beta_beatings_df . misserror_bby , yerr = stdev_df . stdev_miss_y , color = \"C1\" , label = \"Global Beta-Beating from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_tferror_bby , \"^\" , color = \"C0\" , label = \"IP1 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip1_misserror_bby , \"^\" , color = \"C1\" , label = \"IP1 Beta-Beating Value from Misalignment Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_tferror_bby , \"x\" , color = \"C0\" , label = \"IP5 Beta-Beating Value from Field Errors\" , ) axes . plot ( errors , beta_beatings_df . ip5_misserror_bby , \"x\" , color = \"C1\" , label = \"IP5 Beta-Beating Value from Misalignment Errors\" , ) axes . set_xlabel ( r \"TRelative Field Error [$10^{-4}$] or Longitudinal Misalignment [mm]\" , fontsize = 15 ) axes . set_ylabel ( r \"$\\Delta \\beta / \\beta$ [%]\" , fontsize = 15 ) plt . tight_layout () plt . title ( f \"Beta-Beating Against Triplet Errors, {plane} Plane\" , fontsize = 15 ) plt . legend ( loc = \"best\" ) plt . savefig ( figname , format = \"png\" , dpi = 300 ) else : logger . warning ( f \"Invalid plane parameter {plane} provided, aborting plot\" ) raise ValueError ( \"Plane parameter should be either `Horizontal` or `Vertical`\" ) logger . info ( f \"Plotted beta-beatings (including IPs) with error bars for {plane.lower()} plane\" )","title":"plot_bbing_with_ips_errorbar"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/plotting_functions/#plot_betas_across_machine","text":"def plot_betas_across_machine ( s_values : List [ float ], betx_values : List [ float ], bety_values : List [ float ], error_type : str , error_value : str ) -> None Plot beta functions across the machine. Save according to simulation scenario. Creates a plot of the horizontal and vertical beta functions across the whole machine. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: s_values (List[float]): the values of the s axis. betx_values (List[float]): horizontal betatron function values accross the machine. bety_values (List[float]): vertical betatron function values accross the machine. error_type (str): which error you have simulated too get those results. error_value (str): the value of the error you used in your simulations. View Source def plot_betas_across_machine ( s_values : List [ float ] , betx_values : List [ float ] , bety_values : List [ float ] , error_type : str , error_value : str , ) -> None : \"\"\" Plot beta functions across the machine. Save according to simulation scenario. Creates a plot of the horizontal and vertical beta functions across the whole machine. Gives a title generated according to the error type and error value. Saves in dedicated subfolder. Args: s_values (List[float]): the values of the s axis. betx_values (List[float]): horizontal betatron function values accross the machine. bety_values (List[float]): vertical betatron function values accross the machine. error_type (str): which error you have simulated too get those results. error_value (str): the value of the error you used in your simulations. \"\"\" if error_type == \"TFERROR\" : title = ( f \"r'Beta values, hllhc1.3, 15cm optics, relative field error: {error_value}[$10^{-4}$]'\" ) elif error_type == \"MISERROR\" : title = f \"r'Beta values, hllhc1.3 15cm optics, misalignment: {error_value}[mm]'\" else : logger . warning ( f \"Invalid error parameter {error_type} provided, aborting plot\" ) raise ValueError ( \"Error parameter should be either `TFERROR` or `MISERROR`.\" ) output_dir = pathlib . Path ( \"beta_plots\" ) / f \"{error_type}\" / f \"{error_value}\" if not output_dir . is_dir () : logger . info ( f \"Creating directory {output_dir}\" ) output_dir . mkdir () plt . figure ( figsize = ( 18 , 10 )) plt . title ( title , fontsize = 21 ) plt . xlabel ( \"Position alongside s axis [m]\" , fontsize = 17 ) plt . ylabel ( r \"$\\beta$ value [m]\" , fontsize = 17 ) plt . xticks ( fontsize = 12 ) plt . yticks ( fontsize = 12 ) plt . xlim ( 6500 , max ( s_values )) plt . plot ( s_values , betx_values , label = \"BETX\" ) plt . plot ( s_values , bety_values , label = \"BETY\" ) plt . legend ( loc = \"best\" , fontsize = \"xx-large\" ) plt . savefig ( f \"beta_plots/{error_type}/{error_value}/betas_across_machine.png\" , format = \"png\" , dpi = 300 ) logger . info ( f \"Plotted betas for {error_type} {error_value}\" )","title":"plot_betas_across_machine"},{"location":"reference/pyhdtoolkit/scripts/triplet_errors/plotting_functions/#plot_intermediate_beta_histograms","text":"def plot_intermediate_beta_histograms ( betasx : List [ float ], betasy : List [ float ], error_val : float , title : str , outputname : str ) -> None Plot histogram distribution for betas at seeds. Args: betasx (List[float]): horizontal beta values for all seeds for a specific error value. betasy (List[float]): vertical beta values for all seeds for a specific error value. error_val (float): the error value. title (str): the title to give the figure. outputname (str): the name to give the file saving the figure. View Source def plot_intermediate_beta_histograms ( betasx : List [ float ] , betasy : List [ float ] , error_val : float , title : str , outputname : str ) -> None : \"\"\" Plot histogram distribution for betas at seeds. Args: betasx (List[float]): horizontal beta values for all seeds for a specific error value. betasy (List[float]): vertical beta values for all seeds for a specific error value. error_val (float): the error value. title (str): the title to give the figure. outputname (str): the name to give the file saving the figure. \"\"\" plt . hist ( betasx , bins = 50 , label = f \"{error_val}, horizontal\" , alpha = 0.6 , density = True ) plt . hist ( betasy , bins = 50 , label = f \"{error_val}, vertical\" , alpha = 0.6 , density = True ) plt . legend ( loc = \"best\" ) plt . title ( title ) plt . savefig ( outputname , format = \"png\" , dpi = 300 ) logger . info ( f \"Plotted intermediate beta histogram, saved as {outputname}\" )","title":"plot_intermediate_beta_histograms"},{"location":"reference/pyhdtoolkit/tfstools/","text":"Module pyhdtoolkit.tfstools tfstools package ~ ~ ~ ~ ~ ~ ~ tfstools is a collection of utilities that integrate within my workflow when manipulating tfs files. :copyright: \u00a9 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. View Source \"\"\" tfstools package ~~~~~~~~~~~~~~~~~~~ tfstools is a collection of utilities that integrate within my workflow when manipulating `tfs` files. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .latwiss import LaTwiss Sub-modules pyhdtoolkit.tfstools.latwiss","title":"Index"},{"location":"reference/pyhdtoolkit/tfstools/#module-pyhdtoolkittfstools","text":"tfstools package ~ ~ ~ ~ ~ ~ ~ tfstools is a collection of utilities that integrate within my workflow when manipulating tfs files. :copyright: \u00a9 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. View Source \"\"\" tfstools package ~~~~~~~~~~~~~~~~~~~ tfstools is a collection of utilities that integrate within my workflow when manipulating `tfs` files. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .latwiss import LaTwiss","title":"Module pyhdtoolkit.tfstools"},{"location":"reference/pyhdtoolkit/tfstools/#sub-modules","text":"pyhdtoolkit.tfstools.latwiss","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/tfstools/latwiss/","text":"Module pyhdtoolkit.tfstools.latwiss Module tfstools.latwiss Created on 2020.10.15 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A collection of functions to elegantly plot the Twiss parameters output of a MADX twiss command, either from a file on disk or a loaded TfsDataFrame. View Source \"\"\" Module tfstools.latwiss -------------------------- Created on 2020.10.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions to elegantly plot the Twiss parameters output of a MADX twiss command, either from a file on disk or a loaded TfsDataFrame. \"\"\" from pathlib import Path from typing import Dict , List , Optional , Tuple , Union import matplotlib import matplotlib.axes import matplotlib.patches as patches import matplotlib.pyplot as plt import pandas as pd import tfs from loguru import logger from pydantic import BaseModel from pyhdtoolkit.plotting.settings import PLOT_PARAMS plt . rcParams . update ( PLOT_PARAMS ) # ----- Plotting Functionality ----- class LaTwiss : \"\"\" A class to manage plotting the machine survey as well as an elegant plot for elements as well as Twiss parameters. \"\"\" @staticmethod def _plot_lattice_series ( ax : matplotlib . axes . Axes , series : pd . DataFrame , height : float = 1.0 , v_offset : float = 0.0 , color : str = \"r\" , alpha : float = 0.5 , lw : int = 3 , ) -> None : \"\"\" Plots the layout of your machine as a patch of rectangles for different element types. Original code from Guido Sterbini. Args: ax (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. series (pd.DataFrame): a dataframe with your elements' data. height (float): value to reach for the patch on the y axis. v_offset (float): vertical offset for the patch. color (str): color kwarg to transmit to pyplot. alpha (float): alpha kwarg to transmit to pyplot. lw (int): linewidth kwarg to transmit to pyplot. Returns: Nothing, acts directly on the provided axis. \"\"\" # pylint: disable=too-many-arguments ax . add_patch ( patches . Rectangle ( ( series . s - series . l , v_offset - height / 2.0 ), series . l , # width height , # height color = color , alpha = alpha , lw = lw , ) ) @staticmethod def plot_latwiss ( twiss_ouptut : Union [ str , Path , tfs . TfsDataFrame , pd . DataFrame ] = None , title : str = None , figsize : Tuple [ int , int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: twiss_ouptut (Union[str, Path, tfs.TfsDataFrame, pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint: disable=too-many-arguments twiss_df : tfs . TfsDataFrame = _get_tfs_dataframe_from_input ( twiss_ouptut ) twiss_df . columns = [ colname . lower () for colname in twiss_df . columns ] _assert_necessary_columns ( twiss_df , columns = [ \"s\" , \"keyword\" , \"betx\" , \"bety\" , \"dx\" , \"dy\" ]) elements_df = _make_survey_groups ( twiss_df ) logger . info ( \"Setting up figure\" ) figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches (takes a third of figure) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( r \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( r \"$\\theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # Plotting dipole patches, beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : _assert_necessary_columns ( twiss_df , columns = [ \"k0l\" , \"angle\" ]) dipoles_df = elements_df [ \"dipoles\" ] logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows (): if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) elif dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : _assert_necessary_columns ( twiss_df , columns = [ \"k1l\" ]) quadrupoles_df = elements_df [ \"quadrupoles\" ] logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows (): LaTwiss . _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : _assert_necessary_columns ( twiss_df , columns = [ \"k2l\" ]) sextupoles_df = elements_df [ \"sextupoles\" ] logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows (): LaTwiss . _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid ( ( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = r \"$\\beta_{x}$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = r \"$\\beta_{y}$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( r \"$\\beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = r \"$D_{x}$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = r \"$D_{y}$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersion [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 350 ) return figure # ----- Helpers ----1- def _get_tfs_dataframe_from_input ( twiss_input : Union [ str , Path , tfs . TfsDataFrame , pd . DataFrame ] ) -> tfs . TfsDataFrame : \"\"\" Args: twiss_input (Union[str, Path, tfs.TfsDataFrame. pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. Returns: A TfsDataFrame or pd.DataFrame with the data. \"\"\" if isinstance ( twiss_input , str ) or isinstance ( twiss_input , Path ): logger . trace ( \"Loading Twiss dataframe from disk\" ) return tfs . read ( Path ( twiss_input )) elif isinstance ( twiss_input , tfs . TfsDataFrame ) or isinstance ( twiss_input , pd . DataFrame ): logger . trace ( \"Copying input dataframe\" ) return twiss_input . copy () else : logger . error ( \"Expected either a string, Path object or TfsDataFrame, but provided input \" f \"was of type '{type(twiss_input)}'\" ) raise ValueError ( f \"Invalid input type for argument 'twiss_input': {type(twiss_input)}\" ) def _assert_necessary_columns ( dataframe : Union [ pd . DataFrame , tfs . TfsDataFrame ], columns : List [ str ] ) -> None : \"\"\" Checks the presence of needed inputs for the latwiss plot in the provided dataframe. Will raise a KeyError if any of them is missing. Args: dataframe (Union[pd.DataFrame, tfs.TfsDataFrame]): the dataframe used for the data. columns (List[str]): list of column names to check for. \"\"\" if any ( colname not in dataframe . columns for colname in columns ): logger . error ( \"Some necessary columns are missing in the provided dataframe. \\n \" f \"The required columns are: {columns} \\n \" f \"The detected columns are: {dataframe.columns.to_numpy()}\" ) raise KeyError ( \"Missing columns in the provided dataframe\" ) def _make_survey_groups ( survey_df : pd . DataFrame ) -> Dict [ str , pd . DataFrame ]: \"\"\" Gets a survey dataframe and returns different sub-dataframes corresponding to different magnetic elements. Args: survey_df (pd.DataFrame): machine survey dataframe obtained from your Madx instance, with <instance>.table.survey.dframe(). Returns: A dictionary containing a dataframe for dipoles, focusing quadrupoles, defocusing quadrupoles, sextupoles and octupoles. The keys are self-explanatory. \"\"\" logger . debug ( \"Getting different element groups dframes from MAD-X survey\" ) return { \"dipoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sbend\" , \"rbend\" ])) & ( survey_df . name . str . contains ( \"B\" , case = False )) ], \"quadrupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) ], \"quad_foc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"F\" , case = False )) ], \"quad_defoc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"D\" , case = False )) ], \"sextupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sextupole\" ])) & ( survey_df . name . str . contains ( \"S\" , case = False )) ], \"octupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"octupole\" ])) & ( survey_df . name . str . contains ( \"O\" , case = False )) ], } Variables PLOT_PARAMS Classes LaTwiss class LaTwiss ( / , * args , ** kwargs ) A class to manage plotting the machine survey as well as an elegant plot for elements as well as Twiss parameters. View Source class LaTwiss : \"\"\" A class to manage plotting the machine survey as well as an elegant plot for elements as well as Twiss parameters. \"\"\" @staticmethod def _plot_lattice_series ( ax : matplotlib . axes . Axes , series : pd . DataFrame , height : float = 1.0 , v_offset : float = 0.0 , color : str = \"r\" , alpha : float = 0.5 , lw : int = 3 , ) -> None : \"\"\" Plots the layout of your machine as a patch of rectangles for different element types. Original code from Guido Sterbini. Args: ax (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. series (pd.DataFrame): a dataframe with your elements' data. height (float): value to reach for the patch on the y axis. v_offset (float): vertical offset for the patch. color (str): color kwarg to transmit to pyplot. alpha (float): alpha kwarg to transmit to pyplot. lw (int): linewidth kwarg to transmit to pyplot. Returns: Nothing, acts directly on the provided axis. \"\"\" # pylint : disable = too - many - arguments ax . add_patch ( patches . Rectangle ( ( series . s - series . l , v_offset - height / 2.0 ), series . l , # width height , # height color = color , alpha = alpha , lw = lw , ) ) @staticmethod def plot_latwiss ( twiss_ouptut : Union [ str, Path, tfs.TfsDataFrame, pd.DataFrame ] = None , title : str = None , figsize : Tuple [ int, int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float, float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float, float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float, float ] = None , k0l_lim : Tuple [ float, float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float, float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: twiss_ouptut (Union[str, Path, tfs.TfsDataFrame, pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments twiss_df : tfs . TfsDataFrame = _get_tfs_dataframe_from_input ( twiss_ouptut ) twiss_df . columns = [ colname.lower() for colname in twiss_df.columns ] _assert_necessary_columns ( twiss_df , columns =[ \"s\", \"keyword\", \"betx\", \"bety\", \"dx\", \"dy\" ] ) elements_df = _make_survey_groups ( twiss_df ) logger . info ( \"Setting up figure\" ) figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches ( takes a third of figure ) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( r \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( r \"$\\theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # Plotting dipole patches , beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : _assert_necessary_columns ( twiss_df , columns =[ \"k0l\", \"angle\" ] ) dipoles_df = elements_df [ \"dipoles\" ] logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows () : if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) elif dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : _assert_necessary_columns ( twiss_df , columns =[ \"k1l\" ] ) quadrupoles_df = elements_df [ \"quadrupoles\" ] logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : _assert_necessary_columns ( twiss_df , columns =[ \"k2l\" ] ) sextupoles_df = elements_df [ \"sextupoles\" ] logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid ( ( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = r \"$\\beta_{x}$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = r \"$\\beta_{y}$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( r \"$\\beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = r \"$D_{x}$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = r \"$D_{y}$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersion [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 350 ) return figure Static methods plot_latwiss def plot_latwiss ( twiss_ouptut : Union [ str , pathlib . Path , tfs . handler . TfsDataFrame , pandas . core . frame . DataFrame ] = None , title : str = None , figsize : Tuple [ int , int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ) ) -> matplotlib . figure . Figure Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: twiss_ouptut (Union[str, Path, tfs.TfsDataFrame, pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_latwiss ( twiss_ouptut : Union [ str, Path, tfs.TfsDataFrame, pd.DataFrame ] = None , title : str = None , figsize : Tuple [ int, int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float, float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float, float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float, float ] = None , k0l_lim : Tuple [ float, float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float, float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: twiss_ouptut (Union[str, Path, tfs.TfsDataFrame, pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments twiss_df : tfs . TfsDataFrame = _get_tfs_dataframe_from_input ( twiss_ouptut ) twiss_df . columns = [ colname.lower() for colname in twiss_df.columns ] _assert_necessary_columns ( twiss_df , columns =[ \"s\", \"keyword\", \"betx\", \"bety\", \"dx\", \"dy\" ] ) elements_df = _make_survey_groups ( twiss_df ) logger . info ( \"Setting up figure\" ) figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches ( takes a third of figure ) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( r \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( r \"$\\theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # Plotting dipole patches , beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : _assert_necessary_columns ( twiss_df , columns =[ \"k0l\", \"angle\" ] ) dipoles_df = elements_df [ \"dipoles\" ] logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows () : if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) elif dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : _assert_necessary_columns ( twiss_df , columns =[ \"k1l\" ] ) quadrupoles_df = elements_df [ \"quadrupoles\" ] logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : _assert_necessary_columns ( twiss_df , columns =[ \"k2l\" ] ) sextupoles_df = elements_df [ \"sextupoles\" ] logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid ( ( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = r \"$\\beta_{x}$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = r \"$\\beta_{y}$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( r \"$\\beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = r \"$D_{x}$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = r \"$D_{y}$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersion [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 350 ) return figure","title":"Latwiss"},{"location":"reference/pyhdtoolkit/tfstools/latwiss/#module-pyhdtoolkittfstoolslatwiss","text":"","title":"Module pyhdtoolkit.tfstools.latwiss"},{"location":"reference/pyhdtoolkit/tfstools/latwiss/#module-tfstoolslatwiss","text":"Created on 2020.10.15 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A collection of functions to elegantly plot the Twiss parameters output of a MADX twiss command, either from a file on disk or a loaded TfsDataFrame. View Source \"\"\" Module tfstools.latwiss -------------------------- Created on 2020.10.15 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection of functions to elegantly plot the Twiss parameters output of a MADX twiss command, either from a file on disk or a loaded TfsDataFrame. \"\"\" from pathlib import Path from typing import Dict , List , Optional , Tuple , Union import matplotlib import matplotlib.axes import matplotlib.patches as patches import matplotlib.pyplot as plt import pandas as pd import tfs from loguru import logger from pydantic import BaseModel from pyhdtoolkit.plotting.settings import PLOT_PARAMS plt . rcParams . update ( PLOT_PARAMS ) # ----- Plotting Functionality ----- class LaTwiss : \"\"\" A class to manage plotting the machine survey as well as an elegant plot for elements as well as Twiss parameters. \"\"\" @staticmethod def _plot_lattice_series ( ax : matplotlib . axes . Axes , series : pd . DataFrame , height : float = 1.0 , v_offset : float = 0.0 , color : str = \"r\" , alpha : float = 0.5 , lw : int = 3 , ) -> None : \"\"\" Plots the layout of your machine as a patch of rectangles for different element types. Original code from Guido Sterbini. Args: ax (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. series (pd.DataFrame): a dataframe with your elements' data. height (float): value to reach for the patch on the y axis. v_offset (float): vertical offset for the patch. color (str): color kwarg to transmit to pyplot. alpha (float): alpha kwarg to transmit to pyplot. lw (int): linewidth kwarg to transmit to pyplot. Returns: Nothing, acts directly on the provided axis. \"\"\" # pylint: disable=too-many-arguments ax . add_patch ( patches . Rectangle ( ( series . s - series . l , v_offset - height / 2.0 ), series . l , # width height , # height color = color , alpha = alpha , lw = lw , ) ) @staticmethod def plot_latwiss ( twiss_ouptut : Union [ str , Path , tfs . TfsDataFrame , pd . DataFrame ] = None , title : str = None , figsize : Tuple [ int , int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: twiss_ouptut (Union[str, Path, tfs.TfsDataFrame, pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint: disable=too-many-arguments twiss_df : tfs . TfsDataFrame = _get_tfs_dataframe_from_input ( twiss_ouptut ) twiss_df . columns = [ colname . lower () for colname in twiss_df . columns ] _assert_necessary_columns ( twiss_df , columns = [ \"s\" , \"keyword\" , \"betx\" , \"bety\" , \"dx\" , \"dy\" ]) elements_df = _make_survey_groups ( twiss_df ) logger . info ( \"Setting up figure\" ) figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches (takes a third of figure) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( r \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( r \"$\\theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # Plotting dipole patches, beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : _assert_necessary_columns ( twiss_df , columns = [ \"k0l\" , \"angle\" ]) dipoles_df = elements_df [ \"dipoles\" ] logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows (): if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) elif dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : _assert_necessary_columns ( twiss_df , columns = [ \"k1l\" ]) quadrupoles_df = elements_df [ \"quadrupoles\" ] logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows (): LaTwiss . _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : _assert_necessary_columns ( twiss_df , columns = [ \"k2l\" ]) sextupoles_df = elements_df [ \"sextupoles\" ] logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows (): LaTwiss . _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid ( ( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = r \"$\\beta_{x}$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = r \"$\\beta_{y}$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( r \"$\\beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = r \"$D_{x}$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = r \"$D_{y}$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersion [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 350 ) return figure # ----- Helpers ----1- def _get_tfs_dataframe_from_input ( twiss_input : Union [ str , Path , tfs . TfsDataFrame , pd . DataFrame ] ) -> tfs . TfsDataFrame : \"\"\" Args: twiss_input (Union[str, Path, tfs.TfsDataFrame. pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. Returns: A TfsDataFrame or pd.DataFrame with the data. \"\"\" if isinstance ( twiss_input , str ) or isinstance ( twiss_input , Path ): logger . trace ( \"Loading Twiss dataframe from disk\" ) return tfs . read ( Path ( twiss_input )) elif isinstance ( twiss_input , tfs . TfsDataFrame ) or isinstance ( twiss_input , pd . DataFrame ): logger . trace ( \"Copying input dataframe\" ) return twiss_input . copy () else : logger . error ( \"Expected either a string, Path object or TfsDataFrame, but provided input \" f \"was of type '{type(twiss_input)}'\" ) raise ValueError ( f \"Invalid input type for argument 'twiss_input': {type(twiss_input)}\" ) def _assert_necessary_columns ( dataframe : Union [ pd . DataFrame , tfs . TfsDataFrame ], columns : List [ str ] ) -> None : \"\"\" Checks the presence of needed inputs for the latwiss plot in the provided dataframe. Will raise a KeyError if any of them is missing. Args: dataframe (Union[pd.DataFrame, tfs.TfsDataFrame]): the dataframe used for the data. columns (List[str]): list of column names to check for. \"\"\" if any ( colname not in dataframe . columns for colname in columns ): logger . error ( \"Some necessary columns are missing in the provided dataframe. \\n \" f \"The required columns are: {columns} \\n \" f \"The detected columns are: {dataframe.columns.to_numpy()}\" ) raise KeyError ( \"Missing columns in the provided dataframe\" ) def _make_survey_groups ( survey_df : pd . DataFrame ) -> Dict [ str , pd . DataFrame ]: \"\"\" Gets a survey dataframe and returns different sub-dataframes corresponding to different magnetic elements. Args: survey_df (pd.DataFrame): machine survey dataframe obtained from your Madx instance, with <instance>.table.survey.dframe(). Returns: A dictionary containing a dataframe for dipoles, focusing quadrupoles, defocusing quadrupoles, sextupoles and octupoles. The keys are self-explanatory. \"\"\" logger . debug ( \"Getting different element groups dframes from MAD-X survey\" ) return { \"dipoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sbend\" , \"rbend\" ])) & ( survey_df . name . str . contains ( \"B\" , case = False )) ], \"quadrupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) ], \"quad_foc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"F\" , case = False )) ], \"quad_defoc\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"quadrupole\" ])) & ( survey_df . name . str . contains ( \"Q\" , case = False )) & ( survey_df . name . str . contains ( \"D\" , case = False )) ], \"sextupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"sextupole\" ])) & ( survey_df . name . str . contains ( \"S\" , case = False )) ], \"octupoles\" : survey_df [ ( survey_df . keyword . isin ([ \"multipole\" , \"octupole\" ])) & ( survey_df . name . str . contains ( \"O\" , case = False )) ], }","title":"Module tfstools.latwiss"},{"location":"reference/pyhdtoolkit/tfstools/latwiss/#variables","text":"PLOT_PARAMS","title":"Variables"},{"location":"reference/pyhdtoolkit/tfstools/latwiss/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/tfstools/latwiss/#latwiss","text":"class LaTwiss ( / , * args , ** kwargs ) A class to manage plotting the machine survey as well as an elegant plot for elements as well as Twiss parameters. View Source class LaTwiss : \"\"\" A class to manage plotting the machine survey as well as an elegant plot for elements as well as Twiss parameters. \"\"\" @staticmethod def _plot_lattice_series ( ax : matplotlib . axes . Axes , series : pd . DataFrame , height : float = 1.0 , v_offset : float = 0.0 , color : str = \"r\" , alpha : float = 0.5 , lw : int = 3 , ) -> None : \"\"\" Plots the layout of your machine as a patch of rectangles for different element types. Original code from Guido Sterbini. Args: ax (matplotlib.axes.Axes): an existing matplotlib.axis `Axes` object to act on. series (pd.DataFrame): a dataframe with your elements' data. height (float): value to reach for the patch on the y axis. v_offset (float): vertical offset for the patch. color (str): color kwarg to transmit to pyplot. alpha (float): alpha kwarg to transmit to pyplot. lw (int): linewidth kwarg to transmit to pyplot. Returns: Nothing, acts directly on the provided axis. \"\"\" # pylint : disable = too - many - arguments ax . add_patch ( patches . Rectangle ( ( series . s - series . l , v_offset - height / 2.0 ), series . l , # width height , # height color = color , alpha = alpha , lw = lw , ) ) @staticmethod def plot_latwiss ( twiss_ouptut : Union [ str, Path, tfs.TfsDataFrame, pd.DataFrame ] = None , title : str = None , figsize : Tuple [ int, int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float, float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float, float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float, float ] = None , k0l_lim : Tuple [ float, float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float, float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: twiss_ouptut (Union[str, Path, tfs.TfsDataFrame, pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments twiss_df : tfs . TfsDataFrame = _get_tfs_dataframe_from_input ( twiss_ouptut ) twiss_df . columns = [ colname.lower() for colname in twiss_df.columns ] _assert_necessary_columns ( twiss_df , columns =[ \"s\", \"keyword\", \"betx\", \"bety\", \"dx\", \"dy\" ] ) elements_df = _make_survey_groups ( twiss_df ) logger . info ( \"Setting up figure\" ) figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches ( takes a third of figure ) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( r \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( r \"$\\theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # Plotting dipole patches , beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : _assert_necessary_columns ( twiss_df , columns =[ \"k0l\", \"angle\" ] ) dipoles_df = elements_df [ \"dipoles\" ] logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows () : if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) elif dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : _assert_necessary_columns ( twiss_df , columns =[ \"k1l\" ] ) quadrupoles_df = elements_df [ \"quadrupoles\" ] logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : _assert_necessary_columns ( twiss_df , columns =[ \"k2l\" ] ) sextupoles_df = elements_df [ \"sextupoles\" ] logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid ( ( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = r \"$\\beta_{x}$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = r \"$\\beta_{y}$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( r \"$\\beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = r \"$D_{x}$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = r \"$D_{y}$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersion [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 350 ) return figure","title":"LaTwiss"},{"location":"reference/pyhdtoolkit/tfstools/latwiss/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/tfstools/latwiss/#plot_latwiss","text":"def plot_latwiss ( twiss_ouptut : Union [ str , pathlib . Path , tfs . handler . TfsDataFrame , pandas . core . frame . DataFrame ] = None , title : str = None , figsize : Tuple [ int , int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float , float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float , float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float , float ] = None , k0l_lim : Tuple [ float , float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float , float ] = ( - 0.08 , 0.08 ) ) -> matplotlib . figure . Figure Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: twiss_ouptut (Union[str, Path, tfs.TfsDataFrame, pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. View Source @staticmethod def plot_latwiss ( twiss_ouptut : Union [ str, Path, tfs.TfsDataFrame, pd.DataFrame ] = None , title : str = None , figsize : Tuple [ int, int ] = ( 16 , 10 ), savefig : str = None , xlimits : Tuple [ float, float ] = None , plot_dipoles : bool = True , plot_quadrupoles : bool = True , plot_sextupoles : bool = False , disp_ylim : Tuple [ float, float ] = ( - 10 , 125 ), beta_ylim : Tuple [ float, float ] = None , k0l_lim : Tuple [ float, float ] = ( - 0.25 , 0.25 ), k1l_lim : Tuple [ float, float ] = ( - 0.08 , 0.08 ), ) -> matplotlib . figure . Figure : \"\"\" Provided with an active Cpymad class after having ran a script, will create a plot representing nicely the lattice layout and the beta functions along with the horizontal dispertion function. This is heavily refactored code, but the original is from Guido Sterbini. WARNING: This will FAIL if you have not included 'q' or 'Q' in your quadrupoles' names, and 'b' or 'B' in your dipoles' names when defining your MAD-X sequence. Args: twiss_ouptut (Union[str, Path, tfs.TfsDataFrame, pd.DataFrame]): the output of the MADX twiss command, either loaded as a tfs.TfsDataFrame or the location of the output file on disk. title (str): title of your plot. figsize (Tuple[int, int]): size of the figure, defaults to (16, 10). savefig (str): will save the figure if this is not None, using the string value passed. xlimits (Tuple[float, float]): will implement xlim (for the s coordinate) if this is not None, using the tuple passed. plot_dipoles (bool): if True, dipole patches will be plotted on the layout subplot of the figure. Defaults to True. Dipoles are plotted in blue. plot_quadrupoles (bool): if True, quadrupole patches will be plotted on the layout subplot of the figure. Defaults to True. Quadrupoles are plotted in red. plot_sextupoles (bool): if True, sextupole patches will be plotted on the layout subplot of the figure. Defaults to False. Sextupoles are plotted in yellow. disp_ylim (Tuple[float, float]): vertical axis limits for the dispersion values. Defaults to (-10, 125). beta_ylim (Tuple[float, float]): vertical axis limits for the betatron function values. Defaults to None, to be determined by matplotlib based on the provided beta values. k0l_lim (Tuple[float, float]): vertical axis limits for the k0l values used for the height of dipole patches. Defaults to (-0.25, 0.25). k1l_lim (Tuple[float, float]): vertical axis limits for the k1l values used for the height of quadrupole patches. Defaults to (-0.08, 0.08). Returns: The figure on which the plots are drawn. The underlying axes can be accessed with 'fig.get_axes()'. Eventually saves the figure as a file. \"\"\" # pylint : disable = too - many - arguments twiss_df : tfs . TfsDataFrame = _get_tfs_dataframe_from_input ( twiss_ouptut ) twiss_df . columns = [ colname.lower() for colname in twiss_df.columns ] _assert_necessary_columns ( twiss_df , columns =[ \"s\", \"keyword\", \"betx\", \"bety\", \"dx\", \"dy\" ] ) elements_df = _make_survey_groups ( twiss_df ) logger . info ( \"Setting up figure\" ) figure = plt . figure ( figsize = figsize ) # Create a subplot for the lattice patches ( takes a third of figure ) logger . trace ( \"Setting up element patches subplots\" ) quadrupole_patches_axis = plt . subplot2grid (( 3 , 3 ), ( 0 , 0 ), colspan = 3 , rowspan = 1 ) dipole_patches_axis = quadrupole_patches_axis . twinx () quadrupole_patches_axis . set_ylabel ( r \"1/f=K1L [m$^{-1}$]\" , color = \"red\" ) # quadrupole in red quadrupole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"red\" ) dipole_patches_axis . set_ylabel ( r \"$\\theta$=K0L [rad]\" , color = \"blue\" ) # dipoles in blue dipole_patches_axis . tick_params ( axis = \"y\" , labelcolor = \"blue\" ) quadrupole_patches_axis . set_ylim ( k1l_lim ) dipole_patches_axis . set_ylim ( k0l_lim ) dipole_patches_axis . grid ( False ) quadrupole_patches_axis . set_title ( title ) quadrupole_patches_axis . plot ( twiss_df . s , 0 * twiss_df . s , \"k\" ) # Plotting dipole patches , beware 'sbend' and 'rbend' have an 'angle' value and not a 'k0l' if plot_dipoles : _assert_necessary_columns ( twiss_df , columns =[ \"k0l\", \"angle\" ] ) dipoles_df = elements_df [ \"dipoles\" ] logger . debug ( \"Plotting dipole patches\" ) for _ , dipole in dipoles_df . iterrows () : if dipole . k0l != 0 : logger . trace ( \"Plotting dipole element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . k0l , v_offset = dipole . k0l / 2 , color = \"b\" , ) elif dipole . angle != 0 : logger . trace ( \"Plotting 'sbend' / 'rbend' element\" ) LaTwiss . _plot_lattice_series ( dipole_patches_axis , dipole , height = dipole . angle , v_offset = dipole . angle / 2 , color = \"b\" , ) # Plotting the quadrupole patches if plot_quadrupoles : _assert_necessary_columns ( twiss_df , columns =[ \"k1l\" ] ) quadrupoles_df = elements_df [ \"quadrupoles\" ] logger . debug ( \"Plotting quadrupole patches\" ) for _ , quad in quadrupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( quadrupole_patches_axis , quad , height = quad . k1l , v_offset = quad . k1l / 2 , color = \"r\" ) # Plotting the sextupole patches if plot_sextupoles : _assert_necessary_columns ( twiss_df , columns =[ \"k2l\" ] ) sextupoles_df = elements_df [ \"sextupoles\" ] logger . debug ( \"Plotting sextupole patches\" ) for _ , sext in sextupoles_df . iterrows () : LaTwiss . _plot_lattice_series ( dipole_patches_axis , sext , height = sext . k2l , v_offset = sext . k2l / 2 , color = \"y\" ) # Plotting beta functions on remaining two thirds of the figure logger . trace ( \"Setting up betatron functions subplot\" ) betatron_axis = plt . subplot2grid ( ( 3 , 3 ), ( 1 , 0 ), colspan = 3 , rowspan = 2 , sharex = quadrupole_patches_axis ) betatron_axis . plot ( twiss_df . s , twiss_df . betx , label = r \"$\\beta_{x}$\" , lw = 1.5 ) betatron_axis . plot ( twiss_df . s , twiss_df . bety , label = r \"$\\beta_{y}$\" , lw = 1.5 ) betatron_axis . legend ( loc = 2 ) betatron_axis . set_ylabel ( r \"$\\beta$-functions [m]\" ) if beta_ylim : logger . debug ( \"Setting ylim for betatron functions plot\" ) betatron_axis . set_ylim ( beta_ylim ) betatron_axis . set_xlabel ( \"s [m]\" ) # Plotting the dispersion logger . trace ( \"Setting up dispersion functions subplot\" ) dispertion_axis = betatron_axis . twinx () dispertion_axis . plot ( twiss_df . s , twiss_df . dx , color = \"brown\" , label = r \"$D_{x}$\" , lw = 2 ) dispertion_axis . plot ( twiss_df . s , twiss_df . dy , ls = \"-.\" , color = \"sienna\" , label = r \"$D_{y}$\" , lw = 2 ) dispertion_axis . legend ( loc = 1 ) dispertion_axis . set_ylabel ( \"Dispersion [m]\" , color = \"brown\" ) dispertion_axis . tick_params ( axis = \"y\" , labelcolor = \"brown\" ) dispertion_axis . grid ( False ) if disp_ylim : logger . debug ( \"Setting ylim for dispersion plot\" ) dispertion_axis . set_ylim ( disp_ylim ) if xlimits : logger . debug ( \"Setting xlim for longitudinal coordinate\" ) plt . xlim ( xlimits ) if savefig : logger . info ( f \"Saving latwiss plot as {savefig}\" ) plt . savefig ( savefig , format = \"png\" , dpi = 350 ) return figure","title":"plot_latwiss"},{"location":"reference/pyhdtoolkit/utils/","text":"Module pyhdtoolkit.utils utils package ~ ~ ~ ~ ~ ~ ~ These are miscellaneous modules with functions that sometime tunr out useful to my workflow. These are mainly wrappers around lower-level tools, or simply just additional niceties. :copyright: \u00a9 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. View Source \"\"\" utils package ~~~~~~~~~~~~~~~~~~~ These are miscellaneous modules with functions that sometime tunr out useful to my workflow. These are mainly wrappers around lower-level tools, or simply just additional niceties. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .cmdline import CommandLine from .executors import MultiProcessor , MultiThreader from .printutil import END , Background , Foreground , Styles Sub-modules pyhdtoolkit.utils.cmdline pyhdtoolkit.utils.contexts pyhdtoolkit.utils.defaults pyhdtoolkit.utils.executors pyhdtoolkit.utils.operations pyhdtoolkit.utils.printutil Variables python3 END","title":"Index"},{"location":"reference/pyhdtoolkit/utils/#module-pyhdtoolkitutils","text":"utils package ~ ~ ~ ~ ~ ~ ~ These are miscellaneous modules with functions that sometime tunr out useful to my workflow. These are mainly wrappers around lower-level tools, or simply just additional niceties. :copyright: \u00a9 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. View Source \"\"\" utils package ~~~~~~~~~~~~~~~~~~~ These are miscellaneous modules with functions that sometime tunr out useful to my workflow. These are mainly wrappers around lower-level tools, or simply just additional niceties. :copyright: (c) 2019 by Felix Soubelet. :license: MIT, see LICENSE for more details. \"\"\" from .cmdline import CommandLine from .executors import MultiProcessor , MultiThreader from .printutil import END , Background , Foreground , Styles","title":"Module pyhdtoolkit.utils"},{"location":"reference/pyhdtoolkit/utils/#sub-modules","text":"pyhdtoolkit.utils.cmdline pyhdtoolkit.utils.contexts pyhdtoolkit.utils.defaults pyhdtoolkit.utils.executors pyhdtoolkit.utils.operations pyhdtoolkit.utils.printutil","title":"Sub-modules"},{"location":"reference/pyhdtoolkit/utils/#variables","text":"python3 END","title":"Variables"},{"location":"reference/pyhdtoolkit/utils/cmdline/","text":"Module pyhdtoolkit.utils.cmdline Module utils.cmdline Created on 2019.11.06 :author: Felix Soubelet ( felix.soubelet@cern.ch ) Utility script to help run commands and access the commandline. View Source \"\"\" Module utils.cmdline -------------------- Created on 2019.11.06 :author: Felix Soubelet (felix.soubelet@cern.ch) Utility script to help run commands and access the commandline. \"\"\" import errno import os import signal import subprocess from typing import Mapping , Optional , Tuple from loguru import logger from pyhdtoolkit.utils.contexts import timeit class CommandLine : \"\"\" A high-level object to encapsulate the different methods for interacting with the commandline. \"\"\" @staticmethod def check_pid_exists ( pid : int ) -> bool : \"\"\" Check whether the given PID exists in the current process table. Args: pid (int): the Process ID you want to check. Returns: A boolean stating the result. \"\"\" if pid == 0 : # According to \"man 2 kill\", PID 0 refers to <<every process in the process group of # the calling process>>. Best not to go any further. logger . warning ( \"PID 0 refers to 'every process in calling processes', and should be untouched\" ) return True try : # Sending SIG 0 only checks if process has terminated, we're not actually terminating it os . kill ( pid , 0 ) except OSError as pid_checkout_error : if pid_checkout_error . errno == errno . ESRCH : # ERROR \"No such process\" return False if ( pid_checkout_error . errno == errno . EPERM ): # ERROR \"Operation not permitted\" -> there's a process to deny access to. return True # According to \"man 2 kill\" possible error values are (EINVAL, EPERM, ESRCH), therefore # we should never get here. If so let's be explicit in considering this an error. logger . exception ( \"Could not figure out the provided PID for some reason\" ) raise pid_checkout_error return True @staticmethod def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Optional [ int ], bytes ]: \"\"\" Run command based on `subprocess.Popen` and return the tuple of `(returncode, stdout)`. Note that `stderr` is redirected to `stdout`. `shell` is same to parameter of `Popen`. If the process does not terminate after `timeout` seconds, a `TimeoutExpired` exception will be raised. Args: command (str): string, the command you want to run. shell (bool): same as `Popen` argument. Setting the shell argument to a true value causes subprocess to spawn an intermediate shell process, and tell it to run the command. In other words, using an intermediate shell means that variables, glob patterns, and other special shell features in the command string are processed before the command is ran. Defaults to True. env (Mapping): mapping that defines the environment variables for the new process. timeout (float): same as `Popen.communicate` argument, number of seconds to wait for a response before raising a TimeoutExpired exception. Returns: The tuple of (returncode, stdout). Beware, the stdout will be a byte array (id est b'some returned text'). This output, returned as stdout, needs to be decoded properly before you do anything with it, especially if you intend to log it into a file. While it will most likely be 'utf-8', the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on. Usage: CommandLine.run('echo hello') -> (0, b'hello\\r\\n') modified_env = os.environ.copy() modified_env['ENV_VAR'] = new_value CommandLine.run('echo $ENV_VAR', env=modified_env) -> (0, b'new_value') \"\"\" with timeit ( lambda spanned : logger . info ( f \"Ran command '{command}' in a subprocess, in: {spanned:.4f} seconds\" ) ): process = subprocess . Popen ( command , shell = shell , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , env = env ) stdout , _ = process . communicate ( timeout = timeout ) if process . poll () != 0 : logger . warning ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) else : logger . success ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) return process . poll (), stdout @staticmethod def terminate ( pid : int ) -> bool : \"\"\" Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Args: pid (int): the process ID to kill. Returns: A boolean stating the success of the operation. \"\"\" if CommandLine . check_pid_exists ( pid ): os . kill ( pid , signal . SIGTERM ) logger . debug ( f \"Process {pid} has successfully been terminated.\" ) return True logger . error ( f \"Process with ID {pid} could not be terminated.\" ) return False Classes CommandLine class CommandLine ( / , * args , ** kwargs ) A high-level object to encapsulate the different methods for interacting with the commandline. View Source class CommandLine : \" \"\" A high-level object to encapsulate the different methods for interacting with the commandline. \"\" \" @staticmethod def check_pid_exists ( pid : int ) -> bool : \" \"\" Check whether the given PID exists in the current process table. Args: pid (int): the Process ID you want to check. Returns: A boolean stating the result. \"\" \" if pid == 0 : # According to \"man 2 kill\", PID 0 refers to <<every process in the process group of # the calling process>>. Best not to go any further. logger . warning ( \"PID 0 refers to 'every process in calling processes', and should be untouched\" ) return True try : # Sending SIG 0 only checks if process has terminated, we're not actually terminating it os . kill ( pid , 0 ) except OSError as pid_checkout_error : if pid_checkout_error . errno == errno . ESRCH : # ERROR \"No such process\" return False if ( pid_checkout_error . errno == errno . EPERM ) : # ERROR \"Operation not permitted\" -> there's a process to deny access to. return True # According to \"man 2 kill\" possible error values are (EINVAL, EPERM, ESRCH), therefore # we should never get here. If so let's be explicit in considering this an error. logger . exception ( \"Could not figure out the provided PID for some reason\" ) raise pid_checkout_error return True @staticmethod def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Optional [ int ] , bytes ] : \" \"\" Run command based on `subprocess.Popen` and return the tuple of `(returncode, stdout)`. Note that `stderr` is redirected to `stdout`. `shell` is same to parameter of `Popen`. If the process does not terminate after `timeout` seconds, a `TimeoutExpired` exception will be raised. Args: command (str): string, the command you want to run. shell (bool): same as `Popen` argument. Setting the shell argument to a true value causes subprocess to spawn an intermediate shell process, and tell it to run the command. In other words, using an intermediate shell means that variables, glob patterns, and other special shell features in the command string are processed before the command is ran. Defaults to True. env (Mapping): mapping that defines the environment variables for the new process. timeout (float): same as `Popen.communicate` argument, number of seconds to wait for a response before raising a TimeoutExpired exception. Returns: The tuple of (returncode, stdout). Beware, the stdout will be a byte array (id est b'some returned text'). This output, returned as stdout, needs to be decoded properly before you do anything with it, especially if you intend to log it into a file. While it will most likely be 'utf-8', the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on. Usage: CommandLine.run('echo hello') -> (0, b'hello \\r\\n ') modified_env = os.environ.copy() modified_env['ENV_VAR'] = new_value CommandLine.run('echo $ENV_VAR', env=modified_env) -> (0, b'new_value') \"\" \" with timeit ( lambda spanned : logger . info ( f \"Ran command '{command}' in a subprocess, in: {spanned:.4f} seconds\" ) ) : process = subprocess . Popen ( command , shell = shell , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , env = env ) stdout , _ = process . communicate ( timeout = timeout ) if process . poll () != 0 : logger . warning ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) else : logger . success ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) return process . poll (), stdout @staticmethod def terminate ( pid : int ) -> bool : \" \"\" Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Args: pid (int): the process ID to kill. Returns: A boolean stating the success of the operation. \"\" \" if CommandLine . check_pid_exists ( pid ) : os . kill ( pid , signal . SIGTERM ) logger . debug ( f \"Process {pid} has successfully been terminated.\" ) return True logger . error ( f \"Process with ID {pid} could not be terminated.\" ) return False Static methods check_pid_exists def check_pid_exists ( pid : int ) -> bool Check whether the given PID exists in the current process table. Args: pid (int): the Process ID you want to check. Returns: A boolean stating the result. View Source @staticmethod def check_pid_exists ( pid : int ) -> bool : \"\"\" Check whether the given PID exists in the current process table. Args: pid (int): the Process ID you want to check. Returns: A boolean stating the result. \"\"\" if pid == 0 : # According to \"man 2 kill\" , PID 0 refers to << every process in the process group of # the calling process >> . Best not to go any further . logger . warning ( \"PID 0 refers to 'every process in calling processes', and should be untouched\" ) return True try : # Sending SIG 0 only checks if process has terminated , we 're not actually terminating it os.kill(pid, 0) except OSError as pid_checkout_error: if pid_checkout_error.errno == errno.ESRCH: # ERROR \"No such process\" return False if ( pid_checkout_error.errno == errno.EPERM ): # ERROR \"Operation not permitted\" -> there' s a process to deny access to . return True # According to \"man 2 kill\" possible error values are ( EINVAL , EPERM , ESRCH ), therefore # we should never get here . If so let ' s be explicit in considering this an error . logger . exception ( \"Could not figure out the provided PID for some reason\" ) raise pid_checkout_error return True run def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Union [ int , NoneType ], bytes ] Run command based on subprocess.Popen and return the tuple of (returncode, stdout) . Note that stderr is redirected to stdout . shell is same to parameter of Popen . If the process does not terminate after timeout seconds, a TimeoutExpired exception will be raised. Args : command ( str ) : string , the command you want to run . shell ( bool ) : same as `Popen` argument . Set ting the shell argument to a true value causes subprocess to spawn an intermediate shell process , and tell it to run the command . In other words , using an intermediate shell means that variables , glob patterns , and other special shell features in the command string are processed before the command is ran . Defaults to True . env ( Mapping ) : mapping that defines the environment variables for the new process . timeout ( float ) : same as `Popen.communicate` argument , number of seconds to wait for a response before raising a TimeoutExpired exception . Returns : The tuple of ( returncode , stdout ). Beware , the stdout will be a byte array ( id est b 'some returned text' ). This output , returned as stdout , needs to be decoded properly before you do anything with it , especially if you intend to log it into a file . While it will most likely be 'utf-8' , the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on . Usage : CommandLine . run ( 'echo hello' ) -> ( 0 , b 'hello ') modified_env = os.environ.copy() modified_env['ENV_VAR'] = new_value CommandLine.run('echo $ENV_VAR', env=modified_env) -> (0, b'new_value') View Source @staticmethod def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Optional [ int ] , bytes ] : \" \"\" Run command based on `subprocess.Popen` and return the tuple of `(returncode, stdout)`. Note that `stderr` is redirected to `stdout`. `shell` is same to parameter of `Popen`. If the process does not terminate after `timeout` seconds, a `TimeoutExpired` exception will be raised. Args: command (str): string, the command you want to run. shell (bool): same as `Popen` argument. Setting the shell argument to a true value causes subprocess to spawn an intermediate shell process, and tell it to run the command. In other words, using an intermediate shell means that variables, glob patterns, and other special shell features in the command string are processed before the command is ran. Defaults to True. env (Mapping): mapping that defines the environment variables for the new process. timeout (float): same as `Popen.communicate` argument, number of seconds to wait for a response before raising a TimeoutExpired exception. Returns: The tuple of (returncode, stdout). Beware, the stdout will be a byte array (id est b'some returned text'). This output, returned as stdout, needs to be decoded properly before you do anything with it, especially if you intend to log it into a file. While it will most likely be 'utf-8', the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on. Usage: CommandLine.run('echo hello') -> (0, b'hello \\r\\n ') modified_env = os.environ.copy() modified_env['ENV_VAR'] = new_value CommandLine.run('echo $ENV_VAR', env=modified_env) -> (0, b'new_value') \"\" \" with timeit ( lambda spanned : logger . info ( f \"Ran command '{command}' in a subprocess, in: {spanned:.4f} seconds\" ) ) : process = subprocess . Popen ( command , shell = shell , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , env = env ) stdout , _ = process . communicate ( timeout = timeout ) if process . poll () != 0 : logger . warning ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) else : logger . success ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) return process . poll (), stdout terminate def terminate ( pid : int ) -> bool Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Args: pid (int): the process ID to kill. Returns: A boolean stating the success of the operation. View Source @ staticmethod def terminate ( pid : int ) -> bool : \"\"\" Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Args: pid (int): the process ID to kill. Returns: A boolean stating the success of the operation. \"\"\" if CommandLine . check_pid_exists ( pid ): os . kill ( pid , signal . SIGTERM ) logger . debug ( f \"Process {pid} has successfully been terminated.\" ) return True logger . error ( f \"Process with ID {pid} could not be terminated.\" ) return False","title":"Cmdline"},{"location":"reference/pyhdtoolkit/utils/cmdline/#module-pyhdtoolkitutilscmdline","text":"","title":"Module pyhdtoolkit.utils.cmdline"},{"location":"reference/pyhdtoolkit/utils/cmdline/#module-utilscmdline","text":"Created on 2019.11.06 :author: Felix Soubelet ( felix.soubelet@cern.ch ) Utility script to help run commands and access the commandline. View Source \"\"\" Module utils.cmdline -------------------- Created on 2019.11.06 :author: Felix Soubelet (felix.soubelet@cern.ch) Utility script to help run commands and access the commandline. \"\"\" import errno import os import signal import subprocess from typing import Mapping , Optional , Tuple from loguru import logger from pyhdtoolkit.utils.contexts import timeit class CommandLine : \"\"\" A high-level object to encapsulate the different methods for interacting with the commandline. \"\"\" @staticmethod def check_pid_exists ( pid : int ) -> bool : \"\"\" Check whether the given PID exists in the current process table. Args: pid (int): the Process ID you want to check. Returns: A boolean stating the result. \"\"\" if pid == 0 : # According to \"man 2 kill\", PID 0 refers to <<every process in the process group of # the calling process>>. Best not to go any further. logger . warning ( \"PID 0 refers to 'every process in calling processes', and should be untouched\" ) return True try : # Sending SIG 0 only checks if process has terminated, we're not actually terminating it os . kill ( pid , 0 ) except OSError as pid_checkout_error : if pid_checkout_error . errno == errno . ESRCH : # ERROR \"No such process\" return False if ( pid_checkout_error . errno == errno . EPERM ): # ERROR \"Operation not permitted\" -> there's a process to deny access to. return True # According to \"man 2 kill\" possible error values are (EINVAL, EPERM, ESRCH), therefore # we should never get here. If so let's be explicit in considering this an error. logger . exception ( \"Could not figure out the provided PID for some reason\" ) raise pid_checkout_error return True @staticmethod def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Optional [ int ], bytes ]: \"\"\" Run command based on `subprocess.Popen` and return the tuple of `(returncode, stdout)`. Note that `stderr` is redirected to `stdout`. `shell` is same to parameter of `Popen`. If the process does not terminate after `timeout` seconds, a `TimeoutExpired` exception will be raised. Args: command (str): string, the command you want to run. shell (bool): same as `Popen` argument. Setting the shell argument to a true value causes subprocess to spawn an intermediate shell process, and tell it to run the command. In other words, using an intermediate shell means that variables, glob patterns, and other special shell features in the command string are processed before the command is ran. Defaults to True. env (Mapping): mapping that defines the environment variables for the new process. timeout (float): same as `Popen.communicate` argument, number of seconds to wait for a response before raising a TimeoutExpired exception. Returns: The tuple of (returncode, stdout). Beware, the stdout will be a byte array (id est b'some returned text'). This output, returned as stdout, needs to be decoded properly before you do anything with it, especially if you intend to log it into a file. While it will most likely be 'utf-8', the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on. Usage: CommandLine.run('echo hello') -> (0, b'hello\\r\\n') modified_env = os.environ.copy() modified_env['ENV_VAR'] = new_value CommandLine.run('echo $ENV_VAR', env=modified_env) -> (0, b'new_value') \"\"\" with timeit ( lambda spanned : logger . info ( f \"Ran command '{command}' in a subprocess, in: {spanned:.4f} seconds\" ) ): process = subprocess . Popen ( command , shell = shell , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , env = env ) stdout , _ = process . communicate ( timeout = timeout ) if process . poll () != 0 : logger . warning ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) else : logger . success ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) return process . poll (), stdout @staticmethod def terminate ( pid : int ) -> bool : \"\"\" Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Args: pid (int): the process ID to kill. Returns: A boolean stating the success of the operation. \"\"\" if CommandLine . check_pid_exists ( pid ): os . kill ( pid , signal . SIGTERM ) logger . debug ( f \"Process {pid} has successfully been terminated.\" ) return True logger . error ( f \"Process with ID {pid} could not be terminated.\" ) return False","title":"Module utils.cmdline"},{"location":"reference/pyhdtoolkit/utils/cmdline/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/utils/cmdline/#commandline","text":"class CommandLine ( / , * args , ** kwargs ) A high-level object to encapsulate the different methods for interacting with the commandline. View Source class CommandLine : \" \"\" A high-level object to encapsulate the different methods for interacting with the commandline. \"\" \" @staticmethod def check_pid_exists ( pid : int ) -> bool : \" \"\" Check whether the given PID exists in the current process table. Args: pid (int): the Process ID you want to check. Returns: A boolean stating the result. \"\" \" if pid == 0 : # According to \"man 2 kill\", PID 0 refers to <<every process in the process group of # the calling process>>. Best not to go any further. logger . warning ( \"PID 0 refers to 'every process in calling processes', and should be untouched\" ) return True try : # Sending SIG 0 only checks if process has terminated, we're not actually terminating it os . kill ( pid , 0 ) except OSError as pid_checkout_error : if pid_checkout_error . errno == errno . ESRCH : # ERROR \"No such process\" return False if ( pid_checkout_error . errno == errno . EPERM ) : # ERROR \"Operation not permitted\" -> there's a process to deny access to. return True # According to \"man 2 kill\" possible error values are (EINVAL, EPERM, ESRCH), therefore # we should never get here. If so let's be explicit in considering this an error. logger . exception ( \"Could not figure out the provided PID for some reason\" ) raise pid_checkout_error return True @staticmethod def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Optional [ int ] , bytes ] : \" \"\" Run command based on `subprocess.Popen` and return the tuple of `(returncode, stdout)`. Note that `stderr` is redirected to `stdout`. `shell` is same to parameter of `Popen`. If the process does not terminate after `timeout` seconds, a `TimeoutExpired` exception will be raised. Args: command (str): string, the command you want to run. shell (bool): same as `Popen` argument. Setting the shell argument to a true value causes subprocess to spawn an intermediate shell process, and tell it to run the command. In other words, using an intermediate shell means that variables, glob patterns, and other special shell features in the command string are processed before the command is ran. Defaults to True. env (Mapping): mapping that defines the environment variables for the new process. timeout (float): same as `Popen.communicate` argument, number of seconds to wait for a response before raising a TimeoutExpired exception. Returns: The tuple of (returncode, stdout). Beware, the stdout will be a byte array (id est b'some returned text'). This output, returned as stdout, needs to be decoded properly before you do anything with it, especially if you intend to log it into a file. While it will most likely be 'utf-8', the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on. Usage: CommandLine.run('echo hello') -> (0, b'hello \\r\\n ') modified_env = os.environ.copy() modified_env['ENV_VAR'] = new_value CommandLine.run('echo $ENV_VAR', env=modified_env) -> (0, b'new_value') \"\" \" with timeit ( lambda spanned : logger . info ( f \"Ran command '{command}' in a subprocess, in: {spanned:.4f} seconds\" ) ) : process = subprocess . Popen ( command , shell = shell , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , env = env ) stdout , _ = process . communicate ( timeout = timeout ) if process . poll () != 0 : logger . warning ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) else : logger . success ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) return process . poll (), stdout @staticmethod def terminate ( pid : int ) -> bool : \" \"\" Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Args: pid (int): the process ID to kill. Returns: A boolean stating the success of the operation. \"\" \" if CommandLine . check_pid_exists ( pid ) : os . kill ( pid , signal . SIGTERM ) logger . debug ( f \"Process {pid} has successfully been terminated.\" ) return True logger . error ( f \"Process with ID {pid} could not be terminated.\" ) return False","title":"CommandLine"},{"location":"reference/pyhdtoolkit/utils/cmdline/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/utils/cmdline/#check_pid_exists","text":"def check_pid_exists ( pid : int ) -> bool Check whether the given PID exists in the current process table. Args: pid (int): the Process ID you want to check. Returns: A boolean stating the result. View Source @staticmethod def check_pid_exists ( pid : int ) -> bool : \"\"\" Check whether the given PID exists in the current process table. Args: pid (int): the Process ID you want to check. Returns: A boolean stating the result. \"\"\" if pid == 0 : # According to \"man 2 kill\" , PID 0 refers to << every process in the process group of # the calling process >> . Best not to go any further . logger . warning ( \"PID 0 refers to 'every process in calling processes', and should be untouched\" ) return True try : # Sending SIG 0 only checks if process has terminated , we 're not actually terminating it os.kill(pid, 0) except OSError as pid_checkout_error: if pid_checkout_error.errno == errno.ESRCH: # ERROR \"No such process\" return False if ( pid_checkout_error.errno == errno.EPERM ): # ERROR \"Operation not permitted\" -> there' s a process to deny access to . return True # According to \"man 2 kill\" possible error values are ( EINVAL , EPERM , ESRCH ), therefore # we should never get here . If so let ' s be explicit in considering this an error . logger . exception ( \"Could not figure out the provided PID for some reason\" ) raise pid_checkout_error return True","title":"check_pid_exists"},{"location":"reference/pyhdtoolkit/utils/cmdline/#run","text":"def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Union [ int , NoneType ], bytes ] Run command based on subprocess.Popen and return the tuple of (returncode, stdout) . Note that stderr is redirected to stdout . shell is same to parameter of Popen . If the process does not terminate after timeout seconds, a TimeoutExpired exception will be raised. Args : command ( str ) : string , the command you want to run . shell ( bool ) : same as `Popen` argument . Set ting the shell argument to a true value causes subprocess to spawn an intermediate shell process , and tell it to run the command . In other words , using an intermediate shell means that variables , glob patterns , and other special shell features in the command string are processed before the command is ran . Defaults to True . env ( Mapping ) : mapping that defines the environment variables for the new process . timeout ( float ) : same as `Popen.communicate` argument , number of seconds to wait for a response before raising a TimeoutExpired exception . Returns : The tuple of ( returncode , stdout ). Beware , the stdout will be a byte array ( id est b 'some returned text' ). This output , returned as stdout , needs to be decoded properly before you do anything with it , especially if you intend to log it into a file . While it will most likely be 'utf-8' , the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on . Usage : CommandLine . run ( 'echo hello' ) -> ( 0 , b 'hello ') modified_env = os.environ.copy() modified_env['ENV_VAR'] = new_value CommandLine.run('echo $ENV_VAR', env=modified_env) -> (0, b'new_value') View Source @staticmethod def run ( command : str , shell : bool = True , env : Mapping = None , timeout : float = None ) -> Tuple [ Optional [ int ] , bytes ] : \" \"\" Run command based on `subprocess.Popen` and return the tuple of `(returncode, stdout)`. Note that `stderr` is redirected to `stdout`. `shell` is same to parameter of `Popen`. If the process does not terminate after `timeout` seconds, a `TimeoutExpired` exception will be raised. Args: command (str): string, the command you want to run. shell (bool): same as `Popen` argument. Setting the shell argument to a true value causes subprocess to spawn an intermediate shell process, and tell it to run the command. In other words, using an intermediate shell means that variables, glob patterns, and other special shell features in the command string are processed before the command is ran. Defaults to True. env (Mapping): mapping that defines the environment variables for the new process. timeout (float): same as `Popen.communicate` argument, number of seconds to wait for a response before raising a TimeoutExpired exception. Returns: The tuple of (returncode, stdout). Beware, the stdout will be a byte array (id est b'some returned text'). This output, returned as stdout, needs to be decoded properly before you do anything with it, especially if you intend to log it into a file. While it will most likely be 'utf-8', the encoding can vary from system to system so the standard output is returned in bytes format and should be decoded later on. Usage: CommandLine.run('echo hello') -> (0, b'hello \\r\\n ') modified_env = os.environ.copy() modified_env['ENV_VAR'] = new_value CommandLine.run('echo $ENV_VAR', env=modified_env) -> (0, b'new_value') \"\" \" with timeit ( lambda spanned : logger . info ( f \"Ran command '{command}' in a subprocess, in: {spanned:.4f} seconds\" ) ) : process = subprocess . Popen ( command , shell = shell , stdout = subprocess . PIPE , stderr = subprocess . STDOUT , env = env ) stdout , _ = process . communicate ( timeout = timeout ) if process . poll () != 0 : logger . warning ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) else : logger . success ( f \"Subprocess command '{command}' finished with exit code: {process.poll()}\" ) return process . poll (), stdout","title":"run"},{"location":"reference/pyhdtoolkit/utils/cmdline/#terminate","text":"def terminate ( pid : int ) -> bool Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Args: pid (int): the process ID to kill. Returns: A boolean stating the success of the operation. View Source @ staticmethod def terminate ( pid : int ) -> bool : \"\"\" Terminate process by given pid. On Other platforms, using os.kill with signal.SIGTERM to kill. Args: pid (int): the process ID to kill. Returns: A boolean stating the success of the operation. \"\"\" if CommandLine . check_pid_exists ( pid ): os . kill ( pid , signal . SIGTERM ) logger . debug ( f \"Process {pid} has successfully been terminated.\" ) return True logger . error ( f \"Process with ID {pid} could not be terminated.\" ) return False","title":"terminate"},{"location":"reference/pyhdtoolkit/utils/contexts/","text":"Module pyhdtoolkit.utils.contexts Module utils.contexts Provides contexts to use functions in. View Source \"\"\" Module utils.contexts --------------------- Provides contexts to use functions in. \"\"\" import time from contextlib import contextmanager from typing import Callable , Iterator @contextmanager def timeit ( function : Callable ) -> Iterator [ None ]: \"\"\" Returns the time elapsed when executing code in the context via `function`. Original code from @jaimecp89 Args: function (Callable): any callable taking one argument. Was conceived with a lambda in mind. Returns: The elapsed time as an argument for the provided function. Usage: with timeit(lambda spanned: logger.debug(f'Did some stuff in {spanned} seconds')): some_stuff() some_other_stuff() \"\"\" start_time = time . time () try : yield finally : time_used = time . time () - start_time function ( time_used ) Functions timeit def timeit ( function : Callable ) -> Iterator [ NoneType ] Returns the time elapsed when executing code in the context via function . Original code from @jaimecp89 Args: function (Callable): any callable taking one argument. Was conceived with a lambda in mind. Returns: The elapsed time as an argument for the provided function. Usage: with timeit(lambda spanned: logger.debug(f'Did some stuff in {spanned} seconds')): some_stuff() some_other_stuff() View Source @contextmanager def timeit ( function : Callable ) -> Iterator [ None ] : \"\"\" Returns the time elapsed when executing code in the context via `function`. Original code from @jaimecp89 Args: function (Callable): any callable taking one argument. Was conceived with a lambda in mind. Returns: The elapsed time as an argument for the provided function. Usage: with timeit(lambda spanned: logger.debug(f'Did some stuff in {spanned} seconds')): some_stuff() some_other_stuff() \"\"\" start_time = time . time () try : yield finally : time_used = time . time () - start_time function ( time_used )","title":"Contexts"},{"location":"reference/pyhdtoolkit/utils/contexts/#module-pyhdtoolkitutilscontexts","text":"","title":"Module pyhdtoolkit.utils.contexts"},{"location":"reference/pyhdtoolkit/utils/contexts/#module-utilscontexts","text":"Provides contexts to use functions in. View Source \"\"\" Module utils.contexts --------------------- Provides contexts to use functions in. \"\"\" import time from contextlib import contextmanager from typing import Callable , Iterator @contextmanager def timeit ( function : Callable ) -> Iterator [ None ]: \"\"\" Returns the time elapsed when executing code in the context via `function`. Original code from @jaimecp89 Args: function (Callable): any callable taking one argument. Was conceived with a lambda in mind. Returns: The elapsed time as an argument for the provided function. Usage: with timeit(lambda spanned: logger.debug(f'Did some stuff in {spanned} seconds')): some_stuff() some_other_stuff() \"\"\" start_time = time . time () try : yield finally : time_used = time . time () - start_time function ( time_used )","title":"Module utils.contexts"},{"location":"reference/pyhdtoolkit/utils/contexts/#functions","text":"","title":"Functions"},{"location":"reference/pyhdtoolkit/utils/contexts/#timeit","text":"def timeit ( function : Callable ) -> Iterator [ NoneType ] Returns the time elapsed when executing code in the context via function . Original code from @jaimecp89 Args: function (Callable): any callable taking one argument. Was conceived with a lambda in mind. Returns: The elapsed time as an argument for the provided function. Usage: with timeit(lambda spanned: logger.debug(f'Did some stuff in {spanned} seconds')): some_stuff() some_other_stuff() View Source @contextmanager def timeit ( function : Callable ) -> Iterator [ None ] : \"\"\" Returns the time elapsed when executing code in the context via `function`. Original code from @jaimecp89 Args: function (Callable): any callable taking one argument. Was conceived with a lambda in mind. Returns: The elapsed time as an argument for the provided function. Usage: with timeit(lambda spanned: logger.debug(f'Did some stuff in {spanned} seconds')): some_stuff() some_other_stuff() \"\"\" start_time = time . time () try : yield finally : time_used = time . time () - start_time function ( time_used )","title":"timeit"},{"location":"reference/pyhdtoolkit/utils/defaults/","text":"Module pyhdtoolkit.utils.defaults Module utils.defaults Created on 2019.11.12 :author: Felix Soubelet ( felix.soubelet@cern.ch ) Provides defaults to import for different settings. View Source \"\"\" Module utils.defaults --------------------- Created on 2019.11.12 :author: Felix Soubelet (felix.soubelet@cern.ch) Provides defaults to import for different settings. \"\"\" from pathlib import Path ANACONDA_INSTALL = Path () . home () / \"anaconda3\" OMC_PYTHON = ANACONDA_INSTALL / \"envs\" / \"OMC\" / \"bin\" / \"python\" WORK_REPOSITORIES = Path . home () / \"Repositories\" / \"Work\" BETABEAT_REPO = WORK_REPOSITORIES / \"Beta-Beat.src\" OMC3_REPO = WORK_REPOSITORIES / \"omc3\" TBT_CONVERTER_SCRIPT = OMC3_REPO / \"omc3\" / \"tbt_converter.py\" LOGURU_FORMAT = ( \"<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | \" \"<level>{level: <8}</level> | \" \"<cyan>{name}</cyan>:<cyan>{line}</cyan> - \" \"<level>{message}</level>\" ) Variables ANACONDA_INSTALL BETABEAT_REPO LOGURU_FORMAT OMC3_REPO OMC_PYTHON TBT_CONVERTER_SCRIPT WORK_REPOSITORIES","title":"Defaults"},{"location":"reference/pyhdtoolkit/utils/defaults/#module-pyhdtoolkitutilsdefaults","text":"","title":"Module pyhdtoolkit.utils.defaults"},{"location":"reference/pyhdtoolkit/utils/defaults/#module-utilsdefaults","text":"Created on 2019.11.12 :author: Felix Soubelet ( felix.soubelet@cern.ch ) Provides defaults to import for different settings. View Source \"\"\" Module utils.defaults --------------------- Created on 2019.11.12 :author: Felix Soubelet (felix.soubelet@cern.ch) Provides defaults to import for different settings. \"\"\" from pathlib import Path ANACONDA_INSTALL = Path () . home () / \"anaconda3\" OMC_PYTHON = ANACONDA_INSTALL / \"envs\" / \"OMC\" / \"bin\" / \"python\" WORK_REPOSITORIES = Path . home () / \"Repositories\" / \"Work\" BETABEAT_REPO = WORK_REPOSITORIES / \"Beta-Beat.src\" OMC3_REPO = WORK_REPOSITORIES / \"omc3\" TBT_CONVERTER_SCRIPT = OMC3_REPO / \"omc3\" / \"tbt_converter.py\" LOGURU_FORMAT = ( \"<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | \" \"<level>{level: <8}</level> | \" \"<cyan>{name}</cyan>:<cyan>{line}</cyan> - \" \"<level>{message}</level>\" )","title":"Module utils.defaults"},{"location":"reference/pyhdtoolkit/utils/defaults/#variables","text":"ANACONDA_INSTALL BETABEAT_REPO LOGURU_FORMAT OMC3_REPO OMC_PYTHON TBT_CONVERTER_SCRIPT WORK_REPOSITORIES","title":"Variables"},{"location":"reference/pyhdtoolkit/utils/executors/","text":"Module pyhdtoolkit.utils.executors Module utils.executors Created on 2019.12.09 :author: Felix Soubelet A module providing two classes to execute functions + arguments couples through either a multiprocessing approach, or a multithreading approach. Here are a few tidbits to keep in mind: - There can only be one thread running at any given time in a python process because of the GIL. - Multiprocessing is parallelism. Multithreading is concurrency. - Multiprocessing is for increasing speed. Multithreading is for hiding latency. - Multiprocessing is best for computations. Multithreading is best for IO. - If you have CPU heavy tasks, use multiprocessing with n_process = n_cores and never more. Never. - If you have IO heavy tasks, use multithreading with n_threads = m * n_cores with m a number bigger than 1 that you can tweak on your own. Try many values and choose the one with the best speedup because there isn\u2019t a general rule. For instance the default value of m in ThreadPoolExecutor is set to 5 which I think is quite random. View Source \"\"\" Module utils.executors ---------------------- Created on 2019.12.09 :author: Felix Soubelet A module providing two classes to execute functions + arguments couples through either a multiprocessing approach, or a multithreading approach. Here are a few tidbits to keep in mind: - There can only be one thread running at any given time in a python process because of the GIL. - Multiprocessing is parallelism. Multithreading is concurrency. - Multiprocessing is for increasing speed. Multithreading is for hiding latency. - Multiprocessing is best for computations. Multithreading is best for IO. - If you have CPU heavy tasks, use multiprocessing with n_process = n_cores and never more. Never. - If you have IO heavy tasks, use multithreading with n_threads = m * n_cores with m a number bigger than 1 that you can tweak on your own. Try many values and choose the one with the best speedup because there isn\u2019t a general rule. For instance the default value of m in ThreadPoolExecutor is set to 5 which I think is quite random. \"\"\" from concurrent import futures from typing import Callable , List from loguru import logger class MultiProcessor : \"\"\" A class to easily wrap a multi-processing context manager call to a function. Reminder: multiprocessing is good for cpu-heavy tasks. Reminder: only picklable objects can be executed and returned. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_cpu_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ] : \"\"\" Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_processes (int): the number of processes to fire up. No more than your number of cores! If n_processes is `None` or not given, ProcessPoolExecutor will default it to the number of processors on the machine. Returns: A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multiprocessing with {n_processes} processes\" ) with futures . ProcessPoolExecutor ( n_processes ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_processes} processes finished\" ) return list ( results ) class MultiThreader : \"\"\" A class to easily wrap a multi-threading context manager call to a function. Reminder: multithreading is good for IO-heavy tasks. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_io_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ] : \"\"\" Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_threads (int): the number of threads to fire up. If n_threads is `None` or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. Returns: A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multithreading with {n_threads} threads\" ) with futures . ThreadPoolExecutor ( n_threads ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_threads} threads finished\" ) return list ( results ) Classes MultiProcessor class MultiProcessor ( / , * args , ** kwargs ) A class to easily wrap a multi-processing context manager call to a function. Reminder: multiprocessing is good for cpu-heavy tasks. Reminder: only picklable objects can be executed and returned. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_cpu_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) View Source class MultiProcessor : \"\"\" A class to easily wrap a multi-processing context manager call to a function. Reminder: multiprocessing is good for cpu-heavy tasks. Reminder: only picklable objects can be executed and returned. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_cpu_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_processes (int): the number of processes to fire up. No more than your number of cores! If n_processes is `None` or not given, ProcessPoolExecutor will default it to the number of processors on the machine. Returns: A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multiprocessing with {n_processes} processes\" ) with futures . ProcessPoolExecutor ( n_processes ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_processes} processes finished\" ) return list ( results ) Static methods execute_function def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ] Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_processes (int): the number of processes to fire up. No more than your number of cores! If n_processes is None or not given, ProcessPoolExecutor will default it to the number of processors on the machine. Returns: A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. View Source @ staticmethod def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_processes (int): the number of processes to fire up. No more than your number of cores! If n_processes is `None` or not given, ProcessPoolExecutor will default it to the number of processors on the machine. Returns: A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multiprocessing with {n_processes} processes\" ) with futures . ProcessPoolExecutor ( n_processes ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_processes} processes finished\" ) return list ( results ) MultiThreader class MultiThreader ( / , * args , ** kwargs ) A class to easily wrap a multi-threading context manager call to a function. Reminder: multithreading is good for IO-heavy tasks. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_io_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) View Source class MultiThreader : \"\"\" A class to easily wrap a multi-threading context manager call to a function. Reminder: multithreading is good for IO-heavy tasks. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_io_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_threads (int): the number of threads to fire up. If n_threads is `None` or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. Returns: A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multithreading with {n_threads} threads\" ) with futures . ThreadPoolExecutor ( n_threads ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_threads} threads finished\" ) return list ( results ) Static methods execute_function def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ] Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_threads (int): the number of threads to fire up. If n_threads is None or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. Returns: A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. View Source @ staticmethod def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_threads (int): the number of threads to fire up. If n_threads is `None` or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. Returns: A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multithreading with {n_threads} threads\" ) with futures . ThreadPoolExecutor ( n_threads ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_threads} threads finished\" ) return list ( results )","title":"Executors"},{"location":"reference/pyhdtoolkit/utils/executors/#module-pyhdtoolkitutilsexecutors","text":"","title":"Module pyhdtoolkit.utils.executors"},{"location":"reference/pyhdtoolkit/utils/executors/#module-utilsexecutors","text":"Created on 2019.12.09 :author: Felix Soubelet A module providing two classes to execute functions + arguments couples through either a multiprocessing approach, or a multithreading approach. Here are a few tidbits to keep in mind: - There can only be one thread running at any given time in a python process because of the GIL. - Multiprocessing is parallelism. Multithreading is concurrency. - Multiprocessing is for increasing speed. Multithreading is for hiding latency. - Multiprocessing is best for computations. Multithreading is best for IO. - If you have CPU heavy tasks, use multiprocessing with n_process = n_cores and never more. Never. - If you have IO heavy tasks, use multithreading with n_threads = m * n_cores with m a number bigger than 1 that you can tweak on your own. Try many values and choose the one with the best speedup because there isn\u2019t a general rule. For instance the default value of m in ThreadPoolExecutor is set to 5 which I think is quite random. View Source \"\"\" Module utils.executors ---------------------- Created on 2019.12.09 :author: Felix Soubelet A module providing two classes to execute functions + arguments couples through either a multiprocessing approach, or a multithreading approach. Here are a few tidbits to keep in mind: - There can only be one thread running at any given time in a python process because of the GIL. - Multiprocessing is parallelism. Multithreading is concurrency. - Multiprocessing is for increasing speed. Multithreading is for hiding latency. - Multiprocessing is best for computations. Multithreading is best for IO. - If you have CPU heavy tasks, use multiprocessing with n_process = n_cores and never more. Never. - If you have IO heavy tasks, use multithreading with n_threads = m * n_cores with m a number bigger than 1 that you can tweak on your own. Try many values and choose the one with the best speedup because there isn\u2019t a general rule. For instance the default value of m in ThreadPoolExecutor is set to 5 which I think is quite random. \"\"\" from concurrent import futures from typing import Callable , List from loguru import logger class MultiProcessor : \"\"\" A class to easily wrap a multi-processing context manager call to a function. Reminder: multiprocessing is good for cpu-heavy tasks. Reminder: only picklable objects can be executed and returned. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_cpu_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ] : \"\"\" Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_processes (int): the number of processes to fire up. No more than your number of cores! If n_processes is `None` or not given, ProcessPoolExecutor will default it to the number of processors on the machine. Returns: A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multiprocessing with {n_processes} processes\" ) with futures . ProcessPoolExecutor ( n_processes ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_processes} processes finished\" ) return list ( results ) class MultiThreader : \"\"\" A class to easily wrap a multi-threading context manager call to a function. Reminder: multithreading is good for IO-heavy tasks. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_io_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ] : \"\"\" Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_threads (int): the number of threads to fire up. If n_threads is `None` or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. Returns: A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multithreading with {n_threads} threads\" ) with futures . ThreadPoolExecutor ( n_threads ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_threads} threads finished\" ) return list ( results )","title":"Module utils.executors"},{"location":"reference/pyhdtoolkit/utils/executors/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/utils/executors/#multiprocessor","text":"class MultiProcessor ( / , * args , ** kwargs ) A class to easily wrap a multi-processing context manager call to a function. Reminder: multiprocessing is good for cpu-heavy tasks. Reminder: only picklable objects can be executed and returned. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_cpu_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) View Source class MultiProcessor : \"\"\" A class to easily wrap a multi-processing context manager call to a function. Reminder: multiprocessing is good for cpu-heavy tasks. Reminder: only picklable objects can be executed and returned. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_cpu_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_processes (int): the number of processes to fire up. No more than your number of cores! If n_processes is `None` or not given, ProcessPoolExecutor will default it to the number of processors on the machine. Returns: A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multiprocessing with {n_processes} processes\" ) with futures . ProcessPoolExecutor ( n_processes ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_processes} processes finished\" ) return list ( results )","title":"MultiProcessor"},{"location":"reference/pyhdtoolkit/utils/executors/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/utils/executors/#execute_function","text":"def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ] Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_processes (int): the number of processes to fire up. No more than your number of cores! If n_processes is None or not given, ProcessPoolExecutor will default it to the number of processors on the machine. Returns: A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. View Source @ staticmethod def execute_function ( func : Callable , func_args : list , n_processes : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple processes. Do not fire up more processes than you have cores! Never! Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_processes (int): the number of processes to fire up. No more than your number of cores! If n_processes is `None` or not given, ProcessPoolExecutor will default it to the number of processors on the machine. Returns: A list of tuples, each tuple being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multiprocessing with {n_processes} processes\" ) with futures . ProcessPoolExecutor ( n_processes ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_processes} processes finished\" ) return list ( results )","title":"execute_function"},{"location":"reference/pyhdtoolkit/utils/executors/#multithreader","text":"class MultiThreader ( / , * args , ** kwargs ) A class to easily wrap a multi-threading context manager call to a function. Reminder: multithreading is good for IO-heavy tasks. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_io_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) View Source class MultiThreader : \"\"\" A class to easily wrap a multi-threading context manager call to a function. Reminder: multithreading is good for IO-heavy tasks. Usage: Processor = MultiProcessor() results_one_tuple_per_run = Processor.execute_function( func=your_io_heavy_function, func_args=list_of_args_for_each_call, n_processes=some_int_up_to_you, ) \"\"\" @ staticmethod def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_threads (int): the number of threads to fire up. If n_threads is `None` or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. Returns: A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multithreading with {n_threads} threads\" ) with futures . ThreadPoolExecutor ( n_threads ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_threads} threads finished\" ) return list ( results )","title":"MultiThreader"},{"location":"reference/pyhdtoolkit/utils/executors/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/utils/executors/#execute_function_1","text":"def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ] Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_threads (int): the number of threads to fire up. If n_threads is None or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. Returns: A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. View Source @ staticmethod def execute_function ( func : Callable , func_args : list , n_threads : int ) -> List [ tuple ]: \"\"\" Executes the function with the provided arguments as multiple threads. Remember there is no point of having more threads than the number calls to be executed, the excess threads would be idle and you'd lose the time spent to fire them up. Args: func (Callable): the function to call. func_args (list): list of the different parameters for each call. If your function takes more than one parameter, wrap them up in tuples, e.g.: [(params, run, one), (params, run, two), (params, run, three)]. n_threads (int): the number of threads to fire up. If n_threads is `None` or not given, ThreadPoolExecutor will default it to the number of processors on the machine multiplied by 5, assuming that is often used to overlap I/O instead of CPU work and the number of workers should be higher than the number of workers for a ProcessPoolExecutor. Returns: A list of tuples, each tuples being the returned value(s) of your function for the given call, for instance [(results, run, one), (results, run, two), (results, run, three)]. \"\"\" logger . debug ( f \"Starting multithreading with {n_threads} threads\" ) with futures . ThreadPoolExecutor ( n_threads ) as ex : results = ex . map ( func , func_args ) logger . debug ( f \"All {n_threads} threads finished\" ) return list ( results )","title":"execute_function"},{"location":"reference/pyhdtoolkit/utils/operations/","text":"Module pyhdtoolkit.utils.operations Module utils.operations Created on 2019.11.12 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A collection classes with utility functions to perform common / convenient operations on the classic Python structures. View Source \"\"\" Module utils.operations ----------------------- Created on 2019.11.12 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection classes with utility functions to perform common / convenient operations on the classic Python structures. \"\"\" import copy import itertools import math import random import re from functools import reduce from typing import Callable , Dict , List , Sequence , Tuple , Union class ListOperations : \"\"\" A class to group some common / useful operations on lists. \"\"\" @staticmethod def all_unique ( sequence : Sequence ) -> bool : \"\"\" Returns True if all the values in a flat list are unique, False otherwise. Args: sequence (Sequence): a sequence of elements. Returns: True if all elements are unique, False otherwise. \"\"\" return len ( sequence ) == len ( set ( sequence )) @staticmethod def average_by ( sequence : Sequence , function : Callable = lambda x : x ) -> float : \"\"\" Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Args: sequence (Sequence): a sequence of elements. function (Callable): function to apply to elements of the sequence. Returns: The average of each element's result through `function`. Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 \"\"\" return float ( sum ( map ( function , sequence ), 0.0 ) / len ( sequence )) @staticmethod def bifurcate ( sequence : Sequence , filters : List [ bool ]) -> Sequence : \"\"\" Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Args: sequence (Sequence): a sequence of elements. filters (List[bool]): a list of booleans. Returns: A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] \"\"\" return [ [ x for i , x in enumerate ( sequence ) if filters [ i ]], [ x for i , x in enumerate ( sequence ) if not filters [ i ]], ] @staticmethod def bifurcate_by ( sequence : Sequence , function : Callable ) -> list : \"\"\" Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of lst, that should return a boolean. Returns: A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] \"\"\" return [[ x for x in sequence if function ( x )], [ x for x in sequence if not function ( x )]] @staticmethod def chunk_list ( sequence : Sequence , size : int ) -> Sequence : \"\"\" Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Args: sequence (Sequence): a sequence of elements. size (int): the size of the wanted sublists. Returns: A list of lists of length `size` (except maybe the last element), with elements from `lst`. Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] \"\"\" if size > len ( sequence ) : return sequence return list ( map ( lambda x : sequence [ x * size : x * size + size ], list ( range ( math . ceil ( len ( sequence ) / size ))), ) ) @staticmethod def deep_flatten ( sequence : Sequence ) -> list : \"\"\" Deep flattens a list, no matter the nesting levels. This is a recursive approach. Args: sequence (Sequence): a sequence of elements. Returns: A list with all elements of `lst`, but flattened. Usage: deep_flatten([[\" a \", \" b \"], [1, 2], None, [True, False]]) -> [\" a \", \" b \", 1, 2, None True, False] \"\"\" return ( [ elem for sublist in sequence for elem in ListOperations . deep_flatten ( sublist )] if isinstance ( sequence , list ) else [ sequence ] ) @staticmethod def eval_none ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False \"\"\" return not any ( map ( function , sequence )) @staticmethod def eval_some ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False \"\"\" return any ( map ( function , sequence )) @staticmethod def get_indices ( element , sequence : Sequence ) -> List [ int ] : \"\"\" Return all array indices at which number is located. Args: element: any reference element to check. sequence (Sequence): a sequence containing objects comparable to `elements`. A string can be compared to an int in Python, custom objects probably won't be comparable. Returns: A list of all indices at which `element` is found in `sequence`. Empty list if `element` is not present in `sequence` at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] \"\"\" return [ i for ( y , i ) in zip ( sequence , range ( len ( sequence ))) if element == y ] @staticmethod def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ] : \"\"\" Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of `sequence` that should return a boolean. Returns: A dict with keys \" True \" and \" False \", each having as value a list of all elements of `lst` that were evaluated to respectively `True` or `False` through `function`. Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} \"\"\" groups = {} for key in list ( map ( function , sequence )) : groups [ key ] = [ item for item in sequence if function ( item ) == key ] return groups @staticmethod def has_duplicates ( sequence : Sequence ) -> bool : \"\"\" Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Args: sequence (Sequence): a sequence of elements. Returns: A boolean indicating the presence of duplicates in `lst`. Usage: has_duplicates([1, 2, 1]) -> True \"\"\" return len ( sequence ) ! = len ( set ( sequence )) @staticmethod def sample ( sequence : Sequence ) -> list : \"\"\" Returns a random element from an array. Args: sequence (Sequence): a sequence of elements. Returns: A random element from `lst` in a list (to manage potentially nested lists as input). \"\"\" return sequence [ random . randint ( 0 , len ( sequence ) - 1 )] @staticmethod def sanitize_list ( sequence : Sequence ) -> list : \"\"\" Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Args: sequence (Sequence): a sequence of elements. Returns: The sequence without falsy values. Usage: sanitize_list([1, False, \" a \", 2, \"\", None, 6, 0]) -> [1, \" a \", 2, 6] \"\"\" return list ( filter ( bool , sequence )) @staticmethod def shuffle ( sequence : Sequence ) -> Sequence : \"\"\" Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm (https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle) to reorder the elements. Args: sequence (Sequence): a sequence of elements. Returns: The `lst` with original elements at a random index. \"\"\" temp_list = copy . deepcopy ( sequence ) amount_to_shuffle = len ( temp_list ) while amount_to_shuffle > 1 : rand_index = int ( math . floor ( random . random () * amount_to_shuffle )) amount_to_shuffle -= 1 temp_list [ rand_index ], temp_list [ amount_to_shuffle ] = ( temp_list [ amount_to_shuffle ], temp_list [ rand_index ], ) return temp_list @staticmethod def spread ( sequence : Sequence ) -> list : \"\"\" Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in `lst` are iterables! Args: sequence (Sequence): a sequence of elements. Returns: The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] \"\"\" return list ( itertools . chain . from_iterable ( sequence )) @staticmethod def symmetric_difference_by ( lst_1: Sequence , lst_2: Sequence , function : Callable ) -> list : \"\"\" Returns the symmetric difference (https://en.wikipedia.org/wiki/Symmetric_difference) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] \"\"\" _ lst_1 , _ lst_2 = set ( map ( function , lst_1 )), set ( map ( function , lst_2 )) return [ item for item in lst_1 if function ( item ) not in _ lst_2 ] + [ item for item in lst_2 if function ( item ) not in _ lst_1 ] @staticmethod def union_by ( lst_1: Sequence , lst_2: Sequence , function : Callable ) -> list : \"\"\" Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union (https://en.wikipedia.org/wiki/Union_(set_theory)) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] \"\"\" _ lst_1 = set ( map ( function , lst_1 )) return sorted ( list ( set ( lst_1 + [ item for item in lst_2 if function ( item ) not in _ lst_1 ]))) @staticmethod def zipper ( * args , fillvalue = None ) -> list : \"\"\" Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Args: *args: a number (>= 2) of different iterables. fillvalue: value to use in case of length mismatch. Returns: A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\" a \", \" b \", \" c \"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] \"\"\" max_length = max ( len ( lst ) for lst in args ) return [ [ args [ k ][ i ] if i < len ( args [ k ]) else fillvalue for k in range ( len ( args ))] for i in range ( max_length ) ] class MiscellaneousOperations : \"\"\" A class to group some misc. operations that don't pertain to classic structures. \"\"\" @staticmethod def longest_item ( * args ) : \"\"\" Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Args: *args: any number (>= 2) of iterables. Returns: The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) \"\"\" return max ( args , key = len ) @staticmethod def map_values ( obj : dict , function : Callable ) -> dict : \"\"\" Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Args: obj: a dictionary. function (Callable): a callable on values of `obj`. Returns: A new dictionary with the results. Usage: map_values( {\" a \": list(range(5)), \" b \": list(range(10)), \" c \": list(range(15))}, lambda x: len(x) ) -> {\" a \": 5, \" b \": 10, \" c \": 15} \"\"\" ret = {} for key in obj : ret [ key ] = function ( obj [ key ]) return ret class NumberOperations : \"\"\" A class to group some common / useful operations on numbers. \"\"\" @staticmethod def clamp_number ( num : Union [ int , float ], a_val: Union [ int , float ], b_val: Union [ int , float ] ) -> Union [ int , float ] : \"\"\" Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Args: num (Union[int, float]): a number (float / int) a_val (Union[int, float]): a number (float / int) b_val (Union[int, float]): a number (float / int) Returns: A number (float / int), being the nearest to `num` in the range [`a_val`, `b_val`]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 \"\"\" return max ( min ( num , max ( a_val , b_val )), min ( a_val , b_val )) @staticmethod def degrees_to_radians ( deg_value: Union [ int , float ], decompose : bool = False ) -> Union [ Tuple [ float , str , str ], int , float ] : \"\"\" Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Args: deg_value (Union[int, float]): angle value in degrees. decompose (bool): boolean option to return a more verbose result. Defaults to False. Returns: The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \" pi \", \" rad \") \"\"\" if decompose : return deg_value / 180 , \"pi\" , \"rad\" return ( deg_value * math . pi ) / 180.0 @staticmethod def greatest_common_divisor ( numbers_list: Sequence ) -> Union [ int , float ] : \"\"\" Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in `numbers_list`. Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 \"\"\" return reduce ( math . gcd , numbers_list ) @staticmethod def is_divisible_by ( dividend : Union [ int , float ], divisor : Union [ int , float ]) -> bool : \"\"\" Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Args: dividend (Union[int, float]): a number. divisor (Union[int, float]): a number. Returns: A boolean stating if `dividend` can be divided by `divisor`. \"\"\" return dividend % divisor == 0 @staticmethod def least_common_multiple ( * args ) -> int : \"\"\" Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 \"\"\" numbers = list ( ListOperations . spread ( list ( args ))) def _ lcm ( number1 , number2 ) : \"\"\"A least common multiple method for two numbers only\"\"\" return int ( number1 * number2 / math . gcd ( number1 , number2 )) return reduce ( lambda x , y : _ lcm ( x , y ), numbers ) @staticmethod def radians_to_degrees ( rad_value: Union [ int , float ]) -> Union [ int , float ] : \"\"\" Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Args: rad_value (Union[int, float]): angle value in degrees. Returns: The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 \"\"\" return ( rad_value * 180.0 ) / math . pi class StringOperations : \"\"\" A class to group some common / useful operations on strings. \"\"\" @staticmethod def camel_case ( text : str ) -> str : \"\"\" Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Args: text (str): a string. Returns: The same string best adapted to camel_case. Usage: camel_case(\" a_snake_case_name \") -> \" aSnakeCaseName \" camel_case(\" A Title Case Name \") -> \" aTitleCaseName \" \"\"\" text = re . sub ( r \"(\\s|_|-)+\" , \" \" , text ). title (). replace ( \" \" , \"\" ) return text [ 0 ]. lower () + text [ 1 : ] @staticmethod def capitalize ( text : str , lower_rest: bool = False ) -> str : \"\"\" Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Args: text (str): a string. lower_rest (bool): boolean option to lower all elements starting from the second. Returns: The `string`, capitalized. Usage: capitalize(\" astringtocapitalize \") -> \" Astringtocapitalize \" capitalize(\" astRIngTocApItalizE \", lower_rest=True) -> \" Astringtocapitalize \" \"\"\" return text [ : 1 ]. upper () + ( text [ 1 : ]. lower () if lower_rest else text [ 1 : ]) @staticmethod def is_anagram ( str_1: str , str_2: str ) -> bool : \"\"\" Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Args: str_1 (str): a string. str_2 (str): a string. Returns: A boolean stating whether `str_1` is an anagram of `str_2` or not. Usage: is_anagram(\" Tom Marvolo Riddle \", \" I am Lord Voldemort \") -> True is_anagram(\" A first string \", \" Definitely not an anagram \") -> False \"\"\" _ str1 , _ str2 = ( str_1 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), str_2 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), ) return sorted ( _ str1 . lower ()) == sorted ( _ str2 . lower ()) @staticmethod def is_palindrome ( text : str ) -> bool : \"\"\" Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Args: text (str): a string. Returns: A boolean stating whether `string` is a palindrome or not. Usage: is_palindrome(\" racecar \") -> True is_palindrome(\" definitelynot \") -> False \"\"\" s_reverse = re . sub ( r \" [ \\ W_ ] \", \"\", text.lower()) return s_reverse == s_reverse[::-1] @staticmethod def kebab_case(text: str) -> str: \"\"\" Converts a string to kebab - case . Break the string into words and combine them adding - as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to kebab_case . Usage : kebab_case ( \"camel Case\" ) -> \"camel-case\" kebab_case ( \"snake_case\" ) -> \"snake-case\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" - \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \", lambda mo: mo.group(0).lower(), text, ), ) @staticmethod def snake_case(text: str) -> str: \"\"\" Converts a string to snake_case . Break the string into words and combine them adding _ as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to snake_case . Usage : snake_case ( \"A bunch of words\" ) -> \"a_bunch_of_words\" snake_case ( \"camelCase\" ) -> \"camelcase\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" _ \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \" , lambda mo : mo . group ( 0 ). lower (), text , ), ) Classes ListOperations class ListOperations ( / , * args , ** kwargs ) A class to group some common / useful operations on lists. View Source class ListOperations : \"\"\" A class to group some common / useful operations on lists. \"\"\" @ staticmethod def all_unique ( sequence : Sequence ) -> bool : \"\"\" Returns True if all the values in a flat list are unique, False otherwise. Args: sequence (Sequence): a sequence of elements. Returns: True if all elements are unique, False otherwise. \"\"\" return len ( sequence ) == len ( set ( sequence )) @ staticmethod def average_by ( sequence : Sequence , function : Callable = lambda x : x ) -> float : \"\"\" Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Args: sequence (Sequence): a sequence of elements. function (Callable): function to apply to elements of the sequence. Returns: The average of each element's result through `function`. Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 \"\"\" return float ( sum ( map ( function , sequence ), 0.0 ) / len ( sequence )) @ staticmethod def bifurcate ( sequence : Sequence , filters : List [ bool ]) -> Sequence : \"\"\" Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Args: sequence (Sequence): a sequence of elements. filters (List[bool]): a list of booleans. Returns: A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] \"\"\" return [ [ x for i , x in enumerate ( sequence ) if filters [ i ]], [ x for i , x in enumerate ( sequence ) if not filters [ i ]], ] @ staticmethod def bifurcate_by ( sequence : Sequence , function : Callable ) -> list : \"\"\" Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of lst, that should return a boolean. Returns: A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] \"\"\" return [[ x for x in sequence if function ( x )], [ x for x in sequence if not function ( x )]] @ staticmethod def chunk_list ( sequence : Sequence , size : int ) -> Sequence : \"\"\" Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Args: sequence (Sequence): a sequence of elements. size (int): the size of the wanted sublists. Returns: A list of lists of length `size` (except maybe the last element), with elements from `lst`. Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] \"\"\" if size > len ( sequence ): return sequence return list ( map ( lambda x : sequence [ x * size : x * size + size ], list ( range ( math . ceil ( len ( sequence ) / size ))), ) ) @ staticmethod def deep_flatten ( sequence : Sequence ) -> list : \"\"\" Deep flattens a list, no matter the nesting levels. This is a recursive approach. Args: sequence (Sequence): a sequence of elements. Returns: A list with all elements of `lst`, but flattened. Usage: deep_flatten([[\"a\", \"b\"], [1, 2], None, [True, False]]) -> [\"a\", \"b\", 1, 2, None True, False] \"\"\" return ( [ elem for sublist in sequence for elem in ListOperations . deep_flatten ( sublist )] if isinstance ( sequence , list ) else [ sequence ] ) @ staticmethod def eval_none ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False \"\"\" return not any ( map ( function , sequence )) @ staticmethod def eval_some ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False \"\"\" return any ( map ( function , sequence )) @ staticmethod def get_indices ( element , sequence : Sequence ) -> List [ int ]: \"\"\" Return all array indices at which number is located. Args: element: any reference element to check. sequence (Sequence): a sequence containing objects comparable to `elements`. A string can be compared to an int in Python, custom objects probably won't be comparable. Returns: A list of all indices at which `element` is found in `sequence`. Empty list if `element` is not present in `sequence` at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] \"\"\" return [ i for ( y , i ) in zip ( sequence , range ( len ( sequence ))) if element == y ] @ staticmethod def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ]: \"\"\" Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of `sequence` that should return a boolean. Returns: A dict with keys \"True\" and \"False\", each having as value a list of all elements of `lst` that were evaluated to respectively `True` or `False` through `function`. Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} \"\"\" groups = {} for key in list ( map ( function , sequence )): groups [ key ] = [ item for item in sequence if function ( item ) == key ] return groups @ staticmethod def has_duplicates ( sequence : Sequence ) -> bool : \"\"\" Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Args: sequence (Sequence): a sequence of elements. Returns: A boolean indicating the presence of duplicates in `lst`. Usage: has_duplicates([1, 2, 1]) -> True \"\"\" return len ( sequence ) != len ( set ( sequence )) @ staticmethod def sample ( sequence : Sequence ) -> list : \"\"\" Returns a random element from an array. Args: sequence (Sequence): a sequence of elements. Returns: A random element from `lst` in a list (to manage potentially nested lists as input). \"\"\" return sequence [ random . randint ( 0 , len ( sequence ) - 1 )] @ staticmethod def sanitize_list ( sequence : Sequence ) -> list : \"\"\" Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Args: sequence (Sequence): a sequence of elements. Returns: The sequence without falsy values. Usage: sanitize_list([1, False, \"a\", 2, \"\", None, 6, 0]) -> [1, \"a\", 2, 6] \"\"\" return list ( filter ( bool , sequence )) @ staticmethod def shuffle ( sequence : Sequence ) -> Sequence : \"\"\" Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm (https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle) to reorder the elements. Args: sequence (Sequence): a sequence of elements. Returns: The `lst` with original elements at a random index. \"\"\" temp_list = copy . deepcopy ( sequence ) amount_to_shuffle = len ( temp_list ) while amount_to_shuffle > 1 : rand_index = int ( math . floor ( random . random () * amount_to_shuffle )) amount_to_shuffle -= 1 temp_list [ rand_index ], temp_list [ amount_to_shuffle ] = ( temp_list [ amount_to_shuffle ], temp_list [ rand_index ], ) return temp_list @ staticmethod def spread ( sequence : Sequence ) -> list : \"\"\" Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in `lst` are iterables! Args: sequence (Sequence): a sequence of elements. Returns: The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] \"\"\" return list ( itertools . chain . from_iterable ( sequence )) @ staticmethod def symmetric_difference_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \"\"\" Returns the symmetric difference (https://en.wikipedia.org/wiki/Symmetric_difference) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] \"\"\" _lst_1 , _lst_2 = set ( map ( function , lst_1 )), set ( map ( function , lst_2 )) return [ item for item in lst_1 if function ( item ) not in _lst_2 ] + [ item for item in lst_2 if function ( item ) not in _lst_1 ] @ staticmethod def union_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \"\"\" Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union (https://en.wikipedia.org/wiki/Union_(set_theory)) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] \"\"\" _lst_1 = set ( map ( function , lst_1 )) return sorted ( list ( set ( lst_1 + [ item for item in lst_2 if function ( item ) not in _lst_1 ]))) @ staticmethod def zipper ( * args , fillvalue = None ) -> list : \"\"\" Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Args: *args: a number (>= 2) of different iterables. fillvalue: value to use in case of length mismatch. Returns: A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\"a\", \"b\", \"c\"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] \"\"\" max_length = max ( len ( lst ) for lst in args ) return [ [ args [ k ][ i ] if i < len ( args [ k ]) else fillvalue for k in range ( len ( args ))] for i in range ( max_length ) ] Static methods all_unique def all_unique ( sequence : Sequence ) -> bool Returns True if all the values in a flat list are unique, False otherwise. Args: sequence (Sequence): a sequence of elements. Returns: True if all elements are unique, False otherwise. View Source @staticmethod def all_unique ( sequence : Sequence ) -> bool : \"\"\" Returns True if all the values in a flat list are unique, False otherwise. Args: sequence (Sequence): a sequence of elements. Returns: True if all elements are unique, False otherwise. \"\"\" return len ( sequence ) == len ( set ( sequence )) average_by def average_by ( sequence : Sequence , function : Callable = < function ListOperations .< lambda > at 0x7ff23826e4d0 > ) -> float Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Args: sequence (Sequence): a sequence of elements. function (Callable): function to apply to elements of the sequence. Returns: The average of each element's result through function . Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 View Source @staticmethod def average_by ( sequence : Sequence , function : Callable = lambda x : x ) -> float : \" \"\" Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Args: sequence (Sequence): a sequence of elements. function (Callable): function to apply to elements of the sequence. Returns: The average of each element's result through `function`. Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 \"\" \" return float ( sum ( map ( function , sequence ), 0.0 ) / len ( sequence )) bifurcate def bifurcate ( sequence : Sequence , filters : List [ bool ] ) -> Sequence Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Args: sequence (Sequence): a sequence of elements. filters (List[bool]): a list of booleans. Returns: A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] View Source @staticmethod def bifurcate ( sequence : Sequence , filters : List [ bool ] ) -> Sequence : \"\"\" Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Args: sequence (Sequence): a sequence of elements. filters (List[bool]): a list of booleans. Returns: A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] \"\"\" return [ [x for i, x in enumerate(sequence) if filters[i ] ] , [ x for i, x in enumerate(sequence) if not filters[i ] ] , ] bifurcate_by def bifurcate_by ( sequence : Sequence , function : Callable ) -> list Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of lst, that should return a boolean. Returns: A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] View Source @staticmethod def bifurcate_by ( sequence : Sequence , function : Callable ) -> list : \"\"\" Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of lst, that should return a boolean. Returns: A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] \"\"\" return [ [x for x in sequence if function(x) ] , [ x for x in sequence if not function(x) ] ] chunk_list def chunk_list ( sequence : Sequence , size : int ) -> Sequence Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Args: sequence (Sequence): a sequence of elements. size (int): the size of the wanted sublists. Returns: A list of lists of length size (except maybe the last element), with elements from lst . Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] View Source @staticmethod def chunk_list ( sequence : Sequence , size : int ) -> Sequence : \" \"\" Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Args: sequence (Sequence): a sequence of elements. size (int): the size of the wanted sublists. Returns: A list of lists of length `size` (except maybe the last element), with elements from `lst`. Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] \"\" \" if size > len ( sequence ) : return sequence return list ( map ( lambda x : sequence [ x * size : x * size + size ] , list ( range ( math . ceil ( len ( sequence ) / size ))), ) ) deep_flatten def deep_flatten ( sequence : Sequence ) -> list Deep flattens a list, no matter the nesting levels. This is a recursive approach. Args: sequence (Sequence): a sequence of elements. Returns: A list with all elements of lst , but flattened. Usage: deep_flatten([[\"a\", \"b\"], [1, 2], None, [True, False]]) -> [\"a\", \"b\", 1, 2, None True, False] View Source @staticmethod def deep_flatten ( sequence : Sequence ) -> list : \"\"\" Deep flattens a list, no matter the nesting levels. This is a recursive approach. Args: sequence (Sequence): a sequence of elements. Returns: A list with all elements of `lst`, but flattened. Usage: deep_flatten([[\" a \", \" b \"], [1, 2], None, [True, False]]) -> [\" a \", \" b \", 1, 2, None True, False] \"\"\" return ( [ elem for sublist in sequence for elem in ListOperations.deep_flatten(sublist) ] if isinstance ( sequence , list ) else [ sequence ] ) eval_none def eval_none ( sequence : Sequence , function : Callable = < function ListOperations .< lambda > at 0x7ff23826e830 > ) -> bool Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of sequence that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False View Source @staticmethod def eval_none ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \" \"\" Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False \"\" \" return not any ( map ( function , sequence )) eval_some def eval_some ( sequence : Sequence , function : Callable = < function ListOperations .< lambda > at 0x7ff23826e950 > ) -> bool Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of sequence that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False View Source @staticmethod def eval_some ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \" \"\" Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False \"\" \" return any ( map ( function , sequence )) get_indices def get_indices ( element , sequence : Sequence ) -> List [ int ] Return all array indices at which number is located. Args: element: any reference element to check. sequence (Sequence): a sequence containing objects comparable to elements . A string can be compared to an int in Python, custom objects probably won't be comparable. Returns: A list of all indices at which element is found in sequence . Empty list if element is not present in sequence at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] View Source @staticmethod def get_indices ( element , sequence : Sequence ) -> List [ int ] : \" \"\" Return all array indices at which number is located. Args: element: any reference element to check. sequence (Sequence): a sequence containing objects comparable to `elements`. A string can be compared to an int in Python, custom objects probably won't be comparable. Returns: A list of all indices at which `element` is found in `sequence`. Empty list if `element` is not present in `sequence` at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] \"\" \" return [ i for ( y , i ) in zip ( sequence , range ( len ( sequence ))) if element == y ] group_by def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ] Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of sequence that should return a boolean. Returns: A dict with keys \"True\" and \"False\", each having as value a list of all elements of lst that were evaluated to respectively True or False through function . Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} View Source @staticmethod def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ] : \" \"\" Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of `sequence` that should return a boolean. Returns: A dict with keys \" True \" and \" False \", each having as value a list of all elements of `lst` that were evaluated to respectively `True` or `False` through `function`. Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} \"\" \" groups = {} for key in list ( map ( function , sequence )) : groups [ key ] = [ item for item in sequence if function ( item ) == key ] return groups has_duplicates def has_duplicates ( sequence : Sequence ) -> bool Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Args: sequence (Sequence): a sequence of elements. Returns: A boolean indicating the presence of duplicates in lst . Usage: has_duplicates([1, 2, 1]) -> True View Source @staticmethod def has_duplicates ( sequence : Sequence ) -> bool : \" \"\" Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Args: sequence (Sequence): a sequence of elements. Returns: A boolean indicating the presence of duplicates in `lst`. Usage: has_duplicates([1, 2, 1]) -> True \"\" \" return len ( sequence ) != len ( set ( sequence )) sample def sample ( sequence : Sequence ) -> list Returns a random element from an array. Args: sequence (Sequence): a sequence of elements. Returns: A random element from lst in a list (to manage potentially nested lists as input). View Source @staticmethod def sample ( sequence : Sequence ) -> list : \" \"\" Returns a random element from an array. Args: sequence (Sequence): a sequence of elements. Returns: A random element from `lst` in a list (to manage potentially nested lists as input). \"\" \" return sequence [ random . randint ( 0 , len ( sequence ) - 1 ) ] sanitize_list def sanitize_list ( sequence : Sequence ) -> list Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Args: sequence (Sequence): a sequence of elements. Returns: The sequence without falsy values. Usage: sanitize_list([1, False, \"a\", 2, \"\", None, 6, 0]) -> [1, \"a\", 2, 6] View Source @staticmethod def sanitize_list ( sequence : Sequence ) -> list : \"\"\" Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Args: sequence (Sequence): a sequence of elements. Returns: The sequence without falsy values. Usage: sanitize_list([1, False, \" a \", 2, \"\", None, 6, 0]) -> [1, \" a \", 2, 6] \"\"\" return list ( filter ( bool , sequence )) shuffle def shuffle ( sequence : Sequence ) -> Sequence Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm ( https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle ) to reorder the elements. Args: sequence (Sequence): a sequence of elements. Returns: The lst with original elements at a random index. View Source @staticmethod def shuffle ( sequence : Sequence ) -> Sequence : \"\"\" Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm (https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle) to reorder the elements. Args: sequence (Sequence): a sequence of elements. Returns: The `lst` with original elements at a random index. \"\"\" temp_list = copy . deepcopy ( sequence ) amount_to_shuffle = len ( temp_list ) while amount_to_shuffle > 1 : rand_index = int ( math . floor ( random . random () * amount_to_shuffle )) amount_to_shuffle -= 1 temp_list [ rand_index ] , temp_list [ amount_to_shuffle ] = ( temp_list [ amount_to_shuffle ] , temp_list [ rand_index ] , ) return temp_list spread def spread ( sequence : Sequence ) -> list Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in lst are iterables! Args: sequence (Sequence): a sequence of elements. Returns: The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] View Source @staticmethod def spread ( sequence : Sequence ) -> list : \" \"\" Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in `lst` are iterables! Args: sequence (Sequence): a sequence of elements. Returns: The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] \"\" \" return list ( itertools . chain . from_iterable ( sequence )) symmetric_difference_by def symmetric_difference_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list Returns the symmetric difference ( https://en.wikipedia.org/wiki/Symmetric_difference ) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of lst_1 and lst_2 . Returns: A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] View Source @staticmethod def symmetric_difference_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \" \"\" Returns the symmetric difference (https://en.wikipedia.org/wiki/Symmetric_difference) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] \"\" \" _lst_1 , _lst_2 = set ( map ( function , lst_1 )), set ( map ( function , lst_2 )) return [ item for item in lst_1 if function ( item ) not in _lst_2 ] + [ item for item in lst_2 if function ( item ) not in _lst_1 ] union_by def union_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union ( https://en.wikipedia.org/wiki/Union_(set_theory )) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of lst_1 and lst_2 . Returns: A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] View Source @staticmethod def union_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \" \"\" Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union (https://en.wikipedia.org/wiki/Union_(set_theory)) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] \"\" \" _lst_1 = set ( map ( function , lst_1 )) return sorted ( list ( set ( lst_1 + [ item for item in lst_2 if function ( item ) not in _lst_1 ] ))) zipper def zipper ( * args , fillvalue = None ) -> list Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Args: *args: a number (>= 2) of different iterables. fillvalue: value to use in case of length mismatch. Returns: A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\"a\", \"b\", \"c\"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] View Source @staticmethod def zipper ( * args , fillvalue = None ) -> list : \"\"\" Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Args: *args: a number (>= 2) of different iterables. fillvalue: value to use in case of length mismatch. Returns: A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\" a \", \" b \", \" c \"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] \"\"\" max_length = max ( len ( lst ) for lst in args ) return [ [args[k ][ i ] if i < len ( args [ k ] ) else fillvalue for k in range ( len ( args )) ] for i in range ( max_length ) ] MiscellaneousOperations class MiscellaneousOperations ( / , * args , ** kwargs ) A class to group some misc. operations that don't pertain to classic structures. View Source class MiscellaneousOperations : \"\"\" A class to group some misc. operations that don't pertain to classic structures. \"\"\" @staticmethod def longest_item ( * args ) : \"\"\" Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Args: *args: any number (>= 2) of iterables. Returns: The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) \"\"\" return max ( args , key = len ) @staticmethod def map_values ( obj : dict , function : Callable ) -> dict : \"\"\" Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Args: obj: a dictionary. function (Callable): a callable on values of `obj`. Returns: A new dictionary with the results. Usage: map_values( {\" a \": list(range(5)), \" b \": list(range(10)), \" c \": list(range(15))}, lambda x: len(x) ) -> {\" a \": 5, \" b \": 10, \" c \": 15} \"\"\" ret = {} for key in obj : ret [ key ] = function ( obj [ key ] ) return ret Static methods longest_item def longest_item ( * args ) Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Args: *args: any number (>= 2) of iterables. Returns: The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) View Source @staticmethod def longest_item ( * args ) : \"\"\" Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Args: *args: any number (>= 2) of iterables. Returns: The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) \"\"\" return max ( args , key = len ) map_values def map_values ( obj : dict , function : Callable ) -> dict Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Args: obj: a dictionary. function (Callable): a callable on values of obj . Returns: A new dictionary with the results. Usage: map_values( {\"a\": list(range(5)), \"b\": list(range(10)), \"c\": list(range(15))}, lambda x: len(x) ) -> {\"a\": 5, \"b\": 10, \"c\": 15} View Source @staticmethod def map_values ( obj : dict , function : Callable ) -> dict : \"\"\" Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Args: obj: a dictionary. function (Callable): a callable on values of `obj`. Returns: A new dictionary with the results. Usage: map_values( {\" a \": list(range(5)), \" b \": list(range(10)), \" c \": list(range(15))}, lambda x: len(x) ) -> {\" a \": 5, \" b \": 10, \" c \": 15} \"\"\" ret = {} for key in obj : ret [ key ] = function ( obj [ key ] ) return ret NumberOperations class NumberOperations ( / , * args , ** kwargs ) A class to group some common / useful operations on numbers. View Source class NumberOperations : \" \"\" A class to group some common / useful operations on numbers. \"\" \" @staticmethod def clamp_number ( num : Union [ int , float ] , a_val : Union [ int , float ] , b_val : Union [ int , float ] ) -> Union [ int , float ] : \" \"\" Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Args: num (Union[int, float]): a number (float / int) a_val (Union[int, float]): a number (float / int) b_val (Union[int, float]): a number (float / int) Returns: A number (float / int), being the nearest to `num` in the range [`a_val`, `b_val`]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 \"\" \" return max ( min ( num , max ( a_val , b_val )), min ( a_val , b_val )) @staticmethod def degrees_to_radians ( deg_value : Union [ int , float ] , decompose : bool = False ) -> Union [ Tuple [ float , str , str ] , int , float ] : \" \"\" Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Args: deg_value (Union[int, float]): angle value in degrees. decompose (bool): boolean option to return a more verbose result. Defaults to False. Returns: The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \" pi \", \" rad \") \"\" \" if decompose : return deg_value / 180 , \"pi\" , \"rad\" return ( deg_value * math . pi ) / 180.0 @staticmethod def greatest_common_divisor ( numbers_list : Sequence ) -> Union [ int , float ] : \" \"\" Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in `numbers_list`. Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 \"\" \" return reduce ( math . gcd , numbers_list ) @staticmethod def is_divisible_by ( dividend : Union [ int , float ] , divisor : Union [ int , float ] ) -> bool : \" \"\" Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Args: dividend (Union[int, float]): a number. divisor (Union[int, float]): a number. Returns: A boolean stating if `dividend` can be divided by `divisor`. \"\" \" return dividend % divisor == 0 @staticmethod def least_common_multiple ( * args ) -> int : \" \"\" Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 \"\" \" numbers = list ( ListOperations . spread ( list ( args ))) def _lcm ( number1 , number2 ) : \" \"\" A least common multiple method for two numbers only \"\" \" return int ( number1 * number2 / math . gcd ( number1 , number2 )) return reduce ( lambda x , y : _lcm ( x , y ), numbers ) @staticmethod def radians_to_degrees ( rad_value : Union [ int , float ] ) -> Union [ int , float ] : \" \"\" Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Args: rad_value (Union[int, float]): angle value in degrees. Returns: The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 \"\" \" return ( rad_value * 180.0 ) / math . pi Static methods clamp_number def clamp_number ( num : Union [ int , float ], a_val : Union [ int , float ], b_val : Union [ int , float ] ) -> Union [ int , float ] Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Args: num (Union[int, float]): a number (float / int) a_val (Union[int, float]): a number (float / int) b_val (Union[int, float]): a number (float / int) Returns: A number (float / int), being the nearest to num in the range [ a_val , b_val ]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 View Source @staticmethod def clamp_number ( num : Union [ int , float ] , a_val : Union [ int , float ] , b_val : Union [ int , float ] ) -> Union [ int , float ] : \" \"\" Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Args: num (Union[int, float]): a number (float / int) a_val (Union[int, float]): a number (float / int) b_val (Union[int, float]): a number (float / int) Returns: A number (float / int), being the nearest to `num` in the range [`a_val`, `b_val`]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 \"\" \" return max ( min ( num , max ( a_val , b_val )), min ( a_val , b_val )) degrees_to_radians def degrees_to_radians ( deg_value : Union [ int , float ], decompose : bool = False ) -> Union [ Tuple [ float , str , str ], int , float ] Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Args: deg_value (Union[int, float]): angle value in degrees. decompose (bool): boolean option to return a more verbose result. Defaults to False. Returns: The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \"pi\", \"rad\") View Source @staticmethod def degrees_to_radians ( deg_value : Union [ int, float ] , decompose : bool = False ) -> Union [ Tuple[float, str, str ] , int , float ]: \"\"\" Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Args: deg_value (Union[int, float]): angle value in degrees. decompose (bool): boolean option to return a more verbose result. Defaults to False. Returns: The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \" pi \", \" rad \") \"\"\" if decompose : return deg_value / 180 , \"pi\" , \"rad\" return ( deg_value * math . pi ) / 180.0 greatest_common_divisor def greatest_common_divisor ( numbers_list : Sequence ) -> Union [ int , float ] Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in numbers_list . Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 View Source @staticmethod def greatest_common_divisor ( numbers_list : Sequence ) -> Union [ int , float ] : \" \"\" Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in `numbers_list`. Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 \"\" \" return reduce ( math . gcd , numbers_list ) is_divisible_by def is_divisible_by ( dividend : Union [ int , float ], divisor : Union [ int , float ] ) -> bool Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Args: dividend (Union[int, float]): a number. divisor (Union[int, float]): a number. Returns: A boolean stating if dividend can be divided by divisor . View Source @staticmethod def is_divisible_by ( dividend : Union [ int , float ] , divisor : Union [ int , float ] ) -> bool : \" \"\" Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Args: dividend (Union[int, float]): a number. divisor (Union[int, float]): a number. Returns: A boolean stating if `dividend` can be divided by `divisor`. \"\" \" return dividend % divisor == 0 least_common_multiple def least_common_multiple ( * args ) -> int Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 View Source @staticmethod def least_common_multiple ( * args ) -> int : \"\"\" Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 \"\"\" numbers = list ( ListOperations . spread ( list ( args ))) def _lcm ( number1 , number2 ) : \"\"\"A least common multiple method for two numbers only\"\"\" return int ( number1 * number2 / math . gcd ( number1 , number2 )) return reduce ( lambda x , y : _lcm ( x , y ), numbers ) radians_to_degrees def radians_to_degrees ( rad_value : Union [ int , float ] ) -> Union [ int , float ] Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Args: rad_value (Union[int, float]): angle value in degrees. Returns: The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 View Source @staticmethod def radians_to_degrees ( rad_value : Union [ int, float ] ) -> Union [ int, float ] : \"\"\" Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Args: rad_value (Union[int, float]): angle value in degrees. Returns: The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 \"\"\" return ( rad_value * 180.0 ) / math . pi StringOperations class StringOperations ( / , * args , ** kwargs ) A class to group some common / useful operations on strings. View Source class StringOperations : \"\"\" A class to group some common / useful operations on strings. \"\"\" @staticmethod def camel_case ( text : str ) -> str : \"\"\" Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Args: text (str): a string. Returns: The same string best adapted to camel_case. Usage: camel_case(\" a_snake_case_name \") -> \" aSnakeCaseName \" camel_case(\" A Title Case Name \") -> \" aTitleCaseName \" \"\"\" text = re . sub ( r \"(\\s|_|-)+\" , \" \" , text ). title (). replace ( \" \" , \"\" ) return text [ 0 ]. lower () + text [ 1 : ] @staticmethod def capitalize ( text : str , lower_rest: bool = False ) -> str : \"\"\" Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Args: text (str): a string. lower_rest (bool): boolean option to lower all elements starting from the second. Returns: The `string`, capitalized. Usage: capitalize(\" astringtocapitalize \") -> \" Astringtocapitalize \" capitalize(\" astRIngTocApItalizE \", lower_rest=True) -> \" Astringtocapitalize \" \"\"\" return text [ : 1 ]. upper () + ( text [ 1 : ]. lower () if lower_rest else text [ 1 : ]) @staticmethod def is_anagram ( str_1: str , str_2: str ) -> bool : \"\"\" Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Args: str_1 (str): a string. str_2 (str): a string. Returns: A boolean stating whether `str_1` is an anagram of `str_2` or not. Usage: is_anagram(\" Tom Marvolo Riddle \", \" I am Lord Voldemort \") -> True is_anagram(\" A first string \", \" Definitely not an anagram \") -> False \"\"\" _ str1 , _ str2 = ( str_1 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), str_2 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), ) return sorted ( _ str1 . lower ()) == sorted ( _ str2 . lower ()) @staticmethod def is_palindrome ( text : str ) -> bool : \"\"\" Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Args: text (str): a string. Returns: A boolean stating whether `string` is a palindrome or not. Usage: is_palindrome(\" racecar \") -> True is_palindrome(\" definitelynot \") -> False \"\"\" s_reverse = re . sub ( r \" [ \\ W_ ] \", \"\", text.lower()) return s_reverse == s_reverse[::-1] @staticmethod def kebab_case(text: str) -> str: \"\"\" Converts a string to kebab - case . Break the string into words and combine them adding - as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to kebab_case . Usage : kebab_case ( \"camel Case\" ) -> \"camel-case\" kebab_case ( \"snake_case\" ) -> \"snake-case\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" - \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \", lambda mo: mo.group(0).lower(), text, ), ) @staticmethod def snake_case(text: str) -> str: \"\"\" Converts a string to snake_case . Break the string into words and combine them adding _ as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to snake_case . Usage : snake_case ( \"A bunch of words\" ) -> \"a_bunch_of_words\" snake_case ( \"camelCase\" ) -> \"camelcase\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" _ \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \" , lambda mo : mo . group ( 0 ). lower (), text , ), ) Static methods camel_case def camel_case ( text : str ) -> str Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Args: text (str): a string. Returns: The same string best adapted to camel_case. Usage: camel_case(\"a_snake_case_name\") -> \"aSnakeCaseName\" camel_case(\"A Title Case Name\") -> \"aTitleCaseName\" View Source @staticmethod def camel_case ( text : str ) -> str : \"\"\" Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Args: text (str): a string. Returns: The same string best adapted to camel_case. Usage: camel_case(\" a_snake_case_name \") -> \" aSnakeCaseName \" camel_case(\" A Title Case Name \") -> \" aTitleCaseName \" \"\"\" text = re . sub ( r \"(\\s|_|-)+\" , \" \" , text ). title (). replace ( \" \" , \"\" ) return text [ 0 ] . lower () + text [ 1: ] capitalize def capitalize ( text : str , lower_rest : bool = False ) -> str Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Args: text (str): a string. lower_rest (bool): boolean option to lower all elements starting from the second. Returns: The string , capitalized. Usage: capitalize(\"astringtocapitalize\") -> \"Astringtocapitalize\" capitalize(\"astRIngTocApItalizE\", lower_rest=True) -> \"Astringtocapitalize\" View Source @staticmethod def capitalize ( text : str , lower_rest : bool = False ) -> str : \" \"\" Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Args: text (str): a string. lower_rest (bool): boolean option to lower all elements starting from the second. Returns: The `string`, capitalized. Usage: capitalize(\" astringtocapitalize \") -> \" Astringtocapitalize \" capitalize(\" astRIngTocApItalizE \", lower_rest=True) -> \" Astringtocapitalize \" \"\" \" return text [ : 1 ] . upper () + ( text [ 1 : ] . lower () if lower_rest else text [ 1 : ] ) is_anagram def is_anagram ( str_1 : str , str_2 : str ) -> bool Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Args: str_1 (str): a string. str_2 (str): a string. Returns: A boolean stating whether str_1 is an anagram of str_2 or not. Usage: is_anagram(\"Tom Marvolo Riddle\", \"I am Lord Voldemort\") -> True is_anagram(\"A first string\", \"Definitely not an anagram\") -> False View Source @staticmethod def is_anagram ( str_1 : str , str_2 : str ) -> bool : \" \"\" Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Args: str_1 (str): a string. str_2 (str): a string. Returns: A boolean stating whether `str_1` is an anagram of `str_2` or not. Usage: is_anagram(\" Tom Marvolo Riddle \", \" I am Lord Voldemort \") -> True is_anagram(\" A first string \", \" Definitely not an anagram \") -> False \"\" \" _str1 , _str2 = ( str_1 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), str_2 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), ) return sorted ( _str1 . lower ()) == sorted ( _str2 . lower ()) is_palindrome def is_palindrome ( text : str ) -> bool Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Args: text (str): a string. Returns: A boolean stating whether string is a palindrome or not. Usage: is_palindrome(\"racecar\") -> True is_palindrome(\"definitelynot\") -> False View Source @staticmethod def is_palindrome ( text : str ) -> bool : \"\"\" Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Args: text (str): a string. Returns: A boolean stating whether `string` is a palindrome or not. Usage: is_palindrome(\" racecar \") -> True is_palindrome(\" definitelynot \") -> False \"\"\" s_reverse = re . sub ( r \" [ \\ W_ ] \", \" \" , text . lower ()) return s_reverse == s_reverse [ ::- 1 ] kebab_case def kebab_case ( text : str ) -> str Converts a string to kebab-case. Break the string into words and combine them adding - as a separator, using a regexp. Args: text (str): a string. Returns: The same string best adapted to kebab_case. Usage: kebab_case(\"camel Case\") -> \"camel-case\" kebab_case(\"snake_case\") -> \"snake-case\" View Source @staticmethod def kebab_case ( text : str ) -> str : \"\"\" Converts a string to kebab-case. Break the string into words and combine them adding - as a separator, using a regexp. Args: text (str): a string. Returns: The same string best adapted to kebab_case. Usage: kebab_case(\" camel Case \") -> \" camel - case \" kebab_case(\" snake_case \") -> \" snake - case \" \"\"\" return re . sub ( r \"(\\s|_|-)+\" , \"-\" , re . sub ( r \"[A-Z]{2,}(?=[A-Z][a-z]+[0-9]*|\\b)|[A-Z]?[a-z]+[0-9]*|[A-Z]|[0-9]+\" , lambda mo : mo . group ( 0 ). lower (), text , ), ) snake_case def snake_case ( text : str ) -> str Converts a string to snake_case. Break the string into words and combine them adding _ as a separator, using a regexp. Args: text (str): a string. Returns: The same string best adapted to snake_case. Usage: snake_case(\"A bunch of words\") -> \"a_bunch_of_words\" snake_case(\"camelCase\") -> \"camelcase\" View Source @staticmethod def snake_case ( text : str ) -> str : \"\"\" Converts a string to snake_case. Break the string into words and combine them adding _ as a separator, using a regexp. Args: text (str): a string. Returns: The same string best adapted to snake_case. Usage: snake_case(\" A bunch of words \") -> \" a_bunch_of_words \" snake_case(\" camelCase \") -> \" camelcase \" \"\"\" return re . sub ( r \"(\\s|_|-)+\" , \"_\" , re . sub ( r \"[A-Z]{2,}(?=[A-Z][a-z]+[0-9]*|\\b)|[A-Z]?[a-z]+[0-9]*|[A-Z]|[0-9]+\" , lambda mo : mo . group ( 0 ). lower (), text , ), )","title":"Operations"},{"location":"reference/pyhdtoolkit/utils/operations/#module-pyhdtoolkitutilsoperations","text":"","title":"Module pyhdtoolkit.utils.operations"},{"location":"reference/pyhdtoolkit/utils/operations/#module-utilsoperations","text":"Created on 2019.11.12 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A collection classes with utility functions to perform common / convenient operations on the classic Python structures. View Source \"\"\" Module utils.operations ----------------------- Created on 2019.11.12 :author: Felix Soubelet (felix.soubelet@cern.ch) A collection classes with utility functions to perform common / convenient operations on the classic Python structures. \"\"\" import copy import itertools import math import random import re from functools import reduce from typing import Callable , Dict , List , Sequence , Tuple , Union class ListOperations : \"\"\" A class to group some common / useful operations on lists. \"\"\" @staticmethod def all_unique ( sequence : Sequence ) -> bool : \"\"\" Returns True if all the values in a flat list are unique, False otherwise. Args: sequence (Sequence): a sequence of elements. Returns: True if all elements are unique, False otherwise. \"\"\" return len ( sequence ) == len ( set ( sequence )) @staticmethod def average_by ( sequence : Sequence , function : Callable = lambda x : x ) -> float : \"\"\" Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Args: sequence (Sequence): a sequence of elements. function (Callable): function to apply to elements of the sequence. Returns: The average of each element's result through `function`. Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 \"\"\" return float ( sum ( map ( function , sequence ), 0.0 ) / len ( sequence )) @staticmethod def bifurcate ( sequence : Sequence , filters : List [ bool ]) -> Sequence : \"\"\" Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Args: sequence (Sequence): a sequence of elements. filters (List[bool]): a list of booleans. Returns: A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] \"\"\" return [ [ x for i , x in enumerate ( sequence ) if filters [ i ]], [ x for i , x in enumerate ( sequence ) if not filters [ i ]], ] @staticmethod def bifurcate_by ( sequence : Sequence , function : Callable ) -> list : \"\"\" Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of lst, that should return a boolean. Returns: A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] \"\"\" return [[ x for x in sequence if function ( x )], [ x for x in sequence if not function ( x )]] @staticmethod def chunk_list ( sequence : Sequence , size : int ) -> Sequence : \"\"\" Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Args: sequence (Sequence): a sequence of elements. size (int): the size of the wanted sublists. Returns: A list of lists of length `size` (except maybe the last element), with elements from `lst`. Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] \"\"\" if size > len ( sequence ) : return sequence return list ( map ( lambda x : sequence [ x * size : x * size + size ], list ( range ( math . ceil ( len ( sequence ) / size ))), ) ) @staticmethod def deep_flatten ( sequence : Sequence ) -> list : \"\"\" Deep flattens a list, no matter the nesting levels. This is a recursive approach. Args: sequence (Sequence): a sequence of elements. Returns: A list with all elements of `lst`, but flattened. Usage: deep_flatten([[\" a \", \" b \"], [1, 2], None, [True, False]]) -> [\" a \", \" b \", 1, 2, None True, False] \"\"\" return ( [ elem for sublist in sequence for elem in ListOperations . deep_flatten ( sublist )] if isinstance ( sequence , list ) else [ sequence ] ) @staticmethod def eval_none ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False \"\"\" return not any ( map ( function , sequence )) @staticmethod def eval_some ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False \"\"\" return any ( map ( function , sequence )) @staticmethod def get_indices ( element , sequence : Sequence ) -> List [ int ] : \"\"\" Return all array indices at which number is located. Args: element: any reference element to check. sequence (Sequence): a sequence containing objects comparable to `elements`. A string can be compared to an int in Python, custom objects probably won't be comparable. Returns: A list of all indices at which `element` is found in `sequence`. Empty list if `element` is not present in `sequence` at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] \"\"\" return [ i for ( y , i ) in zip ( sequence , range ( len ( sequence ))) if element == y ] @staticmethod def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ] : \"\"\" Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of `sequence` that should return a boolean. Returns: A dict with keys \" True \" and \" False \", each having as value a list of all elements of `lst` that were evaluated to respectively `True` or `False` through `function`. Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} \"\"\" groups = {} for key in list ( map ( function , sequence )) : groups [ key ] = [ item for item in sequence if function ( item ) == key ] return groups @staticmethod def has_duplicates ( sequence : Sequence ) -> bool : \"\"\" Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Args: sequence (Sequence): a sequence of elements. Returns: A boolean indicating the presence of duplicates in `lst`. Usage: has_duplicates([1, 2, 1]) -> True \"\"\" return len ( sequence ) ! = len ( set ( sequence )) @staticmethod def sample ( sequence : Sequence ) -> list : \"\"\" Returns a random element from an array. Args: sequence (Sequence): a sequence of elements. Returns: A random element from `lst` in a list (to manage potentially nested lists as input). \"\"\" return sequence [ random . randint ( 0 , len ( sequence ) - 1 )] @staticmethod def sanitize_list ( sequence : Sequence ) -> list : \"\"\" Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Args: sequence (Sequence): a sequence of elements. Returns: The sequence without falsy values. Usage: sanitize_list([1, False, \" a \", 2, \"\", None, 6, 0]) -> [1, \" a \", 2, 6] \"\"\" return list ( filter ( bool , sequence )) @staticmethod def shuffle ( sequence : Sequence ) -> Sequence : \"\"\" Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm (https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle) to reorder the elements. Args: sequence (Sequence): a sequence of elements. Returns: The `lst` with original elements at a random index. \"\"\" temp_list = copy . deepcopy ( sequence ) amount_to_shuffle = len ( temp_list ) while amount_to_shuffle > 1 : rand_index = int ( math . floor ( random . random () * amount_to_shuffle )) amount_to_shuffle -= 1 temp_list [ rand_index ], temp_list [ amount_to_shuffle ] = ( temp_list [ amount_to_shuffle ], temp_list [ rand_index ], ) return temp_list @staticmethod def spread ( sequence : Sequence ) -> list : \"\"\" Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in `lst` are iterables! Args: sequence (Sequence): a sequence of elements. Returns: The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] \"\"\" return list ( itertools . chain . from_iterable ( sequence )) @staticmethod def symmetric_difference_by ( lst_1: Sequence , lst_2: Sequence , function : Callable ) -> list : \"\"\" Returns the symmetric difference (https://en.wikipedia.org/wiki/Symmetric_difference) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] \"\"\" _ lst_1 , _ lst_2 = set ( map ( function , lst_1 )), set ( map ( function , lst_2 )) return [ item for item in lst_1 if function ( item ) not in _ lst_2 ] + [ item for item in lst_2 if function ( item ) not in _ lst_1 ] @staticmethod def union_by ( lst_1: Sequence , lst_2: Sequence , function : Callable ) -> list : \"\"\" Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union (https://en.wikipedia.org/wiki/Union_(set_theory)) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] \"\"\" _ lst_1 = set ( map ( function , lst_1 )) return sorted ( list ( set ( lst_1 + [ item for item in lst_2 if function ( item ) not in _ lst_1 ]))) @staticmethod def zipper ( * args , fillvalue = None ) -> list : \"\"\" Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Args: *args: a number (>= 2) of different iterables. fillvalue: value to use in case of length mismatch. Returns: A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\" a \", \" b \", \" c \"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] \"\"\" max_length = max ( len ( lst ) for lst in args ) return [ [ args [ k ][ i ] if i < len ( args [ k ]) else fillvalue for k in range ( len ( args ))] for i in range ( max_length ) ] class MiscellaneousOperations : \"\"\" A class to group some misc. operations that don't pertain to classic structures. \"\"\" @staticmethod def longest_item ( * args ) : \"\"\" Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Args: *args: any number (>= 2) of iterables. Returns: The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) \"\"\" return max ( args , key = len ) @staticmethod def map_values ( obj : dict , function : Callable ) -> dict : \"\"\" Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Args: obj: a dictionary. function (Callable): a callable on values of `obj`. Returns: A new dictionary with the results. Usage: map_values( {\" a \": list(range(5)), \" b \": list(range(10)), \" c \": list(range(15))}, lambda x: len(x) ) -> {\" a \": 5, \" b \": 10, \" c \": 15} \"\"\" ret = {} for key in obj : ret [ key ] = function ( obj [ key ]) return ret class NumberOperations : \"\"\" A class to group some common / useful operations on numbers. \"\"\" @staticmethod def clamp_number ( num : Union [ int , float ], a_val: Union [ int , float ], b_val: Union [ int , float ] ) -> Union [ int , float ] : \"\"\" Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Args: num (Union[int, float]): a number (float / int) a_val (Union[int, float]): a number (float / int) b_val (Union[int, float]): a number (float / int) Returns: A number (float / int), being the nearest to `num` in the range [`a_val`, `b_val`]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 \"\"\" return max ( min ( num , max ( a_val , b_val )), min ( a_val , b_val )) @staticmethod def degrees_to_radians ( deg_value: Union [ int , float ], decompose : bool = False ) -> Union [ Tuple [ float , str , str ], int , float ] : \"\"\" Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Args: deg_value (Union[int, float]): angle value in degrees. decompose (bool): boolean option to return a more verbose result. Defaults to False. Returns: The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \" pi \", \" rad \") \"\"\" if decompose : return deg_value / 180 , \"pi\" , \"rad\" return ( deg_value * math . pi ) / 180.0 @staticmethod def greatest_common_divisor ( numbers_list: Sequence ) -> Union [ int , float ] : \"\"\" Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in `numbers_list`. Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 \"\"\" return reduce ( math . gcd , numbers_list ) @staticmethod def is_divisible_by ( dividend : Union [ int , float ], divisor : Union [ int , float ]) -> bool : \"\"\" Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Args: dividend (Union[int, float]): a number. divisor (Union[int, float]): a number. Returns: A boolean stating if `dividend` can be divided by `divisor`. \"\"\" return dividend % divisor == 0 @staticmethod def least_common_multiple ( * args ) -> int : \"\"\" Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 \"\"\" numbers = list ( ListOperations . spread ( list ( args ))) def _ lcm ( number1 , number2 ) : \"\"\"A least common multiple method for two numbers only\"\"\" return int ( number1 * number2 / math . gcd ( number1 , number2 )) return reduce ( lambda x , y : _ lcm ( x , y ), numbers ) @staticmethod def radians_to_degrees ( rad_value: Union [ int , float ]) -> Union [ int , float ] : \"\"\" Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Args: rad_value (Union[int, float]): angle value in degrees. Returns: The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 \"\"\" return ( rad_value * 180.0 ) / math . pi class StringOperations : \"\"\" A class to group some common / useful operations on strings. \"\"\" @staticmethod def camel_case ( text : str ) -> str : \"\"\" Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Args: text (str): a string. Returns: The same string best adapted to camel_case. Usage: camel_case(\" a_snake_case_name \") -> \" aSnakeCaseName \" camel_case(\" A Title Case Name \") -> \" aTitleCaseName \" \"\"\" text = re . sub ( r \"(\\s|_|-)+\" , \" \" , text ). title (). replace ( \" \" , \"\" ) return text [ 0 ]. lower () + text [ 1 : ] @staticmethod def capitalize ( text : str , lower_rest: bool = False ) -> str : \"\"\" Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Args: text (str): a string. lower_rest (bool): boolean option to lower all elements starting from the second. Returns: The `string`, capitalized. Usage: capitalize(\" astringtocapitalize \") -> \" Astringtocapitalize \" capitalize(\" astRIngTocApItalizE \", lower_rest=True) -> \" Astringtocapitalize \" \"\"\" return text [ : 1 ]. upper () + ( text [ 1 : ]. lower () if lower_rest else text [ 1 : ]) @staticmethod def is_anagram ( str_1: str , str_2: str ) -> bool : \"\"\" Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Args: str_1 (str): a string. str_2 (str): a string. Returns: A boolean stating whether `str_1` is an anagram of `str_2` or not. Usage: is_anagram(\" Tom Marvolo Riddle \", \" I am Lord Voldemort \") -> True is_anagram(\" A first string \", \" Definitely not an anagram \") -> False \"\"\" _ str1 , _ str2 = ( str_1 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), str_2 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), ) return sorted ( _ str1 . lower ()) == sorted ( _ str2 . lower ()) @staticmethod def is_palindrome ( text : str ) -> bool : \"\"\" Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Args: text (str): a string. Returns: A boolean stating whether `string` is a palindrome or not. Usage: is_palindrome(\" racecar \") -> True is_palindrome(\" definitelynot \") -> False \"\"\" s_reverse = re . sub ( r \" [ \\ W_ ] \", \"\", text.lower()) return s_reverse == s_reverse[::-1] @staticmethod def kebab_case(text: str) -> str: \"\"\" Converts a string to kebab - case . Break the string into words and combine them adding - as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to kebab_case . Usage : kebab_case ( \"camel Case\" ) -> \"camel-case\" kebab_case ( \"snake_case\" ) -> \"snake-case\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" - \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \", lambda mo: mo.group(0).lower(), text, ), ) @staticmethod def snake_case(text: str) -> str: \"\"\" Converts a string to snake_case . Break the string into words and combine them adding _ as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to snake_case . Usage : snake_case ( \"A bunch of words\" ) -> \"a_bunch_of_words\" snake_case ( \"camelCase\" ) -> \"camelcase\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" _ \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \" , lambda mo : mo . group ( 0 ). lower (), text , ), )","title":"Module utils.operations"},{"location":"reference/pyhdtoolkit/utils/operations/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/utils/operations/#listoperations","text":"class ListOperations ( / , * args , ** kwargs ) A class to group some common / useful operations on lists. View Source class ListOperations : \"\"\" A class to group some common / useful operations on lists. \"\"\" @ staticmethod def all_unique ( sequence : Sequence ) -> bool : \"\"\" Returns True if all the values in a flat list are unique, False otherwise. Args: sequence (Sequence): a sequence of elements. Returns: True if all elements are unique, False otherwise. \"\"\" return len ( sequence ) == len ( set ( sequence )) @ staticmethod def average_by ( sequence : Sequence , function : Callable = lambda x : x ) -> float : \"\"\" Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Args: sequence (Sequence): a sequence of elements. function (Callable): function to apply to elements of the sequence. Returns: The average of each element's result through `function`. Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 \"\"\" return float ( sum ( map ( function , sequence ), 0.0 ) / len ( sequence )) @ staticmethod def bifurcate ( sequence : Sequence , filters : List [ bool ]) -> Sequence : \"\"\" Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Args: sequence (Sequence): a sequence of elements. filters (List[bool]): a list of booleans. Returns: A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] \"\"\" return [ [ x for i , x in enumerate ( sequence ) if filters [ i ]], [ x for i , x in enumerate ( sequence ) if not filters [ i ]], ] @ staticmethod def bifurcate_by ( sequence : Sequence , function : Callable ) -> list : \"\"\" Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of lst, that should return a boolean. Returns: A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] \"\"\" return [[ x for x in sequence if function ( x )], [ x for x in sequence if not function ( x )]] @ staticmethod def chunk_list ( sequence : Sequence , size : int ) -> Sequence : \"\"\" Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Args: sequence (Sequence): a sequence of elements. size (int): the size of the wanted sublists. Returns: A list of lists of length `size` (except maybe the last element), with elements from `lst`. Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] \"\"\" if size > len ( sequence ): return sequence return list ( map ( lambda x : sequence [ x * size : x * size + size ], list ( range ( math . ceil ( len ( sequence ) / size ))), ) ) @ staticmethod def deep_flatten ( sequence : Sequence ) -> list : \"\"\" Deep flattens a list, no matter the nesting levels. This is a recursive approach. Args: sequence (Sequence): a sequence of elements. Returns: A list with all elements of `lst`, but flattened. Usage: deep_flatten([[\"a\", \"b\"], [1, 2], None, [True, False]]) -> [\"a\", \"b\", 1, 2, None True, False] \"\"\" return ( [ elem for sublist in sequence for elem in ListOperations . deep_flatten ( sublist )] if isinstance ( sequence , list ) else [ sequence ] ) @ staticmethod def eval_none ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False \"\"\" return not any ( map ( function , sequence )) @ staticmethod def eval_some ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \"\"\" Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False \"\"\" return any ( map ( function , sequence )) @ staticmethod def get_indices ( element , sequence : Sequence ) -> List [ int ]: \"\"\" Return all array indices at which number is located. Args: element: any reference element to check. sequence (Sequence): a sequence containing objects comparable to `elements`. A string can be compared to an int in Python, custom objects probably won't be comparable. Returns: A list of all indices at which `element` is found in `sequence`. Empty list if `element` is not present in `sequence` at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] \"\"\" return [ i for ( y , i ) in zip ( sequence , range ( len ( sequence ))) if element == y ] @ staticmethod def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ]: \"\"\" Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of `sequence` that should return a boolean. Returns: A dict with keys \"True\" and \"False\", each having as value a list of all elements of `lst` that were evaluated to respectively `True` or `False` through `function`. Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} \"\"\" groups = {} for key in list ( map ( function , sequence )): groups [ key ] = [ item for item in sequence if function ( item ) == key ] return groups @ staticmethod def has_duplicates ( sequence : Sequence ) -> bool : \"\"\" Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Args: sequence (Sequence): a sequence of elements. Returns: A boolean indicating the presence of duplicates in `lst`. Usage: has_duplicates([1, 2, 1]) -> True \"\"\" return len ( sequence ) != len ( set ( sequence )) @ staticmethod def sample ( sequence : Sequence ) -> list : \"\"\" Returns a random element from an array. Args: sequence (Sequence): a sequence of elements. Returns: A random element from `lst` in a list (to manage potentially nested lists as input). \"\"\" return sequence [ random . randint ( 0 , len ( sequence ) - 1 )] @ staticmethod def sanitize_list ( sequence : Sequence ) -> list : \"\"\" Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Args: sequence (Sequence): a sequence of elements. Returns: The sequence without falsy values. Usage: sanitize_list([1, False, \"a\", 2, \"\", None, 6, 0]) -> [1, \"a\", 2, 6] \"\"\" return list ( filter ( bool , sequence )) @ staticmethod def shuffle ( sequence : Sequence ) -> Sequence : \"\"\" Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm (https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle) to reorder the elements. Args: sequence (Sequence): a sequence of elements. Returns: The `lst` with original elements at a random index. \"\"\" temp_list = copy . deepcopy ( sequence ) amount_to_shuffle = len ( temp_list ) while amount_to_shuffle > 1 : rand_index = int ( math . floor ( random . random () * amount_to_shuffle )) amount_to_shuffle -= 1 temp_list [ rand_index ], temp_list [ amount_to_shuffle ] = ( temp_list [ amount_to_shuffle ], temp_list [ rand_index ], ) return temp_list @ staticmethod def spread ( sequence : Sequence ) -> list : \"\"\" Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in `lst` are iterables! Args: sequence (Sequence): a sequence of elements. Returns: The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] \"\"\" return list ( itertools . chain . from_iterable ( sequence )) @ staticmethod def symmetric_difference_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \"\"\" Returns the symmetric difference (https://en.wikipedia.org/wiki/Symmetric_difference) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] \"\"\" _lst_1 , _lst_2 = set ( map ( function , lst_1 )), set ( map ( function , lst_2 )) return [ item for item in lst_1 if function ( item ) not in _lst_2 ] + [ item for item in lst_2 if function ( item ) not in _lst_1 ] @ staticmethod def union_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \"\"\" Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union (https://en.wikipedia.org/wiki/Union_(set_theory)) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] \"\"\" _lst_1 = set ( map ( function , lst_1 )) return sorted ( list ( set ( lst_1 + [ item for item in lst_2 if function ( item ) not in _lst_1 ]))) @ staticmethod def zipper ( * args , fillvalue = None ) -> list : \"\"\" Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Args: *args: a number (>= 2) of different iterables. fillvalue: value to use in case of length mismatch. Returns: A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\"a\", \"b\", \"c\"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] \"\"\" max_length = max ( len ( lst ) for lst in args ) return [ [ args [ k ][ i ] if i < len ( args [ k ]) else fillvalue for k in range ( len ( args ))] for i in range ( max_length ) ]","title":"ListOperations"},{"location":"reference/pyhdtoolkit/utils/operations/#static-methods","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/utils/operations/#all_unique","text":"def all_unique ( sequence : Sequence ) -> bool Returns True if all the values in a flat list are unique, False otherwise. Args: sequence (Sequence): a sequence of elements. Returns: True if all elements are unique, False otherwise. View Source @staticmethod def all_unique ( sequence : Sequence ) -> bool : \"\"\" Returns True if all the values in a flat list are unique, False otherwise. Args: sequence (Sequence): a sequence of elements. Returns: True if all elements are unique, False otherwise. \"\"\" return len ( sequence ) == len ( set ( sequence ))","title":"all_unique"},{"location":"reference/pyhdtoolkit/utils/operations/#average_by","text":"def average_by ( sequence : Sequence , function : Callable = < function ListOperations .< lambda > at 0x7ff23826e4d0 > ) -> float Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Args: sequence (Sequence): a sequence of elements. function (Callable): function to apply to elements of the sequence. Returns: The average of each element's result through function . Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 View Source @staticmethod def average_by ( sequence : Sequence , function : Callable = lambda x : x ) -> float : \" \"\" Returns the average of lst after mapping each element to a value using the provided function. Use map() to map each element to the value returned by function. Use sum() to sum all of the mapped values, divide by len(lst). Args: sequence (Sequence): a sequence of elements. function (Callable): function to apply to elements of the sequence. Returns: The average of each element's result through `function`. Usage: average_by([{'n': 4}, {'n': 2}, {'n': 8}, {'n': 6}], lambda x: x['n']) -> 5.0 \"\" \" return float ( sum ( map ( function , sequence ), 0.0 ) / len ( sequence ))","title":"average_by"},{"location":"reference/pyhdtoolkit/utils/operations/#bifurcate","text":"def bifurcate ( sequence : Sequence , filters : List [ bool ] ) -> Sequence Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Args: sequence (Sequence): a sequence of elements. filters (List[bool]): a list of booleans. Returns: A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] View Source @staticmethod def bifurcate ( sequence : Sequence , filters : List [ bool ] ) -> Sequence : \"\"\" Splits values into two groups. If an element in filter is True, the corresponding element in the collection belongs to the first group; otherwise, it belongs to the second group. Use list comprehension and enumerate() to add elements to groups, based on filter. Args: sequence (Sequence): a sequence of elements. filters (List[bool]): a list of booleans. Returns: A list of two lists, one for each boolean output of the filters Usage: bifurcate(['beep', 'boop', 'foo', 'bar'], [True, True, False, True]) -> [['beep', 'boop', 'bar'], ['foo']] \"\"\" return [ [x for i, x in enumerate(sequence) if filters[i ] ] , [ x for i, x in enumerate(sequence) if not filters[i ] ] , ]","title":"bifurcate"},{"location":"reference/pyhdtoolkit/utils/operations/#bifurcate_by","text":"def bifurcate_by ( sequence : Sequence , function : Callable ) -> list Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of lst, that should return a boolean. Returns: A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] View Source @staticmethod def bifurcate_by ( sequence : Sequence , function : Callable ) -> list : \"\"\" Splits values into two groups according to a function, which specifies which group an element in the input list belongs to. If the function returns True, the element belongs to the first group; otherwise it belongs to the second group. Use list comprehension to add elements to groups, based on function. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of lst, that should return a boolean. Returns: A list of two lists, as groups of elements of lst classified depending on their result through function. Usage: bifurcate_by(list(range(5)), lambda x: x % 2 == 0) -> [[0, 2, 4], [1, 3]] \"\"\" return [ [x for x in sequence if function(x) ] , [ x for x in sequence if not function(x) ] ]","title":"bifurcate_by"},{"location":"reference/pyhdtoolkit/utils/operations/#chunk_list","text":"def chunk_list ( sequence : Sequence , size : int ) -> Sequence Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Args: sequence (Sequence): a sequence of elements. size (int): the size of the wanted sublists. Returns: A list of lists of length size (except maybe the last element), with elements from lst . Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] View Source @staticmethod def chunk_list ( sequence : Sequence , size : int ) -> Sequence : \" \"\" Chunks a list into smaller lists of a specified size. If the size is bigger than initial list, return the initial list to avoid unnecessary nesting. Use list() and range() to create a list of the desired size. Use map() on the list and fill it with splices of the given list. Finally, return use created list. Args: sequence (Sequence): a sequence of elements. size (int): the size of the wanted sublists. Returns: A list of lists of length `size` (except maybe the last element), with elements from `lst`. Usage: chunk_list(list(range(10)), 3) -> [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9]] \"\" \" if size > len ( sequence ) : return sequence return list ( map ( lambda x : sequence [ x * size : x * size + size ] , list ( range ( math . ceil ( len ( sequence ) / size ))), ) )","title":"chunk_list"},{"location":"reference/pyhdtoolkit/utils/operations/#deep_flatten","text":"def deep_flatten ( sequence : Sequence ) -> list Deep flattens a list, no matter the nesting levels. This is a recursive approach. Args: sequence (Sequence): a sequence of elements. Returns: A list with all elements of lst , but flattened. Usage: deep_flatten([[\"a\", \"b\"], [1, 2], None, [True, False]]) -> [\"a\", \"b\", 1, 2, None True, False] View Source @staticmethod def deep_flatten ( sequence : Sequence ) -> list : \"\"\" Deep flattens a list, no matter the nesting levels. This is a recursive approach. Args: sequence (Sequence): a sequence of elements. Returns: A list with all elements of `lst`, but flattened. Usage: deep_flatten([[\" a \", \" b \"], [1, 2], None, [True, False]]) -> [\" a \", \" b \", 1, 2, None True, False] \"\"\" return ( [ elem for sublist in sequence for elem in ListOperations.deep_flatten(sublist) ] if isinstance ( sequence , list ) else [ sequence ] )","title":"deep_flatten"},{"location":"reference/pyhdtoolkit/utils/operations/#eval_none","text":"def eval_none ( sequence : Sequence , function : Callable = < function ListOperations .< lambda > at 0x7ff23826e830 > ) -> bool Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of sequence that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False View Source @staticmethod def eval_none ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \" \"\" Returns False if the provided function returns True for at least one element in the list, True otherwise. Iterate over the elements of the list to test if every element in the list returns False based on function. Omit the seconds argument, function, to check if all elements are False. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_none([0, 0, 1, 0], lambda x: x >= 2) -> True eval_none([0, 1, 2, 0], lambda x: x >= 2) -> False \"\" \" return not any ( map ( function , sequence ))","title":"eval_none"},{"location":"reference/pyhdtoolkit/utils/operations/#eval_some","text":"def eval_some ( sequence : Sequence , function : Callable = < function ListOperations .< lambda > at 0x7ff23826e950 > ) -> bool Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of sequence that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False View Source @staticmethod def eval_some ( sequence : Sequence , function : Callable = lambda x : not not x ) -> bool : \" \"\" Returns True if the provided function returns True for at least one element in the list, False otherwise. Iterate over the elements of the list to test if every element in the list returns True based on function. Omit the seconds argument, function, to check if all elements are True. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on elements of `sequence` that should return a boolean. Returns: A boolean. See first line of docstring. Usage: eval_some([0, 1, 2, 0], lambda x: x >= 2) -> True eval_some([0, 0, 1, 0], lambda x: x >= 2) -> False \"\" \" return any ( map ( function , sequence ))","title":"eval_some"},{"location":"reference/pyhdtoolkit/utils/operations/#get_indices","text":"def get_indices ( element , sequence : Sequence ) -> List [ int ] Return all array indices at which number is located. Args: element: any reference element to check. sequence (Sequence): a sequence containing objects comparable to elements . A string can be compared to an int in Python, custom objects probably won't be comparable. Returns: A list of all indices at which element is found in sequence . Empty list if element is not present in sequence at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] View Source @staticmethod def get_indices ( element , sequence : Sequence ) -> List [ int ] : \" \"\" Return all array indices at which number is located. Args: element: any reference element to check. sequence (Sequence): a sequence containing objects comparable to `elements`. A string can be compared to an int in Python, custom objects probably won't be comparable. Returns: A list of all indices at which `element` is found in `sequence`. Empty list if `element` is not present in `sequence` at all. Usage: get_indices(0, [0, 1, 3, 5, 7, 3, 9, 0, 0, 5, 3, 2]) -> [0, 7, 8] \"\" \" return [ i for ( y , i ) in zip ( sequence , range ( len ( sequence ))) if element == y ]","title":"get_indices"},{"location":"reference/pyhdtoolkit/utils/operations/#group_by","text":"def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ] Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of sequence that should return a boolean. Returns: A dict with keys \"True\" and \"False\", each having as value a list of all elements of lst that were evaluated to respectively True or False through function . Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} View Source @staticmethod def group_by ( sequence : Sequence , function : Callable ) -> Dict [ str , list ] : \" \"\" Groups the elements of a list based on the given function. Use list() in combination with map() and function to map the values of the list to the keys of an object. Use list comprehension to map each element to the appropriate key. Args: sequence (Sequence): a sequence of elements. function (Callable): a callable on the elements of `sequence` that should return a boolean. Returns: A dict with keys \" True \" and \" False \", each having as value a list of all elements of `lst` that were evaluated to respectively `True` or `False` through `function`. Usage: group_by(list(range(5)), lambda x: x % 2 == 0) -> {True: [0, 2, 4], False: [1, 3]} \"\" \" groups = {} for key in list ( map ( function , sequence )) : groups [ key ] = [ item for item in sequence if function ( item ) == key ] return groups","title":"group_by"},{"location":"reference/pyhdtoolkit/utils/operations/#has_duplicates","text":"def has_duplicates ( sequence : Sequence ) -> bool Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Args: sequence (Sequence): a sequence of elements. Returns: A boolean indicating the presence of duplicates in lst . Usage: has_duplicates([1, 2, 1]) -> True View Source @staticmethod def has_duplicates ( sequence : Sequence ) -> bool : \" \"\" Returns True if there are duplicate values in a fast list, False otherwise. Use set() on the given list to remove duplicates, then compare its length with the length of the list. Args: sequence (Sequence): a sequence of elements. Returns: A boolean indicating the presence of duplicates in `lst`. Usage: has_duplicates([1, 2, 1]) -> True \"\" \" return len ( sequence ) != len ( set ( sequence ))","title":"has_duplicates"},{"location":"reference/pyhdtoolkit/utils/operations/#sample","text":"def sample ( sequence : Sequence ) -> list Returns a random element from an array. Args: sequence (Sequence): a sequence of elements. Returns: A random element from lst in a list (to manage potentially nested lists as input). View Source @staticmethod def sample ( sequence : Sequence ) -> list : \" \"\" Returns a random element from an array. Args: sequence (Sequence): a sequence of elements. Returns: A random element from `lst` in a list (to manage potentially nested lists as input). \"\" \" return sequence [ random . randint ( 0 , len ( sequence ) - 1 ) ]","title":"sample"},{"location":"reference/pyhdtoolkit/utils/operations/#sanitize_list","text":"def sanitize_list ( sequence : Sequence ) -> list Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Args: sequence (Sequence): a sequence of elements. Returns: The sequence without falsy values. Usage: sanitize_list([1, False, \"a\", 2, \"\", None, 6, 0]) -> [1, \"a\", 2, 6] View Source @staticmethod def sanitize_list ( sequence : Sequence ) -> list : \"\"\" Removes falsey values from a list. Use filter() to filter out falsey values (False, None, 0, and \"\"). Args: sequence (Sequence): a sequence of elements. Returns: The sequence without falsy values. Usage: sanitize_list([1, False, \" a \", 2, \"\", None, 6, 0]) -> [1, \" a \", 2, 6] \"\"\" return list ( filter ( bool , sequence ))","title":"sanitize_list"},{"location":"reference/pyhdtoolkit/utils/operations/#shuffle","text":"def shuffle ( sequence : Sequence ) -> Sequence Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm ( https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle ) to reorder the elements. Args: sequence (Sequence): a sequence of elements. Returns: The lst with original elements at a random index. View Source @staticmethod def shuffle ( sequence : Sequence ) -> Sequence : \"\"\" Randomizes the order of the values of an list, returning a new list. Uses an improved version of the Fisher-Yates algorithm (https://en.wikipedia.org/wiki/Fisher%E2%80%93Yates_shuffle) to reorder the elements. Args: sequence (Sequence): a sequence of elements. Returns: The `lst` with original elements at a random index. \"\"\" temp_list = copy . deepcopy ( sequence ) amount_to_shuffle = len ( temp_list ) while amount_to_shuffle > 1 : rand_index = int ( math . floor ( random . random () * amount_to_shuffle )) amount_to_shuffle -= 1 temp_list [ rand_index ] , temp_list [ amount_to_shuffle ] = ( temp_list [ amount_to_shuffle ] , temp_list [ rand_index ] , ) return temp_list","title":"shuffle"},{"location":"reference/pyhdtoolkit/utils/operations/#spread","text":"def spread ( sequence : Sequence ) -> list Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in lst are iterables! Args: sequence (Sequence): a sequence of elements. Returns: The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] View Source @staticmethod def spread ( sequence : Sequence ) -> list : \" \"\" Flattens a list, by spreading its elements into a new list. Loop over elements, use list.extend() if the element is a list, list.append() otherwise. This might look like deep_flatten but is a subset of its functionality, and is used in deep_flatten. This only works if all elements in `lst` are iterables! Args: sequence (Sequence): a sequence of elements. Returns: The sequence flattened, see first docstring sentence. Usage: spread([list(range(5)), list(range(5))]) -> [0, 1, 2, 3, 4, 0, 1, 2, 3, 4] \"\" \" return list ( itertools . chain . from_iterable ( sequence ))","title":"spread"},{"location":"reference/pyhdtoolkit/utils/operations/#symmetric_difference_by","text":"def symmetric_difference_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list Returns the symmetric difference ( https://en.wikipedia.org/wiki/Symmetric_difference ) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of lst_1 and lst_2 . Returns: A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] View Source @staticmethod def symmetric_difference_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \" \"\" Returns the symmetric difference (https://en.wikipedia.org/wiki/Symmetric_difference) of lists, after applying the provided function to each list element of both. Create a set by applying the function to each element in every list, then use list comprehension in combination with function on each one to only keep values not contained in the previously created set of the other. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: symmetric_difference_by([2.1, 1.2], [2.3, 3.4], math.floor) -> [1.2, 3.4] symmetric_difference_by([2.1, 1.2], [0.5, 1.2], lambda x: x >= 2) -> [2.1] \"\" \" _lst_1 , _lst_2 = set ( map ( function , lst_1 )), set ( map ( function , lst_2 )) return [ item for item in lst_1 if function ( item ) not in _lst_2 ] + [ item for item in lst_2 if function ( item ) not in _lst_1 ]","title":"symmetric_difference_by"},{"location":"reference/pyhdtoolkit/utils/operations/#union_by","text":"def union_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union ( https://en.wikipedia.org/wiki/Union_(set_theory )) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of lst_1 and lst_2 . Returns: A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] View Source @staticmethod def union_by ( lst_1 : Sequence , lst_2 : Sequence , function : Callable ) -> list : \" \"\" Returns every element that exists in any of the two lists once, after applying the provided function to each element of both. This is the set theory union (https://en.wikipedia.org/wiki/Union_(set_theory)) of the two lists, but based on the results of applying the function to each list. Python's set() is strange in how is gives output, so this function sorts the final list before returning it, in order to give it predictable behavior. Create a set by applying the function to each element in lst_1, then use list comprehension in combination with function on lst_2 to only keep values not contained in the previously created set, _lst_1. Finally, create a set from the previous result and _lst_1 and transform it into a list. Args: lst_1 (Sequence): a sequence of elements. lst_2 (Sequence): a sequence of elements. function (Callable): a callable on elements of `lst_1` and `lst_2`. Returns: A list, see first docstring sentence reference. Usage: union_by([2.1], [1.2, 2.3], math.floor) -> [1.2, 2.1] \"\" \" _lst_1 = set ( map ( function , lst_1 )) return sorted ( list ( set ( lst_1 + [ item for item in lst_2 if function ( item ) not in _lst_1 ] )))","title":"union_by"},{"location":"reference/pyhdtoolkit/utils/operations/#zipper","text":"def zipper ( * args , fillvalue = None ) -> list Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Args: *args: a number (>= 2) of different iterables. fillvalue: value to use in case of length mismatch. Returns: A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\"a\", \"b\", \"c\"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] View Source @staticmethod def zipper ( * args , fillvalue = None ) -> list : \"\"\" Creates a list of lists of elements, each internal list being a grouping based on the position of elements in the original lists. Essentially, a list containing: a first list with all first elements, then a second list with all second elements, etc. Use max combined with list comprehension to get the length of the longest list in the arguments. Loop for max_length times grouping elements. If lengths of lists vary, use fill_value (defaults to None). Args: *args: a number (>= 2) of different iterables. fillvalue: value to use in case of length mismatch. Returns: A list with the proper level of nesting, and original elements zipped. Usage: zipper([1, 2, 3], [2, 5, 3, 7], [\" a \", \" b \", \" c \"]) -> [[1, 2, 'a'], [2, 5, 'b'], [3, 3, 'c'], [None, 7, None]] \"\"\" max_length = max ( len ( lst ) for lst in args ) return [ [args[k ][ i ] if i < len ( args [ k ] ) else fillvalue for k in range ( len ( args )) ] for i in range ( max_length ) ]","title":"zipper"},{"location":"reference/pyhdtoolkit/utils/operations/#miscellaneousoperations","text":"class MiscellaneousOperations ( / , * args , ** kwargs ) A class to group some misc. operations that don't pertain to classic structures. View Source class MiscellaneousOperations : \"\"\" A class to group some misc. operations that don't pertain to classic structures. \"\"\" @staticmethod def longest_item ( * args ) : \"\"\" Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Args: *args: any number (>= 2) of iterables. Returns: The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) \"\"\" return max ( args , key = len ) @staticmethod def map_values ( obj : dict , function : Callable ) -> dict : \"\"\" Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Args: obj: a dictionary. function (Callable): a callable on values of `obj`. Returns: A new dictionary with the results. Usage: map_values( {\" a \": list(range(5)), \" b \": list(range(10)), \" c \": list(range(15))}, lambda x: len(x) ) -> {\" a \": 5, \" b \": 10, \" c \": 15} \"\"\" ret = {} for key in obj : ret [ key ] = function ( obj [ key ] ) return ret","title":"MiscellaneousOperations"},{"location":"reference/pyhdtoolkit/utils/operations/#static-methods_1","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/utils/operations/#longest_item","text":"def longest_item ( * args ) Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Args: *args: any number (>= 2) of iterables. Returns: The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) View Source @staticmethod def longest_item ( * args ) : \"\"\" Takes any number of iterable objects or objects with a length property and returns the longest one. If multiple objects have the same length, the first one will be returned. Use max() with len as the key to return the item with the greatest length. Args: *args: any number (>= 2) of iterables. Returns: The longest elements of provided iterables. Usage: longest_item(list(range(5)), list(range(100)), list(range(50))) -> list(range(100)) \"\"\" return max ( args , key = len )","title":"longest_item"},{"location":"reference/pyhdtoolkit/utils/operations/#map_values","text":"def map_values ( obj : dict , function : Callable ) -> dict Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Args: obj: a dictionary. function (Callable): a callable on values of obj . Returns: A new dictionary with the results. Usage: map_values( {\"a\": list(range(5)), \"b\": list(range(10)), \"c\": list(range(15))}, lambda x: len(x) ) -> {\"a\": 5, \"b\": 10, \"c\": 15} View Source @staticmethod def map_values ( obj : dict , function : Callable ) -> dict : \"\"\" Creates an new dict with the same keys as the provided dict, and values generated by running the provided function on the provided dict's values. Use dict.keys() to iterate over the object's keys, assigning the values produced by function to each key of a new object. Args: obj: a dictionary. function (Callable): a callable on values of `obj`. Returns: A new dictionary with the results. Usage: map_values( {\" a \": list(range(5)), \" b \": list(range(10)), \" c \": list(range(15))}, lambda x: len(x) ) -> {\" a \": 5, \" b \": 10, \" c \": 15} \"\"\" ret = {} for key in obj : ret [ key ] = function ( obj [ key ] ) return ret","title":"map_values"},{"location":"reference/pyhdtoolkit/utils/operations/#numberoperations","text":"class NumberOperations ( / , * args , ** kwargs ) A class to group some common / useful operations on numbers. View Source class NumberOperations : \" \"\" A class to group some common / useful operations on numbers. \"\" \" @staticmethod def clamp_number ( num : Union [ int , float ] , a_val : Union [ int , float ] , b_val : Union [ int , float ] ) -> Union [ int , float ] : \" \"\" Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Args: num (Union[int, float]): a number (float / int) a_val (Union[int, float]): a number (float / int) b_val (Union[int, float]): a number (float / int) Returns: A number (float / int), being the nearest to `num` in the range [`a_val`, `b_val`]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 \"\" \" return max ( min ( num , max ( a_val , b_val )), min ( a_val , b_val )) @staticmethod def degrees_to_radians ( deg_value : Union [ int , float ] , decompose : bool = False ) -> Union [ Tuple [ float , str , str ] , int , float ] : \" \"\" Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Args: deg_value (Union[int, float]): angle value in degrees. decompose (bool): boolean option to return a more verbose result. Defaults to False. Returns: The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \" pi \", \" rad \") \"\" \" if decompose : return deg_value / 180 , \"pi\" , \"rad\" return ( deg_value * math . pi ) / 180.0 @staticmethod def greatest_common_divisor ( numbers_list : Sequence ) -> Union [ int , float ] : \" \"\" Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in `numbers_list`. Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 \"\" \" return reduce ( math . gcd , numbers_list ) @staticmethod def is_divisible_by ( dividend : Union [ int , float ] , divisor : Union [ int , float ] ) -> bool : \" \"\" Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Args: dividend (Union[int, float]): a number. divisor (Union[int, float]): a number. Returns: A boolean stating if `dividend` can be divided by `divisor`. \"\" \" return dividend % divisor == 0 @staticmethod def least_common_multiple ( * args ) -> int : \" \"\" Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 \"\" \" numbers = list ( ListOperations . spread ( list ( args ))) def _lcm ( number1 , number2 ) : \" \"\" A least common multiple method for two numbers only \"\" \" return int ( number1 * number2 / math . gcd ( number1 , number2 )) return reduce ( lambda x , y : _lcm ( x , y ), numbers ) @staticmethod def radians_to_degrees ( rad_value : Union [ int , float ] ) -> Union [ int , float ] : \" \"\" Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Args: rad_value (Union[int, float]): angle value in degrees. Returns: The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 \"\" \" return ( rad_value * 180.0 ) / math . pi","title":"NumberOperations"},{"location":"reference/pyhdtoolkit/utils/operations/#static-methods_2","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/utils/operations/#clamp_number","text":"def clamp_number ( num : Union [ int , float ], a_val : Union [ int , float ], b_val : Union [ int , float ] ) -> Union [ int , float ] Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Args: num (Union[int, float]): a number (float / int) a_val (Union[int, float]): a number (float / int) b_val (Union[int, float]): a number (float / int) Returns: A number (float / int), being the nearest to num in the range [ a_val , b_val ]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 View Source @staticmethod def clamp_number ( num : Union [ int , float ] , a_val : Union [ int , float ] , b_val : Union [ int , float ] ) -> Union [ int , float ] : \" \"\" Clamps num within the inclusive range specified by the boundary values a and b. If num falls within the range, return num. Otherwise, return the nearest number in the range. Args: num (Union[int, float]): a number (float / int) a_val (Union[int, float]): a number (float / int) b_val (Union[int, float]): a number (float / int) Returns: A number (float / int), being the nearest to `num` in the range [`a_val`, `b_val`]. Usage: clamp_number(17, 4, 5) -> 5 clamp_number(23, 20, 30) -> 23 \"\" \" return max ( min ( num , max ( a_val , b_val )), min ( a_val , b_val ))","title":"clamp_number"},{"location":"reference/pyhdtoolkit/utils/operations/#degrees_to_radians","text":"def degrees_to_radians ( deg_value : Union [ int , float ], decompose : bool = False ) -> Union [ Tuple [ float , str , str ], int , float ] Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Args: deg_value (Union[int, float]): angle value in degrees. decompose (bool): boolean option to return a more verbose result. Defaults to False. Returns: The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \"pi\", \"rad\") View Source @staticmethod def degrees_to_radians ( deg_value : Union [ int, float ] , decompose : bool = False ) -> Union [ Tuple[float, str, str ] , int , float ]: \"\"\" Converts an angle from degrees to radians. Use math.pi and the degree to radian formula to convert the angle from degrees to radians. Args: deg_value (Union[int, float]): angle value in degrees. decompose (bool): boolean option to return a more verbose result. Defaults to False. Returns: The angle value in radians. Usage: degrees_to_radians(160) -> 2.792526803190927 degrees_to_radians(360, decompose=True) -> (2, \" pi \", \" rad \") \"\"\" if decompose : return deg_value / 180 , \"pi\" , \"rad\" return ( deg_value * math . pi ) / 180.0","title":"degrees_to_radians"},{"location":"reference/pyhdtoolkit/utils/operations/#greatest_common_divisor","text":"def greatest_common_divisor ( numbers_list : Sequence ) -> Union [ int , float ] Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in numbers_list . Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 View Source @staticmethod def greatest_common_divisor ( numbers_list : Sequence ) -> Union [ int , float ] : \" \"\" Calculates the greatest common divisor of a list of numbers. Use reduce() and math.gcd over the given list. Args: numbers_list (Sequence): a list of numbers (floats are advised against as this would become a very heavy computation). Returns: The greatest common divisor of all elements in `numbers_list`. Usage: greatest_common_divisor([54, 24]) -> greatest_common_divisor([30, 132, 378, 582, 738]) -> 6 \"\" \" return reduce ( math . gcd , numbers_list )","title":"greatest_common_divisor"},{"location":"reference/pyhdtoolkit/utils/operations/#is_divisible_by","text":"def is_divisible_by ( dividend : Union [ int , float ], divisor : Union [ int , float ] ) -> bool Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Args: dividend (Union[int, float]): a number. divisor (Union[int, float]): a number. Returns: A boolean stating if dividend can be divided by divisor . View Source @staticmethod def is_divisible_by ( dividend : Union [ int , float ] , divisor : Union [ int , float ] ) -> bool : \" \"\" Checks if the first numeric argument is divisible by the second one. Use the modulo operator (%) to check if the remainder is equal to 0. Args: dividend (Union[int, float]): a number. divisor (Union[int, float]): a number. Returns: A boolean stating if `dividend` can be divided by `divisor`. \"\" \" return dividend % divisor == 0","title":"is_divisible_by"},{"location":"reference/pyhdtoolkit/utils/operations/#least_common_multiple","text":"def least_common_multiple ( * args ) -> int Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 View Source @staticmethod def least_common_multiple ( * args ) -> int : \"\"\" Returns the least common multiple of two or more numbers. Define a function, spread, that uses either list.extend() or list.append() on each element in a list to flatten it. Use math.gcd() and lcm(x,y) = x * y / gcd(x,y) to determine the least common multiple. Args: *args: any number (>= 2) of numbers (floats are advised against as this would become a very heavy computation). Returns: The least common multiple of all provided numbers. Usage: least_common_multiple(4, 5) -> 20 least_common_multiple(2, 5, 17, 632) -> 53720 \"\"\" numbers = list ( ListOperations . spread ( list ( args ))) def _lcm ( number1 , number2 ) : \"\"\"A least common multiple method for two numbers only\"\"\" return int ( number1 * number2 / math . gcd ( number1 , number2 )) return reduce ( lambda x , y : _lcm ( x , y ), numbers )","title":"least_common_multiple"},{"location":"reference/pyhdtoolkit/utils/operations/#radians_to_degrees","text":"def radians_to_degrees ( rad_value : Union [ int , float ] ) -> Union [ int , float ] Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Args: rad_value (Union[int, float]): angle value in degrees. Returns: The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 View Source @staticmethod def radians_to_degrees ( rad_value : Union [ int, float ] ) -> Union [ int, float ] : \"\"\" Converts an angle from radians to degrees. Use math.pi and the radian to degree formula to convert the angle from radians to degrees. Args: rad_value (Union[int, float]): angle value in degrees. Returns: The angle value in degrees. Usage: radians_to_degrees(2* math.pi) -> 360 radians_to_degrees(2.710) -> 155.2715624804531 \"\"\" return ( rad_value * 180.0 ) / math . pi","title":"radians_to_degrees"},{"location":"reference/pyhdtoolkit/utils/operations/#stringoperations","text":"class StringOperations ( / , * args , ** kwargs ) A class to group some common / useful operations on strings. View Source class StringOperations : \"\"\" A class to group some common / useful operations on strings. \"\"\" @staticmethod def camel_case ( text : str ) -> str : \"\"\" Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Args: text (str): a string. Returns: The same string best adapted to camel_case. Usage: camel_case(\" a_snake_case_name \") -> \" aSnakeCaseName \" camel_case(\" A Title Case Name \") -> \" aTitleCaseName \" \"\"\" text = re . sub ( r \"(\\s|_|-)+\" , \" \" , text ). title (). replace ( \" \" , \"\" ) return text [ 0 ]. lower () + text [ 1 : ] @staticmethod def capitalize ( text : str , lower_rest: bool = False ) -> str : \"\"\" Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Args: text (str): a string. lower_rest (bool): boolean option to lower all elements starting from the second. Returns: The `string`, capitalized. Usage: capitalize(\" astringtocapitalize \") -> \" Astringtocapitalize \" capitalize(\" astRIngTocApItalizE \", lower_rest=True) -> \" Astringtocapitalize \" \"\"\" return text [ : 1 ]. upper () + ( text [ 1 : ]. lower () if lower_rest else text [ 1 : ]) @staticmethod def is_anagram ( str_1: str , str_2: str ) -> bool : \"\"\" Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Args: str_1 (str): a string. str_2 (str): a string. Returns: A boolean stating whether `str_1` is an anagram of `str_2` or not. Usage: is_anagram(\" Tom Marvolo Riddle \", \" I am Lord Voldemort \") -> True is_anagram(\" A first string \", \" Definitely not an anagram \") -> False \"\"\" _ str1 , _ str2 = ( str_1 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), str_2 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), ) return sorted ( _ str1 . lower ()) == sorted ( _ str2 . lower ()) @staticmethod def is_palindrome ( text : str ) -> bool : \"\"\" Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Args: text (str): a string. Returns: A boolean stating whether `string` is a palindrome or not. Usage: is_palindrome(\" racecar \") -> True is_palindrome(\" definitelynot \") -> False \"\"\" s_reverse = re . sub ( r \" [ \\ W_ ] \", \"\", text.lower()) return s_reverse == s_reverse[::-1] @staticmethod def kebab_case(text: str) -> str: \"\"\" Converts a string to kebab - case . Break the string into words and combine them adding - as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to kebab_case . Usage : kebab_case ( \"camel Case\" ) -> \"camel-case\" kebab_case ( \"snake_case\" ) -> \"snake-case\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" - \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \", lambda mo: mo.group(0).lower(), text, ), ) @staticmethod def snake_case(text: str) -> str: \"\"\" Converts a string to snake_case . Break the string into words and combine them adding _ as a separator , using a regexp . Args : text ( str ) : a string . Returns : The same string best adapted to snake_case . Usage : snake_case ( \"A bunch of words\" ) -> \"a_bunch_of_words\" snake_case ( \"camelCase\" ) -> \"camelcase\" \"\"\" return re.sub( r\" ( \\s | _ | - ) + \", \" _ \", re.sub( r\" [ A - Z ]{ 2 ,}( ?= [ A - Z ][ a - z ] + [ 0 - 9 ] * | \\b )|[ A - Z ] ? [ a - z ] + [ 0 - 9 ] * |[ A - Z ]|[ 0 - 9 ] + \" , lambda mo : mo . group ( 0 ). lower (), text , ), )","title":"StringOperations"},{"location":"reference/pyhdtoolkit/utils/operations/#static-methods_3","text":"","title":"Static methods"},{"location":"reference/pyhdtoolkit/utils/operations/#camel_case","text":"def camel_case ( text : str ) -> str Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Args: text (str): a string. Returns: The same string best adapted to camel_case. Usage: camel_case(\"a_snake_case_name\") -> \"aSnakeCaseName\" camel_case(\"A Title Case Name\") -> \"aTitleCaseName\" View Source @staticmethod def camel_case ( text : str ) -> str : \"\"\" Converts a string to camelCase. Break the string into words and combine them capitalizing the first letter of each word, using a regexp, title() and lower. Args: text (str): a string. Returns: The same string best adapted to camel_case. Usage: camel_case(\" a_snake_case_name \") -> \" aSnakeCaseName \" camel_case(\" A Title Case Name \") -> \" aTitleCaseName \" \"\"\" text = re . sub ( r \"(\\s|_|-)+\" , \" \" , text ). title (). replace ( \" \" , \"\" ) return text [ 0 ] . lower () + text [ 1: ]","title":"camel_case"},{"location":"reference/pyhdtoolkit/utils/operations/#capitalize","text":"def capitalize ( text : str , lower_rest : bool = False ) -> str Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Args: text (str): a string. lower_rest (bool): boolean option to lower all elements starting from the second. Returns: The string , capitalized. Usage: capitalize(\"astringtocapitalize\") -> \"Astringtocapitalize\" capitalize(\"astRIngTocApItalizE\", lower_rest=True) -> \"Astringtocapitalize\" View Source @staticmethod def capitalize ( text : str , lower_rest : bool = False ) -> str : \" \"\" Capitalizes the first letter of a string, eventually lowers the rest of it. Capitalize the first letter of the string and then add it with rest of the string. Omit the lower_rest parameter to keep the rest of the string intact, or set it to True to convert to lowercase. Args: text (str): a string. lower_rest (bool): boolean option to lower all elements starting from the second. Returns: The `string`, capitalized. Usage: capitalize(\" astringtocapitalize \") -> \" Astringtocapitalize \" capitalize(\" astRIngTocApItalizE \", lower_rest=True) -> \" Astringtocapitalize \" \"\" \" return text [ : 1 ] . upper () + ( text [ 1 : ] . lower () if lower_rest else text [ 1 : ] )","title":"capitalize"},{"location":"reference/pyhdtoolkit/utils/operations/#is_anagram","text":"def is_anagram ( str_1 : str , str_2 : str ) -> bool Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Args: str_1 (str): a string. str_2 (str): a string. Returns: A boolean stating whether str_1 is an anagram of str_2 or not. Usage: is_anagram(\"Tom Marvolo Riddle\", \"I am Lord Voldemort\") -> True is_anagram(\"A first string\", \"Definitely not an anagram\") -> False View Source @staticmethod def is_anagram ( str_1 : str , str_2 : str ) -> bool : \" \"\" Checks if a string is an anagram of another string (case-insensitive, ignores spaces, punctuation and special characters). Use str.replace() to remove spaces from both strings. Compare the lengths of the two strings, return False if they are not equal. Use sorted() on both strings and compare the results. Args: str_1 (str): a string. str_2 (str): a string. Returns: A boolean stating whether `str_1` is an anagram of `str_2` or not. Usage: is_anagram(\" Tom Marvolo Riddle \", \" I am Lord Voldemort \") -> True is_anagram(\" A first string \", \" Definitely not an anagram \") -> False \"\" \" _str1 , _str2 = ( str_1 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), str_2 . replace ( \" \" , \"\" ). replace ( \"'\" , \"\" ), ) return sorted ( _str1 . lower ()) == sorted ( _str2 . lower ())","title":"is_anagram"},{"location":"reference/pyhdtoolkit/utils/operations/#is_palindrome","text":"def is_palindrome ( text : str ) -> bool Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Args: text (str): a string. Returns: A boolean stating whether string is a palindrome or not. Usage: is_palindrome(\"racecar\") -> True is_palindrome(\"definitelynot\") -> False View Source @staticmethod def is_palindrome ( text : str ) -> bool : \"\"\" Returns True if the given string is a palindrome, False otherwise. Use str.lower() and re.sub() to convert to lowercase and remove non-alphanumeric characters from the given string. Then compare the new string with its reverse. Args: text (str): a string. Returns: A boolean stating whether `string` is a palindrome or not. Usage: is_palindrome(\" racecar \") -> True is_palindrome(\" definitelynot \") -> False \"\"\" s_reverse = re . sub ( r \" [ \\ W_ ] \", \" \" , text . lower ()) return s_reverse == s_reverse [ ::- 1 ]","title":"is_palindrome"},{"location":"reference/pyhdtoolkit/utils/operations/#kebab_case","text":"def kebab_case ( text : str ) -> str Converts a string to kebab-case. Break the string into words and combine them adding - as a separator, using a regexp. Args: text (str): a string. Returns: The same string best adapted to kebab_case. Usage: kebab_case(\"camel Case\") -> \"camel-case\" kebab_case(\"snake_case\") -> \"snake-case\" View Source @staticmethod def kebab_case ( text : str ) -> str : \"\"\" Converts a string to kebab-case. Break the string into words and combine them adding - as a separator, using a regexp. Args: text (str): a string. Returns: The same string best adapted to kebab_case. Usage: kebab_case(\" camel Case \") -> \" camel - case \" kebab_case(\" snake_case \") -> \" snake - case \" \"\"\" return re . sub ( r \"(\\s|_|-)+\" , \"-\" , re . sub ( r \"[A-Z]{2,}(?=[A-Z][a-z]+[0-9]*|\\b)|[A-Z]?[a-z]+[0-9]*|[A-Z]|[0-9]+\" , lambda mo : mo . group ( 0 ). lower (), text , ), )","title":"kebab_case"},{"location":"reference/pyhdtoolkit/utils/operations/#snake_case","text":"def snake_case ( text : str ) -> str Converts a string to snake_case. Break the string into words and combine them adding _ as a separator, using a regexp. Args: text (str): a string. Returns: The same string best adapted to snake_case. Usage: snake_case(\"A bunch of words\") -> \"a_bunch_of_words\" snake_case(\"camelCase\") -> \"camelcase\" View Source @staticmethod def snake_case ( text : str ) -> str : \"\"\" Converts a string to snake_case. Break the string into words and combine them adding _ as a separator, using a regexp. Args: text (str): a string. Returns: The same string best adapted to snake_case. Usage: snake_case(\" A bunch of words \") -> \" a_bunch_of_words \" snake_case(\" camelCase \") -> \" camelcase \" \"\"\" return re . sub ( r \"(\\s|_|-)+\" , \"_\" , re . sub ( r \"[A-Z]{2,}(?=[A-Z][a-z]+[0-9]*|\\b)|[A-Z]?[a-z]+[0-9]*|[A-Z]|[0-9]+\" , lambda mo : mo . group ( 0 ). lower (), text , ), )","title":"snake_case"},{"location":"reference/pyhdtoolkit/utils/printutil/","text":"Module pyhdtoolkit.utils.printutil Module utils.printutil Created on 2019.12.11 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A class utility class to allow me printing text in color, bold, etc. View Source \"\"\" Module utils.printutil ---------------------- Created on 2019.12.11 :author: Felix Soubelet (felix.soubelet@cern.ch) A class utility class to allow me printing text in color, bold, etc. \"\"\" END = \"\\033[0m\" class Background : \"\"\" ANSI color escape sequences for the background of a terminal output. \"\"\" black = \"\\033[40m\" blue = \"\\033[44m\" cyan = \"\\033[46m\" green = \"\\033[42m\" grey = \"\\033[47m\" magenta = \"\\033[45m\" red = \"\\033[41m\" yellow = \"\\033[43m\" class Foreground : \"\"\" ANSI color escape sequences for the foreground of a terminal output. \"\"\" blue = \"\\033[94m\" cyan = \"\\033[96m\" dark_blue = \"\\033[34m\" dark_cyan = \"\\033[36m\" dark_green = \"\\033[32m\" dark_grey = \"\\033[90m\" dark_red = \"\\033[31m\" dark_yellow = \"\\033[33m\" green = \"\\033[92m\" grey = \"\\033[37m\" magenta = \"\\033[35m\" pink = \"\\033[95m\" red = \"\\033[91m\" yellow = \"\\033[93m\" white = \"\\033[30m\" class Styles : \"\"\" ANSI style escape sequences for a terminal output. \"\"\" all_off = \"\\033[0m\" bold = \"\\033[1m\" concealed = \"\\033[7m\" disable = \"\\033[02m\" reverse = \"\\033[7m\" strikethrough = \"\\033[09m\" underscore = \"\\033[4m\" Variables END Classes Background class Background ( / , * args , ** kwargs ) ANSI color escape sequences for the background of a terminal output. View Source class Background: \"\"\" ANSI color escape sequences for the background of a terminal output. \"\"\" black = \"\\033[40m\" blue = \"\\033[44m\" cyan = \"\\033[46m\" green = \"\\033[42m\" grey = \"\\033[47m\" magenta = \"\\033[45m\" red = \"\\033[41m\" yellow = \"\\033[43m\" Class variables black blue cyan green grey magenta red yellow Foreground class Foreground ( / , * args , ** kwargs ) ANSI color escape sequences for the foreground of a terminal output. View Source class Foreground: \"\"\" ANSI color escape sequences for the foreground of a terminal output . \"\"\" blue = \" \\033 [94m\" cyan = \" \\033 [96m\" dark_blue = \" \\033 [34m\" dark_cyan = \" \\033 [36m\" dark_green = \" \\033 [32m\" dark_grey = \" \\033 [90m\" dark_red = \" \\033 [31m\" dark_yellow = \" \\033 [33m\" green = \" \\033 [92m\" grey = \" \\033 [37m\" magenta = \" \\033 [35m\" pink = \" \\033 [95m\" red = \" \\033 [91m\" yellow = \" \\033 [93m\" white = \" \\033 [30m\" Class variables blue cyan dark_blue dark_cyan dark_green dark_grey dark_red dark_yellow green grey magenta pink red white yellow Styles class Styles ( / , * args , ** kwargs ) ANSI style escape sequences for a terminal output. View Source class Styles: \"\"\" ANSI style escape sequences for a terminal output. \"\"\" all_off = \"\\033[0m\" bold = \"\\033[1m\" concealed = \"\\033[7m\" disable = \"\\033[02m\" reverse = \"\\033[7m\" strikethrough = \"\\033[09m\" underscore = \"\\033[4m\" Class variables all_off bold concealed disable reverse strikethrough underscore","title":"Printutil"},{"location":"reference/pyhdtoolkit/utils/printutil/#module-pyhdtoolkitutilsprintutil","text":"","title":"Module pyhdtoolkit.utils.printutil"},{"location":"reference/pyhdtoolkit/utils/printutil/#module-utilsprintutil","text":"Created on 2019.12.11 :author: Felix Soubelet ( felix.soubelet@cern.ch ) A class utility class to allow me printing text in color, bold, etc. View Source \"\"\" Module utils.printutil ---------------------- Created on 2019.12.11 :author: Felix Soubelet (felix.soubelet@cern.ch) A class utility class to allow me printing text in color, bold, etc. \"\"\" END = \"\\033[0m\" class Background : \"\"\" ANSI color escape sequences for the background of a terminal output. \"\"\" black = \"\\033[40m\" blue = \"\\033[44m\" cyan = \"\\033[46m\" green = \"\\033[42m\" grey = \"\\033[47m\" magenta = \"\\033[45m\" red = \"\\033[41m\" yellow = \"\\033[43m\" class Foreground : \"\"\" ANSI color escape sequences for the foreground of a terminal output. \"\"\" blue = \"\\033[94m\" cyan = \"\\033[96m\" dark_blue = \"\\033[34m\" dark_cyan = \"\\033[36m\" dark_green = \"\\033[32m\" dark_grey = \"\\033[90m\" dark_red = \"\\033[31m\" dark_yellow = \"\\033[33m\" green = \"\\033[92m\" grey = \"\\033[37m\" magenta = \"\\033[35m\" pink = \"\\033[95m\" red = \"\\033[91m\" yellow = \"\\033[93m\" white = \"\\033[30m\" class Styles : \"\"\" ANSI style escape sequences for a terminal output. \"\"\" all_off = \"\\033[0m\" bold = \"\\033[1m\" concealed = \"\\033[7m\" disable = \"\\033[02m\" reverse = \"\\033[7m\" strikethrough = \"\\033[09m\" underscore = \"\\033[4m\"","title":"Module utils.printutil"},{"location":"reference/pyhdtoolkit/utils/printutil/#variables","text":"END","title":"Variables"},{"location":"reference/pyhdtoolkit/utils/printutil/#classes","text":"","title":"Classes"},{"location":"reference/pyhdtoolkit/utils/printutil/#background","text":"class Background ( / , * args , ** kwargs ) ANSI color escape sequences for the background of a terminal output. View Source class Background: \"\"\" ANSI color escape sequences for the background of a terminal output. \"\"\" black = \"\\033[40m\" blue = \"\\033[44m\" cyan = \"\\033[46m\" green = \"\\033[42m\" grey = \"\\033[47m\" magenta = \"\\033[45m\" red = \"\\033[41m\" yellow = \"\\033[43m\"","title":"Background"},{"location":"reference/pyhdtoolkit/utils/printutil/#class-variables","text":"black blue cyan green grey magenta red yellow","title":"Class variables"},{"location":"reference/pyhdtoolkit/utils/printutil/#foreground","text":"class Foreground ( / , * args , ** kwargs ) ANSI color escape sequences for the foreground of a terminal output. View Source class Foreground: \"\"\" ANSI color escape sequences for the foreground of a terminal output . \"\"\" blue = \" \\033 [94m\" cyan = \" \\033 [96m\" dark_blue = \" \\033 [34m\" dark_cyan = \" \\033 [36m\" dark_green = \" \\033 [32m\" dark_grey = \" \\033 [90m\" dark_red = \" \\033 [31m\" dark_yellow = \" \\033 [33m\" green = \" \\033 [92m\" grey = \" \\033 [37m\" magenta = \" \\033 [35m\" pink = \" \\033 [95m\" red = \" \\033 [91m\" yellow = \" \\033 [93m\" white = \" \\033 [30m\"","title":"Foreground"},{"location":"reference/pyhdtoolkit/utils/printutil/#class-variables_1","text":"blue cyan dark_blue dark_cyan dark_green dark_grey dark_red dark_yellow green grey magenta pink red white yellow","title":"Class variables"},{"location":"reference/pyhdtoolkit/utils/printutil/#styles","text":"class Styles ( / , * args , ** kwargs ) ANSI style escape sequences for a terminal output. View Source class Styles: \"\"\" ANSI style escape sequences for a terminal output. \"\"\" all_off = \"\\033[0m\" bold = \"\\033[1m\" concealed = \"\\033[7m\" disable = \"\\033[02m\" reverse = \"\\033[7m\" strikethrough = \"\\033[09m\" underscore = \"\\033[4m\"","title":"Styles"},{"location":"reference/pyhdtoolkit/utils/printutil/#class-variables_2","text":"all_off bold concealed disable reverse strikethrough underscore","title":"Class variables"}]}