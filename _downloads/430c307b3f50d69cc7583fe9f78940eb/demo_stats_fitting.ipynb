{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Distributions Fitting\n\nThis example shows how to use the `~.maths.stats_fitting.best_fit_distribution` function\nto determine which statistical distribution best first a given data set, and plot the\nresults together.\n\nIn this example, we'll go further and see how by using the probability density function of\na fit to a chi-square_ distrubtion, one can get knowledge of the underlying normal distributions\nit originated from.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport scipy\nimport scipy.stats as st\n\nfrom pyhdtoolkit.maths import stats_fitting as fitting\nfrom pyhdtoolkit.plotting.helpers import AnnotationsPlotter\nfrom pyhdtoolkit.utils import defaults\n\ndefaults.config_logger(level=\"warning\")\nplt.rcParams.update(defaults._SPHINX_GALLERY_PARAMS)  # for readability of this tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We will for this example create a chi-square_ distribution with known parameters. As the\nchisquare distribution is based on deviations of independent, normal distribution variables,\nwe will create a normal distribution with K degrees of freedom, and compute the associated\n\n\\begin{align}\\sigma_{j}^{2} = \\frac{1}{K} \\cdot \\sum_{i=1}^{K} \\big(X_{i} - \\bar{X} \\big)^{2}\\end{align}\n\nBy repeating so a few thousand times, we get a chi-square distribution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def chi_square_dist(num: int, meas_used: int) -> np.ndarray:\n    \"\"\"\n    Generates a chi-square distribution of *num* elements, each computed\n    from a normal distribution of *meas_used* elements.\n\n    Args:\n        num (int): number of elements for the generated distribution.\n        meas_used (int): number of values for each.\n\n    Returns:\n        The resulting distribution as a `numpy.ndarray`.\n    \"\"\"\n    result = []\n    for _ in range(num):\n        norm_dist = np.random.default_rng().normal(loc=0, scale=1, size=meas_used)\n        result.append(np.sum(np.square([i - np.mean(norm_dist) for i in norm_dist])))\n    return np.array(result)\n\n\ndef chi_dist(num: int, meas_used: int) -> np.ndarray:\n    \"\"\"\n    Generates a chi distribution of *num* elements, each computed from a\n    normal distribution of *meas_used* elements.\n\n    Args:\n        num (int): number of elements for the generated distribution.\n        meas_used (int): number of values for each.\n\n    Returns:\n        The resulting distribution as a `numpy.ndarray`.\n    \"\"\"\n    result = []\n    for _ in range(num):\n        norm_dist = np.random.default_rng().normal(loc=0, scale=1, size=meas_used)\n        result.append(np.sqrt(np.sum(np.square([i - np.mean(norm_dist) for i in norm_dist]))))\n    return np.array(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, from this chi-squared distribution of values, how do we find back the standard deviation\n$\\sigma_{0}$ of the normal (gaussian) distributions it is computed from?\nLet's first start by fitting a statistical chisquared model to the data!\n\nFrom there, we can plot the Probability Density Function of our best candidate and see how well\nit fits our data. It should fit very well, and then a good guess of this :math`\\sigma_{0}`` is\nbased on the index at which to find the peak of the best candidate's PDF.\n\nSince this peak happens at $K - 2$, then we have:\n\n\\begin{align}\\sigma_{0} = \\sqrt{\\frac{index\\_at\\_peak}{(K - 2)}}\\end{align}\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>In the case where we use $N$ measurements, we have $K = N - 1$` degrees of freedom.\n    This means that $N$ measurements lead to a Chisquare(N-1) distribution.\n    As a consequence, it is important to replace $K$` by $N - 1$` in all the equations above,\n    and the normal distribution's stdev estimator becomes:\n\n    .. math::\n\n       \\sigma_{0} = \\sqrt{\\frac{index\\_at\\_peak}{(N - 3)}}</p></div>\n\nEnough talk, see below an example with $N = 5$ measurements.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "measurements_used = 5\ndegrees_of_freedom = measurements_used - 1\n\n# Chi-square distribution\nsigs = chi_square_dist(50_000, meas_used=measurements_used)\ndata = pd.Series(sigs)\n\n# Chi distribution\nchis = chi_dist(num=50_000, meas_used=measurements_used)\nchi_data = pd.Series(chis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the sake of not over-crowding our plot, let's reduce the amount of statistical\ndistributions we will try to fit to the data:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "DISTRIBUTIONS = {\n    st.chi: \"Chi\",\n    st.chi2: \"ChiSquared\",\n    st.norm: \"Normal\",\n}\nfitting.set_distributions_dict(DISTRIBUTIONS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we plot our data, and try to fit these three distributions to it, by calling\nthe `~.maths.stats_fitting.best_fit_distribution` function:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ax = data.plot(\n    kind=\"hist\",\n    bins=100,\n    density=True,\n    alpha=0.6,\n    label=\"Generated Distribution\",\n    figsize=(20, 12),\n)\ndata_y_lim = ax.get_ylim()\n\n# Find best fit candidate\nbest_fit_func, best_fit_params = fitting.best_fit_distribution(data, 200, ax)\nax.set_ylim(data_y_lim)\n\nax.set_title(f\"All Fitted Distributions\")\nax.set_ylabel(\"Normed Hist Counts\")\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That's nice. We can already see that only the chi-squared distrubtion seems to\nbe a good fit. Let's do a new plot with only the best fit's probability density\nfunction (which we get with `~.maths.stats_fitting.make_pdf` function) added onto\nthe data, and determine its mode:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Let's get the PDF of the best fit\npdf: pd.Series = fitting.make_pdf(best_fit_func, best_fit_params)\n\nplt.figure(figsize=(20, 12))\n\nax = pdf.plot(lw=2, label=f\"{fitting.DISTRIBUTIONS[best_fit_func]} fit PDF\", legend=True)\ndata.plot(\n    kind=\"hist\",\n    bins=100,\n    density=True,\n    alpha=0.5,\n    label=f\"Generated ({measurements_used - 1} degrees of freedom)\",\n    legend=True,\n    ax=ax,\n)\nparam_names = (\n    (best_fit_func.shapes + \", loc, scale\").split(\", \")\n    if best_fit_func.shapes\n    else [\"loc\", \"scale\"]\n)\nparam_str = \", \".join([f\"{k}={v:0.2f}\" for k, v in zip(param_names, best_fit_params)])\ndist_str = f\"{fitting.DISTRIBUTIONS[best_fit_func]}({param_str})\"\n\n# Let's add to the plot some info on the fit's peak\nAnnotationsPlotter.set_arrow_label(\n    axis=ax,\n    label=f\"Measured Mode: {pdf.idxmax():.3f}\",\n    arrow_position=(pdf.idxmax(), pdf.max()),\n    label_position=(1.1 * np.mean(ax.get_xlim()), 0.75 * max(pdf.to_numpy())),\n    color=\"indianred\",\n    arrow_arc_rad=0.3,\n)\nplt.vlines(pdf.idxmax(), ymin=0, ymax=max(pdf.to_numpy()), linestyles=\"--\", color=\"indianred\")\nax.set_title(f\"Best fit to distribution:\\n\" + dist_str)\nax.set_ylabel(\"Normed Hist Counts\")\nax.set_xlabel(\"x\")\nax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We expect a mode of 2, we can check that this is indeed the case. Here we leave\na nice tolerance to ensure the documentation build does not fail.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "assert np.isclose(pdf.idxmax(), 2, rtol=2e-2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With this knowledge, we can now determine the standard deviation of the normal\ndistribution we've used to create this chi-square distribution. Remember that\nin the `chi_square_dist` function we have called `np.random.default_rng().normal`\nwith ``loc=0`` and ``scale=1``, so we expect here to find a standard deviation of\none.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "factor = (\n    np.sqrt(2)\n    * scipy.special.gamma((degrees_of_freedom + 1) / 2)\n    / scipy.special.gamma(degrees_of_freedom / 2)\n)\n\ndetermined_stdev = chi_data.mean() / factor\nassert np.isclose(determined_stdev, 1, rtol=1e-2)  # nice tolerance here too"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Which we do :)\n\nBonus: here's a plot of trying to fit all basic distributions to the chi\ndistribution generated above.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Let's reset the distributions dict\nDISTRIBUTIONS = {\n    st.chi: \"Chi\",\n    st.chi2: \"Chi-Square\",\n    st.expon: \"Exponential\",\n    st.laplace: \"Laplace\",\n    st.lognorm: \"LogNorm\",\n    st.norm: \"Normal\",\n}\nfitting.set_distributions_dict(DISTRIBUTIONS)\n\nac = chi_data.plot(\n    kind=\"hist\",\n    bins=100,\n    density=True,\n    alpha=0.6,\n    label=\"Generated Chi Distribution\",\n    figsize=(20, 12),\n)\ndataYLim = ac.get_ylim()\n\n# Find best fit candidate\nbest_fit_func, best_fit_params = fitting.best_fit_distribution(chi_data, 200, ac)\nac.set_ylim(dataYLim)\nac.set_title(f\"All Fitted Distributions\")\nac.set_ylabel(\"Normed Hist Counts\")\nplt.legend()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}